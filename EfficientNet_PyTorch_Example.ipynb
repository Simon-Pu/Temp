{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EfficientNet PyTorch Example",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Simon-Pu/Temp/blob/master/EfficientNet_PyTorch_Example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XK31YiAliweW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbKu9g9pi390",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pynvml\n",
        "\n",
        "pynvml.nvmlInit()\n",
        "handle = pynvml.nvmlDeviceGetHandleByIndex(0)\n",
        "device_name = pynvml.nvmlDeviceGetName(handle)\n",
        "\n",
        "if device_name != b'Tesla T4' and device_name != b'Tesla P100-PCIE-16GB':\n",
        "  raise Exception(\"\"\"\n",
        "    Unfortunately this instance does not have a T4 GPU.   \n",
        "    Please make sure you've configured Colab to request a GPU instance type.\n",
        "    Sometimes Colab allocates a Tesla K80 instead of a T4. Resetting the instance.\n",
        "    If you get a K80 GPU, try Runtime -> Reset all runtimes...\n",
        "  \"\"\")\n",
        "else:\n",
        "  print('Woo! You got the right kind of GPU!:::', device_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQPjQivwywhV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download image and class labels\n",
        "!wget https://raw.githubusercontent.com/lukemelas/EfficientNet-PyTorch/master/examples/simple/img.jpg\n",
        "!wget https://raw.githubusercontent.com/lukemelas/EfficientNet-PyTorch/master/examples/simple/labels_map.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ma1EIr7UyCOE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get EfficientNet PyTorch\n",
        "#!pip install efficientnet_pytorch\n",
        "# Get PyTorch Image Models, etc\n",
        "# https://github.com/rwightman/pytorch-image-models\n",
        "!pip install timm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpcopDTyyFzR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.backends.cudnn as cudnn\n",
        "from torch.autograd import Variable\n",
        "#from torchvision import transforms\n",
        "\n",
        "#from efficientnet_pytorch import EfficientNet\n",
        "import timm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5D5FWdfyFma",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed = 0\n",
        "gpu = 0\n",
        "\n",
        "np.random.seed(seed)\n",
        "torch.cuda.set_device(gpu)\n",
        "cudnn.benchmark = True\n",
        "torch.manual_seed(seed)\n",
        "cudnn.enabled = True\n",
        "torch.cuda.manual_seed(seed)\n",
        "\n",
        "model_name = 'efficientnet-b0'\n",
        "#image_size = EfficientNet.get_image_size(model_name) # 224\n",
        "image_size = 224"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sb13T_M0yFb1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img = Image.open('img.jpg')\n",
        "#img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzgmGb73yFNj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preprocess image\n",
        "tfms = transforms.Compose([transforms.Resize(image_size), transforms.CenterCrop(image_size), \n",
        "                           transforms.ToTensor(),\n",
        "                           transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),])\n",
        "img = tfms(img).unsqueeze(0)\n",
        "img = Variable(img)\n",
        "img = img.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OeK5JBQ8yE-Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load class names\n",
        "labels_map = json.load(open('labels_map.txt'))\n",
        "labels_map = [labels_map[str(i)] for i in range(1000)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfDtoYnlzP9m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Classify with EfficientNet\n",
        "#model = EfficientNet.from_pretrained(model_name)\n",
        "#model = model.cuda()\n",
        "#model.cuda()\n",
        "#model.eval()\n",
        "#with torch.no_grad():\n",
        "#    logits = model(img)\n",
        "#preds = torch.topk(logits, k=5).indices.squeeze(0).tolist()\n",
        "\n",
        "#print('-----')\n",
        "#for idx in preds:\n",
        "#    label = labels_map[idx]\n",
        "#    prob = torch.softmax(logits, dim=1)[0, idx].item()\n",
        "#    print('{:<75} ({:.2f}%)'.format(label, prob*100))\n",
        "\n",
        "# How to profiling layer-by-layer in Pytroch?\n",
        "#with torch.autograd.profiler.profile(use_cuda=True) as prof:\n",
        "#    model(img)\n",
        "#print(prof) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnR4zfWNTfxo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Classify with EfficientNet\n",
        "# https://github.com/rwightman/pytorch-image-models\n",
        "model = timm.create_model('efficientnet_b0', pretrained=True)\n",
        "#model = EfficientNet.from_pretrained(model_name)\n",
        "model = model.cuda()\n",
        "#model.cuda()\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    logits = model(img)\n",
        "preds = torch.topk(logits, k=5).indices.squeeze(0).tolist()\n",
        "\n",
        "print('-----')\n",
        "for idx in preds:\n",
        "    label = labels_map[idx]\n",
        "    prob = torch.softmax(logits, dim=1)[0, idx].item()\n",
        "    print('{:<75} ({:.2f}%)'.format(label, prob*100))\n",
        "\n",
        "# How to profiling layer-by-layer in Pytroch?\n",
        "with torch.autograd.profiler.profile(use_cuda=True) as prof:\n",
        "    model(img)\n",
        "print(prof) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJaDHFQjJFDV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://s3.amazonaws.com/fast-ai-imageclas/imagewoof.tgz\n",
        "!tar zxvf imagewoof.tgz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_Ul4BApL3nd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!ls ./imagewoof/val/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCyiTp9xV9Sz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import argparse\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import time\n",
        "import warnings\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.distributed as dist\n",
        "import torch.optim\n",
        "import torch.multiprocessing as mp\n",
        "import torch.utils.data\n",
        "import torch.utils.data.distributed\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.models as models\n",
        "from torch.nn import Linear\n",
        "\n",
        "# define loss function (criterion) and optimizer\n",
        "lr = 0.1\n",
        "momentum = 0.9\n",
        "weight_decay = 1e-4\n",
        "print_freq = 50\n",
        "start_epoch = 0\n",
        "epochs = 10\n",
        "gpu = 0\n",
        "\n",
        "model = timm.create_model('efficientnet_b0', pretrained=True)\n",
        "#print(model)\n",
        "#classifier): Linear(in_features=1280, out_features=1000, bias=True)\n",
        "model.classifier = Linear(in_features=1280, out_features=10, bias=True)\n",
        "#model = EfficientNet.from_pretrained(model_name)\n",
        "model = model.cuda()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss().cuda(gpu)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr,\n",
        "                            momentum=momentum,\n",
        "                            weight_decay=weight_decay)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWeiiU0KW1NA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data loading code\n",
        "traindir = os.path.join('./imagewoof/train')\n",
        "valdir = os.path.join('./imagewoof/val/')\n",
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225])\n",
        "\n",
        "train_dataset = datasets.ImageFolder(\n",
        "     traindir,\n",
        "     transforms.Compose([\n",
        "         transforms.RandomResizedCrop(224),\n",
        "         transforms.RandomHorizontalFlip(),\n",
        "         transforms.ToTensor(),\n",
        "         normalize,\n",
        "     ]))\n",
        "\n",
        "train_sampler = None\n",
        "batch_size = 32\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset, batch_size=batch_size, shuffle=(train_sampler is None),\n",
        "    pin_memory=True, sampler=train_sampler)\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    datasets.ImageFolder(valdir, transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        normalize,\n",
        "    ])),\n",
        "    batch_size=batch_size, shuffle=False,\n",
        "    pin_memory=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6UsMx1G3ZH36",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
        "    torch.save(state, filename)\n",
        "    if is_best:\n",
        "        shutil.copyfile(filename, 'model_best.pth.tar')\n",
        "\n",
        "\n",
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self, name, fmt=':f'):\n",
        "        self.name = name\n",
        "        self.fmt = fmt\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "    def __str__(self):\n",
        "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
        "        return fmtstr.format(**self.__dict__)\n",
        "\n",
        "\n",
        "class ProgressMeter(object):\n",
        "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
        "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
        "        self.meters = meters\n",
        "        self.prefix = prefix\n",
        "\n",
        "    def display(self, batch):\n",
        "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
        "        entries += [str(meter) for meter in self.meters]\n",
        "        print('\\t'.join(entries))\n",
        "\n",
        "    def _get_batch_fmtstr(self, num_batches):\n",
        "        num_digits = len(str(num_batches // 1))\n",
        "        fmt = '{:' + str(num_digits) + 'd}'\n",
        "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'\n",
        "\n",
        "\n",
        "def adjust_learning_rate(optimizer, epoch, lr):\n",
        "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
        "    lr = lr * (0.1 ** (epoch // 30))\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr\n",
        "\n",
        "\n",
        "def accuracy(output, target, topk=(1,)):\n",
        "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
        "    with torch.no_grad():\n",
        "        maxk = max(topk)\n",
        "        batch_size = target.size(0)\n",
        "\n",
        "        _, pred = output.topk(maxk, 1, True, True)\n",
        "        pred = pred.t()\n",
        "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "        res = []\n",
        "        for k in topk:\n",
        "            correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
        "            res.append(correct_k.mul_(100.0 / batch_size))\n",
        "        return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1pTI4z3bHDu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(train_loader, model, criterion, optimizer, epoch):\n",
        "    batch_time = AverageMeter('Time', ':6.3f')\n",
        "    data_time = AverageMeter('Data', ':6.3f')\n",
        "    losses = AverageMeter('Loss', ':.4e')\n",
        "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
        "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
        "    progress = ProgressMeter(\n",
        "        len(train_loader),\n",
        "        [batch_time, data_time, losses, top1, top5],\n",
        "        prefix=\"Epoch: [{}]\".format(epoch))\n",
        "\n",
        "    # switch to train mode\n",
        "    model.train()\n",
        "\n",
        "    end = time.time()\n",
        "    for i, (images, target) in enumerate(train_loader):\n",
        "        # measure data loading time\n",
        "        data_time.update(time.time() - end)\n",
        "\n",
        "        #if args.gpu is not None:\n",
        "        images = images.cuda(0, non_blocking=True)\n",
        "        target = target.cuda(0, non_blocking=True)\n",
        "\n",
        "        # compute output\n",
        "        output = model(images)\n",
        "        loss = criterion(output, target)\n",
        "\n",
        "        # measure accuracy and record loss\n",
        "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
        "        losses.update(loss.item(), images.size(0))\n",
        "        top1.update(acc1[0], images.size(0))\n",
        "        top5.update(acc5[0], images.size(0))\n",
        "\n",
        "        # compute gradient and do SGD step\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # measure elapsed time\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "\n",
        "        if i % print_freq == 0:\n",
        "            progress.display(i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4A3rkLogbZV6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def validate(val_loader, model, criterion):\n",
        "    batch_time = AverageMeter('Time', ':6.3f')\n",
        "    losses = AverageMeter('Loss', ':.4e')\n",
        "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
        "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
        "    progress = ProgressMeter(\n",
        "        len(val_loader),\n",
        "        [batch_time, losses, top1, top5],\n",
        "        prefix='Test: ')\n",
        "\n",
        "    # switch to evaluate mode\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        end = time.time()\n",
        "        for i, (images, target) in enumerate(val_loader):\n",
        "            #if args.gpu is not None:\n",
        "            images = images.cuda(0, non_blocking=True)\n",
        "            target = target.cuda(0, non_blocking=True)\n",
        "\n",
        "            # compute output\n",
        "            output = model(images)\n",
        "            loss = criterion(output, target)\n",
        "\n",
        "            # measure accuracy and record loss\n",
        "            acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
        "            losses.update(loss.item(), images.size(0))\n",
        "            top1.update(acc1[0], images.size(0))\n",
        "            top5.update(acc5[0], images.size(0))\n",
        "\n",
        "            # measure elapsed time\n",
        "            batch_time.update(time.time() - end)\n",
        "            end = time.time()\n",
        "\n",
        "            if i % print_freq == 0:\n",
        "                progress.display(i)\n",
        "\n",
        "        # TODO: this should also be done with the ProgressMeter\n",
        "        print(' * Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f}'\n",
        "              .format(top1=top1, top5=top5))\n",
        "\n",
        "    return top1.avg\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4H2V83s8X2J_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best_acc1 = 0.0\n",
        "for epoch in range(start_epoch, epochs):\n",
        "\n",
        "   adjust_learning_rate(optimizer, epoch, lr)\n",
        "\n",
        "   # train for one epoch\n",
        "   train(train_loader, model, criterion, optimizer, epoch)\n",
        "\n",
        "   # evaluate on validation set\n",
        "   acc1 = validate(val_loader, model, criterion)\n",
        "\n",
        "   # remember best acc@1 and save checkpoint\n",
        "   is_best = acc1 > best_acc1\n",
        "   best_acc1 = max(acc1, best_acc1)\n",
        "   #print (best_acc1)\n",
        "\n",
        "print ('Finish')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aqi5I_jKLpRT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_sub = './imagewoof/val/'\n",
        "batch_size = 1\n",
        "test_transform = transforms.Compose([\n",
        "            transforms.Resize(224, interpolation=Image.BICUBIC),\n",
        "            transforms.ToTensor(),\n",
        "        ])        \n",
        "test_data = torchvision.datasets.ImageFolder(root=data_sub, transform=test_transform)\n",
        "\n",
        "num_test = len(test_data)\n",
        "print (num_test)\n",
        "test_queue = torch.utils.data.DataLoader(\n",
        "            test_data,\n",
        "            batch_size=batch_size,\n",
        "            shuffle=False,\n",
        "            pin_memory=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hTuI209KUdt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "confusion_matrix = torch.zeros(10, 10)\n",
        "with torch.no_grad():\n",
        "\n",
        "   for step, (input, target) in enumerate(test_queue):\n",
        "       input = Variable(input).cuda()\n",
        "       target = Variable(target).cuda(async=True)\n",
        "       #input = Variable(input)\n",
        "       #target = Variable(target)\n",
        "\n",
        "       outputs = model(input)\n",
        "       _, preds = torch.max(outputs, 1)\n",
        "       #print(preds)\n",
        "       for t, p in zip(target.view(-1), preds.view(-1)):\n",
        "           #print(t, p)\n",
        "           confusion_matrix[t.long(), p.long()] += 1\n",
        "#print(confusion_matrix)\n",
        "#print(confusion_matrix.diag()/confusion_matrix.sum(1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXlo2zAjieVK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print(target.view(-1))\n",
        "#print(preds.view(-1))\n",
        "#print(confusion_matrix[0,155]>=1)\n",
        "#for t in range (10):\n",
        "# for p in range (10): \n",
        "#  if confusion_matrix[t,p]>=1:\n",
        "#   print(t, p, confusion_matrix[t,p])\n",
        "\n",
        "import pandas as  pd\n",
        "import seaborn as sn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "px = confusion_matrix.numpy()\n",
        "px = pd.DataFrame(px)\n",
        "sn.set(font_scale=1.4) # for label size\n",
        "sn.heatmap(px, annot=True, annot_kws={\"size\": 16}) # font size\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvmLYlCAPNnE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as  pd\n",
        "import seaborn as sn\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "confusion_matrix = torch.zeros(10, 10)\n",
        "# 36, 8\n",
        "confusion_matrix = torch.tensor([[48.,  0.,  0.,  0.,  1.,  0.,  1.,  0.,  0.,  0.],\n",
        "        [ 0., 49.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
        "        [ 0.,  0., 48.,  1.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
        "        [ 0.,  2., 12., 33.,  0.,  0.,  1.,  0.,  0.,  2.],\n",
        "        [ 0.,  2.,  0.,  0., 48.,  0.,  0.,  0.,  0.,  0.],\n",
        "        [ 3.,  0.,  0.,  0.,  1., 44.,  1.,  1.,  0.,  0.],\n",
        "        [ 0.,  0.,  1.,  0.,  0.,  0., 47.,  0.,  0.,  2.],\n",
        "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0., 49.,  0.,  0.],\n",
        "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., 50.,  0.],\n",
        "        [ 1.,  1.,  2.,  0.,  1.,  0.,  0.,  0.,  0., 45.]])\n",
        "# 24, 8\n",
        "confusion_matrix = torch.tensor([[47.,  0.,  0.,  0.,  2.,  1.,  0.,  0.,  0.,  0.],\n",
        "        [ 0., 49.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
        "        [ 0.,  1., 45.,  4.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
        "        [ 1.,  1., 13., 33.,  0.,  0.,  1.,  0.,  0.,  1.],\n",
        "        [ 0.,  1.,  1.,  0., 48.,  0.,  0.,  0.,  0.,  0.],\n",
        "        [ 2.,  0.,  0.,  0.,  3., 42.,  0.,  2.,  0.,  1.],\n",
        "        [ 0.,  0.,  1.,  0.,  1.,  0., 47.,  0.,  0.,  1.],\n",
        "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0., 49.,  1.,  0.],\n",
        "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., 50.,  0.],\n",
        "        [ 0.,  2.,  1.,  2.,  1.,  0.,  0.,  1.,  0., 43.]])\n",
        "px = confusion_matrix.numpy()\n",
        "px = pd.DataFrame(px)\n",
        "sn.set(font_scale=1.4) # for label size\n",
        "sn.heatmap(px, annot=True, annot_kws={\"size\": 16}) # font size\n",
        "\n",
        "plt.show()\n",
        "print(confusion_matrix.diag()/confusion_matrix.sum(1))\n",
        "TP = confusion_matrix.diag() \n",
        "print('TP :', confusion_matrix.diag())\n",
        "Total= confusion_matrix.sum(1) \n",
        "print(confusion_matrix.sum(1))\n",
        "print('Total :', Total.sum(0))\n",
        "FP = confusion_matrix.sum(0)-confusion_matrix.diag()\n",
        "print('FP :', confusion_matrix.sum(0)-confusion_matrix.diag())\n",
        "FN = confusion_matrix.sum(1)-confusion_matrix.diag()\n",
        "print('FN :', confusion_matrix.sum(1)-confusion_matrix.diag())\n",
        "TN = Total.sum(0)- TP - FP - FN\n",
        "print('TN :', Total.sum(0)- TP - FP - FN)\n",
        "Precision = TP/(TP+FP)\n",
        "print('Precision(TP/(TP+FP)):', confusion_matrix.diag()/(confusion_matrix.diag()+( confusion_matrix.sum(0) - confusion_matrix.diag() )))\n",
        "Recall = TP/(TP+FN)\n",
        "print('Recall(TP/(TP+FN)) :', confusion_matrix.diag()/(confusion_matrix.diag()+( confusion_matrix.sum(1) - confusion_matrix.diag() )))\n",
        "Accuracy = (TP+TN)/(TP+FN+FP+TN)\n",
        "print('Accuracy(TP+TN/(TP+FN+FP+TN)) :',(TP+TN)/(TP+FN+FP+TN))\n",
        "F1 = (2/((1/Precision)+(1/Recall)))\n",
        "print('F1 Score(2/(1/Precision)+(1/Recall)) :', (2/((1/Precision)+(1/Recall))))\n",
        "print('-----------------------------------------------------------------------')\n",
        "print('Finial Precision:', Precision.sum(0)/10)\n",
        "print('Finial Recall   :', Recall.sum(0)/10)\n",
        "print('Finial Accuracy :', Accuracy.sum(0)/10)\n",
        "print('Finial F1 Score :', F1.sum(0)/10)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}