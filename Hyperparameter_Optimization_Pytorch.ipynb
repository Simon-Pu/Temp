{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hyperparameter Optimization Pytorch.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPtSfFtb+EZiOomEmwqucYv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Simon-Pu/Temp/blob/master/Hyperparameter_Optimization_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64cklvUQGJFJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSwJL_WyIBcW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch import *\n",
        "%matplotlib inline\n",
        "\n",
        "from torchvision.models import densenet201\n",
        "from torchvision.models import resnext50_32x4d\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torchvision import transforms\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Linear\n",
        "import torch\n",
        "\n",
        "print(torch.cuda.get_device_name(0))\n",
        "print(torch.cuda.get_device_properties(0).total_memory)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8IDLCo8Icfy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model = densenet201(pretrained = True)\n",
        "model = resnext50_32x4d(pretrained = True)\n",
        "model.classifier = Linear(1920,10)\n",
        "\n",
        "# Move model to GPU for faster training\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "# Set model to training mode\n",
        "model.train()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqchjRTWIk0r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Change the value of bs to change the batch size\n",
        "bs = 256\n",
        "\n",
        "train_tfms = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "test_tfms = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "\n",
        "train_ds = CIFAR10(root='./data', train=True, download=True, transform=train_tfms)\n",
        "test_ds = CIFAR10(root='./data', train=False, download=True, transform=test_tfms)\n",
        "\n",
        "train_dl = DataLoader(train_ds, batch_size = bs)\n",
        "test_dl = DataLoader(test_ds , batch_size = bs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qY5ZSXAlIqjy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "loss_func = F.cross_entropy\n",
        "  # Define function to check model accuracy\n",
        "def accuracy(out, yb):\n",
        "    preds = torch.argmax(out, dim=1)\n",
        "    return (preds == yb).float().mean()\n",
        "\n",
        "# Change the value of lr to change the learning rate\n",
        "lr = 1e-3\n",
        "optim = Adam(model.parameters(), lr = lr)\n",
        "\n",
        "# Change the value of epochs to change the number of epochs\n",
        "epochs = 5\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    \n",
        "    for xb, yb in train_dl:\n",
        "        \n",
        "        # .to(device) moves torch.Tensor objects to the GPU for faster training\n",
        "        \n",
        "        preds = model(xb.to(device))\n",
        "        loss = loss_func(preds, yb.to(device))\n",
        "        acc = accuracy(preds,yb.to(device))\n",
        "\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        optim.zero_grad()\n",
        "        \n",
        "    print(\"Loss: \" + str(loss.item()) + \"\\t \\t Accuracy: \" + str(100 * acc.item()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcBg0vNwJU1y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_model_accuracy():\n",
        "  tot_acc = 0\n",
        "  avg_acc = 0\n",
        "  \n",
        "  # Set model to evaluation mode\n",
        "  model.eval()\n",
        "\n",
        "  for xbt, ybt in test_dl:\n",
        "\n",
        "    pred = model(xbt.to(device))\n",
        "    tot_acc += accuracy(pred,ybt.to(device))\n",
        "\n",
        "  avg_acc = tot_acc / len(test_dl)\n",
        "  \n",
        "  return avg_acc.item()\n",
        "\n",
        "\n",
        "# Print accuracy of model\n",
        "print(\"The average accuracy is: \" + str(get_model_accuracy()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XIyPhElJen5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install bayesian-optimization"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCIs48hAJfu9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def obj_func(lr, bs, epochs):\n",
        "      \n",
        "      # We need to round off bs and epochs because Gaussian processes cannot deal with discrete variables \n",
        "      bs = int(bs)\n",
        "      epochs = int(epochs)\n",
        "      \n",
        "      train_dl = DataLoader(train_ds, batch_size = bs)\n",
        "      test_dl = DataLoader(test_ds , batch_size = bs)\n",
        "      \n",
        "      optim = Adam(model.parameters(), lr = lr)\n",
        "      \n",
        "      for epoch in range(epochs):\n",
        "    \n",
        "        for xb, yb in train_dl:\n",
        "        \n",
        "            # .to(device) moves torch.Tensor objects to the GPU for faster training\n",
        "        \n",
        "            preds = model(xb.to(device))\n",
        "            loss = loss_func(preds, yb.to(device))\n",
        "            acc = accuracy(preds,yb.to(device))\n",
        "        \n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "            optim.zero_grad()\n",
        "        \n",
        "        print(\"Loss: \" + str(loss.item()) + \"\\t \\t Accuracy: \" + str(100 * acc.item()))\n",
        "\n",
        "      acc = get_model_accuracy()\n",
        "      \n",
        "      return acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCiFHIZfJokt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from bayes_opt import BayesianOptimization\n",
        "\n",
        "# Bounded region of parameter space\n",
        "pbounds = {'lr': (1e-4, 1e-2), 'bs': (64, 512), 'epochs': (1,25)}\n",
        "\n",
        "optimizer = BayesianOptimization(\n",
        "    f=obj_func,\n",
        "    pbounds=pbounds,\n",
        "    verbose=2, # verbose = 1 prints only when a maximum is observed, verbose = 0 is silent\n",
        "    random_state=1,\n",
        ")\n",
        "\n",
        "optimizer.maximize(init_points=2, n_iter=3,)\n",
        "\n",
        "print(optimizer.max)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qa_XJsVZZnZW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from bayes_opt import BayesianOptimization\n",
        "\n",
        "# Bounded region of parameter space\n",
        "pbounds = {'lr': (1e-4, 1e-2), 'bs': (64, 512), 'epochs': (1,25)}\n",
        "\n",
        "optimizer = BayesianOptimization(\n",
        "    f=obj_func,\n",
        "    pbounds=pbounds,\n",
        "    verbose=2, # verbose = 1 prints only when a maximum is observed, verbose = 0 is silent\n",
        "    random_state=1,\n",
        ")\n",
        "\n",
        "optimizer.maximize(init_points=2, n_iter=3,)\n",
        "\n",
        "print(optimizer.max)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoaddMAwHWml",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install optuna"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnVqsbjmHhrU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def objective(trial):\n",
        "      # We need to round off bs and epochs because Gaussian processes cannot deal with discrete variables \n",
        "      #bs = int(bs)\n",
        "      #epochs = int(epochs)\n",
        "      \n",
        "      # Generate the optimizers.\n",
        "      lr = trial.suggest_uniform(\"lr\", 1e-4, 1e-2)\n",
        "      bs = trial.suggest_int('bs', 32, 265)\n",
        "      epochs = trial.suggest_int('epochs', 5, 5)\n",
        "\n",
        "      print(lr, bs, epochs)\n",
        "      train_dl = DataLoader(train_ds, batch_size = bs)\n",
        "      test_dl = DataLoader(test_ds , batch_size = bs)\n",
        "      \n",
        "      optim = Adam(model.parameters(), lr = lr)\n",
        "      \n",
        "      for epoch in range(epochs):\n",
        "    \n",
        "        for xb, yb in train_dl:\n",
        "        \n",
        "            # .to(device) moves torch.Tensor objects to the GPU for faster training\n",
        "        \n",
        "            preds = model(xb.to(device))\n",
        "            loss = loss_func(preds, yb.to(device))\n",
        "            acc = accuracy(preds,yb.to(device))\n",
        "        \n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "            optim.zero_grad()\n",
        "        \n",
        "        print(\"Loss: \" + str(loss.item()) + \"\\t \\t Accuracy: \" + str(100 * acc.item()))\n",
        "\n",
        "      acc = get_model_accuracy()\n",
        "      \n",
        "      return acc  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7jbmAg_KEj4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import optuna\n",
        "   \n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "#study.optimize(objective, n_trials=100)\n",
        "study.optimize(objective, n_trials=100)\n",
        "\n",
        "print(\"Number of finished trials: \", len(study.trials))\n",
        "\n",
        "print(\"Best trial:\")\n",
        "trial = study.best_trial\n",
        "\n",
        "print(\"  Value: \", trial.value)\n",
        "\n",
        "print(\"  Params: \")\n",
        "for key, value in trial.params.items():\n",
        "   print(\"    {}: {}\".format(key, value))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}