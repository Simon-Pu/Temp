# -*- coding: utf-8 -*-
"""Mnasnet Example.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/tensorflow/tpu/blob/master/models/official/mnasnet/mnasnet_example.ipynb

# Prerequisites (downloading tensorflow/tpu and checkpoints)
"""

from IPython import display
!git clone https://github.com/tensorflow/tpu
display.clear_output()

from __future__ import print_function

checkpoint_name = 'mnasnet-a1' #@param
url = 'https://storage.googleapis.com/mnasnet/checkpoints/' + checkpoint_name + '.tar.gz'
print('Downloading from ', url)
!wget {url}
print('Unpacking')
!tar -xvf {checkpoint_name}.tar.gz

display.clear_output()
print('Successfully downloaded checkpoint from ', url,
      '. It is available as', checkpoint_name)

!wget https://upload.wikimedia.org/wikipedia/commons/f/fe/Giant_Panda_in_Beijing_Zoo_1.JPG -O panda.jpg

# setup path
import sys
sys.path.append('/content/tpu/models/official/mnasnet')
sys.path.append('/content/tpu/models/common')

"""```
# This is formatted as code
```

# Inference with SavedModel
"""

from IPython import display
import pylab
import PIL
import numpy as np
filename = 'panda.jpg'
display.display(display.Image(filename))
img = np.array(PIL.Image.open(filename).resize((224, 224))).astype(np.float)

import os
import tensorflow as tf

checkpoint_name = 'mnasnet-a1'
export_dir = os.path.join(checkpoint_name, 'saved_model')
serv_sess = tf.Session(graph=tf.Graph())
meta_graph_def = tf.saved_model.loader.load(serv_sess, [tf.saved_model.tag_constants.SERVING], export_dir)

# Checks the saved model signatures.
signature = 'serving_default'
print('Serving Signature: ', signature)
print(meta_graph_def.signature_def[signature])

import imagenet
import time

start = time.time()
top_class, probs = serv_sess.run(fetches=["ArgMax:0", "softmax_tensor:0"], feed_dict={"Placeholder:0": [img]})
print (time.time()-start)
print("Top class: ", top_class[0], " with Probability= ", probs[0][top_class[0]])
label_map = imagenet.create_readable_names_for_imagenet_labels()  
for idx, label_id in enumerate(reversed(list(np.argsort(probs)[0][-5:]))):
  print("Top %d Prediction: %d, %s, probs=%f" % (idx+1, label_id, label_map[label_id], probs[0][label_id]))

# est is the estimator object created with model_fn and input_fn.
converter = tf.lite.TFLiteConverter.from_saved_model(export_dir)
tflite_model = converter.convert()
tflite_file = os.path.join(export_dir, checkpoint_name + '.tflite')
tf.gfile.GFile(tflite_file, 'wb').write(tflite_model)

!ls  mnasnet-a1/saved_model

from PIL import Image

#model_path = "./model/quantize_frozen_graph.tflite"
model_path = "mnasnet-a1/saved_model/mnasnet-a1.tflite"
#export_dir = os.path.join(checkpoint_name, 'saved_model')
# Load TFLite model and allocate tensors.
interpreter = tf.lite.Interpreter(model_path=model_path)
interpreter.allocate_tensors()

# Get input and output tensors.
input_details = interpreter.get_input_details()
#print(str(input_details))
output_details = interpreter.get_output_details()
#print(str(output_details))


# check the type of the input tensor
if input_details[0]['dtype'] == np.float32:
  floating_model = True

# NxHxWxC, H:1, W:2
height = input_details[0]['shape'][1]
width = input_details[0]['shape'][2]
img = Image.open('panda.jpg')
img = img.resize((224, 224))

# add N dim
input_data = np.expand_dims(img, axis=0)

if floating_model:
  input_data = (np.float32(input_data) - 127.5) / 127.5

interpreter.set_tensor(input_details[0]['index'], input_data)

# Test model on random input data.
#input_shape = input_details[0]['shape']
#input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)
#interpreter.set_tensor(input_details[0]['index'], input_data)

interpreter.invoke()

output_data = interpreter.get_tensor(output_details[0]['index'])
#print (output_data)
results = np.squeeze(output_data)
#print (results)

top_k = results.argsort()[-5:][::-1]
label_map = imagenet.create_readable_names_for_imagenet_labels() 
print (top_k)
#print (label_map)
#labels = load_labels(label_map)

#for idx, label_id in enumerate(reversed(list(np.argsort(results)[0][-5:]))):
#  print("Top %d Prediction: %d, %s, probs=%f" % (idx+1, label_id, label_map[label_id], results[0][label_id]))
  
#for i in top_k:
#  if floating_model:
#    print('{0:08.6f}'.format(float(results[i]))+":", label_map[i])
#  else:
#    print('{0:08.6f}'.format(float(results[i]/255.0))+":", label_map[i])

model_path = "mnasnet-a1/mnasnet-a1.tflite"
#export_dir = os.path.join(checkpoint_name, 'saved_model')
# Load TFLite model and allocate tensors.
interpreter = tf.lite.Interpreter(model_path=model_path)
interpreter.allocate_tensors()

# Get input and output tensors.
input_details = interpreter.get_input_details()
#print(str(input_details))
output_details = interpreter.get_output_details()
#print(str(output_details))


# check the type of the input tensor
if input_details[0]['dtype'] == np.float32:
  floating_model = True

# NxHxWxC, H:1, W:2
height = input_details[0]['shape'][1]
width = input_details[0]['shape'][2]
img = Image.open('panda.jpg')
img = img.resize((224, 224))

# add N dim
input_data = np.expand_dims(img, axis=0)

if floating_model:
  input_data = (np.float32(input_data) - 127.5) / 127.5

interpreter.set_tensor(input_details[0]['index'], input_data)

# Test model on random input data.
#input_shape = input_details[0]['shape']
#input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)
#interpreter.set_tensor(input_details[0]['index'], input_data)

interpreter.invoke()

output_data = interpreter.get_tensor(output_details[0]['index'])
#print (output_data)
results = np.squeeze(output_data)


top_k = results.argsort()[-5:][::-1]
label_map = imagenet.create_readable_names_for_imagenet_labels() 
print (top_k)
for i in top_k:
  print('{0:08.6f}'.format(float(results[i])))

model_path = "mnasnet-a1/mnasnet-a1_postquant.tflite"
#export_dir = os.path.join(checkpoint_name, 'saved_model')
# Load TFLite model and allocate tensors.
interpreter = tf.lite.Interpreter(model_path=model_path)
interpreter.allocate_tensors()

# Get input and output tensors.
input_details = interpreter.get_input_details()
#print(str(input_details))
output_details = interpreter.get_output_details()
#print(str(output_details))


# check the type of the input tensor
if input_details[0]['dtype'] == np.float32:
  floating_model = True

# NxHxWxC, H:1, W:2
height = input_details[0]['shape'][1]
width = input_details[0]['shape'][2]
img = Image.open('panda.jpg')
img = img.resize((224, 224))

# add N dim
input_data = np.expand_dims(img, axis=0)

if floating_model:
  input_data = (np.float32(input_data) - 127.5) / 127.5

interpreter.set_tensor(input_details[0]['index'], input_data)

# Test model on random input data.
#input_shape = input_details[0]['shape']
#input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)
#interpreter.set_tensor(input_details[0]['index'], input_data)

interpreter.invoke()

output_data = interpreter.get_tensor(output_details[0]['index'])
#print (output_data)
results = np.squeeze(output_data)


top_k = results.argsort()[-5:][::-1]
label_map = imagenet.create_readable_names_for_imagenet_labels() 
print (top_k)
for i in top_k:
  print('{0:08.6f}'.format(float(results[i])))  

#print (label_map)