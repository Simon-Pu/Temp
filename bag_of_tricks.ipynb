{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bag-of-tricks.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "JZ_zmZhTyOSN",
        "ZiaIqUQKWHgT",
        "5HShJN2xh22e"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZ_zmZhTyOSN",
        "colab_type": "text"
      },
      "source": [
        "### Recommended: running on GCP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUJEUs3ND0eq",
        "colab_type": "text"
      },
      "source": [
        "You can run this notebook using a free Colab GPU instance (Tesla T4) but timings will be considerably slower than on a V100. \n",
        "If you have a GCP account and want to  use a faster V100 GPU you can follow the instructions [here](https://blog.kovalevskyi.com/gce-deeplearning-images-as-a-backend-for-google-colaboratory-bc4903d24947) to use that as an alternative Colab backend. Don't forget to shut down the GCP instance (not just the Colab notebook) once you've finished!\n",
        "\n",
        "FWIW, I use the following (preemptible) instance type:\n",
        "\n",
        "```\n",
        "export IMAGE_FAMILY=\"pytorch-latest-gpu\"\n",
        "export ZONE=\"europe-west4-a\"\n",
        "export INSTANCE_NAME=\"pytorch-colab-backend\"\n",
        "\n",
        "gcloud compute instances create $INSTANCE_NAME \\\n",
        "  --zone $ZONE \\\n",
        "  --machine-type n1-standard-4 \\\n",
        "  --accelerator type=nvidia-tesla-v100,count=1 \\\n",
        "  --image-family $IMAGE_FAMILY \\\n",
        "  --image-project=deeplearning-platform-release \\\n",
        "  --metadata install-nvidia-driver=True \\\n",
        "  --maintenance-policy TERMINATE \\\n",
        "  --preemptible \n",
        "  ```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjOIoRO9ZNE2",
        "colab_type": "text"
      },
      "source": [
        "On GCP you will need to install altair for plotting. This is pre-installed on Colab instances."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8m1LCN_bZIrs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#GCP only\n",
        "#!python -m pip install -q vega altair"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ns4mKklxZGIT",
        "colab_type": "text"
      },
      "source": [
        "You can check the details of your setup (free Colab GPU or V100 on GCP) with this nice utility from fastai:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpxpGgl_yJ8r",
        "colab_type": "code",
        "outputId": "56e3485b-dc30-4cc9-8ea5-fd183548af07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        }
      },
      "source": [
        "from fastai.utils.show_install import show_install \n",
        "show_install()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "```text\n",
            "=== Software === \n",
            "python        : 3.6.8\n",
            "fastai        : 1.0.57\n",
            "fastprogress  : 0.1.21\n",
            "torch         : 1.1.0\n",
            "nvidia driver : 418.67\n",
            "torch cuda    : 10.0.130 / is available\n",
            "torch cudnn   : 7501 / is enabled\n",
            "\n",
            "=== Hardware === \n",
            "nvidia gpus   : 1\n",
            "torch devices : 1\n",
            "  - gpu0      : 15079MB | Tesla T4\n",
            "\n",
            "=== Environment === \n",
            "platform      : Linux-4.14.137+-x86_64-with-Ubuntu-18.04-bionic\n",
            "distro        : #1 SMP Thu Aug 8 02:47:02 PDT 2019\n",
            "conda env     : Unknown\n",
            "python        : /usr/bin/python3\n",
            "sys.path      : \n",
            "/env/python\n",
            "/usr/lib/python36.zip\n",
            "/usr/lib/python3.6\n",
            "/usr/lib/python3.6/lib-dynload\n",
            "/usr/local/lib/python3.6/dist-packages\n",
            "/usr/lib/python3/dist-packages\n",
            "/usr/local/lib/python3.6/dist-packages/IPython/extensions\n",
            "/root/.ipython\n",
            "```\n",
            "\n",
            "Please make sure to include opening/closing ``` when you paste into forums/github to make the reports appear formatted as code sections.\n",
            "\n",
            "Optional package(s) to enhance the diagnostics can be installed with:\n",
            "pip install distro\n",
            "Once installed, re-run this utility to get the additional information\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6IGml3SMd6ID",
        "colab_type": "text"
      },
      "source": [
        "# How to Train Your ResNet - 8: Bag of Tricks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tac7LB2td_Cs",
        "colab_type": "text"
      },
      "source": [
        "In the [final post of the series](https://myrtle.ai/how-to-train-your-resnet-8-bag-of-tricks/) we come full circle, speeding up our single-GPU training implementation to take on a field of multi-GPU competitors. Whilst we've been otherwise occupied - investigating [hyperparameter tuning](https://myrtle.ai/learn/how-to-train-your-resnet-5-hyperparameters/), [weight decay](https://myrtle.ai/learn/how-to-train-your-resnet-6-weight-decay/) and [batch norm](https://myrtle.ai/learn/how-to-train-your-resnet-7-batch-norm/) - our entry for training CIFAR10 to 94% test accuracy has slipped five (!) places on the DAWNBench leaderboard:\n",
        "\n",
        "![](https://drive.google.com/uc?id=1MzB0-FR_oIPVe9PCffvRI9DB13m2YI21)\n",
        "\n",
        "The top six entries all use 9-layer ResNets which are cousins - or twins - of the network we developed  [earlier in the series](https://myrtle.ai/learn/how-to-train-your-resnet-4-architecture/). First place is a 4-GPU implementation from Kakao Brain which completes in an impressive 37s. The single-GPU version of the same comes in third with 68s, an apparent 7s improvement over our single-GPU entry from last year, although close inspection shows that these submissions are using test-time augmentation (TTA). We shall discuss the validity of this approach towards the end of the post (our conclusion is that any reasonable restriction should be based on total inference cost and that the form of mild TTA used here, along with a lightweight network, passes on that front.) Note that our earlier submission, allowing the same TTA, would achieve a time of 60s on a 19 epoch training schedule without further changes.\n",
        "\n",
        "By the end of the post our single-GPU implementation surpasses the top multi-GPU times comfortably, reclaiming the coveted DAWNBench crown with a time of 34s and achieving a 10Ã— improvement over the single-GPU state-of-the-art at the start of the series! Using the same TTA employed by the Kakao Brain submission, this drops to 26s. We achieve these times by accumulating a series of small (typically 0.1-0.3% in absolute test accuracy) improvements, which can be traded for shorter training times. These improvements are based on a collection of standard and not-so-standard tricks. \n",
        "\n",
        "Our main weapon is statistical significance. The standard deviation in test accuracy for a single training run is roughly 0.15% and when comparing between two runs we need to multiply this by $\\sqrt{2}$. This is larger than many of the effects that we are measuring. Given that training times soon drop below a minute, we can afford to run experiments 10s-100s of times to make sure that improvements are real and this allows us to make consistent progress.\n",
        "\n",
        "Sharp experimental results are essential to advancing the field but if a baseline is poorly-tuned or the number of runs too few, experimental validation holds little value. The main goal of today's post is to provide a well-tuned baseline on which to test novel techniques, allowing one to complete a statistically significant number of training runs within minutes on a single GPU. We confirm, at the end of the post, that improvements in training speed translate into improvements in final accuarcy if training is allowed to proceed towards convergence.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWyjxzQb_yMA",
        "colab_type": "text"
      },
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7WeTS0FF4iQE",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Lib (RUN ME) - double-click to show/hide code\n",
        "####################\n",
        "## CORE\n",
        "#####################\n",
        "\n",
        "import inspect\n",
        "from collections import namedtuple, defaultdict\n",
        "from functools import partial\n",
        "import functools\n",
        "from itertools import chain, count, islice as take\n",
        "\n",
        "#####################\n",
        "## dict utils\n",
        "#####################\n",
        "\n",
        "union = lambda *dicts: {k: v for d in dicts for (k, v) in d.items()}\n",
        "\n",
        "make_tuple = lambda path: (path,) if isinstance(path, str) else path\n",
        "\n",
        "def path_iter(nested_dict, pfx=()):\n",
        "    for name, val in nested_dict.items():\n",
        "        if isinstance(val, dict): yield from path_iter(val, pfx+make_tuple(name))\n",
        "        else: yield (pfx+make_tuple(name), val)  \n",
        "            \n",
        "map_values = lambda func, dct: {k: func(v) for k,v in dct.items()}\n",
        "\n",
        "def map_nested(func, nested_dict):\n",
        "    return {k: map_nested(func, v) if isinstance(v, dict) else func(v) for k,v in nested_dict.items()}\n",
        "\n",
        "def group_by_key(seq):\n",
        "    res = defaultdict(list)\n",
        "    for k, v in seq: \n",
        "        res[k].append(v) \n",
        "    return res\n",
        "\n",
        "reorder = lambda dct, keys: {k: dct[k] for k in keys}\n",
        "\n",
        "#####################\n",
        "## graph building\n",
        "#####################\n",
        "\n",
        "def identity(value): return value\n",
        "\n",
        "def build_graph(net, path_map='_'.join):\n",
        "    net = {path: node if len(node) is 3 else (*node, None) for path, node in path_iter(net)}\n",
        "    default_inputs = chain([('input',)], net.keys())\n",
        "    resolve_path = lambda path, pfx: pfx+path if (pfx+path in net or not pfx) else resolve_path(net, path, pfx[:-1])\n",
        "    return {path_map(path): (typ, value, ([path_map(default)] if inputs is None else [path_map(resolve_path(make_tuple(k), path[:-1])) for k in inputs])) \n",
        "            for (path, (typ, value, inputs)), default in zip(net.items(), default_inputs)}\n",
        "\n",
        "#####################\n",
        "## network visualisation (requires pydot)\n",
        "#####################\n",
        "import IPython.display\n",
        "\n",
        "class ColorMap(dict):\n",
        "    palette = (\n",
        "        'bebada,ffffb3,fb8072,8dd3c7,80b1d3,fdb462,b3de69,fccde5,bc80bd,ccebc5,ffed6f,1f78b4,33a02c,e31a1c,ff7f00,'\n",
        "        '4dddf8,e66493,b07b87,4e90e3,dea05e,d0c281,f0e189,e9e8b1,e0eb71,bbd2a4,6ed641,57eb9c,3ca4d4,92d5e7,b15928'\n",
        "    ).split(',')\n",
        " \n",
        "    def __missing__(self, key):\n",
        "        self[key] = self.palette[len(self) % len(self.palette)]\n",
        "        return self[key]\n",
        "\n",
        "def make_pydot(nodes, edges, direction='LR', sep='_', **kwargs):\n",
        "    from pydot import Dot, Cluster, Node, Edge\n",
        "    class Subgraphs(dict):\n",
        "        def __missing__(self, path):\n",
        "            *parent, label = path\n",
        "            subgraph = Cluster(sep.join(path), label=label, style='rounded, filled', fillcolor='#77777744')\n",
        "            self[tuple(parent)].add_subgraph(subgraph)\n",
        "            return subgraph\n",
        "    g = Dot(rankdir=direction, directed=True, **kwargs)\n",
        "    g.set_node_defaults(\n",
        "        shape='box', style='rounded, filled', fillcolor='#ffffff')\n",
        "    subgraphs = Subgraphs({(): g})\n",
        "    for path, attr in nodes:\n",
        "        *parent, label = path.split(sep)\n",
        "        subgraphs[tuple(parent)].add_node(\n",
        "            Node(name=path, label=label, **attr))\n",
        "    for src, dst, attr in edges:\n",
        "        g.add_edge(Edge(src, dst, **attr))\n",
        "    return g\n",
        "\n",
        "class DotGraph():\n",
        "    colors = ColorMap()   \n",
        "    def __init__(self, graph, size=15, direction='LR'):\n",
        "        self.nodes = [(k, {\n",
        "            'tooltip': '%s %.1000r' % (typ, value), \n",
        "            'fillcolor': '#'+self.colors[typ],\n",
        "        }) for k, (typ, value, inputs) in graph.items()] \n",
        "        self.edges = [(src, k, {}) for (k, (_,_,inputs)) in graph.items() for src in inputs]\n",
        "        self.size, self.direction = size, direction\n",
        "\n",
        "    def dot_graph(self, **kwargs):\n",
        "        return make_pydot(self.nodes, self.edges, size=self.size, \n",
        "                            direction=self.direction, **kwargs)\n",
        "\n",
        "    def svg(self, **kwargs):\n",
        "        return self.dot_graph(**kwargs).create(format='svg').decode('utf-8')\n",
        "\n",
        "    try:\n",
        "        import pydot\n",
        "        def _repr_svg_(self):\n",
        "            return self.svg()\n",
        "    except ImportError:\n",
        "        def __repr__(self):\n",
        "            return 'pydot is needed for network visualisation'\n",
        "\n",
        "\n",
        "#####################\n",
        "## Layers\n",
        "##################### \n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from collections import namedtuple\n",
        "import copy\n",
        "\n",
        "torch.backends.cudnn.benchmark = True\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "cpu = torch.device('cpu')\n",
        "    \n",
        "class Network(nn.Module):\n",
        "    def __init__(self, net, loss=None):\n",
        "        super().__init__()\n",
        "        self.graph = {path: (typ, typ(**params), inputs) for path, (typ, params, inputs) in build_graph(net).items()}\n",
        "        self.loss = loss or identity\n",
        "        for path, (_,node,_) in self.graph.items(): \n",
        "            setattr(self, path, node)\n",
        "    \n",
        "    def nodes(self):\n",
        "        return (node for _,node,_ in self.graph.values())\n",
        "    \n",
        "    def forward(self, inputs):\n",
        "        outputs = dict(inputs)\n",
        "        for k, (_, node, ins) in self.graph.items():\n",
        "            outputs[k] = node(*[outputs[x] for x in ins])\n",
        "        return outputs\n",
        "    \n",
        "    def half(self):\n",
        "        for node in self.nodes():\n",
        "            if isinstance(node, nn.Module) and not isinstance(node, nn.BatchNorm2d):\n",
        "                node.half()\n",
        "        return self\n",
        "\n",
        "build_model = lambda network, loss: Network(network, loss).half().to(device)\n",
        "show = lambda network, size=15: display(DotGraph(network.graph if isinstance(network, Network) else build_graph(network), size=size))\n",
        "    \n",
        "class Add(namedtuple('Add', [])):\n",
        "    def __call__(self, x, y): return x + y \n",
        "    \n",
        "class AddWeighted(namedtuple('AddWeighted', ['wx', 'wy'])):\n",
        "    def __call__(self, x, y): return self.wx*x + self.wy*y \n",
        "    \n",
        "class Identity(namedtuple('Identity', [])):\n",
        "    def __call__(self, x): return x\n",
        "\n",
        "class BatchNorm(nn.BatchNorm2d):\n",
        "    def __init__(self, num_features, eps=1e-05, momentum=0.1, weight=True, bias=True):\n",
        "        super().__init__(num_features, eps=eps, momentum=momentum)\n",
        "        self.weight.data.fill_(1.0)\n",
        "        self.bias.data.fill_(0.0)\n",
        "        self.weight.requires_grad = weight\n",
        "        self.bias.requires_grad = bias\n",
        "\n",
        "class GhostBatchNorm(BatchNorm):\n",
        "    def __init__(self, num_features, num_splits, **kw):\n",
        "        super().__init__(num_features, **kw)\n",
        "        self.num_splits = num_splits\n",
        "        self.register_buffer('running_mean', torch.zeros(num_features*self.num_splits))\n",
        "        self.register_buffer('running_var', torch.ones(num_features*self.num_splits))\n",
        "\n",
        "    def train(self, mode=True):\n",
        "        if (self.training is True) and (mode is False): #lazily collate stats when we are going to use them\n",
        "            self.running_mean = torch.mean(self.running_mean.view(self.num_splits, self.num_features), dim=0).repeat(self.num_splits)\n",
        "            self.running_var = torch.mean(self.running_var.view(self.num_splits, self.num_features), dim=0).repeat(self.num_splits)\n",
        "        return super().train(mode)\n",
        "        \n",
        "    def forward(self, input):\n",
        "        N, C, H, W = input.shape\n",
        "        if self.training or not self.track_running_stats:\n",
        "            return F.batch_norm(\n",
        "                input.view(-1, C*self.num_splits, H, W), self.running_mean, self.running_var, \n",
        "                self.weight.repeat(self.num_splits), self.bias.repeat(self.num_splits),\n",
        "                True, self.momentum, self.eps).view(N, C, H, W) \n",
        "        else:\n",
        "            return F.batch_norm(\n",
        "                input, self.running_mean[:self.num_features], self.running_var[:self.num_features], \n",
        "                self.weight, self.bias, False, self.momentum, self.eps)\n",
        "        \n",
        "class Mul(nn.Module):\n",
        "    def __init__(self, weight):\n",
        "        super().__init__()\n",
        "        self.weight = weight\n",
        "    def __call__(self, x): \n",
        "        return x*self.weight\n",
        "    \n",
        "class Flatten(nn.Module):\n",
        "    def forward(self, x): \n",
        "        return x.view(x.size(0), x.size(1))\n",
        "\n",
        "# Losses\n",
        "class CrossEntropyLoss(namedtuple('CrossEntropyLoss', [])):\n",
        "    def __call__(self, log_probs, target):\n",
        "        return torch.nn.functional.nll_loss(log_probs, target, reduction='none')\n",
        "    \n",
        "class KLLoss(namedtuple('KLLoss', [])):        \n",
        "    def __call__(self, log_probs):\n",
        "        return -log_probs.mean(dim=1)\n",
        "\n",
        "class Correct(namedtuple('Correct', [])):\n",
        "    def __call__(self, classifier, target):\n",
        "        return classifier.max(dim = 1)[1] == target\n",
        "\n",
        "class LogSoftmax(namedtuple('LogSoftmax', ['dim'])):\n",
        "    def __call__(self, x):\n",
        "        return torch.nn.functional.log_softmax(x, self.dim, _stacklevel=5)\n",
        "\n",
        "    \n",
        "# node definitions   \n",
        "from inspect import signature    \n",
        "empty_signature = inspect.Signature()\n",
        "\n",
        "class node_def(namedtuple('node_def', ['type'])):\n",
        "    def __call__(self, *args, **kwargs):\n",
        "        return (self.type, dict(signature(self.type).bind(*args, **kwargs).arguments))\n",
        "\n",
        "conv = node_def(nn.Conv2d)\n",
        "linear = node_def(nn.Linear)\n",
        "batch_norm = node_def(BatchNorm)\n",
        "pool = node_def(nn.MaxPool2d)\n",
        "relu = node_def(nn.ReLU)\n",
        "    \n",
        "def map_types(mapping, net):\n",
        "    def f(node):\n",
        "        typ, *rest = node\n",
        "        return (mapping.get(typ, typ), *rest)\n",
        "    return map_nested(f, net) \n",
        "\n",
        "#####################\n",
        "## Compat\n",
        "##################### \n",
        "\n",
        "def to_numpy(x):\n",
        "    if isinstance(x, torch.Tensor):\n",
        "        return x.detach().cpu().numpy()  \n",
        "    return x\n",
        "  \n",
        "def flip_lr(x):\n",
        "    if isinstance(x, torch.Tensor):\n",
        "        return torch.flip(x, [-1]) \n",
        "    return x[..., ::-1].copy()\n",
        "  \n",
        "trainable_params = lambda model: {k:p for k,p in model.named_parameters() if p.requires_grad}\n",
        "\n",
        "#####################\n",
        "## Optimisers\n",
        "##################### \n",
        "\n",
        "from functools import partial\n",
        "\n",
        "def nesterov_update(w, dw, v, lr, weight_decay, momentum):\n",
        "    dw.add_(weight_decay, w).mul_(-lr)\n",
        "    v.mul_(momentum).add_(dw)\n",
        "    w.add_(dw.add_(momentum, v))\n",
        "\n",
        "norm = lambda x: torch.norm(x.reshape(x.size(0),-1).float(), dim=1)[:,None,None,None]\n",
        "\n",
        "def LARS_update(w, dw, v, lr, weight_decay, momentum):\n",
        "    nesterov_update(w, dw, v, lr*(norm(w)/(norm(dw)+1e-2)).to(w.dtype), weight_decay, momentum)\n",
        "\n",
        "def zeros_like(weights):\n",
        "    return [torch.zeros_like(w) for w in weights]\n",
        "\n",
        "def optimiser(weights, param_schedule, update, state_init):\n",
        "    weights = list(weights)\n",
        "    return {'update': update, 'param_schedule': param_schedule, 'step_number': 0, 'weights': weights,  'opt_state': state_init(weights)}\n",
        "\n",
        "def opt_step(update, param_schedule, step_number, weights, opt_state):\n",
        "    step_number += 1\n",
        "    param_values = {k: f(step_number) for k, f in param_schedule.items()}\n",
        "    for w, v in zip(weights, opt_state):\n",
        "        if w.requires_grad:\n",
        "            update(w.data, w.grad.data, v, **param_values)\n",
        "    return {'update': update, 'param_schedule': param_schedule, 'step_number': step_number, 'weights': weights,  'opt_state': opt_state}\n",
        "\n",
        "LARS = partial(optimiser, update=LARS_update, state_init=zeros_like)\n",
        "SGD = partial(optimiser, update=nesterov_update, state_init=zeros_like)\n",
        "  \n",
        "class PiecewiseLinear(namedtuple('PiecewiseLinear', ('knots', 'vals'))):\n",
        "    def __call__(self, t):\n",
        "        return np.interp([t], self.knots, self.vals)[0]\n",
        "     \n",
        "class Const(namedtuple('Const', ['val'])):\n",
        "    def __call__(self, x):\n",
        "        return self.val\n",
        "\n",
        "#####################\n",
        "## DATA\n",
        "##################### \n",
        "\n",
        "import torchvision\n",
        "from functools import lru_cache as cache\n",
        "\n",
        "@cache(None)\n",
        "def cifar10(root='./data'):\n",
        "    download = lambda train: torchvision.datasets.CIFAR10(root=root, train=train, download=True)\n",
        "    return {k: {'data': torch.tensor(v.data), 'targets': torch.tensor(v.targets)} \n",
        "            for k,v in [('train', download(True)), ('valid', download(False))]}\n",
        "  \n",
        "cifar10_mean, cifar10_std = [\n",
        "    (125.31, 122.95, 113.87), # equals np.mean(cifar10()['train']['data'], axis=(0,1,2)) \n",
        "    (62.99, 62.09, 66.70), # equals np.std(cifar10()['train']['data'], axis=(0,1,2))\n",
        "]\n",
        "cifar10_classes= 'airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck'.split(', ')\n",
        "\n",
        "#####################\n",
        "## data preprocessing\n",
        "#####################\n",
        "mean, std = [torch.tensor(x, device=device, dtype=torch.float16) for x in (cifar10_mean, cifar10_std)]\n",
        "\n",
        "normalise = lambda data, mean=mean, std=std: (data - mean)/std\n",
        "unnormalise = lambda data, mean=mean, std=std: data*std + mean\n",
        "pad = lambda data, border: nn.ReflectionPad2d(border)(data)\n",
        "transpose = lambda x, source='NHWC', target='NCHW': x.permute([source.index(d) for d in target]) \n",
        "to = lambda *args, **kwargs: (lambda x: x.to(*args, **kwargs))\n",
        "\n",
        "def preprocess(dataset, transforms):\n",
        "    dataset = copy.copy(dataset)\n",
        "    for transform in reversed(transforms):\n",
        "        dataset['data'] = transform(dataset['data'])\n",
        "    return dataset\n",
        "\n",
        "#####################\n",
        "## Data augmentation\n",
        "#####################\n",
        "\n",
        "chunks = lambda data, splits: (data[start:end] for (start, end) in zip(splits, splits[1:]))\n",
        "\n",
        "even_splits = lambda N, num_chunks: np.cumsum([0] + [(N//num_chunks)+1]*(N % num_chunks)  + [N//num_chunks]*(num_chunks - (N % num_chunks)))\n",
        "\n",
        "def shuffled(xs, inplace=False):\n",
        "    xs = xs if inplace else copy.copy(xs) \n",
        "    np.random.shuffle(xs)\n",
        "    return xs\n",
        "\n",
        "def transformed(data, targets, transform, max_options=None, unshuffle=False):\n",
        "    i = torch.randperm(len(data), device=device)\n",
        "    data = data[i]\n",
        "    options = shuffled(transform.options(data.shape), inplace=True)[:max_options]\n",
        "    data = torch.cat([transform.apply(x, **choice) for choice, x in zip(options, chunks(data, even_splits(len(data), len(options))))])\n",
        "    return (data[torch.argsort(i)], targets) if unshuffle else (data, targets[i])\n",
        "\n",
        "class Batches():\n",
        "    def __init__(self, batch_size, transforms=(), dataset=None, shuffle=True, drop_last=False, max_options=None):\n",
        "        self.dataset, self.transforms, self.shuffle, self.max_options = dataset, transforms, shuffle, max_options\n",
        "        N = len(dataset['data'])\n",
        "        self.splits = list(range(0, N+1, batch_size))\n",
        "        if not drop_last and self.splits[-1] != N:\n",
        "            self.splits.append(N)\n",
        "     \n",
        "    def __iter__(self):\n",
        "        data, targets = self.dataset['data'], self.dataset['targets']\n",
        "        for transform in self.transforms:\n",
        "            data, targets = transformed(data, targets, transform, max_options=self.max_options, unshuffle=not self.shuffle)\n",
        "        if self.shuffle:\n",
        "            i = torch.randperm(len(data), device=device)\n",
        "            data, targets = data[i], targets[i]\n",
        "        return ({'input': x.clone(), 'target': y} for (x, y) in zip(chunks(data, self.splits), chunks(targets, self.splits)))\n",
        "    \n",
        "    def __len__(self): \n",
        "        return len(self.splits) - 1\n",
        "    \n",
        "#####################\n",
        "## Augmentations\n",
        "#####################\n",
        "\n",
        "class Crop(namedtuple('Crop', ('h', 'w'))):\n",
        "    def apply(self, x, x0, y0):\n",
        "        return x[..., y0:y0+self.h, x0:x0+self.w] \n",
        "\n",
        "    def options(self, shape):\n",
        "        *_, H, W = shape\n",
        "        return [{'x0': x0, 'y0': y0} for x0 in range(W+1-self.w) for y0 in range(H+1-self.h)]\n",
        "    \n",
        "class FlipLR(namedtuple('FlipLR', ())):\n",
        "    def apply(self, x, choice):\n",
        "        return flip_lr(x) if choice else x \n",
        "        \n",
        "    def options(self, shape):\n",
        "        return [{'choice': b} for b in [True, False]]\n",
        "\n",
        "class Cutout(namedtuple('Cutout', ('h', 'w'))):\n",
        "    def apply(self, x, x0, y0):\n",
        "        x[..., y0:y0+self.h, x0:x0+self.w] = 0.0\n",
        "        return x\n",
        "\n",
        "    def options(self, shape):\n",
        "        *_, H, W = shape\n",
        "        return [{'x0': x0, 'y0': y0} for x0 in range(W+1-self.w) for y0 in range(H+1-self.h)]  \n",
        "\n",
        "#####################\n",
        "## TRAINING\n",
        "#####################\n",
        "\n",
        "import time\n",
        "\n",
        "class Timer():\n",
        "    def __init__(self, synch=None):\n",
        "        self.synch = synch or (lambda: None)\n",
        "        self.synch()\n",
        "        self.times = [time.perf_counter()]\n",
        "        self.total_time = 0.0\n",
        "\n",
        "    def __call__(self, update_total=True):\n",
        "        self.synch()\n",
        "        self.times.append(time.perf_counter())\n",
        "        delta_t = self.times[-1] - self.times[-2]\n",
        "        if update_total:\n",
        "            self.total_time += delta_t\n",
        "        return delta_t\n",
        "\n",
        "default_table_formats = {float: '{:{w}.4f}', str: '{:>{w}s}', 'default': '{:{w}}', 'title': '{:>{w}s}'}\n",
        "\n",
        "def table_formatter(val, is_title=False, col_width=12, formats=None):\n",
        "    formats = formats or default_table_formats\n",
        "    type_ = lambda val: float if isinstance(val, (float, np.float)) else type(val)\n",
        "    return (formats['title'] if is_title else formats.get(type_(val), formats['default'])).format(val, w=col_width)\n",
        "\n",
        "every = lambda n, col: (lambda data: data[col] % n == 0)\n",
        "\n",
        "class Table():\n",
        "    def __init__(self, keys=None, report=(lambda data: True), formatter=table_formatter):\n",
        "        self.keys, self.report, self.formatter = keys, report, formatter\n",
        "        self.log = []\n",
        "        \n",
        "    def append(self, data):\n",
        "        self.log.append(data)\n",
        "        data = {' '.join(p): v for p,v in path_iter(data)}\n",
        "        self.keys = self.keys or data.keys()\n",
        "        if len(self.log) is 1:\n",
        "            print(*(self.formatter(k, True) for k in self.keys))\n",
        "        if self.report(data):\n",
        "            print(*(self.formatter(data[k]) for k in self.keys))\n",
        "            \n",
        "    def df(self):\n",
        "        return pd.DataFrame([{'_'.join(p): v for p,v in path_iter(row)} for row in self.log])     \n",
        "            \n",
        "def reduce(batches, state, steps):\n",
        "    #state: is a dictionary\n",
        "    #steps: are functions that take (batch, state)\n",
        "    #and return a dictionary of updates to the state (or None)\n",
        "    \n",
        "    for batch in chain(batches, [None]): \n",
        "    #we send an extra batch=None at the end for steps that \n",
        "    #need to do some tidying-up (e.g. log_activations)\n",
        "        for step in steps:\n",
        "            updates = step(batch, state)\n",
        "            if updates:\n",
        "                for k,v in updates.items():\n",
        "                    state[k] = v                  \n",
        "    return state\n",
        "  \n",
        "#define keys in the state dict as constants\n",
        "MODEL = 'model'\n",
        "VALID_MODEL = 'valid_model'\n",
        "OUTPUT = 'output'\n",
        "OPTS = 'optimisers'\n",
        "ACT_LOG = 'activation_log'\n",
        "WEIGHT_LOG = 'weight_log'\n",
        "\n",
        "#step definitions\n",
        "def forward(training_mode):\n",
        "    def step(batch, state):\n",
        "        if not batch: return\n",
        "        model = state[MODEL] if training_mode or (VALID_MODEL not in state) else state[VALID_MODEL]\n",
        "        if model.training != training_mode: #without the guard it's slow!\n",
        "            model.train(training_mode)\n",
        "        return {OUTPUT: model.loss(model(batch))}\n",
        "    return step\n",
        "\n",
        "def forward_tta(tta_transforms):\n",
        "    def step(batch, state):\n",
        "        if not batch: return\n",
        "        model = state[MODEL] if (VALID_MODEL not in state) else state[VALID_MODEL]\n",
        "        if model.training:\n",
        "            model.train(False)\n",
        "        logits = torch.mean(torch.stack([model({'input': transform(batch['input'].clone())})['logits'].detach() for transform in tta_transforms], dim=0), dim=0)\n",
        "        return {OUTPUT: model.loss(dict(batch, logits=logits))}\n",
        "    return step\n",
        "\n",
        "def backward(dtype=torch.float16):\n",
        "    def step(batch, state):\n",
        "        state[MODEL].zero_grad()\n",
        "        if not batch: return\n",
        "        state[OUTPUT]['loss'].to(dtype).sum().backward()\n",
        "    return step\n",
        "\n",
        "def opt_steps(batch, state):\n",
        "    if not batch: return\n",
        "    return {OPTS: [opt_step(**opt) for opt in state[OPTS]]}\n",
        "\n",
        "def log_activations(node_names=('loss', 'acc')):\n",
        "    logs = []\n",
        "    def step(batch, state):\n",
        "        if batch:\n",
        "            logs.extend((k, state[OUTPUT][k].detach()) for k in node_names)\n",
        "        else:\n",
        "            res = map_values((lambda xs: to_numpy(torch.cat(xs)).astype(np.float)), group_by_key(logs))\n",
        "            logs.clear()\n",
        "            return {ACT_LOG: res}\n",
        "    return step\n",
        "\n",
        "def update_ema(momentum, update_freq=1):\n",
        "    n = iter(count())\n",
        "    rho = momentum**update_freq\n",
        "    def step(batch, state):\n",
        "        if not batch: return\n",
        "        if (next(n) % update_freq) != 0: return\n",
        "        for v, ema_v in zip(state[MODEL].state_dict().values(), state[VALID_MODEL].state_dict().values()):\n",
        "            ema_v *= rho\n",
        "            ema_v += (1-rho)*v\n",
        "    return step\n",
        "\n",
        "train_steps = (forward(training_mode=True), log_activations(('loss', 'acc')), backward(), opt_steps)\n",
        "valid_steps = (forward(training_mode=False), log_activations(('loss', 'acc')))\n",
        "\n",
        "epoch_stats = lambda state: {k: np.mean(v) for k, v in state[ACT_LOG].items()}\n",
        "\n",
        "def train_epoch(state, timer, train_batches, valid_batches, train_steps=train_steps, valid_steps=valid_steps, on_epoch_end=identity):\n",
        "    train_summary, train_time = epoch_stats(on_epoch_end(reduce(train_batches, state, train_steps))), timer()\n",
        "    valid_summary, valid_time = epoch_stats(reduce(valid_batches, state, valid_steps)), timer(update_total=False) #DAWNBench rules\n",
        "    return {\n",
        "        'train': union({'time': train_time}, train_summary), \n",
        "        'valid': union({'time': valid_time}, valid_summary), \n",
        "        'total time': timer.total_time\n",
        "    }\n",
        "\n",
        "summary = lambda logs, cols=['valid_acc']: logs.df().query('epoch==epoch.max()')[cols].describe().transpose().astype({'count': int})[\n",
        "    ['count', 'mean', 'min', 'max', 'std']]\n",
        "\n",
        "#on_epoch_end\n",
        "def log_weights(state, weights):\n",
        "    state[WEIGHT_LOG] = state.get(WEIGHT_LOG, [])\n",
        "    state[WEIGHT_LOG].append({k: to_numpy(v.data) for k,v in weights.items()})\n",
        "    return state\n",
        "\n",
        "def fine_tune_bn_stats(state, batches, model_key=VALID_MODEL):\n",
        "    reduce(batches, {MODEL: state[model_key]}, [forward(True)])\n",
        "    return state\n",
        "\n",
        "#misc\n",
        "def warmup_cudnn(model, batch):\n",
        "    #run forward and backward pass of the model\n",
        "    #to allow benchmarking of cudnn kernels \n",
        "    reduce([batch], {MODEL: model}, [forward(True), backward()])\n",
        "    torch.cuda.synchronize()\n",
        "\n",
        "\n",
        "#####################\n",
        "## Plotting\n",
        "#####################\n",
        "\n",
        "import altair as alt\n",
        "alt.renderers.enable('colab')\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import SVG\n",
        "\n",
        "def empty_plot(ax, **kw):\n",
        "    ax.axis('off')\n",
        "    return ax\n",
        "\n",
        "def image_plot(ax, img, title):\n",
        "    ax.imshow(to_numpy(unnormalise(transpose(img, 'CHW', 'HWC'))).astype(np.int))\n",
        "    ax.set_title(title)\n",
        "    ax.axis('off')\n",
        "\n",
        "def layout(figures, sharex=False, sharey=False, figure_title=None, col_width=4, row_height = 3.25, **kw):\n",
        "    nrows, ncols = np.array(figures).shape\n",
        "\n",
        "    fig, axs = plt.subplots(nrows=nrows, ncols=ncols, sharex=sharex, sharey=sharey, figsize=(col_width*ncols, row_height*nrows))\n",
        "    axs = [figure(ax, **kw) for row in zip(np.array(axs).reshape(nrows, ncols), figures) for ax, figure in zip(*row)]\n",
        "    fig.suptitle(figure_title)\n",
        "    return fig, axs\n",
        "\n",
        "#####################\n",
        "## Network\n",
        "#####################\n",
        "\n",
        "conv_block = lambda c_in, c_out: {\n",
        "    'conv': conv(in_channels=c_in, out_channels=c_out, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), \n",
        "    'norm': batch_norm(c_out), \n",
        "    'act':  relu(),\n",
        "}\n",
        "\n",
        "conv_pool_block = lambda c_in, c_out: dict(conv_block(c_in, c_out), pool=pool(2))\n",
        "conv_pool_block_pre = lambda c_in, c_out: reorder(conv_pool_block(c_in, c_out), ('conv', 'pool', 'norm', 'act'))\n",
        "\n",
        "residual = lambda c, conv_block: {\n",
        "    'in': (Identity, {}),\n",
        "    'res1': conv_block(c, c),\n",
        "    'res2': conv_block(c, c),\n",
        "    'out': (Identity, {}),\n",
        "    'add': (Add, {}, ['in', 'out']),\n",
        "}\n",
        "\n",
        "def build_network(channels, extra_layers, res_layers, scale, conv_block=conv_block, \n",
        "                  prep_block=conv_block, conv_pool_block=conv_pool_block, types=None): \n",
        "    net = {\n",
        "        'prep': prep_block(3, channels['prep']),\n",
        "        'layer1': conv_pool_block(channels['prep'], channels['layer1']),\n",
        "        'layer2': conv_pool_block(channels['layer1'], channels['layer2']),\n",
        "        'layer3': conv_pool_block(channels['layer2'], channels['layer3']),\n",
        "        'pool': pool(4),\n",
        "        'classifier': {\n",
        "            'flatten': (Flatten, {}),\n",
        "            'conv': linear(channels['layer3'], 10, bias=False),\n",
        "            'scale': (Mul, {'weight': scale}),\n",
        "        },\n",
        "        'logits': (Identity, {}),\n",
        "    }\n",
        "    for layer in res_layers:\n",
        "        net[layer]['residual'] = residual(channels[layer], conv_block)\n",
        "    for layer in extra_layers:\n",
        "        net[layer]['extra'] = conv_block(channels[layer], channels[layer])     \n",
        "    if types: net = map_types(types, net)\n",
        "    return net\n",
        "\n",
        "channels={'prep': 64, 'layer1': 128, 'layer2': 256, 'layer3': 512}\n",
        "network = partial(build_network, channels=channels, extra_layers=(), res_layers=('layer1', 'layer3'), scale=1/8)   \n",
        "\n",
        "x_ent_loss = Network({\n",
        "  'loss':  (nn.CrossEntropyLoss, {'reduction': 'none'}, ['logits', 'target']),\n",
        "  'acc': (Correct, {}, ['logits', 'target'])\n",
        "})\n",
        "\n",
        "label_smoothing_loss = lambda alpha: Network({\n",
        "        'logprobs': (LogSoftmax, {'dim': 1}, ['logits']),\n",
        "        'KL':  (KLLoss, {}, ['logprobs']),\n",
        "        'xent':  (CrossEntropyLoss, {}, ['logprobs', 'target']),\n",
        "        'loss': (AddWeighted, {'wx': 1-alpha, 'wy': alpha}, ['xent', 'KL']),\n",
        "        'acc': (Correct, {}, ['logits', 'target']),\n",
        "    })\n",
        "\n",
        "#####################\n",
        "## Misc\n",
        "#####################\n",
        "\n",
        "lr_schedule = lambda knots, vals, batch_size: PiecewiseLinear(np.array(knots)*len(train_batches(batch_size)), np.array(vals)/batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izQpvJHoBnAx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#####################\n",
        "## Config\n",
        "#####################\n",
        "\n",
        "N_RUNS = 5 #number of times to run each experiment"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tofkr8ecBqgF",
        "colab_type": "text"
      },
      "source": [
        "### Baseline (75s)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kngp4RTwBKNl",
        "colab_type": "text"
      },
      "source": [
        "First we should check that timings haven't changed since November and our submission still runs in 75 seconds (note that this requires a V100 GPU, see instructions at the top of the notebook for how to use one from Colab.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "223954b6-7667-45e7-a05d-56b04a4f5f9b",
        "id": "n___bs94Rvm2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        }
      },
      "source": [
        "!git clone -q https://github.com/davidcpage/cifar10-fast.git\n",
        "!cd cifar10-fast && python -m dawn --data_dir=~/data "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading datasets\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /root/data/cifar-10-python.tar.gz\n",
            "170500096it [00:01, 86072427.47it/s]                   \n",
            "Files already downloaded and verified\n",
            "Warming up cudnn on random inputs\n",
            "Starting timer\n",
            "Preprocessing training data\n",
            "Finished in 2.6 seconds\n",
            "Preprocessing test data\n",
            "Finished in 0.085 seconds\n",
            "       epoch           lr   train time   train loss    train acc    test time    test loss     test acc   total time\n",
            "           1       0.0800      11.3172       1.6122       0.4191       0.6688       1.1063       0.6060      14.0197\n",
            "           2       0.1600      11.4894       0.9398       0.6681       0.6848       1.5387       0.5579      25.5091\n",
            "           3       0.2400      11.7494       0.7313       0.7443       0.6997       0.8398       0.7127      37.2585\n",
            "           4       0.3200      11.8132       0.6262       0.7816       0.7163       0.9213       0.6928      49.0716\n",
            "           5       0.4000      12.1061       0.5615       0.8065       0.7218       0.6149       0.7836      61.1777\n",
            "           6       0.3789      11.8667       0.4987       0.8278       0.7076       0.5109       0.8212      73.0445\n",
            "           7       0.3579      11.7827       0.4418       0.8484       0.6971       0.5462       0.8081      84.8272\n",
            "           8       0.3368      11.7727       0.4087       0.8607       0.6915       0.4667       0.8376      96.5999\n",
            "           9       0.3158      11.7779       0.3851       0.8691       0.6909       0.5176       0.8212     108.3778\n",
            "          10       0.2947      11.7705       0.3671       0.8741       0.6950       0.4428       0.8490     120.1482\n",
            "          11       0.2737      11.7738       0.3463       0.8820       0.6956       0.4155       0.8606     131.9221\n",
            "          12       0.2526      11.7876       0.3235       0.8914       0.6991       0.6483       0.7885     143.7096\n",
            "          13       0.2316      11.7724       0.3056       0.8966       0.6980       0.3970       0.8653     155.4821\n",
            "          14       0.2105      11.7704       0.2929       0.8997       0.6954       0.3869       0.8679     167.2524\n",
            "          15       0.1895      11.7709       0.2725       0.9081       0.6944       0.3827       0.8691     179.0234\n",
            "          16       0.1684      11.7735       0.2511       0.9163       0.6941       0.3523       0.8826     190.7968\n",
            "          17       0.1474      11.7761       0.2267       0.9231       0.6938       0.3197       0.8942     202.5729\n",
            "          18       0.1263      11.7739       0.2152       0.9288       0.6947       0.3158       0.8902     214.3468\n",
            "          19       0.1053      11.7759       0.1871       0.9369       0.6953       0.3364       0.8882     226.1228\n",
            "          20       0.0842      11.7727       0.1650       0.9454       0.6952       0.3245       0.8971     237.8954\n",
            "          21       0.0632      11.7739       0.1418       0.9540       0.6959       0.2560       0.9159     249.6693\n",
            "          22       0.0421      11.7729       0.1148       0.9638       0.6950       0.2138       0.9299     261.4423\n",
            "          23       0.0211      11.7859       0.0929       0.9733       0.6954       0.1989       0.9360     273.2281\n",
            "          24       0.0000      11.7754       0.0762       0.9784       0.6963       0.1825       0.9402     285.0036\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6woN6tKcCLLy",
        "colab_type": "text"
      },
      "source": [
        "Training indeed reaches ~94% test accuracy and completes in about 75s. We will need to cut this in half and then a bit more....\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOPAnn6orgLn",
        "colab_type": "text"
      },
      "source": [
        "### Preprocessing on the GPU (70s)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WyIgaE0Yr6wl",
        "colab_type": "text"
      },
      "source": [
        "We start with the practical matter of some code optimisation. The logs above show three seconds wasted on data preprocessing, which counts towards training time. Recall that we are normalising, transposing and padding the dataset before training to avoid repeating the work at each epoch.\n",
        "\n",
        "We can do better by transferring the data to the GPU, preprocessing there and then transferring back to the CPU for random data augmentation and batching:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-y1gWp1zsWA",
        "colab_type": "code",
        "outputId": "eca7b431-19e9-48f3-e2d4-60686f23fc0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "#####################\n",
        "## timings\n",
        "#####################\n",
        "dataset = cifar10() #downloads dataset\n",
        "print('Starting timer')\n",
        "t = Timer(synch=torch.cuda.synchronize)\n",
        "dataset = map_nested(to(device), dataset)\n",
        "print(f'Transfer to GPU:\\t{t():.3f}s')\n",
        "train_set = preprocess(dataset['train'], [partial(pad, border=4), transpose, normalise, to(torch.float16)])\n",
        "valid_set = preprocess(dataset['valid'], [transpose, normalise, to(torch.float16)])\n",
        "print(f'Data preprocessing:\\t{t():.3f}s')\n",
        "map_nested(to(cpu), {'train': train_set, 'valid': valid_set})\n",
        "print(f'Transfer to CPU:\\t{t():.3f}s')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/170498071 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "170500096it [00:01, 90174739.00it/s]                               \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Starting timer\n",
            "Transfer to GPU:\t0.036s\n",
            "Data preprocessing:\t0.049s\n",
            "Transfer to CPU:\t0.515s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDVW85kFex8c",
        "colab_type": "text"
      },
      "source": [
        "Not bad! We've reduced the preprocessing time to about half a second. Actual preprocessing now takes a negligible amount of time and the bulk of time is spent transferring data back to the CPU. This is a bit silly, since the data will need to cross to the GPU again after batching and augmentation, incurring a further delay at each training step. Can we remove this by doing data augmentation on the GPU?\n",
        "\n",
        "The answer is yes, but it requires a little care. If we naively apply augmentation to individual training examples, as on the CPU, we will incur substantial overhead launching multiple GPU kernels to process each item. We can avoid this by applying the same augmentation to groups of examples and we can preserve randomness by shuffling the data beforehand.\n",
        "\n",
        "For example, consider applying 8Ã—8 cutout augmentation to CIFAR10 images. There are 625 possible 8Ã—8 cutout regions in a  32Ã—32 image, so we can achieve random augmentation by shuffling the dataset and splitting into 625 groups, one for each of the possible cutout regions. If we choose evenly-sized groups, this is not quite the same as making a random choice for each example (which leads to irregular group sizes) but it's close enough. As a further optimisation, if the number of groups for an augmentation becomes too large, we can consider capping it at a reasonable limit - say 200 randomly selected groups per epoch.\n",
        "\n",
        "Our basic implementation takes about 35 lines of code and doesn't use Pytorch DataLoaders."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNz7-dE7fE5J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_batches = partial(Batches, dataset=train_set, shuffle=True,  drop_last=True, max_options=200)\n",
        "valid_batches = partial(Batches, dataset=valid_set, shuffle=False, drop_last=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwHDoIF807rV",
        "colab_type": "text"
      },
      "source": [
        "As a sanity check that we're doing things correctly - here are two random augmentations of the same 8 images:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hF3Grkd1OVW",
        "colab_type": "code",
        "outputId": "fd915dcb-9595-4c70-e75e-e542be8a8756",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "source": [
        "batches = train_batches(batch_size=8, transforms=(Crop(32, 32), FlipLR(), Cutout(8, 8)), shuffle=False)\n",
        "\n",
        "layout([[partial(image_plot, img=x, title=cifar10_classes[y]) for x,y in zip(*next(iter(batches)).values())]], col_width=2, row_height=2)\n",
        "layout([[partial(image_plot, img=x, title=cifar10_classes[y]) for x,y in zip(*next(iter(batches)).values())]], col_width=2, row_height=2);"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA54AAACOCAYAAABZsdfhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 1152x144 with 8 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA54AAACOCAYAAABZsdfhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 1152x144 with 8 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvhwlXlDtEwQ",
        "colab_type": "text"
      },
      "source": [
        "Now let's see how fast it is:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0YBtX02q8T6",
        "colab_type": "code",
        "outputId": "9fbebe12-46b7-4818-e58b-96a3379e308c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "t = Timer(synch=torch.cuda.synchronize)\n",
        "batches = train_batches(batch_size=512, transforms=(Crop(32, 32), FlipLR(), Cutout(8, 8)))\n",
        "\n",
        "for epoch in range(24):\n",
        "    for batch in batches:\n",
        "        pass\n",
        "print(f'{t():.3f}s')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.082s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-mg89jmtg1A",
        "colab_type": "text"
      },
      "source": [
        "This is great! We're able to iterate through 24 epochs of training data, applying data augmentation and shuffling in less than the time taken to transfer the dataset once to the CPU! Moreover, since we're no longer racing CPU preprocessing queues against the GPU, we can stop worrying about dataloading altogether, even if training gets faster. Note: we are relying on the fact that the dataset is small enough to store and manipulate as a whole in GPU memory, but a more sophisticated implementation could work around this - or one could switch to an industrial strength solution such as [Nvidia DALI](https://github.com/NVIDIA/DALI).\n",
        "\n",
        "Let's see if this gives us a speedup on our baseline. The code we use here is essentially equivalent to the DAWNBench submission, apart from the GPU data processing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNFoYZEjH_w8",
        "colab_type": "code",
        "outputId": "6bb6b00a-b454-42d0-a340-1617ebd0d9c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "baseline_net=network()\n",
        "show(baseline_net)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<__main__.DotGraph at 0x7f7f2813d438>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: G Pages: 1 -->\n<svg width=\"1080pt\" height=\"64pt\"\n viewBox=\"0.00 0.00 1080.00 64.20\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(.3102 .3102) rotate(0) translate(4 203)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-203 3478,-203 3478,4 -4,4\"/>\n<g id=\"clust1\" class=\"cluster\">\n<title>cluster_prep</title>\n<path fill=\"#777777\" fill-opacity=\"0.266667\" stroke=\"#000000\" d=\"M94,-44C94,-44 320,-44 320,-44 326,-44 332,-50 332,-56 332,-56 332,-107 332,-107 332,-113 326,-119 320,-119 320,-119 94,-119 94,-119 88,-119 82,-113 82,-107 82,-107 82,-56 82,-56 82,-50 88,-44 94,-44\"/>\n<text text-anchor=\"middle\" x=\"207\" y=\"-103.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">prep</text>\n</g>\n<g id=\"clust2\" class=\"cluster\">\n<title>cluster_layer1</title>\n<path fill=\"#777777\" fill-opacity=\"0.266667\" stroke=\"#000000\" d=\"M364,-8C364,-8 1498,-8 1498,-8 1504,-8 1510,-14 1510,-20 1510,-20 1510,-159 1510,-159 1510,-165 1504,-171 1498,-171 1498,-171 364,-171 364,-171 358,-171 352,-165 352,-159 352,-159 352,-20 352,-20 352,-14 358,-8 364,-8\"/>\n<text text-anchor=\"middle\" x=\"931\" y=\"-155.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">layer1</text>\n</g>\n<g id=\"clust3\" class=\"cluster\">\n<title>cluster_layer1_residual</title>\n<path fill=\"#777777\" fill-opacity=\"0.266667\" stroke=\"#000000\" d=\"M724,-16C724,-16 1490,-16 1490,-16 1496,-16 1502,-22 1502,-28 1502,-28 1502,-128 1502,-128 1502,-134 1496,-140 1490,-140 1490,-140 724,-140 724,-140 718,-140 712,-134 712,-128 712,-128 712,-28 712,-28 712,-22 718,-16 724,-16\"/>\n<text text-anchor=\"middle\" x=\"1107\" y=\"-124.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">residual</text>\n</g>\n<g id=\"clust4\" class=\"cluster\">\n<title>cluster_layer1_residual_res1</title>\n<path fill=\"#777777\" fill-opacity=\"0.266667\" stroke=\"#000000\" d=\"M814,-24C814,-24 1040,-24 1040,-24 1046,-24 1052,-30 1052,-36 1052,-36 1052,-87 1052,-87 1052,-93 1046,-99 1040,-99 1040,-99 814,-99 814,-99 808,-99 802,-93 802,-87 802,-87 802,-36 802,-36 802,-30 808,-24 814,-24\"/>\n<text text-anchor=\"middle\" x=\"927\" y=\"-83.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">res1</text>\n</g>\n<g id=\"clust5\" class=\"cluster\">\n<title>cluster_layer1_residual_res2</title>\n<path fill=\"#777777\" fill-opacity=\"0.266667\" stroke=\"#000000\" d=\"M1084,-24C1084,-24 1310,-24 1310,-24 1316,-24 1322,-30 1322,-36 1322,-36 1322,-87 1322,-87 1322,-93 1316,-99 1310,-99 1310,-99 1084,-99 1084,-99 1078,-99 1072,-93 1072,-87 1072,-87 1072,-36 1072,-36 1072,-30 1078,-24 1084,-24\"/>\n<text text-anchor=\"middle\" x=\"1197\" y=\"-83.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">res2</text>\n</g>\n<g id=\"clust6\" class=\"cluster\">\n<title>cluster_layer2</title>\n<path fill=\"#777777\" fill-opacity=\"0.266667\" stroke=\"#000000\" d=\"M1534,-54C1534,-54 1850,-54 1850,-54 1856,-54 1862,-60 1862,-66 1862,-66 1862,-117 1862,-117 1862,-123 1856,-129 1850,-129 1850,-129 1534,-129 1534,-129 1528,-129 1522,-123 1522,-117 1522,-117 1522,-66 1522,-66 1522,-60 1528,-54 1534,-54\"/>\n<text text-anchor=\"middle\" x=\"1692\" y=\"-113.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">layer2</text>\n</g>\n<g id=\"clust7\" class=\"cluster\">\n<title>cluster_layer3</title>\n<path fill=\"#777777\" fill-opacity=\"0.266667\" stroke=\"#000000\" d=\"M1894,-28C1894,-28 3028,-28 3028,-28 3034,-28 3040,-34 3040,-40 3040,-40 3040,-179 3040,-179 3040,-185 3034,-191 3028,-191 3028,-191 1894,-191 1894,-191 1888,-191 1882,-185 1882,-179 1882,-179 1882,-40 1882,-40 1882,-34 1888,-28 1894,-28\"/>\n<text text-anchor=\"middle\" x=\"2461\" y=\"-175.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">layer3</text>\n</g>\n<g id=\"clust8\" class=\"cluster\">\n<title>cluster_layer3_residual</title>\n<path fill=\"#777777\" fill-opacity=\"0.266667\" stroke=\"#000000\" d=\"M2254,-36C2254,-36 3020,-36 3020,-36 3026,-36 3032,-42 3032,-48 3032,-48 3032,-148 3032,-148 3032,-154 3026,-160 3020,-160 3020,-160 2254,-160 2254,-160 2248,-160 2242,-154 2242,-148 2242,-148 2242,-48 2242,-48 2242,-42 2248,-36 2254,-36\"/>\n<text text-anchor=\"middle\" x=\"2637\" y=\"-144.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">residual</text>\n</g>\n<g id=\"clust9\" class=\"cluster\">\n<title>cluster_layer3_residual_res1</title>\n<path fill=\"#777777\" fill-opacity=\"0.266667\" stroke=\"#000000\" d=\"M2344,-44C2344,-44 2570,-44 2570,-44 2576,-44 2582,-50 2582,-56 2582,-56 2582,-107 2582,-107 2582,-113 2576,-119 2570,-119 2570,-119 2344,-119 2344,-119 2338,-119 2332,-113 2332,-107 2332,-107 2332,-56 2332,-56 2332,-50 2338,-44 2344,-44\"/>\n<text text-anchor=\"middle\" x=\"2457\" y=\"-103.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">res1</text>\n</g>\n<g id=\"clust10\" class=\"cluster\">\n<title>cluster_layer3_residual_res2</title>\n<path fill=\"#777777\" fill-opacity=\"0.266667\" stroke=\"#000000\" d=\"M2614,-44C2614,-44 2840,-44 2840,-44 2846,-44 2852,-50 2852,-56 2852,-56 2852,-107 2852,-107 2852,-113 2846,-119 2840,-119 2840,-119 2614,-119 2614,-119 2608,-119 2602,-113 2602,-107 2602,-107 2602,-56 2602,-56 2602,-50 2608,-44 2614,-44\"/>\n<text text-anchor=\"middle\" x=\"2727\" y=\"-103.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">res2</text>\n</g>\n<g id=\"clust11\" class=\"cluster\">\n<title>cluster_classifier</title>\n<path fill=\"#777777\" fill-opacity=\"0.266667\" stroke=\"#000000\" d=\"M3154,-74C3154,-74 3380,-74 3380,-74 3386,-74 3392,-80 3392,-86 3392,-86 3392,-137 3392,-137 3392,-143 3386,-149 3380,-149 3380,-149 3154,-149 3154,-149 3148,-149 3142,-143 3142,-137 3142,-137 3142,-86 3142,-86 3142,-80 3148,-74 3154,-74\"/>\n<text text-anchor=\"middle\" x=\"3267\" y=\"-133.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">classifier</text>\n</g>\n<!-- prep_conv -->\n<g id=\"node1\" class=\"node\">\n<title>prep_conv</title>\n<g id=\"a_node1\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.conv.Conv2d&#39;&gt; {&#39;in_channels&#39;: 3, &#39;out_channels&#39;: 64, &#39;kernel_size&#39;: (3, 3), &#39;stride&#39;: (1, 1), &#39;padding&#39;: (1, 1), &#39;bias&#39;: False}\">\n<path fill=\"#bebada\" stroke=\"#000000\" d=\"M132,-88C132,-88 102,-88 102,-88 96,-88 90,-82 90,-76 90,-76 90,-64 90,-64 90,-58 96,-52 102,-52 102,-52 132,-52 132,-52 138,-52 144,-58 144,-64 144,-64 144,-76 144,-76 144,-82 138,-88 132,-88\"/>\n<text text-anchor=\"middle\" x=\"117\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">conv</text>\n</a>\n</g>\n</g>\n<!-- prep_norm -->\n<g id=\"node2\" class=\"node\">\n<title>prep_norm</title>\n<g id=\"a_node2\"><a xlink:title=\"&lt;class &#39;__main__.BatchNorm&#39;&gt; {&#39;num_features&#39;: 64}\">\n<path fill=\"#ffffb3\" stroke=\"#000000\" d=\"M222,-88C222,-88 192,-88 192,-88 186,-88 180,-82 180,-76 180,-76 180,-64 180,-64 180,-58 186,-52 192,-52 192,-52 222,-52 222,-52 228,-52 234,-58 234,-64 234,-64 234,-76 234,-76 234,-82 228,-88 222,-88\"/>\n<text text-anchor=\"middle\" x=\"207\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">norm</text>\n</a>\n</g>\n</g>\n<!-- prep_conv&#45;&gt;prep_norm -->\n<g id=\"edge2\" class=\"edge\">\n<title>prep_conv&#45;&gt;prep_norm</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M144.003,-70C152.0277,-70 160.9665,-70 169.5309,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"169.7051,-73.5001 179.705,-70 169.705,-66.5001 169.7051,-73.5001\"/>\n</g>\n<!-- prep_act -->\n<g id=\"node3\" class=\"node\">\n<title>prep_act</title>\n<g id=\"a_node3\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.activation.ReLU&#39;&gt; {}\">\n<path fill=\"#fb8072\" stroke=\"#000000\" d=\"M312,-88C312,-88 282,-88 282,-88 276,-88 270,-82 270,-76 270,-76 270,-64 270,-64 270,-58 276,-52 282,-52 282,-52 312,-52 312,-52 318,-52 324,-58 324,-64 324,-64 324,-76 324,-76 324,-82 318,-88 312,-88\"/>\n<text text-anchor=\"middle\" x=\"297\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">act</text>\n</a>\n</g>\n</g>\n<!-- prep_norm&#45;&gt;prep_act -->\n<g id=\"edge3\" class=\"edge\">\n<title>prep_norm&#45;&gt;prep_act</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M234.003,-70C242.0277,-70 250.9665,-70 259.5309,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"259.7051,-73.5001 269.705,-70 259.705,-66.5001 259.7051,-73.5001\"/>\n</g>\n<!-- layer1_conv -->\n<g id=\"node4\" class=\"node\">\n<title>layer1_conv</title>\n<g id=\"a_node4\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.conv.Conv2d&#39;&gt; {&#39;in_channels&#39;: 64, &#39;out_channels&#39;: 128, &#39;kernel_size&#39;: (3, 3), &#39;stride&#39;: (1, 1), &#39;padding&#39;: (1, 1), &#39;bias&#39;: False}\">\n<path fill=\"#bebada\" stroke=\"#000000\" d=\"M402,-88C402,-88 372,-88 372,-88 366,-88 360,-82 360,-76 360,-76 360,-64 360,-64 360,-58 366,-52 372,-52 372,-52 402,-52 402,-52 408,-52 414,-58 414,-64 414,-64 414,-76 414,-76 414,-82 408,-88 402,-88\"/>\n<text text-anchor=\"middle\" x=\"387\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">conv</text>\n</a>\n</g>\n</g>\n<!-- prep_act&#45;&gt;layer1_conv -->\n<g id=\"edge4\" class=\"edge\">\n<title>prep_act&#45;&gt;layer1_conv</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M324.003,-70C332.0277,-70 340.9665,-70 349.5309,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"349.7051,-73.5001 359.705,-70 349.705,-66.5001 349.7051,-73.5001\"/>\n</g>\n<!-- layer1_norm -->\n<g id=\"node5\" class=\"node\">\n<title>layer1_norm</title>\n<g id=\"a_node5\"><a xlink:title=\"&lt;class &#39;__main__.BatchNorm&#39;&gt; {&#39;num_features&#39;: 128}\">\n<path fill=\"#ffffb3\" stroke=\"#000000\" d=\"M492,-88C492,-88 462,-88 462,-88 456,-88 450,-82 450,-76 450,-76 450,-64 450,-64 450,-58 456,-52 462,-52 462,-52 492,-52 492,-52 498,-52 504,-58 504,-64 504,-64 504,-76 504,-76 504,-82 498,-88 492,-88\"/>\n<text text-anchor=\"middle\" x=\"477\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">norm</text>\n</a>\n</g>\n</g>\n<!-- layer1_conv&#45;&gt;layer1_norm -->\n<g id=\"edge5\" class=\"edge\">\n<title>layer1_conv&#45;&gt;layer1_norm</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M414.003,-70C422.0277,-70 430.9665,-70 439.5309,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"439.7051,-73.5001 449.705,-70 439.705,-66.5001 439.7051,-73.5001\"/>\n</g>\n<!-- layer1_act -->\n<g id=\"node6\" class=\"node\">\n<title>layer1_act</title>\n<g id=\"a_node6\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.activation.ReLU&#39;&gt; {}\">\n<path fill=\"#fb8072\" stroke=\"#000000\" d=\"M582,-88C582,-88 552,-88 552,-88 546,-88 540,-82 540,-76 540,-76 540,-64 540,-64 540,-58 546,-52 552,-52 552,-52 582,-52 582,-52 588,-52 594,-58 594,-64 594,-64 594,-76 594,-76 594,-82 588,-88 582,-88\"/>\n<text text-anchor=\"middle\" x=\"567\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">act</text>\n</a>\n</g>\n</g>\n<!-- layer1_norm&#45;&gt;layer1_act -->\n<g id=\"edge6\" class=\"edge\">\n<title>layer1_norm&#45;&gt;layer1_act</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M504.003,-70C512.0277,-70 520.9665,-70 529.5309,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"529.7051,-73.5001 539.705,-70 529.705,-66.5001 529.7051,-73.5001\"/>\n</g>\n<!-- layer1_pool -->\n<g id=\"node7\" class=\"node\">\n<title>layer1_pool</title>\n<g id=\"a_node7\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.pooling.MaxPool2d&#39;&gt; {&#39;kernel_size&#39;: 2}\">\n<path fill=\"#8dd3c7\" stroke=\"#000000\" d=\"M672,-88C672,-88 642,-88 642,-88 636,-88 630,-82 630,-76 630,-76 630,-64 630,-64 630,-58 636,-52 642,-52 642,-52 672,-52 672,-52 678,-52 684,-58 684,-64 684,-64 684,-76 684,-76 684,-82 678,-88 672,-88\"/>\n<text text-anchor=\"middle\" x=\"657\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">pool</text>\n</a>\n</g>\n</g>\n<!-- layer1_act&#45;&gt;layer1_pool -->\n<g id=\"edge7\" class=\"edge\">\n<title>layer1_act&#45;&gt;layer1_pool</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M594.003,-70C602.0277,-70 610.9665,-70 619.5309,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"619.7051,-73.5001 629.705,-70 619.705,-66.5001 619.7051,-73.5001\"/>\n</g>\n<!-- layer1_residual_in -->\n<g id=\"node8\" class=\"node\">\n<title>layer1_residual_in</title>\n<g id=\"a_node8\"><a xlink:title=\"&lt;class &#39;__main__.Identity&#39;&gt; {}\">\n<path fill=\"#80b1d3\" stroke=\"#000000\" d=\"M762,-88C762,-88 732,-88 732,-88 726,-88 720,-82 720,-76 720,-76 720,-64 720,-64 720,-58 726,-52 732,-52 732,-52 762,-52 762,-52 768,-52 774,-58 774,-64 774,-64 774,-76 774,-76 774,-82 768,-88 762,-88\"/>\n<text text-anchor=\"middle\" x=\"747\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">in</text>\n</a>\n</g>\n</g>\n<!-- layer1_pool&#45;&gt;layer1_residual_in -->\n<g id=\"edge8\" class=\"edge\">\n<title>layer1_pool&#45;&gt;layer1_residual_in</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M684.003,-70C692.0277,-70 700.9665,-70 709.5309,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"709.7051,-73.5001 719.705,-70 709.705,-66.5001 709.7051,-73.5001\"/>\n</g>\n<!-- layer1_residual_res1_conv -->\n<g id=\"node9\" class=\"node\">\n<title>layer1_residual_res1_conv</title>\n<g id=\"a_node9\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.conv.Conv2d&#39;&gt; {&#39;in_channels&#39;: 128, &#39;out_channels&#39;: 128, &#39;kernel_size&#39;: (3, 3), &#39;stride&#39;: (1, 1), &#39;padding&#39;: (1, 1), &#39;bias&#39;: False}\">\n<path fill=\"#bebada\" stroke=\"#000000\" d=\"M852,-68C852,-68 822,-68 822,-68 816,-68 810,-62 810,-56 810,-56 810,-44 810,-44 810,-38 816,-32 822,-32 822,-32 852,-32 852,-32 858,-32 864,-38 864,-44 864,-44 864,-56 864,-56 864,-62 858,-68 852,-68\"/>\n<text text-anchor=\"middle\" x=\"837\" y=\"-46.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">conv</text>\n</a>\n</g>\n</g>\n<!-- layer1_residual_in&#45;&gt;layer1_residual_res1_conv -->\n<g id=\"edge9\" class=\"edge\">\n<title>layer1_residual_in&#45;&gt;layer1_residual_res1_conv</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M774.003,-63.9993C782.1158,-62.1965 791.1631,-60.186 799.8131,-58.2638\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"800.7024,-61.6516 809.705,-56.0655 799.1839,-54.8183 800.7024,-61.6516\"/>\n</g>\n<!-- layer1_residual_add -->\n<g id=\"node16\" class=\"node\">\n<title>layer1_residual_add</title>\n<g id=\"a_node16\"><a xlink:title=\"&lt;class &#39;__main__.Add&#39;&gt; {}\">\n<path fill=\"#fdb462\" stroke=\"#000000\" d=\"M1482,-98C1482,-98 1452,-98 1452,-98 1446,-98 1440,-92 1440,-86 1440,-86 1440,-74 1440,-74 1440,-68 1446,-62 1452,-62 1452,-62 1482,-62 1482,-62 1488,-62 1494,-68 1494,-74 1494,-74 1494,-86 1494,-86 1494,-92 1488,-98 1482,-98\"/>\n<text text-anchor=\"middle\" x=\"1467\" y=\"-76.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">add</text>\n</a>\n</g>\n</g>\n<!-- layer1_residual_in&#45;&gt;layer1_residual_add -->\n<g id=\"edge16\" class=\"edge\">\n<title>layer1_residual_in&#45;&gt;layer1_residual_add</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M771.2203,-88.104C780.3892,-93.9663 791.2234,-99.7818 802,-103 855.2752,-118.9095 871.4,-108 927,-108 927,-108 927,-108 1287,-108 1336.7971,-108 1393.4324,-97.4074 1429.6554,-89.2525\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1430.8023,-92.5799 1439.7594,-86.9214 1429.2285,-85.7591 1430.8023,-92.5799\"/>\n</g>\n<!-- layer1_residual_res1_norm -->\n<g id=\"node10\" class=\"node\">\n<title>layer1_residual_res1_norm</title>\n<g id=\"a_node10\"><a xlink:title=\"&lt;class &#39;__main__.BatchNorm&#39;&gt; {&#39;num_features&#39;: 128}\">\n<path fill=\"#ffffb3\" stroke=\"#000000\" d=\"M942,-68C942,-68 912,-68 912,-68 906,-68 900,-62 900,-56 900,-56 900,-44 900,-44 900,-38 906,-32 912,-32 912,-32 942,-32 942,-32 948,-32 954,-38 954,-44 954,-44 954,-56 954,-56 954,-62 948,-68 942,-68\"/>\n<text text-anchor=\"middle\" x=\"927\" y=\"-46.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">norm</text>\n</a>\n</g>\n</g>\n<!-- layer1_residual_res1_conv&#45;&gt;layer1_residual_res1_norm -->\n<g id=\"edge10\" class=\"edge\">\n<title>layer1_residual_res1_conv&#45;&gt;layer1_residual_res1_norm</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M864.003,-50C872.0277,-50 880.9665,-50 889.5309,-50\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"889.7051,-53.5001 899.705,-50 889.705,-46.5001 889.7051,-53.5001\"/>\n</g>\n<!-- layer1_residual_res1_act -->\n<g id=\"node11\" class=\"node\">\n<title>layer1_residual_res1_act</title>\n<g id=\"a_node11\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.activation.ReLU&#39;&gt; {}\">\n<path fill=\"#fb8072\" stroke=\"#000000\" d=\"M1032,-68C1032,-68 1002,-68 1002,-68 996,-68 990,-62 990,-56 990,-56 990,-44 990,-44 990,-38 996,-32 1002,-32 1002,-32 1032,-32 1032,-32 1038,-32 1044,-38 1044,-44 1044,-44 1044,-56 1044,-56 1044,-62 1038,-68 1032,-68\"/>\n<text text-anchor=\"middle\" x=\"1017\" y=\"-46.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">act</text>\n</a>\n</g>\n</g>\n<!-- layer1_residual_res1_norm&#45;&gt;layer1_residual_res1_act -->\n<g id=\"edge11\" class=\"edge\">\n<title>layer1_residual_res1_norm&#45;&gt;layer1_residual_res1_act</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M954.003,-50C962.0277,-50 970.9665,-50 979.5309,-50\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"979.7051,-53.5001 989.705,-50 979.705,-46.5001 979.7051,-53.5001\"/>\n</g>\n<!-- layer1_residual_res2_conv -->\n<g id=\"node12\" class=\"node\">\n<title>layer1_residual_res2_conv</title>\n<g id=\"a_node12\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.conv.Conv2d&#39;&gt; {&#39;in_channels&#39;: 128, &#39;out_channels&#39;: 128, &#39;kernel_size&#39;: (3, 3), &#39;stride&#39;: (1, 1), &#39;padding&#39;: (1, 1), &#39;bias&#39;: False}\">\n<path fill=\"#bebada\" stroke=\"#000000\" d=\"M1122,-68C1122,-68 1092,-68 1092,-68 1086,-68 1080,-62 1080,-56 1080,-56 1080,-44 1080,-44 1080,-38 1086,-32 1092,-32 1092,-32 1122,-32 1122,-32 1128,-32 1134,-38 1134,-44 1134,-44 1134,-56 1134,-56 1134,-62 1128,-68 1122,-68\"/>\n<text text-anchor=\"middle\" x=\"1107\" y=\"-46.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">conv</text>\n</a>\n</g>\n</g>\n<!-- layer1_residual_res1_act&#45;&gt;layer1_residual_res2_conv -->\n<g id=\"edge12\" class=\"edge\">\n<title>layer1_residual_res1_act&#45;&gt;layer1_residual_res2_conv</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1044.003,-50C1052.0277,-50 1060.9665,-50 1069.5309,-50\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1069.7051,-53.5001 1079.705,-50 1069.705,-46.5001 1069.7051,-53.5001\"/>\n</g>\n<!-- layer1_residual_res2_norm -->\n<g id=\"node13\" class=\"node\">\n<title>layer1_residual_res2_norm</title>\n<g id=\"a_node13\"><a xlink:title=\"&lt;class &#39;__main__.BatchNorm&#39;&gt; {&#39;num_features&#39;: 128}\">\n<path fill=\"#ffffb3\" stroke=\"#000000\" d=\"M1212,-68C1212,-68 1182,-68 1182,-68 1176,-68 1170,-62 1170,-56 1170,-56 1170,-44 1170,-44 1170,-38 1176,-32 1182,-32 1182,-32 1212,-32 1212,-32 1218,-32 1224,-38 1224,-44 1224,-44 1224,-56 1224,-56 1224,-62 1218,-68 1212,-68\"/>\n<text text-anchor=\"middle\" x=\"1197\" y=\"-46.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">norm</text>\n</a>\n</g>\n</g>\n<!-- layer1_residual_res2_conv&#45;&gt;layer1_residual_res2_norm -->\n<g id=\"edge13\" class=\"edge\">\n<title>layer1_residual_res2_conv&#45;&gt;layer1_residual_res2_norm</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1134.003,-50C1142.0277,-50 1150.9665,-50 1159.5309,-50\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1159.7051,-53.5001 1169.705,-50 1159.705,-46.5001 1159.7051,-53.5001\"/>\n</g>\n<!-- layer1_residual_res2_act -->\n<g id=\"node14\" class=\"node\">\n<title>layer1_residual_res2_act</title>\n<g id=\"a_node14\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.activation.ReLU&#39;&gt; {}\">\n<path fill=\"#fb8072\" stroke=\"#000000\" d=\"M1302,-68C1302,-68 1272,-68 1272,-68 1266,-68 1260,-62 1260,-56 1260,-56 1260,-44 1260,-44 1260,-38 1266,-32 1272,-32 1272,-32 1302,-32 1302,-32 1308,-32 1314,-38 1314,-44 1314,-44 1314,-56 1314,-56 1314,-62 1308,-68 1302,-68\"/>\n<text text-anchor=\"middle\" x=\"1287\" y=\"-46.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">act</text>\n</a>\n</g>\n</g>\n<!-- layer1_residual_res2_norm&#45;&gt;layer1_residual_res2_act -->\n<g id=\"edge14\" class=\"edge\">\n<title>layer1_residual_res2_norm&#45;&gt;layer1_residual_res2_act</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1224.003,-50C1232.0277,-50 1240.9665,-50 1249.5309,-50\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1249.7051,-53.5001 1259.705,-50 1249.705,-46.5001 1249.7051,-53.5001\"/>\n</g>\n<!-- layer1_residual_out -->\n<g id=\"node15\" class=\"node\">\n<title>layer1_residual_out</title>\n<g id=\"a_node15\"><a xlink:title=\"&lt;class &#39;__main__.Identity&#39;&gt; {}\">\n<path fill=\"#80b1d3\" stroke=\"#000000\" d=\"M1392,-78C1392,-78 1362,-78 1362,-78 1356,-78 1350,-72 1350,-66 1350,-66 1350,-54 1350,-54 1350,-48 1356,-42 1362,-42 1362,-42 1392,-42 1392,-42 1398,-42 1404,-48 1404,-54 1404,-54 1404,-66 1404,-66 1404,-72 1398,-78 1392,-78\"/>\n<text text-anchor=\"middle\" x=\"1377\" y=\"-56.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">out</text>\n</a>\n</g>\n</g>\n<!-- layer1_residual_res2_act&#45;&gt;layer1_residual_out -->\n<g id=\"edge15\" class=\"edge\">\n<title>layer1_residual_res2_act&#45;&gt;layer1_residual_out</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1314.003,-53.0003C1322.0277,-53.892 1330.9665,-54.8852 1339.5309,-55.8368\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1339.3796,-59.3414 1349.705,-56.9672 1340.1527,-52.3842 1339.3796,-59.3414\"/>\n</g>\n<!-- layer1_residual_out&#45;&gt;layer1_residual_add -->\n<g id=\"edge17\" class=\"edge\">\n<title>layer1_residual_out&#45;&gt;layer1_residual_add</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1404.003,-66.0007C1412.1158,-67.8035 1421.1631,-69.814 1429.8131,-71.7362\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1429.1839,-75.1817 1439.705,-73.9345 1430.7024,-68.3484 1429.1839,-75.1817\"/>\n</g>\n<!-- layer2_conv -->\n<g id=\"node17\" class=\"node\">\n<title>layer2_conv</title>\n<g id=\"a_node17\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.conv.Conv2d&#39;&gt; {&#39;in_channels&#39;: 128, &#39;out_channels&#39;: 256, &#39;kernel_size&#39;: (3, 3), &#39;stride&#39;: (1, 1), &#39;padding&#39;: (1, 1), &#39;bias&#39;: False}\">\n<path fill=\"#bebada\" stroke=\"#000000\" d=\"M1572,-98C1572,-98 1542,-98 1542,-98 1536,-98 1530,-92 1530,-86 1530,-86 1530,-74 1530,-74 1530,-68 1536,-62 1542,-62 1542,-62 1572,-62 1572,-62 1578,-62 1584,-68 1584,-74 1584,-74 1584,-86 1584,-86 1584,-92 1578,-98 1572,-98\"/>\n<text text-anchor=\"middle\" x=\"1557\" y=\"-76.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">conv</text>\n</a>\n</g>\n</g>\n<!-- layer1_residual_add&#45;&gt;layer2_conv -->\n<g id=\"edge18\" class=\"edge\">\n<title>layer1_residual_add&#45;&gt;layer2_conv</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1494.003,-80C1502.0277,-80 1510.9665,-80 1519.5309,-80\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1519.7051,-83.5001 1529.705,-80 1519.705,-76.5001 1519.7051,-83.5001\"/>\n</g>\n<!-- layer2_norm -->\n<g id=\"node18\" class=\"node\">\n<title>layer2_norm</title>\n<g id=\"a_node18\"><a xlink:title=\"&lt;class &#39;__main__.BatchNorm&#39;&gt; {&#39;num_features&#39;: 256}\">\n<path fill=\"#ffffb3\" stroke=\"#000000\" d=\"M1662,-98C1662,-98 1632,-98 1632,-98 1626,-98 1620,-92 1620,-86 1620,-86 1620,-74 1620,-74 1620,-68 1626,-62 1632,-62 1632,-62 1662,-62 1662,-62 1668,-62 1674,-68 1674,-74 1674,-74 1674,-86 1674,-86 1674,-92 1668,-98 1662,-98\"/>\n<text text-anchor=\"middle\" x=\"1647\" y=\"-76.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">norm</text>\n</a>\n</g>\n</g>\n<!-- layer2_conv&#45;&gt;layer2_norm -->\n<g id=\"edge19\" class=\"edge\">\n<title>layer2_conv&#45;&gt;layer2_norm</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1584.003,-80C1592.0277,-80 1600.9665,-80 1609.5309,-80\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1609.7051,-83.5001 1619.705,-80 1609.705,-76.5001 1609.7051,-83.5001\"/>\n</g>\n<!-- layer2_act -->\n<g id=\"node19\" class=\"node\">\n<title>layer2_act</title>\n<g id=\"a_node19\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.activation.ReLU&#39;&gt; {}\">\n<path fill=\"#fb8072\" stroke=\"#000000\" d=\"M1752,-98C1752,-98 1722,-98 1722,-98 1716,-98 1710,-92 1710,-86 1710,-86 1710,-74 1710,-74 1710,-68 1716,-62 1722,-62 1722,-62 1752,-62 1752,-62 1758,-62 1764,-68 1764,-74 1764,-74 1764,-86 1764,-86 1764,-92 1758,-98 1752,-98\"/>\n<text text-anchor=\"middle\" x=\"1737\" y=\"-76.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">act</text>\n</a>\n</g>\n</g>\n<!-- layer2_norm&#45;&gt;layer2_act -->\n<g id=\"edge20\" class=\"edge\">\n<title>layer2_norm&#45;&gt;layer2_act</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1674.003,-80C1682.0277,-80 1690.9665,-80 1699.5309,-80\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1699.7051,-83.5001 1709.705,-80 1699.705,-76.5001 1699.7051,-83.5001\"/>\n</g>\n<!-- layer2_pool -->\n<g id=\"node20\" class=\"node\">\n<title>layer2_pool</title>\n<g id=\"a_node20\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.pooling.MaxPool2d&#39;&gt; {&#39;kernel_size&#39;: 2}\">\n<path fill=\"#8dd3c7\" stroke=\"#000000\" d=\"M1842,-98C1842,-98 1812,-98 1812,-98 1806,-98 1800,-92 1800,-86 1800,-86 1800,-74 1800,-74 1800,-68 1806,-62 1812,-62 1812,-62 1842,-62 1842,-62 1848,-62 1854,-68 1854,-74 1854,-74 1854,-86 1854,-86 1854,-92 1848,-98 1842,-98\"/>\n<text text-anchor=\"middle\" x=\"1827\" y=\"-76.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">pool</text>\n</a>\n</g>\n</g>\n<!-- layer2_act&#45;&gt;layer2_pool -->\n<g id=\"edge21\" class=\"edge\">\n<title>layer2_act&#45;&gt;layer2_pool</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1764.003,-80C1772.0277,-80 1780.9665,-80 1789.5309,-80\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1789.7051,-83.5001 1799.705,-80 1789.705,-76.5001 1789.7051,-83.5001\"/>\n</g>\n<!-- layer3_conv -->\n<g id=\"node21\" class=\"node\">\n<title>layer3_conv</title>\n<g id=\"a_node21\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.conv.Conv2d&#39;&gt; {&#39;in_channels&#39;: 256, &#39;out_channels&#39;: 512, &#39;kernel_size&#39;: (3, 3), &#39;stride&#39;: (1, 1), &#39;padding&#39;: (1, 1), &#39;bias&#39;: False}\">\n<path fill=\"#bebada\" stroke=\"#000000\" d=\"M1932,-98C1932,-98 1902,-98 1902,-98 1896,-98 1890,-92 1890,-86 1890,-86 1890,-74 1890,-74 1890,-68 1896,-62 1902,-62 1902,-62 1932,-62 1932,-62 1938,-62 1944,-68 1944,-74 1944,-74 1944,-86 1944,-86 1944,-92 1938,-98 1932,-98\"/>\n<text text-anchor=\"middle\" x=\"1917\" y=\"-76.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">conv</text>\n</a>\n</g>\n</g>\n<!-- layer2_pool&#45;&gt;layer3_conv -->\n<g id=\"edge22\" class=\"edge\">\n<title>layer2_pool&#45;&gt;layer3_conv</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1854.003,-80C1862.0277,-80 1870.9665,-80 1879.5309,-80\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1879.7051,-83.5001 1889.705,-80 1879.705,-76.5001 1879.7051,-83.5001\"/>\n</g>\n<!-- layer3_norm -->\n<g id=\"node22\" class=\"node\">\n<title>layer3_norm</title>\n<g id=\"a_node22\"><a xlink:title=\"&lt;class &#39;__main__.BatchNorm&#39;&gt; {&#39;num_features&#39;: 512}\">\n<path fill=\"#ffffb3\" stroke=\"#000000\" d=\"M2022,-98C2022,-98 1992,-98 1992,-98 1986,-98 1980,-92 1980,-86 1980,-86 1980,-74 1980,-74 1980,-68 1986,-62 1992,-62 1992,-62 2022,-62 2022,-62 2028,-62 2034,-68 2034,-74 2034,-74 2034,-86 2034,-86 2034,-92 2028,-98 2022,-98\"/>\n<text text-anchor=\"middle\" x=\"2007\" y=\"-76.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">norm</text>\n</a>\n</g>\n</g>\n<!-- layer3_conv&#45;&gt;layer3_norm -->\n<g id=\"edge23\" class=\"edge\">\n<title>layer3_conv&#45;&gt;layer3_norm</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1944.003,-80C1952.0277,-80 1960.9665,-80 1969.5309,-80\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1969.7051,-83.5001 1979.705,-80 1969.705,-76.5001 1969.7051,-83.5001\"/>\n</g>\n<!-- layer3_act -->\n<g id=\"node23\" class=\"node\">\n<title>layer3_act</title>\n<g id=\"a_node23\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.activation.ReLU&#39;&gt; {}\">\n<path fill=\"#fb8072\" stroke=\"#000000\" d=\"M2112,-98C2112,-98 2082,-98 2082,-98 2076,-98 2070,-92 2070,-86 2070,-86 2070,-74 2070,-74 2070,-68 2076,-62 2082,-62 2082,-62 2112,-62 2112,-62 2118,-62 2124,-68 2124,-74 2124,-74 2124,-86 2124,-86 2124,-92 2118,-98 2112,-98\"/>\n<text text-anchor=\"middle\" x=\"2097\" y=\"-76.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">act</text>\n</a>\n</g>\n</g>\n<!-- layer3_norm&#45;&gt;layer3_act -->\n<g id=\"edge24\" class=\"edge\">\n<title>layer3_norm&#45;&gt;layer3_act</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2034.003,-80C2042.0277,-80 2050.9665,-80 2059.5309,-80\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2059.7051,-83.5001 2069.705,-80 2059.705,-76.5001 2059.7051,-83.5001\"/>\n</g>\n<!-- layer3_pool -->\n<g id=\"node24\" class=\"node\">\n<title>layer3_pool</title>\n<g id=\"a_node24\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.pooling.MaxPool2d&#39;&gt; {&#39;kernel_size&#39;: 2}\">\n<path fill=\"#8dd3c7\" stroke=\"#000000\" d=\"M2202,-98C2202,-98 2172,-98 2172,-98 2166,-98 2160,-92 2160,-86 2160,-86 2160,-74 2160,-74 2160,-68 2166,-62 2172,-62 2172,-62 2202,-62 2202,-62 2208,-62 2214,-68 2214,-74 2214,-74 2214,-86 2214,-86 2214,-92 2208,-98 2202,-98\"/>\n<text text-anchor=\"middle\" x=\"2187\" y=\"-76.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">pool</text>\n</a>\n</g>\n</g>\n<!-- layer3_act&#45;&gt;layer3_pool -->\n<g id=\"edge25\" class=\"edge\">\n<title>layer3_act&#45;&gt;layer3_pool</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2124.003,-80C2132.0277,-80 2140.9665,-80 2149.5309,-80\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2149.7051,-83.5001 2159.705,-80 2149.705,-76.5001 2149.7051,-83.5001\"/>\n</g>\n<!-- layer3_residual_in -->\n<g id=\"node25\" class=\"node\">\n<title>layer3_residual_in</title>\n<g id=\"a_node25\"><a xlink:title=\"&lt;class &#39;__main__.Identity&#39;&gt; {}\">\n<path fill=\"#80b1d3\" stroke=\"#000000\" d=\"M2292,-98C2292,-98 2262,-98 2262,-98 2256,-98 2250,-92 2250,-86 2250,-86 2250,-74 2250,-74 2250,-68 2256,-62 2262,-62 2262,-62 2292,-62 2292,-62 2298,-62 2304,-68 2304,-74 2304,-74 2304,-86 2304,-86 2304,-92 2298,-98 2292,-98\"/>\n<text text-anchor=\"middle\" x=\"2277\" y=\"-76.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">in</text>\n</a>\n</g>\n</g>\n<!-- layer3_pool&#45;&gt;layer3_residual_in -->\n<g id=\"edge26\" class=\"edge\">\n<title>layer3_pool&#45;&gt;layer3_residual_in</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2214.003,-80C2222.0277,-80 2230.9665,-80 2239.5309,-80\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2239.7051,-83.5001 2249.705,-80 2239.705,-76.5001 2239.7051,-83.5001\"/>\n</g>\n<!-- layer3_residual_res1_conv -->\n<g id=\"node26\" class=\"node\">\n<title>layer3_residual_res1_conv</title>\n<g id=\"a_node26\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.conv.Conv2d&#39;&gt; {&#39;in_channels&#39;: 512, &#39;out_channels&#39;: 512, &#39;kernel_size&#39;: (3, 3), &#39;stride&#39;: (1, 1), &#39;padding&#39;: (1, 1), &#39;bias&#39;: False}\">\n<path fill=\"#bebada\" stroke=\"#000000\" d=\"M2382,-88C2382,-88 2352,-88 2352,-88 2346,-88 2340,-82 2340,-76 2340,-76 2340,-64 2340,-64 2340,-58 2346,-52 2352,-52 2352,-52 2382,-52 2382,-52 2388,-52 2394,-58 2394,-64 2394,-64 2394,-76 2394,-76 2394,-82 2388,-88 2382,-88\"/>\n<text text-anchor=\"middle\" x=\"2367\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">conv</text>\n</a>\n</g>\n</g>\n<!-- layer3_residual_in&#45;&gt;layer3_residual_res1_conv -->\n<g id=\"edge27\" class=\"edge\">\n<title>layer3_residual_in&#45;&gt;layer3_residual_res1_conv</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2304.003,-76.9997C2312.0277,-76.108 2320.9665,-75.1148 2329.5309,-74.1632\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2330.1527,-77.6158 2339.705,-73.0328 2329.3796,-70.6586 2330.1527,-77.6158\"/>\n</g>\n<!-- layer3_residual_add -->\n<g id=\"node33\" class=\"node\">\n<title>layer3_residual_add</title>\n<g id=\"a_node33\"><a xlink:title=\"&lt;class &#39;__main__.Add&#39;&gt; {}\">\n<path fill=\"#fdb462\" stroke=\"#000000\" d=\"M3012,-118C3012,-118 2982,-118 2982,-118 2976,-118 2970,-112 2970,-106 2970,-106 2970,-94 2970,-94 2970,-88 2976,-82 2982,-82 2982,-82 3012,-82 3012,-82 3018,-82 3024,-88 3024,-94 3024,-94 3024,-106 3024,-106 3024,-112 3018,-118 3012,-118\"/>\n<text text-anchor=\"middle\" x=\"2997\" y=\"-96.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">add</text>\n</a>\n</g>\n</g>\n<!-- layer3_residual_in&#45;&gt;layer3_residual_add -->\n<g id=\"edge34\" class=\"edge\">\n<title>layer3_residual_in&#45;&gt;layer3_residual_add</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2294.5351,-98.3771C2304.5459,-107.5711 2317.8909,-117.8215 2332,-123 2384.1953,-142.1574 2401.4,-128 2457,-128 2457,-128 2457,-128 2817,-128 2866.7971,-128 2923.4324,-117.4074 2959.6554,-109.2525\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2960.8023,-112.5799 2969.7594,-106.9214 2959.2285,-105.7591 2960.8023,-112.5799\"/>\n</g>\n<!-- layer3_residual_res1_norm -->\n<g id=\"node27\" class=\"node\">\n<title>layer3_residual_res1_norm</title>\n<g id=\"a_node27\"><a xlink:title=\"&lt;class &#39;__main__.BatchNorm&#39;&gt; {&#39;num_features&#39;: 512}\">\n<path fill=\"#ffffb3\" stroke=\"#000000\" d=\"M2472,-88C2472,-88 2442,-88 2442,-88 2436,-88 2430,-82 2430,-76 2430,-76 2430,-64 2430,-64 2430,-58 2436,-52 2442,-52 2442,-52 2472,-52 2472,-52 2478,-52 2484,-58 2484,-64 2484,-64 2484,-76 2484,-76 2484,-82 2478,-88 2472,-88\"/>\n<text text-anchor=\"middle\" x=\"2457\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">norm</text>\n</a>\n</g>\n</g>\n<!-- layer3_residual_res1_conv&#45;&gt;layer3_residual_res1_norm -->\n<g id=\"edge28\" class=\"edge\">\n<title>layer3_residual_res1_conv&#45;&gt;layer3_residual_res1_norm</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2394.003,-70C2402.0277,-70 2410.9665,-70 2419.5309,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2419.7051,-73.5001 2429.705,-70 2419.705,-66.5001 2419.7051,-73.5001\"/>\n</g>\n<!-- layer3_residual_res1_act -->\n<g id=\"node28\" class=\"node\">\n<title>layer3_residual_res1_act</title>\n<g id=\"a_node28\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.activation.ReLU&#39;&gt; {}\">\n<path fill=\"#fb8072\" stroke=\"#000000\" d=\"M2562,-88C2562,-88 2532,-88 2532,-88 2526,-88 2520,-82 2520,-76 2520,-76 2520,-64 2520,-64 2520,-58 2526,-52 2532,-52 2532,-52 2562,-52 2562,-52 2568,-52 2574,-58 2574,-64 2574,-64 2574,-76 2574,-76 2574,-82 2568,-88 2562,-88\"/>\n<text text-anchor=\"middle\" x=\"2547\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">act</text>\n</a>\n</g>\n</g>\n<!-- layer3_residual_res1_norm&#45;&gt;layer3_residual_res1_act -->\n<g id=\"edge29\" class=\"edge\">\n<title>layer3_residual_res1_norm&#45;&gt;layer3_residual_res1_act</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2484.003,-70C2492.0277,-70 2500.9665,-70 2509.5309,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2509.7051,-73.5001 2519.705,-70 2509.705,-66.5001 2509.7051,-73.5001\"/>\n</g>\n<!-- layer3_residual_res2_conv -->\n<g id=\"node29\" class=\"node\">\n<title>layer3_residual_res2_conv</title>\n<g id=\"a_node29\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.conv.Conv2d&#39;&gt; {&#39;in_channels&#39;: 512, &#39;out_channels&#39;: 512, &#39;kernel_size&#39;: (3, 3), &#39;stride&#39;: (1, 1), &#39;padding&#39;: (1, 1), &#39;bias&#39;: False}\">\n<path fill=\"#bebada\" stroke=\"#000000\" d=\"M2652,-88C2652,-88 2622,-88 2622,-88 2616,-88 2610,-82 2610,-76 2610,-76 2610,-64 2610,-64 2610,-58 2616,-52 2622,-52 2622,-52 2652,-52 2652,-52 2658,-52 2664,-58 2664,-64 2664,-64 2664,-76 2664,-76 2664,-82 2658,-88 2652,-88\"/>\n<text text-anchor=\"middle\" x=\"2637\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">conv</text>\n</a>\n</g>\n</g>\n<!-- layer3_residual_res1_act&#45;&gt;layer3_residual_res2_conv -->\n<g id=\"edge30\" class=\"edge\">\n<title>layer3_residual_res1_act&#45;&gt;layer3_residual_res2_conv</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2574.003,-70C2582.0277,-70 2590.9665,-70 2599.5309,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2599.7051,-73.5001 2609.705,-70 2599.705,-66.5001 2599.7051,-73.5001\"/>\n</g>\n<!-- layer3_residual_res2_norm -->\n<g id=\"node30\" class=\"node\">\n<title>layer3_residual_res2_norm</title>\n<g id=\"a_node30\"><a xlink:title=\"&lt;class &#39;__main__.BatchNorm&#39;&gt; {&#39;num_features&#39;: 512}\">\n<path fill=\"#ffffb3\" stroke=\"#000000\" d=\"M2742,-88C2742,-88 2712,-88 2712,-88 2706,-88 2700,-82 2700,-76 2700,-76 2700,-64 2700,-64 2700,-58 2706,-52 2712,-52 2712,-52 2742,-52 2742,-52 2748,-52 2754,-58 2754,-64 2754,-64 2754,-76 2754,-76 2754,-82 2748,-88 2742,-88\"/>\n<text text-anchor=\"middle\" x=\"2727\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">norm</text>\n</a>\n</g>\n</g>\n<!-- layer3_residual_res2_conv&#45;&gt;layer3_residual_res2_norm -->\n<g id=\"edge31\" class=\"edge\">\n<title>layer3_residual_res2_conv&#45;&gt;layer3_residual_res2_norm</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2664.003,-70C2672.0277,-70 2680.9665,-70 2689.5309,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2689.7051,-73.5001 2699.705,-70 2689.705,-66.5001 2689.7051,-73.5001\"/>\n</g>\n<!-- layer3_residual_res2_act -->\n<g id=\"node31\" class=\"node\">\n<title>layer3_residual_res2_act</title>\n<g id=\"a_node31\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.activation.ReLU&#39;&gt; {}\">\n<path fill=\"#fb8072\" stroke=\"#000000\" d=\"M2832,-88C2832,-88 2802,-88 2802,-88 2796,-88 2790,-82 2790,-76 2790,-76 2790,-64 2790,-64 2790,-58 2796,-52 2802,-52 2802,-52 2832,-52 2832,-52 2838,-52 2844,-58 2844,-64 2844,-64 2844,-76 2844,-76 2844,-82 2838,-88 2832,-88\"/>\n<text text-anchor=\"middle\" x=\"2817\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">act</text>\n</a>\n</g>\n</g>\n<!-- layer3_residual_res2_norm&#45;&gt;layer3_residual_res2_act -->\n<g id=\"edge32\" class=\"edge\">\n<title>layer3_residual_res2_norm&#45;&gt;layer3_residual_res2_act</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2754.003,-70C2762.0277,-70 2770.9665,-70 2779.5309,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2779.7051,-73.5001 2789.705,-70 2779.705,-66.5001 2779.7051,-73.5001\"/>\n</g>\n<!-- layer3_residual_out -->\n<g id=\"node32\" class=\"node\">\n<title>layer3_residual_out</title>\n<g id=\"a_node32\"><a xlink:title=\"&lt;class &#39;__main__.Identity&#39;&gt; {}\">\n<path fill=\"#80b1d3\" stroke=\"#000000\" d=\"M2922,-98C2922,-98 2892,-98 2892,-98 2886,-98 2880,-92 2880,-86 2880,-86 2880,-74 2880,-74 2880,-68 2886,-62 2892,-62 2892,-62 2922,-62 2922,-62 2928,-62 2934,-68 2934,-74 2934,-74 2934,-86 2934,-86 2934,-92 2928,-98 2922,-98\"/>\n<text text-anchor=\"middle\" x=\"2907\" y=\"-76.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">out</text>\n</a>\n</g>\n</g>\n<!-- layer3_residual_res2_act&#45;&gt;layer3_residual_out -->\n<g id=\"edge33\" class=\"edge\">\n<title>layer3_residual_res2_act&#45;&gt;layer3_residual_out</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2844.003,-73.0003C2852.0277,-73.892 2860.9665,-74.8852 2869.5309,-75.8368\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2869.3796,-79.3414 2879.705,-76.9672 2870.1527,-72.3842 2869.3796,-79.3414\"/>\n</g>\n<!-- layer3_residual_out&#45;&gt;layer3_residual_add -->\n<g id=\"edge35\" class=\"edge\">\n<title>layer3_residual_out&#45;&gt;layer3_residual_add</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2934.003,-86.0007C2942.1158,-87.8035 2951.1631,-89.814 2959.8131,-91.7362\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2959.1839,-95.1817 2969.705,-93.9345 2960.7024,-88.3484 2959.1839,-95.1817\"/>\n</g>\n<!-- pool -->\n<g id=\"node34\" class=\"node\">\n<title>pool</title>\n<g id=\"a_node34\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.pooling.MaxPool2d&#39;&gt; {&#39;kernel_size&#39;: 4}\">\n<path fill=\"#8dd3c7\" stroke=\"#000000\" d=\"M3102,-118C3102,-118 3072,-118 3072,-118 3066,-118 3060,-112 3060,-106 3060,-106 3060,-94 3060,-94 3060,-88 3066,-82 3072,-82 3072,-82 3102,-82 3102,-82 3108,-82 3114,-88 3114,-94 3114,-94 3114,-106 3114,-106 3114,-112 3108,-118 3102,-118\"/>\n<text text-anchor=\"middle\" x=\"3087\" y=\"-96.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">pool</text>\n</a>\n</g>\n</g>\n<!-- layer3_residual_add&#45;&gt;pool -->\n<g id=\"edge36\" class=\"edge\">\n<title>layer3_residual_add&#45;&gt;pool</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M3024.003,-100C3032.0277,-100 3040.9665,-100 3049.5309,-100\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"3049.7051,-103.5001 3059.705,-100 3049.705,-96.5001 3049.7051,-103.5001\"/>\n</g>\n<!-- classifier_flatten -->\n<g id=\"node35\" class=\"node\">\n<title>classifier_flatten</title>\n<g id=\"a_node35\"><a xlink:title=\"&lt;class &#39;__main__.Flatten&#39;&gt; {}\">\n<path fill=\"#b3de69\" stroke=\"#000000\" d=\"M3192,-118C3192,-118 3162,-118 3162,-118 3156,-118 3150,-112 3150,-106 3150,-106 3150,-94 3150,-94 3150,-88 3156,-82 3162,-82 3162,-82 3192,-82 3192,-82 3198,-82 3204,-88 3204,-94 3204,-94 3204,-106 3204,-106 3204,-112 3198,-118 3192,-118\"/>\n<text text-anchor=\"middle\" x=\"3177\" y=\"-96.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">flatten</text>\n</a>\n</g>\n</g>\n<!-- pool&#45;&gt;classifier_flatten -->\n<g id=\"edge37\" class=\"edge\">\n<title>pool&#45;&gt;classifier_flatten</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M3114.003,-100C3122.0277,-100 3130.9665,-100 3139.5309,-100\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"3139.7051,-103.5001 3149.705,-100 3139.705,-96.5001 3139.7051,-103.5001\"/>\n</g>\n<!-- classifier_conv -->\n<g id=\"node36\" class=\"node\">\n<title>classifier_conv</title>\n<g id=\"a_node36\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.linear.Linear&#39;&gt; {&#39;in_features&#39;: 512, &#39;out_features&#39;: 10, &#39;bias&#39;: False}\">\n<path fill=\"#fccde5\" stroke=\"#000000\" d=\"M3282,-118C3282,-118 3252,-118 3252,-118 3246,-118 3240,-112 3240,-106 3240,-106 3240,-94 3240,-94 3240,-88 3246,-82 3252,-82 3252,-82 3282,-82 3282,-82 3288,-82 3294,-88 3294,-94 3294,-94 3294,-106 3294,-106 3294,-112 3288,-118 3282,-118\"/>\n<text text-anchor=\"middle\" x=\"3267\" y=\"-96.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">conv</text>\n</a>\n</g>\n</g>\n<!-- classifier_flatten&#45;&gt;classifier_conv -->\n<g id=\"edge38\" class=\"edge\">\n<title>classifier_flatten&#45;&gt;classifier_conv</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M3204.003,-100C3212.0277,-100 3220.9665,-100 3229.5309,-100\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"3229.7051,-103.5001 3239.705,-100 3229.705,-96.5001 3229.7051,-103.5001\"/>\n</g>\n<!-- classifier_scale -->\n<g id=\"node37\" class=\"node\">\n<title>classifier_scale</title>\n<g id=\"a_node37\"><a xlink:title=\"&lt;class &#39;__main__.Mul&#39;&gt; {&#39;weight&#39;: 0.125}\">\n<path fill=\"#bc80bd\" stroke=\"#000000\" d=\"M3372,-118C3372,-118 3342,-118 3342,-118 3336,-118 3330,-112 3330,-106 3330,-106 3330,-94 3330,-94 3330,-88 3336,-82 3342,-82 3342,-82 3372,-82 3372,-82 3378,-82 3384,-88 3384,-94 3384,-94 3384,-106 3384,-106 3384,-112 3378,-118 3372,-118\"/>\n<text text-anchor=\"middle\" x=\"3357\" y=\"-96.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">scale</text>\n</a>\n</g>\n</g>\n<!-- classifier_conv&#45;&gt;classifier_scale -->\n<g id=\"edge39\" class=\"edge\">\n<title>classifier_conv&#45;&gt;classifier_scale</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M3294.003,-100C3302.0277,-100 3310.9665,-100 3319.5309,-100\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"3319.7051,-103.5001 3329.705,-100 3319.705,-96.5001 3319.7051,-103.5001\"/>\n</g>\n<!-- logits -->\n<g id=\"node38\" class=\"node\">\n<title>logits</title>\n<g id=\"a_node38\"><a xlink:title=\"&lt;class &#39;__main__.Identity&#39;&gt; {}\">\n<path fill=\"#80b1d3\" stroke=\"#000000\" d=\"M3462,-118C3462,-118 3432,-118 3432,-118 3426,-118 3420,-112 3420,-106 3420,-106 3420,-94 3420,-94 3420,-88 3426,-82 3432,-82 3432,-82 3462,-82 3462,-82 3468,-82 3474,-88 3474,-94 3474,-94 3474,-106 3474,-106 3474,-112 3468,-118 3462,-118\"/>\n<text text-anchor=\"middle\" x=\"3447\" y=\"-96.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">logits</text>\n</a>\n</g>\n</g>\n<!-- classifier_scale&#45;&gt;logits -->\n<g id=\"edge40\" class=\"edge\">\n<title>classifier_scale&#45;&gt;logits</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M3384.003,-100C3392.0277,-100 3400.9665,-100 3409.5309,-100\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"3409.7051,-103.5001 3419.705,-100 3409.705,-96.5001 3409.7051,-103.5001\"/>\n</g>\n<!-- input -->\n<g id=\"node39\" class=\"node\">\n<title>input</title>\n<path fill=\"#ffffff\" stroke=\"#000000\" d=\"M42,-88C42,-88 12,-88 12,-88 6,-88 0,-82 0,-76 0,-76 0,-64 0,-64 0,-58 6,-52 12,-52 12,-52 42,-52 42,-52 48,-52 54,-58 54,-64 54,-64 54,-76 54,-76 54,-82 48,-88 42,-88\"/>\n<text text-anchor=\"middle\" x=\"27\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">input</text>\n</g>\n<!-- input&#45;&gt;prep_conv -->\n<g id=\"edge1\" class=\"edge\">\n<title>input&#45;&gt;prep_conv</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M54.003,-70C62.0277,-70 70.9665,-70 79.5309,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"79.7051,-73.5001 89.705,-70 79.705,-66.5001 79.7051,-73.5001\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3v3IsSpij-PL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "67d4fdf5-5720-4074-aba8-cf5cf8886f7b"
      },
      "source": [
        "epochs, batch_size = 24, 512\n",
        "transforms = (Crop(32, 32), FlipLR(), Cutout(8, 8))\n",
        "opt_params = {'lr': lr_schedule([0, 5, epochs], [0.0, 0.4, 0.0], batch_size), 'weight_decay': Const(5e-4*batch_size), 'momentum': Const(0.9)}\n",
        "\n",
        "model = build_model(baseline_net, x_ent_loss)  \n",
        "warmup_cudnn(model, next(iter(train_batches(batch_size, transforms))))\n",
        "logs, state, timer = Table(), {MODEL: model, OPTS: [SGD(trainable_params(model).values(), opt_params)]}, Timer(torch.cuda.synchronize)\n",
        "for epoch in range(epochs):\n",
        "    logs.append(union({'epoch': epoch+1}, train_epoch(state, timer, train_batches(batch_size, transforms), valid_batches(batch_size))))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       epoch   train time   train loss    train acc   valid time   valid loss    valid acc   total time\n",
            "           1      11.8244       1.6415       0.4052       1.3521       1.2406       0.5413      11.8244\n",
            "           2      12.0947       0.9435       0.6633       0.7153       1.0464       0.6572      23.9191\n",
            "           3      11.8684       0.7250       0.7448       0.7057       0.7879       0.7313      35.7875\n",
            "           4      11.8184       0.6269       0.7815       0.6978       0.7070       0.7565      47.6059\n",
            "           5      11.8231       0.5587       0.8062       0.6930       0.7186       0.7515      59.4290\n",
            "           6      11.8194       0.4977       0.8278       0.6932       0.7074       0.7633      71.2484\n",
            "           7      11.8102       0.4511       0.8458       0.6932       0.5888       0.8018      83.0585\n",
            "           8      11.8301       0.4110       0.8584       0.6926       0.4828       0.8361      94.8887\n",
            "           9      11.8258       0.3876       0.8668       0.6966       0.4508       0.8479     106.7144\n",
            "          10      11.8246       0.3656       0.8738       0.6890       0.4895       0.8312     118.5390\n",
            "          11      11.8262       0.3453       0.8817       0.6944       0.5055       0.8258     130.3653\n",
            "          12      11.8093       0.3282       0.8876       0.6919       0.4078       0.8611     142.1746\n",
            "          13      11.8080       0.3074       0.8958       0.6914       0.4736       0.8378     153.9825\n",
            "          14      11.8070       0.2901       0.9021       0.6905       0.3689       0.8740     165.7896\n",
            "          15      11.8091       0.2708       0.9075       0.6910       0.4472       0.8560     177.5987\n",
            "          16      11.8075       0.2547       0.9134       0.6869       0.4182       0.8633     189.4061\n",
            "          17      11.8051       0.2381       0.9197       0.6886       0.2873       0.9009     201.2113\n",
            "          18      11.8025       0.2089       0.9301       0.6856       0.3648       0.8735     213.0137\n",
            "          19      11.8136       0.1854       0.9379       0.6872       0.2665       0.9083     224.8273\n",
            "          20      11.8082       0.1713       0.9437       0.6851       0.2818       0.9079     236.6355\n",
            "          21      11.8033       0.1449       0.9526       0.6871       0.2340       0.9232     248.4388\n",
            "          22      11.8025       0.1173       0.9624       0.6875       0.2098       0.9311     260.2413\n",
            "          23      11.8022       0.0934       0.9719       0.6854       0.1945       0.9331     272.0435\n",
            "          24      11.8016       0.0762       0.9792       0.6863       0.1820       0.9373     283.8451\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10lxhHspp79n",
        "colab_type": "text"
      },
      "source": [
        "Total training time (including the negligible time spent on preprocessing) is under 70s, moving us up two places to fourth on the leaderboard!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZiaIqUQKWHgT",
        "colab_type": "text"
      },
      "source": [
        "#### Aside: mixed precision training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FoPeZCcWmYR",
        "colab_type": "text"
      },
      "source": [
        "In our original DAWNBench submission and in the code above, we simply converted the model to float16 without all the niceties of so-called [mixed precision training](https://arxiv.org/abs/1710.03740) although we include a basic sort of 'loss scaling' by summing rather than averaging losses in a batch. It is straightforward to implement proper mixed precision training but this adds about a second to overall training time and we found it to have no effect on final accuracy, so we continue to do without it below. For completeness, here is a simple implementation which might be useful elsewhere: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvk0e9AfWMjp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "FP32_PARAMS = 'fp32_params'\n",
        "\n",
        "def copy_grads_to_master(batch, state):\n",
        "    if not batch: return\n",
        "    for float_param, param in zip(state[FP32_PARAMS], trainable_params(state[MODEL]).values()):\n",
        "        if float_param.grad is None: \n",
        "            float_param.grad = float_param.data.new(*float_param.data.size())\n",
        "        float_param.grad.data.copy_(param.grad.data)    \n",
        "    \n",
        "def update_params_from_master(batch, state):\n",
        "    if not batch: return\n",
        "    for float_param, param in zip(state[FP32_PARAMS], trainable_params(state[MODEL]).values()):\n",
        "        param.data.copy_(float_param)\n",
        "    \n",
        "train_steps_mixed_precision = (forward(training_mode=True),  log_activations(('loss', 'acc')), backward(torch.float32), copy_grads_to_master, opt_steps, update_params_from_master)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Q9-IXXGYJFL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "88d12593-47fb-4be6-dd5e-d526c920ca52"
      },
      "source": [
        "epochs, batch_size =24, 512\n",
        "transforms = (Crop(32, 32), FlipLR(), Cutout(8, 8))\n",
        "opt_params = {'lr': lr_schedule([0, 5, epochs], [0.0, 0.4, 0.0], batch_size), 'weight_decay': Const(5e-4*batch_size), 'momentum': Const(0.9)}\n",
        "\n",
        "model = build_model(network(), x_ent_loss)\n",
        "fp32_params = [v.clone().to(torch.float32) for v in trainable_params(model).values()]\n",
        "logs, state, timer = Table(), {MODEL: model, OPTS: [SGD(fp32_params, opt_params)], FP32_PARAMS: fp32_params}, Timer(torch.cuda.synchronize)\n",
        "for epoch in range(epochs):\n",
        "    logs.append(union({'epoch': epoch+1}, train_epoch(state, timer, train_batches(batch_size, transforms), valid_batches(batch_size), train_steps=train_steps_mixed_precision)))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       epoch   train time   train loss    train acc   valid time   valid loss    valid acc   total time\n",
            "           1      11.8639       1.6370       0.4095       0.6971       1.7496       0.4271      11.8639\n",
            "           2      11.8319       0.9483       0.6633       0.6998       0.8549       0.7126      23.6958\n",
            "           3      11.8258       0.7370       0.7424       0.7014       0.7029       0.7558      35.5216\n",
            "           4      11.8262       0.6259       0.7831       0.7005       0.5936       0.7974      47.3478\n",
            "           5      11.8257       0.5695       0.8028       0.6985       0.8006       0.7278      59.1735\n",
            "           6      11.8307       0.4964       0.8277       0.6969       0.4866       0.8310      71.0042\n",
            "           7      11.8277       0.4445       0.8480       0.6956       0.5392       0.8157      82.8319\n",
            "           8      11.8260       0.4073       0.8609       0.6944       0.5912       0.7994      94.6579\n",
            "           9      11.8302       0.3802       0.8687       0.6945       0.6058       0.8020     106.4881\n",
            "          10      11.8275       0.3594       0.8757       0.6952       0.5498       0.8088     118.3156\n",
            "          11      11.8269       0.3435       0.8826       0.6924       0.5439       0.8159     130.1425\n",
            "          12      11.8315       0.3255       0.8890       0.6927       0.4517       0.8493     141.9740\n",
            "          13      11.8308       0.3069       0.8959       0.6910       0.4590       0.8458     153.8048\n",
            "          14      11.8303       0.2914       0.9014       0.6912       0.3748       0.8749     165.6351\n",
            "          15      11.8272       0.2705       0.9089       0.6896       0.3148       0.8938     177.4622\n",
            "          16      11.8078       0.2488       0.9158       0.6874       0.3814       0.8726     189.2701\n",
            "          17      11.8204       0.2343       0.9222       0.6920       0.3166       0.8938     201.0904\n",
            "          18      11.8272       0.2115       0.9293       0.6888       0.3365       0.8914     212.9176\n",
            "          19      11.8255       0.1848       0.9374       0.6894       0.2972       0.9010     224.7431\n",
            "          20      11.8089       0.1649       0.9446       0.6866       0.2518       0.9156     236.5520\n",
            "          21      11.8030       0.1418       0.9547       0.6904       0.2660       0.9123     248.3550\n",
            "          22      11.8088       0.1174       0.9630       0.6881       0.2135       0.9265     260.1638\n",
            "          23      11.8042       0.0933       0.9716       0.6903       0.1950       0.9346     271.9680\n",
            "          24      11.8082       0.0766       0.9782       0.6881       0.1798       0.9402     283.7762\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RpWD1rHwNoz",
        "colab_type": "text"
      },
      "source": [
        "### Moving max-pool layers (64s)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTwu1qXPwVCI",
        "colab_type": "text"
      },
      "source": [
        "Max-pooling commutes with a monotonic-increasing activation function such as ReLU. It should be more efficient to apply pooling first. This is the sort of thing a friendly compiler might do for you, but for now let's switch the order by hand:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHSpmXRd-Acj",
        "colab_type": "code",
        "outputId": "29f410ec-7341-485d-fe01-99c2a94e6294",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "conv_pool_block_opt = lambda c_in, c_out: reorder(conv_pool_block(c_in, c_out), ('conv', 'norm', 'pool', 'act'))\n",
        "show(network(conv_pool_block=conv_pool_block_opt))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<__main__.DotGraph at 0x7f7f20be3c88>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: G Pages: 1 -->\n<svg width=\"1080pt\" height=\"64pt\"\n viewBox=\"0.00 0.00 1080.00 64.20\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(.3102 .3102) rotate(0) translate(4 203)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-203 3478,-203 3478,4 -4,4\"/>\n<g id=\"clust1\" class=\"cluster\">\n<title>cluster_prep</title>\n<path fill=\"#777777\" fill-opacity=\"0.266667\" stroke=\"#000000\" d=\"M94,-44C94,-44 320,-44 320,-44 326,-44 332,-50 332,-56 332,-56 332,-107 332,-107 332,-113 326,-119 320,-119 320,-119 94,-119 94,-119 88,-119 82,-113 82,-107 82,-107 82,-56 82,-56 82,-50 88,-44 94,-44\"/>\n<text text-anchor=\"middle\" x=\"207\" y=\"-103.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">prep</text>\n</g>\n<g id=\"clust2\" class=\"cluster\">\n<title>cluster_layer1</title>\n<path fill=\"#777777\" fill-opacity=\"0.266667\" stroke=\"#000000\" d=\"M364,-8C364,-8 1498,-8 1498,-8 1504,-8 1510,-14 1510,-20 1510,-20 1510,-159 1510,-159 1510,-165 1504,-171 1498,-171 1498,-171 364,-171 364,-171 358,-171 352,-165 352,-159 352,-159 352,-20 352,-20 352,-14 358,-8 364,-8\"/>\n<text text-anchor=\"middle\" x=\"931\" y=\"-155.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">layer1</text>\n</g>\n<g id=\"clust3\" class=\"cluster\">\n<title>cluster_layer1_residual</title>\n<path fill=\"#777777\" fill-opacity=\"0.266667\" stroke=\"#000000\" d=\"M724,-16C724,-16 1490,-16 1490,-16 1496,-16 1502,-22 1502,-28 1502,-28 1502,-128 1502,-128 1502,-134 1496,-140 1490,-140 1490,-140 724,-140 724,-140 718,-140 712,-134 712,-128 712,-128 712,-28 712,-28 712,-22 718,-16 724,-16\"/>\n<text text-anchor=\"middle\" x=\"1107\" y=\"-124.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">residual</text>\n</g>\n<g id=\"clust4\" class=\"cluster\">\n<title>cluster_layer1_residual_res1</title>\n<path fill=\"#777777\" fill-opacity=\"0.266667\" stroke=\"#000000\" d=\"M814,-24C814,-24 1040,-24 1040,-24 1046,-24 1052,-30 1052,-36 1052,-36 1052,-87 1052,-87 1052,-93 1046,-99 1040,-99 1040,-99 814,-99 814,-99 808,-99 802,-93 802,-87 802,-87 802,-36 802,-36 802,-30 808,-24 814,-24\"/>\n<text text-anchor=\"middle\" x=\"927\" y=\"-83.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">res1</text>\n</g>\n<g id=\"clust5\" class=\"cluster\">\n<title>cluster_layer1_residual_res2</title>\n<path fill=\"#777777\" fill-opacity=\"0.266667\" stroke=\"#000000\" d=\"M1084,-24C1084,-24 1310,-24 1310,-24 1316,-24 1322,-30 1322,-36 1322,-36 1322,-87 1322,-87 1322,-93 1316,-99 1310,-99 1310,-99 1084,-99 1084,-99 1078,-99 1072,-93 1072,-87 1072,-87 1072,-36 1072,-36 1072,-30 1078,-24 1084,-24\"/>\n<text text-anchor=\"middle\" x=\"1197\" y=\"-83.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">res2</text>\n</g>\n<g id=\"clust6\" class=\"cluster\">\n<title>cluster_layer2</title>\n<path fill=\"#777777\" fill-opacity=\"0.266667\" stroke=\"#000000\" d=\"M1534,-54C1534,-54 1850,-54 1850,-54 1856,-54 1862,-60 1862,-66 1862,-66 1862,-117 1862,-117 1862,-123 1856,-129 1850,-129 1850,-129 1534,-129 1534,-129 1528,-129 1522,-123 1522,-117 1522,-117 1522,-66 1522,-66 1522,-60 1528,-54 1534,-54\"/>\n<text text-anchor=\"middle\" x=\"1692\" y=\"-113.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">layer2</text>\n</g>\n<g id=\"clust7\" class=\"cluster\">\n<title>cluster_layer3</title>\n<path fill=\"#777777\" fill-opacity=\"0.266667\" stroke=\"#000000\" d=\"M1894,-28C1894,-28 3028,-28 3028,-28 3034,-28 3040,-34 3040,-40 3040,-40 3040,-179 3040,-179 3040,-185 3034,-191 3028,-191 3028,-191 1894,-191 1894,-191 1888,-191 1882,-185 1882,-179 1882,-179 1882,-40 1882,-40 1882,-34 1888,-28 1894,-28\"/>\n<text text-anchor=\"middle\" x=\"2461\" y=\"-175.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">layer3</text>\n</g>\n<g id=\"clust8\" class=\"cluster\">\n<title>cluster_layer3_residual</title>\n<path fill=\"#777777\" fill-opacity=\"0.266667\" stroke=\"#000000\" d=\"M2254,-36C2254,-36 3020,-36 3020,-36 3026,-36 3032,-42 3032,-48 3032,-48 3032,-148 3032,-148 3032,-154 3026,-160 3020,-160 3020,-160 2254,-160 2254,-160 2248,-160 2242,-154 2242,-148 2242,-148 2242,-48 2242,-48 2242,-42 2248,-36 2254,-36\"/>\n<text text-anchor=\"middle\" x=\"2637\" y=\"-144.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">residual</text>\n</g>\n<g id=\"clust9\" class=\"cluster\">\n<title>cluster_layer3_residual_res1</title>\n<path fill=\"#777777\" fill-opacity=\"0.266667\" stroke=\"#000000\" d=\"M2344,-44C2344,-44 2570,-44 2570,-44 2576,-44 2582,-50 2582,-56 2582,-56 2582,-107 2582,-107 2582,-113 2576,-119 2570,-119 2570,-119 2344,-119 2344,-119 2338,-119 2332,-113 2332,-107 2332,-107 2332,-56 2332,-56 2332,-50 2338,-44 2344,-44\"/>\n<text text-anchor=\"middle\" x=\"2457\" y=\"-103.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">res1</text>\n</g>\n<g id=\"clust10\" class=\"cluster\">\n<title>cluster_layer3_residual_res2</title>\n<path fill=\"#777777\" fill-opacity=\"0.266667\" stroke=\"#000000\" d=\"M2614,-44C2614,-44 2840,-44 2840,-44 2846,-44 2852,-50 2852,-56 2852,-56 2852,-107 2852,-107 2852,-113 2846,-119 2840,-119 2840,-119 2614,-119 2614,-119 2608,-119 2602,-113 2602,-107 2602,-107 2602,-56 2602,-56 2602,-50 2608,-44 2614,-44\"/>\n<text text-anchor=\"middle\" x=\"2727\" y=\"-103.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">res2</text>\n</g>\n<g id=\"clust11\" class=\"cluster\">\n<title>cluster_classifier</title>\n<path fill=\"#777777\" fill-opacity=\"0.266667\" stroke=\"#000000\" d=\"M3154,-74C3154,-74 3380,-74 3380,-74 3386,-74 3392,-80 3392,-86 3392,-86 3392,-137 3392,-137 3392,-143 3386,-149 3380,-149 3380,-149 3154,-149 3154,-149 3148,-149 3142,-143 3142,-137 3142,-137 3142,-86 3142,-86 3142,-80 3148,-74 3154,-74\"/>\n<text text-anchor=\"middle\" x=\"3267\" y=\"-133.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">classifier</text>\n</g>\n<!-- prep_conv -->\n<g id=\"node1\" class=\"node\">\n<title>prep_conv</title>\n<g id=\"a_node1\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.conv.Conv2d&#39;&gt; {&#39;in_channels&#39;: 3, &#39;out_channels&#39;: 64, &#39;kernel_size&#39;: (3, 3), &#39;stride&#39;: (1, 1), &#39;padding&#39;: (1, 1), &#39;bias&#39;: False}\">\n<path fill=\"#bebada\" stroke=\"#000000\" d=\"M132,-88C132,-88 102,-88 102,-88 96,-88 90,-82 90,-76 90,-76 90,-64 90,-64 90,-58 96,-52 102,-52 102,-52 132,-52 132,-52 138,-52 144,-58 144,-64 144,-64 144,-76 144,-76 144,-82 138,-88 132,-88\"/>\n<text text-anchor=\"middle\" x=\"117\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">conv</text>\n</a>\n</g>\n</g>\n<!-- prep_norm -->\n<g id=\"node2\" class=\"node\">\n<title>prep_norm</title>\n<g id=\"a_node2\"><a xlink:title=\"&lt;class &#39;__main__.BatchNorm&#39;&gt; {&#39;num_features&#39;: 64}\">\n<path fill=\"#ffffb3\" stroke=\"#000000\" d=\"M222,-88C222,-88 192,-88 192,-88 186,-88 180,-82 180,-76 180,-76 180,-64 180,-64 180,-58 186,-52 192,-52 192,-52 222,-52 222,-52 228,-52 234,-58 234,-64 234,-64 234,-76 234,-76 234,-82 228,-88 222,-88\"/>\n<text text-anchor=\"middle\" x=\"207\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">norm</text>\n</a>\n</g>\n</g>\n<!-- prep_conv&#45;&gt;prep_norm -->\n<g id=\"edge2\" class=\"edge\">\n<title>prep_conv&#45;&gt;prep_norm</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M144.003,-70C152.0277,-70 160.9665,-70 169.5309,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"169.7051,-73.5001 179.705,-70 169.705,-66.5001 169.7051,-73.5001\"/>\n</g>\n<!-- prep_act -->\n<g id=\"node3\" class=\"node\">\n<title>prep_act</title>\n<g id=\"a_node3\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.activation.ReLU&#39;&gt; {}\">\n<path fill=\"#fb8072\" stroke=\"#000000\" d=\"M312,-88C312,-88 282,-88 282,-88 276,-88 270,-82 270,-76 270,-76 270,-64 270,-64 270,-58 276,-52 282,-52 282,-52 312,-52 312,-52 318,-52 324,-58 324,-64 324,-64 324,-76 324,-76 324,-82 318,-88 312,-88\"/>\n<text text-anchor=\"middle\" x=\"297\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">act</text>\n</a>\n</g>\n</g>\n<!-- prep_norm&#45;&gt;prep_act -->\n<g id=\"edge3\" class=\"edge\">\n<title>prep_norm&#45;&gt;prep_act</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M234.003,-70C242.0277,-70 250.9665,-70 259.5309,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"259.7051,-73.5001 269.705,-70 259.705,-66.5001 259.7051,-73.5001\"/>\n</g>\n<!-- layer1_conv -->\n<g id=\"node4\" class=\"node\">\n<title>layer1_conv</title>\n<g id=\"a_node4\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.conv.Conv2d&#39;&gt; {&#39;in_channels&#39;: 64, &#39;out_channels&#39;: 128, &#39;kernel_size&#39;: (3, 3), &#39;stride&#39;: (1, 1), &#39;padding&#39;: (1, 1), &#39;bias&#39;: False}\">\n<path fill=\"#bebada\" stroke=\"#000000\" d=\"M402,-88C402,-88 372,-88 372,-88 366,-88 360,-82 360,-76 360,-76 360,-64 360,-64 360,-58 366,-52 372,-52 372,-52 402,-52 402,-52 408,-52 414,-58 414,-64 414,-64 414,-76 414,-76 414,-82 408,-88 402,-88\"/>\n<text text-anchor=\"middle\" x=\"387\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">conv</text>\n</a>\n</g>\n</g>\n<!-- prep_act&#45;&gt;layer1_conv -->\n<g id=\"edge4\" class=\"edge\">\n<title>prep_act&#45;&gt;layer1_conv</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M324.003,-70C332.0277,-70 340.9665,-70 349.5309,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"349.7051,-73.5001 359.705,-70 349.705,-66.5001 349.7051,-73.5001\"/>\n</g>\n<!-- layer1_norm -->\n<g id=\"node5\" class=\"node\">\n<title>layer1_norm</title>\n<g id=\"a_node5\"><a xlink:title=\"&lt;class &#39;__main__.BatchNorm&#39;&gt; {&#39;num_features&#39;: 128}\">\n<path fill=\"#ffffb3\" stroke=\"#000000\" d=\"M492,-88C492,-88 462,-88 462,-88 456,-88 450,-82 450,-76 450,-76 450,-64 450,-64 450,-58 456,-52 462,-52 462,-52 492,-52 492,-52 498,-52 504,-58 504,-64 504,-64 504,-76 504,-76 504,-82 498,-88 492,-88\"/>\n<text text-anchor=\"middle\" x=\"477\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">norm</text>\n</a>\n</g>\n</g>\n<!-- layer1_conv&#45;&gt;layer1_norm -->\n<g id=\"edge5\" class=\"edge\">\n<title>layer1_conv&#45;&gt;layer1_norm</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M414.003,-70C422.0277,-70 430.9665,-70 439.5309,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"439.7051,-73.5001 449.705,-70 439.705,-66.5001 439.7051,-73.5001\"/>\n</g>\n<!-- layer1_pool -->\n<g id=\"node6\" class=\"node\">\n<title>layer1_pool</title>\n<g id=\"a_node6\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.pooling.MaxPool2d&#39;&gt; {&#39;kernel_size&#39;: 2}\">\n<path fill=\"#8dd3c7\" stroke=\"#000000\" d=\"M582,-88C582,-88 552,-88 552,-88 546,-88 540,-82 540,-76 540,-76 540,-64 540,-64 540,-58 546,-52 552,-52 552,-52 582,-52 582,-52 588,-52 594,-58 594,-64 594,-64 594,-76 594,-76 594,-82 588,-88 582,-88\"/>\n<text text-anchor=\"middle\" x=\"567\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">pool</text>\n</a>\n</g>\n</g>\n<!-- layer1_norm&#45;&gt;layer1_pool -->\n<g id=\"edge6\" class=\"edge\">\n<title>layer1_norm&#45;&gt;layer1_pool</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M504.003,-70C512.0277,-70 520.9665,-70 529.5309,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"529.7051,-73.5001 539.705,-70 529.705,-66.5001 529.7051,-73.5001\"/>\n</g>\n<!-- layer1_act -->\n<g id=\"node7\" class=\"node\">\n<title>layer1_act</title>\n<g id=\"a_node7\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.activation.ReLU&#39;&gt; {}\">\n<path fill=\"#fb8072\" stroke=\"#000000\" d=\"M672,-88C672,-88 642,-88 642,-88 636,-88 630,-82 630,-76 630,-76 630,-64 630,-64 630,-58 636,-52 642,-52 642,-52 672,-52 672,-52 678,-52 684,-58 684,-64 684,-64 684,-76 684,-76 684,-82 678,-88 672,-88\"/>\n<text text-anchor=\"middle\" x=\"657\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">act</text>\n</a>\n</g>\n</g>\n<!-- layer1_pool&#45;&gt;layer1_act -->\n<g id=\"edge7\" class=\"edge\">\n<title>layer1_pool&#45;&gt;layer1_act</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M594.003,-70C602.0277,-70 610.9665,-70 619.5309,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"619.7051,-73.5001 629.705,-70 619.705,-66.5001 619.7051,-73.5001\"/>\n</g>\n<!-- layer1_residual_in -->\n<g id=\"node8\" class=\"node\">\n<title>layer1_residual_in</title>\n<g id=\"a_node8\"><a xlink:title=\"&lt;class &#39;__main__.Identity&#39;&gt; {}\">\n<path fill=\"#80b1d3\" stroke=\"#000000\" d=\"M762,-88C762,-88 732,-88 732,-88 726,-88 720,-82 720,-76 720,-76 720,-64 720,-64 720,-58 726,-52 732,-52 732,-52 762,-52 762,-52 768,-52 774,-58 774,-64 774,-64 774,-76 774,-76 774,-82 768,-88 762,-88\"/>\n<text text-anchor=\"middle\" x=\"747\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">in</text>\n</a>\n</g>\n</g>\n<!-- layer1_act&#45;&gt;layer1_residual_in -->\n<g id=\"edge8\" class=\"edge\">\n<title>layer1_act&#45;&gt;layer1_residual_in</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M684.003,-70C692.0277,-70 700.9665,-70 709.5309,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"709.7051,-73.5001 719.705,-70 709.705,-66.5001 709.7051,-73.5001\"/>\n</g>\n<!-- layer1_residual_res1_conv -->\n<g id=\"node9\" class=\"node\">\n<title>layer1_residual_res1_conv</title>\n<g id=\"a_node9\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.conv.Conv2d&#39;&gt; {&#39;in_channels&#39;: 128, &#39;out_channels&#39;: 128, &#39;kernel_size&#39;: (3, 3), &#39;stride&#39;: (1, 1), &#39;padding&#39;: (1, 1), &#39;bias&#39;: False}\">\n<path fill=\"#bebada\" stroke=\"#000000\" d=\"M852,-68C852,-68 822,-68 822,-68 816,-68 810,-62 810,-56 810,-56 810,-44 810,-44 810,-38 816,-32 822,-32 822,-32 852,-32 852,-32 858,-32 864,-38 864,-44 864,-44 864,-56 864,-56 864,-62 858,-68 852,-68\"/>\n<text text-anchor=\"middle\" x=\"837\" y=\"-46.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">conv</text>\n</a>\n</g>\n</g>\n<!-- layer1_residual_in&#45;&gt;layer1_residual_res1_conv -->\n<g id=\"edge9\" class=\"edge\">\n<title>layer1_residual_in&#45;&gt;layer1_residual_res1_conv</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M774.003,-63.9993C782.1158,-62.1965 791.1631,-60.186 799.8131,-58.2638\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"800.7024,-61.6516 809.705,-56.0655 799.1839,-54.8183 800.7024,-61.6516\"/>\n</g>\n<!-- layer1_residual_add -->\n<g id=\"node16\" class=\"node\">\n<title>layer1_residual_add</title>\n<g id=\"a_node16\"><a xlink:title=\"&lt;class &#39;__main__.Add&#39;&gt; {}\">\n<path fill=\"#fdb462\" stroke=\"#000000\" d=\"M1482,-98C1482,-98 1452,-98 1452,-98 1446,-98 1440,-92 1440,-86 1440,-86 1440,-74 1440,-74 1440,-68 1446,-62 1452,-62 1452,-62 1482,-62 1482,-62 1488,-62 1494,-68 1494,-74 1494,-74 1494,-86 1494,-86 1494,-92 1488,-98 1482,-98\"/>\n<text text-anchor=\"middle\" x=\"1467\" y=\"-76.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">add</text>\n</a>\n</g>\n</g>\n<!-- layer1_residual_in&#45;&gt;layer1_residual_add -->\n<g id=\"edge16\" class=\"edge\">\n<title>layer1_residual_in&#45;&gt;layer1_residual_add</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M771.2203,-88.104C780.3892,-93.9663 791.2234,-99.7818 802,-103 855.2752,-118.9095 871.4,-108 927,-108 927,-108 927,-108 1287,-108 1336.7971,-108 1393.4324,-97.4074 1429.6554,-89.2525\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1430.8023,-92.5799 1439.7594,-86.9214 1429.2285,-85.7591 1430.8023,-92.5799\"/>\n</g>\n<!-- layer1_residual_res1_norm -->\n<g id=\"node10\" class=\"node\">\n<title>layer1_residual_res1_norm</title>\n<g id=\"a_node10\"><a xlink:title=\"&lt;class &#39;__main__.BatchNorm&#39;&gt; {&#39;num_features&#39;: 128}\">\n<path fill=\"#ffffb3\" stroke=\"#000000\" d=\"M942,-68C942,-68 912,-68 912,-68 906,-68 900,-62 900,-56 900,-56 900,-44 900,-44 900,-38 906,-32 912,-32 912,-32 942,-32 942,-32 948,-32 954,-38 954,-44 954,-44 954,-56 954,-56 954,-62 948,-68 942,-68\"/>\n<text text-anchor=\"middle\" x=\"927\" y=\"-46.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">norm</text>\n</a>\n</g>\n</g>\n<!-- layer1_residual_res1_conv&#45;&gt;layer1_residual_res1_norm -->\n<g id=\"edge10\" class=\"edge\">\n<title>layer1_residual_res1_conv&#45;&gt;layer1_residual_res1_norm</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M864.003,-50C872.0277,-50 880.9665,-50 889.5309,-50\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"889.7051,-53.5001 899.705,-50 889.705,-46.5001 889.7051,-53.5001\"/>\n</g>\n<!-- layer1_residual_res1_act -->\n<g id=\"node11\" class=\"node\">\n<title>layer1_residual_res1_act</title>\n<g id=\"a_node11\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.activation.ReLU&#39;&gt; {}\">\n<path fill=\"#fb8072\" stroke=\"#000000\" d=\"M1032,-68C1032,-68 1002,-68 1002,-68 996,-68 990,-62 990,-56 990,-56 990,-44 990,-44 990,-38 996,-32 1002,-32 1002,-32 1032,-32 1032,-32 1038,-32 1044,-38 1044,-44 1044,-44 1044,-56 1044,-56 1044,-62 1038,-68 1032,-68\"/>\n<text text-anchor=\"middle\" x=\"1017\" y=\"-46.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">act</text>\n</a>\n</g>\n</g>\n<!-- layer1_residual_res1_norm&#45;&gt;layer1_residual_res1_act -->\n<g id=\"edge11\" class=\"edge\">\n<title>layer1_residual_res1_norm&#45;&gt;layer1_residual_res1_act</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M954.003,-50C962.0277,-50 970.9665,-50 979.5309,-50\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"979.7051,-53.5001 989.705,-50 979.705,-46.5001 979.7051,-53.5001\"/>\n</g>\n<!-- layer1_residual_res2_conv -->\n<g id=\"node12\" class=\"node\">\n<title>layer1_residual_res2_conv</title>\n<g id=\"a_node12\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.conv.Conv2d&#39;&gt; {&#39;in_channels&#39;: 128, &#39;out_channels&#39;: 128, &#39;kernel_size&#39;: (3, 3), &#39;stride&#39;: (1, 1), &#39;padding&#39;: (1, 1), &#39;bias&#39;: False}\">\n<path fill=\"#bebada\" stroke=\"#000000\" d=\"M1122,-68C1122,-68 1092,-68 1092,-68 1086,-68 1080,-62 1080,-56 1080,-56 1080,-44 1080,-44 1080,-38 1086,-32 1092,-32 1092,-32 1122,-32 1122,-32 1128,-32 1134,-38 1134,-44 1134,-44 1134,-56 1134,-56 1134,-62 1128,-68 1122,-68\"/>\n<text text-anchor=\"middle\" x=\"1107\" y=\"-46.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">conv</text>\n</a>\n</g>\n</g>\n<!-- layer1_residual_res1_act&#45;&gt;layer1_residual_res2_conv -->\n<g id=\"edge12\" class=\"edge\">\n<title>layer1_residual_res1_act&#45;&gt;layer1_residual_res2_conv</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1044.003,-50C1052.0277,-50 1060.9665,-50 1069.5309,-50\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1069.7051,-53.5001 1079.705,-50 1069.705,-46.5001 1069.7051,-53.5001\"/>\n</g>\n<!-- layer1_residual_res2_norm -->\n<g id=\"node13\" class=\"node\">\n<title>layer1_residual_res2_norm</title>\n<g id=\"a_node13\"><a xlink:title=\"&lt;class &#39;__main__.BatchNorm&#39;&gt; {&#39;num_features&#39;: 128}\">\n<path fill=\"#ffffb3\" stroke=\"#000000\" d=\"M1212,-68C1212,-68 1182,-68 1182,-68 1176,-68 1170,-62 1170,-56 1170,-56 1170,-44 1170,-44 1170,-38 1176,-32 1182,-32 1182,-32 1212,-32 1212,-32 1218,-32 1224,-38 1224,-44 1224,-44 1224,-56 1224,-56 1224,-62 1218,-68 1212,-68\"/>\n<text text-anchor=\"middle\" x=\"1197\" y=\"-46.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">norm</text>\n</a>\n</g>\n</g>\n<!-- layer1_residual_res2_conv&#45;&gt;layer1_residual_res2_norm -->\n<g id=\"edge13\" class=\"edge\">\n<title>layer1_residual_res2_conv&#45;&gt;layer1_residual_res2_norm</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1134.003,-50C1142.0277,-50 1150.9665,-50 1159.5309,-50\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1159.7051,-53.5001 1169.705,-50 1159.705,-46.5001 1159.7051,-53.5001\"/>\n</g>\n<!-- layer1_residual_res2_act -->\n<g id=\"node14\" class=\"node\">\n<title>layer1_residual_res2_act</title>\n<g id=\"a_node14\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.activation.ReLU&#39;&gt; {}\">\n<path fill=\"#fb8072\" stroke=\"#000000\" d=\"M1302,-68C1302,-68 1272,-68 1272,-68 1266,-68 1260,-62 1260,-56 1260,-56 1260,-44 1260,-44 1260,-38 1266,-32 1272,-32 1272,-32 1302,-32 1302,-32 1308,-32 1314,-38 1314,-44 1314,-44 1314,-56 1314,-56 1314,-62 1308,-68 1302,-68\"/>\n<text text-anchor=\"middle\" x=\"1287\" y=\"-46.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">act</text>\n</a>\n</g>\n</g>\n<!-- layer1_residual_res2_norm&#45;&gt;layer1_residual_res2_act -->\n<g id=\"edge14\" class=\"edge\">\n<title>layer1_residual_res2_norm&#45;&gt;layer1_residual_res2_act</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1224.003,-50C1232.0277,-50 1240.9665,-50 1249.5309,-50\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1249.7051,-53.5001 1259.705,-50 1249.705,-46.5001 1249.7051,-53.5001\"/>\n</g>\n<!-- layer1_residual_out -->\n<g id=\"node15\" class=\"node\">\n<title>layer1_residual_out</title>\n<g id=\"a_node15\"><a xlink:title=\"&lt;class &#39;__main__.Identity&#39;&gt; {}\">\n<path fill=\"#80b1d3\" stroke=\"#000000\" d=\"M1392,-78C1392,-78 1362,-78 1362,-78 1356,-78 1350,-72 1350,-66 1350,-66 1350,-54 1350,-54 1350,-48 1356,-42 1362,-42 1362,-42 1392,-42 1392,-42 1398,-42 1404,-48 1404,-54 1404,-54 1404,-66 1404,-66 1404,-72 1398,-78 1392,-78\"/>\n<text text-anchor=\"middle\" x=\"1377\" y=\"-56.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">out</text>\n</a>\n</g>\n</g>\n<!-- layer1_residual_res2_act&#45;&gt;layer1_residual_out -->\n<g id=\"edge15\" class=\"edge\">\n<title>layer1_residual_res2_act&#45;&gt;layer1_residual_out</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1314.003,-53.0003C1322.0277,-53.892 1330.9665,-54.8852 1339.5309,-55.8368\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1339.3796,-59.3414 1349.705,-56.9672 1340.1527,-52.3842 1339.3796,-59.3414\"/>\n</g>\n<!-- layer1_residual_out&#45;&gt;layer1_residual_add -->\n<g id=\"edge17\" class=\"edge\">\n<title>layer1_residual_out&#45;&gt;layer1_residual_add</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1404.003,-66.0007C1412.1158,-67.8035 1421.1631,-69.814 1429.8131,-71.7362\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1429.1839,-75.1817 1439.705,-73.9345 1430.7024,-68.3484 1429.1839,-75.1817\"/>\n</g>\n<!-- layer2_conv -->\n<g id=\"node17\" class=\"node\">\n<title>layer2_conv</title>\n<g id=\"a_node17\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.conv.Conv2d&#39;&gt; {&#39;in_channels&#39;: 128, &#39;out_channels&#39;: 256, &#39;kernel_size&#39;: (3, 3), &#39;stride&#39;: (1, 1), &#39;padding&#39;: (1, 1), &#39;bias&#39;: False}\">\n<path fill=\"#bebada\" stroke=\"#000000\" d=\"M1572,-98C1572,-98 1542,-98 1542,-98 1536,-98 1530,-92 1530,-86 1530,-86 1530,-74 1530,-74 1530,-68 1536,-62 1542,-62 1542,-62 1572,-62 1572,-62 1578,-62 1584,-68 1584,-74 1584,-74 1584,-86 1584,-86 1584,-92 1578,-98 1572,-98\"/>\n<text text-anchor=\"middle\" x=\"1557\" y=\"-76.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">conv</text>\n</a>\n</g>\n</g>\n<!-- layer1_residual_add&#45;&gt;layer2_conv -->\n<g id=\"edge18\" class=\"edge\">\n<title>layer1_residual_add&#45;&gt;layer2_conv</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1494.003,-80C1502.0277,-80 1510.9665,-80 1519.5309,-80\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1519.7051,-83.5001 1529.705,-80 1519.705,-76.5001 1519.7051,-83.5001\"/>\n</g>\n<!-- layer2_norm -->\n<g id=\"node18\" class=\"node\">\n<title>layer2_norm</title>\n<g id=\"a_node18\"><a xlink:title=\"&lt;class &#39;__main__.BatchNorm&#39;&gt; {&#39;num_features&#39;: 256}\">\n<path fill=\"#ffffb3\" stroke=\"#000000\" d=\"M1662,-98C1662,-98 1632,-98 1632,-98 1626,-98 1620,-92 1620,-86 1620,-86 1620,-74 1620,-74 1620,-68 1626,-62 1632,-62 1632,-62 1662,-62 1662,-62 1668,-62 1674,-68 1674,-74 1674,-74 1674,-86 1674,-86 1674,-92 1668,-98 1662,-98\"/>\n<text text-anchor=\"middle\" x=\"1647\" y=\"-76.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">norm</text>\n</a>\n</g>\n</g>\n<!-- layer2_conv&#45;&gt;layer2_norm -->\n<g id=\"edge19\" class=\"edge\">\n<title>layer2_conv&#45;&gt;layer2_norm</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1584.003,-80C1592.0277,-80 1600.9665,-80 1609.5309,-80\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1609.7051,-83.5001 1619.705,-80 1609.705,-76.5001 1609.7051,-83.5001\"/>\n</g>\n<!-- layer2_pool -->\n<g id=\"node19\" class=\"node\">\n<title>layer2_pool</title>\n<g id=\"a_node19\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.pooling.MaxPool2d&#39;&gt; {&#39;kernel_size&#39;: 2}\">\n<path fill=\"#8dd3c7\" stroke=\"#000000\" d=\"M1752,-98C1752,-98 1722,-98 1722,-98 1716,-98 1710,-92 1710,-86 1710,-86 1710,-74 1710,-74 1710,-68 1716,-62 1722,-62 1722,-62 1752,-62 1752,-62 1758,-62 1764,-68 1764,-74 1764,-74 1764,-86 1764,-86 1764,-92 1758,-98 1752,-98\"/>\n<text text-anchor=\"middle\" x=\"1737\" y=\"-76.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">pool</text>\n</a>\n</g>\n</g>\n<!-- layer2_norm&#45;&gt;layer2_pool -->\n<g id=\"edge20\" class=\"edge\">\n<title>layer2_norm&#45;&gt;layer2_pool</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1674.003,-80C1682.0277,-80 1690.9665,-80 1699.5309,-80\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1699.7051,-83.5001 1709.705,-80 1699.705,-76.5001 1699.7051,-83.5001\"/>\n</g>\n<!-- layer2_act -->\n<g id=\"node20\" class=\"node\">\n<title>layer2_act</title>\n<g id=\"a_node20\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.activation.ReLU&#39;&gt; {}\">\n<path fill=\"#fb8072\" stroke=\"#000000\" d=\"M1842,-98C1842,-98 1812,-98 1812,-98 1806,-98 1800,-92 1800,-86 1800,-86 1800,-74 1800,-74 1800,-68 1806,-62 1812,-62 1812,-62 1842,-62 1842,-62 1848,-62 1854,-68 1854,-74 1854,-74 1854,-86 1854,-86 1854,-92 1848,-98 1842,-98\"/>\n<text text-anchor=\"middle\" x=\"1827\" y=\"-76.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">act</text>\n</a>\n</g>\n</g>\n<!-- layer2_pool&#45;&gt;layer2_act -->\n<g id=\"edge21\" class=\"edge\">\n<title>layer2_pool&#45;&gt;layer2_act</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1764.003,-80C1772.0277,-80 1780.9665,-80 1789.5309,-80\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1789.7051,-83.5001 1799.705,-80 1789.705,-76.5001 1789.7051,-83.5001\"/>\n</g>\n<!-- layer3_conv -->\n<g id=\"node21\" class=\"node\">\n<title>layer3_conv</title>\n<g id=\"a_node21\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.conv.Conv2d&#39;&gt; {&#39;in_channels&#39;: 256, &#39;out_channels&#39;: 512, &#39;kernel_size&#39;: (3, 3), &#39;stride&#39;: (1, 1), &#39;padding&#39;: (1, 1), &#39;bias&#39;: False}\">\n<path fill=\"#bebada\" stroke=\"#000000\" d=\"M1932,-98C1932,-98 1902,-98 1902,-98 1896,-98 1890,-92 1890,-86 1890,-86 1890,-74 1890,-74 1890,-68 1896,-62 1902,-62 1902,-62 1932,-62 1932,-62 1938,-62 1944,-68 1944,-74 1944,-74 1944,-86 1944,-86 1944,-92 1938,-98 1932,-98\"/>\n<text text-anchor=\"middle\" x=\"1917\" y=\"-76.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">conv</text>\n</a>\n</g>\n</g>\n<!-- layer2_act&#45;&gt;layer3_conv -->\n<g id=\"edge22\" class=\"edge\">\n<title>layer2_act&#45;&gt;layer3_conv</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1854.003,-80C1862.0277,-80 1870.9665,-80 1879.5309,-80\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1879.7051,-83.5001 1889.705,-80 1879.705,-76.5001 1879.7051,-83.5001\"/>\n</g>\n<!-- layer3_norm -->\n<g id=\"node22\" class=\"node\">\n<title>layer3_norm</title>\n<g id=\"a_node22\"><a xlink:title=\"&lt;class &#39;__main__.BatchNorm&#39;&gt; {&#39;num_features&#39;: 512}\">\n<path fill=\"#ffffb3\" stroke=\"#000000\" d=\"M2022,-98C2022,-98 1992,-98 1992,-98 1986,-98 1980,-92 1980,-86 1980,-86 1980,-74 1980,-74 1980,-68 1986,-62 1992,-62 1992,-62 2022,-62 2022,-62 2028,-62 2034,-68 2034,-74 2034,-74 2034,-86 2034,-86 2034,-92 2028,-98 2022,-98\"/>\n<text text-anchor=\"middle\" x=\"2007\" y=\"-76.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">norm</text>\n</a>\n</g>\n</g>\n<!-- layer3_conv&#45;&gt;layer3_norm -->\n<g id=\"edge23\" class=\"edge\">\n<title>layer3_conv&#45;&gt;layer3_norm</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1944.003,-80C1952.0277,-80 1960.9665,-80 1969.5309,-80\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1969.7051,-83.5001 1979.705,-80 1969.705,-76.5001 1969.7051,-83.5001\"/>\n</g>\n<!-- layer3_pool -->\n<g id=\"node23\" class=\"node\">\n<title>layer3_pool</title>\n<g id=\"a_node23\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.pooling.MaxPool2d&#39;&gt; {&#39;kernel_size&#39;: 2}\">\n<path fill=\"#8dd3c7\" stroke=\"#000000\" d=\"M2112,-98C2112,-98 2082,-98 2082,-98 2076,-98 2070,-92 2070,-86 2070,-86 2070,-74 2070,-74 2070,-68 2076,-62 2082,-62 2082,-62 2112,-62 2112,-62 2118,-62 2124,-68 2124,-74 2124,-74 2124,-86 2124,-86 2124,-92 2118,-98 2112,-98\"/>\n<text text-anchor=\"middle\" x=\"2097\" y=\"-76.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">pool</text>\n</a>\n</g>\n</g>\n<!-- layer3_norm&#45;&gt;layer3_pool -->\n<g id=\"edge24\" class=\"edge\">\n<title>layer3_norm&#45;&gt;layer3_pool</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2034.003,-80C2042.0277,-80 2050.9665,-80 2059.5309,-80\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2059.7051,-83.5001 2069.705,-80 2059.705,-76.5001 2059.7051,-83.5001\"/>\n</g>\n<!-- layer3_act -->\n<g id=\"node24\" class=\"node\">\n<title>layer3_act</title>\n<g id=\"a_node24\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.activation.ReLU&#39;&gt; {}\">\n<path fill=\"#fb8072\" stroke=\"#000000\" d=\"M2202,-98C2202,-98 2172,-98 2172,-98 2166,-98 2160,-92 2160,-86 2160,-86 2160,-74 2160,-74 2160,-68 2166,-62 2172,-62 2172,-62 2202,-62 2202,-62 2208,-62 2214,-68 2214,-74 2214,-74 2214,-86 2214,-86 2214,-92 2208,-98 2202,-98\"/>\n<text text-anchor=\"middle\" x=\"2187\" y=\"-76.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">act</text>\n</a>\n</g>\n</g>\n<!-- layer3_pool&#45;&gt;layer3_act -->\n<g id=\"edge25\" class=\"edge\">\n<title>layer3_pool&#45;&gt;layer3_act</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2124.003,-80C2132.0277,-80 2140.9665,-80 2149.5309,-80\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2149.7051,-83.5001 2159.705,-80 2149.705,-76.5001 2149.7051,-83.5001\"/>\n</g>\n<!-- layer3_residual_in -->\n<g id=\"node25\" class=\"node\">\n<title>layer3_residual_in</title>\n<g id=\"a_node25\"><a xlink:title=\"&lt;class &#39;__main__.Identity&#39;&gt; {}\">\n<path fill=\"#80b1d3\" stroke=\"#000000\" d=\"M2292,-98C2292,-98 2262,-98 2262,-98 2256,-98 2250,-92 2250,-86 2250,-86 2250,-74 2250,-74 2250,-68 2256,-62 2262,-62 2262,-62 2292,-62 2292,-62 2298,-62 2304,-68 2304,-74 2304,-74 2304,-86 2304,-86 2304,-92 2298,-98 2292,-98\"/>\n<text text-anchor=\"middle\" x=\"2277\" y=\"-76.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">in</text>\n</a>\n</g>\n</g>\n<!-- layer3_act&#45;&gt;layer3_residual_in -->\n<g id=\"edge26\" class=\"edge\">\n<title>layer3_act&#45;&gt;layer3_residual_in</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2214.003,-80C2222.0277,-80 2230.9665,-80 2239.5309,-80\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2239.7051,-83.5001 2249.705,-80 2239.705,-76.5001 2239.7051,-83.5001\"/>\n</g>\n<!-- layer3_residual_res1_conv -->\n<g id=\"node26\" class=\"node\">\n<title>layer3_residual_res1_conv</title>\n<g id=\"a_node26\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.conv.Conv2d&#39;&gt; {&#39;in_channels&#39;: 512, &#39;out_channels&#39;: 512, &#39;kernel_size&#39;: (3, 3), &#39;stride&#39;: (1, 1), &#39;padding&#39;: (1, 1), &#39;bias&#39;: False}\">\n<path fill=\"#bebada\" stroke=\"#000000\" d=\"M2382,-88C2382,-88 2352,-88 2352,-88 2346,-88 2340,-82 2340,-76 2340,-76 2340,-64 2340,-64 2340,-58 2346,-52 2352,-52 2352,-52 2382,-52 2382,-52 2388,-52 2394,-58 2394,-64 2394,-64 2394,-76 2394,-76 2394,-82 2388,-88 2382,-88\"/>\n<text text-anchor=\"middle\" x=\"2367\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">conv</text>\n</a>\n</g>\n</g>\n<!-- layer3_residual_in&#45;&gt;layer3_residual_res1_conv -->\n<g id=\"edge27\" class=\"edge\">\n<title>layer3_residual_in&#45;&gt;layer3_residual_res1_conv</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2304.003,-76.9997C2312.0277,-76.108 2320.9665,-75.1148 2329.5309,-74.1632\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2330.1527,-77.6158 2339.705,-73.0328 2329.3796,-70.6586 2330.1527,-77.6158\"/>\n</g>\n<!-- layer3_residual_add -->\n<g id=\"node33\" class=\"node\">\n<title>layer3_residual_add</title>\n<g id=\"a_node33\"><a xlink:title=\"&lt;class &#39;__main__.Add&#39;&gt; {}\">\n<path fill=\"#fdb462\" stroke=\"#000000\" d=\"M3012,-118C3012,-118 2982,-118 2982,-118 2976,-118 2970,-112 2970,-106 2970,-106 2970,-94 2970,-94 2970,-88 2976,-82 2982,-82 2982,-82 3012,-82 3012,-82 3018,-82 3024,-88 3024,-94 3024,-94 3024,-106 3024,-106 3024,-112 3018,-118 3012,-118\"/>\n<text text-anchor=\"middle\" x=\"2997\" y=\"-96.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">add</text>\n</a>\n</g>\n</g>\n<!-- layer3_residual_in&#45;&gt;layer3_residual_add -->\n<g id=\"edge34\" class=\"edge\">\n<title>layer3_residual_in&#45;&gt;layer3_residual_add</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2294.5351,-98.3771C2304.5459,-107.5711 2317.8909,-117.8215 2332,-123 2384.1953,-142.1574 2401.4,-128 2457,-128 2457,-128 2457,-128 2817,-128 2866.7971,-128 2923.4324,-117.4074 2959.6554,-109.2525\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2960.8023,-112.5799 2969.7594,-106.9214 2959.2285,-105.7591 2960.8023,-112.5799\"/>\n</g>\n<!-- layer3_residual_res1_norm -->\n<g id=\"node27\" class=\"node\">\n<title>layer3_residual_res1_norm</title>\n<g id=\"a_node27\"><a xlink:title=\"&lt;class &#39;__main__.BatchNorm&#39;&gt; {&#39;num_features&#39;: 512}\">\n<path fill=\"#ffffb3\" stroke=\"#000000\" d=\"M2472,-88C2472,-88 2442,-88 2442,-88 2436,-88 2430,-82 2430,-76 2430,-76 2430,-64 2430,-64 2430,-58 2436,-52 2442,-52 2442,-52 2472,-52 2472,-52 2478,-52 2484,-58 2484,-64 2484,-64 2484,-76 2484,-76 2484,-82 2478,-88 2472,-88\"/>\n<text text-anchor=\"middle\" x=\"2457\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">norm</text>\n</a>\n</g>\n</g>\n<!-- layer3_residual_res1_conv&#45;&gt;layer3_residual_res1_norm -->\n<g id=\"edge28\" class=\"edge\">\n<title>layer3_residual_res1_conv&#45;&gt;layer3_residual_res1_norm</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2394.003,-70C2402.0277,-70 2410.9665,-70 2419.5309,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2419.7051,-73.5001 2429.705,-70 2419.705,-66.5001 2419.7051,-73.5001\"/>\n</g>\n<!-- layer3_residual_res1_act -->\n<g id=\"node28\" class=\"node\">\n<title>layer3_residual_res1_act</title>\n<g id=\"a_node28\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.activation.ReLU&#39;&gt; {}\">\n<path fill=\"#fb8072\" stroke=\"#000000\" d=\"M2562,-88C2562,-88 2532,-88 2532,-88 2526,-88 2520,-82 2520,-76 2520,-76 2520,-64 2520,-64 2520,-58 2526,-52 2532,-52 2532,-52 2562,-52 2562,-52 2568,-52 2574,-58 2574,-64 2574,-64 2574,-76 2574,-76 2574,-82 2568,-88 2562,-88\"/>\n<text text-anchor=\"middle\" x=\"2547\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">act</text>\n</a>\n</g>\n</g>\n<!-- layer3_residual_res1_norm&#45;&gt;layer3_residual_res1_act -->\n<g id=\"edge29\" class=\"edge\">\n<title>layer3_residual_res1_norm&#45;&gt;layer3_residual_res1_act</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2484.003,-70C2492.0277,-70 2500.9665,-70 2509.5309,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2509.7051,-73.5001 2519.705,-70 2509.705,-66.5001 2509.7051,-73.5001\"/>\n</g>\n<!-- layer3_residual_res2_conv -->\n<g id=\"node29\" class=\"node\">\n<title>layer3_residual_res2_conv</title>\n<g id=\"a_node29\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.conv.Conv2d&#39;&gt; {&#39;in_channels&#39;: 512, &#39;out_channels&#39;: 512, &#39;kernel_size&#39;: (3, 3), &#39;stride&#39;: (1, 1), &#39;padding&#39;: (1, 1), &#39;bias&#39;: False}\">\n<path fill=\"#bebada\" stroke=\"#000000\" d=\"M2652,-88C2652,-88 2622,-88 2622,-88 2616,-88 2610,-82 2610,-76 2610,-76 2610,-64 2610,-64 2610,-58 2616,-52 2622,-52 2622,-52 2652,-52 2652,-52 2658,-52 2664,-58 2664,-64 2664,-64 2664,-76 2664,-76 2664,-82 2658,-88 2652,-88\"/>\n<text text-anchor=\"middle\" x=\"2637\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">conv</text>\n</a>\n</g>\n</g>\n<!-- layer3_residual_res1_act&#45;&gt;layer3_residual_res2_conv -->\n<g id=\"edge30\" class=\"edge\">\n<title>layer3_residual_res1_act&#45;&gt;layer3_residual_res2_conv</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2574.003,-70C2582.0277,-70 2590.9665,-70 2599.5309,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2599.7051,-73.5001 2609.705,-70 2599.705,-66.5001 2599.7051,-73.5001\"/>\n</g>\n<!-- layer3_residual_res2_norm -->\n<g id=\"node30\" class=\"node\">\n<title>layer3_residual_res2_norm</title>\n<g id=\"a_node30\"><a xlink:title=\"&lt;class &#39;__main__.BatchNorm&#39;&gt; {&#39;num_features&#39;: 512}\">\n<path fill=\"#ffffb3\" stroke=\"#000000\" d=\"M2742,-88C2742,-88 2712,-88 2712,-88 2706,-88 2700,-82 2700,-76 2700,-76 2700,-64 2700,-64 2700,-58 2706,-52 2712,-52 2712,-52 2742,-52 2742,-52 2748,-52 2754,-58 2754,-64 2754,-64 2754,-76 2754,-76 2754,-82 2748,-88 2742,-88\"/>\n<text text-anchor=\"middle\" x=\"2727\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">norm</text>\n</a>\n</g>\n</g>\n<!-- layer3_residual_res2_conv&#45;&gt;layer3_residual_res2_norm -->\n<g id=\"edge31\" class=\"edge\">\n<title>layer3_residual_res2_conv&#45;&gt;layer3_residual_res2_norm</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2664.003,-70C2672.0277,-70 2680.9665,-70 2689.5309,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2689.7051,-73.5001 2699.705,-70 2689.705,-66.5001 2689.7051,-73.5001\"/>\n</g>\n<!-- layer3_residual_res2_act -->\n<g id=\"node31\" class=\"node\">\n<title>layer3_residual_res2_act</title>\n<g id=\"a_node31\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.activation.ReLU&#39;&gt; {}\">\n<path fill=\"#fb8072\" stroke=\"#000000\" d=\"M2832,-88C2832,-88 2802,-88 2802,-88 2796,-88 2790,-82 2790,-76 2790,-76 2790,-64 2790,-64 2790,-58 2796,-52 2802,-52 2802,-52 2832,-52 2832,-52 2838,-52 2844,-58 2844,-64 2844,-64 2844,-76 2844,-76 2844,-82 2838,-88 2832,-88\"/>\n<text text-anchor=\"middle\" x=\"2817\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">act</text>\n</a>\n</g>\n</g>\n<!-- layer3_residual_res2_norm&#45;&gt;layer3_residual_res2_act -->\n<g id=\"edge32\" class=\"edge\">\n<title>layer3_residual_res2_norm&#45;&gt;layer3_residual_res2_act</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2754.003,-70C2762.0277,-70 2770.9665,-70 2779.5309,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2779.7051,-73.5001 2789.705,-70 2779.705,-66.5001 2779.7051,-73.5001\"/>\n</g>\n<!-- layer3_residual_out -->\n<g id=\"node32\" class=\"node\">\n<title>layer3_residual_out</title>\n<g id=\"a_node32\"><a xlink:title=\"&lt;class &#39;__main__.Identity&#39;&gt; {}\">\n<path fill=\"#80b1d3\" stroke=\"#000000\" d=\"M2922,-98C2922,-98 2892,-98 2892,-98 2886,-98 2880,-92 2880,-86 2880,-86 2880,-74 2880,-74 2880,-68 2886,-62 2892,-62 2892,-62 2922,-62 2922,-62 2928,-62 2934,-68 2934,-74 2934,-74 2934,-86 2934,-86 2934,-92 2928,-98 2922,-98\"/>\n<text text-anchor=\"middle\" x=\"2907\" y=\"-76.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">out</text>\n</a>\n</g>\n</g>\n<!-- layer3_residual_res2_act&#45;&gt;layer3_residual_out -->\n<g id=\"edge33\" class=\"edge\">\n<title>layer3_residual_res2_act&#45;&gt;layer3_residual_out</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2844.003,-73.0003C2852.0277,-73.892 2860.9665,-74.8852 2869.5309,-75.8368\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2869.3796,-79.3414 2879.705,-76.9672 2870.1527,-72.3842 2869.3796,-79.3414\"/>\n</g>\n<!-- layer3_residual_out&#45;&gt;layer3_residual_add -->\n<g id=\"edge35\" class=\"edge\">\n<title>layer3_residual_out&#45;&gt;layer3_residual_add</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2934.003,-86.0007C2942.1158,-87.8035 2951.1631,-89.814 2959.8131,-91.7362\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2959.1839,-95.1817 2969.705,-93.9345 2960.7024,-88.3484 2959.1839,-95.1817\"/>\n</g>\n<!-- pool -->\n<g id=\"node34\" class=\"node\">\n<title>pool</title>\n<g id=\"a_node34\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.pooling.MaxPool2d&#39;&gt; {&#39;kernel_size&#39;: 4}\">\n<path fill=\"#8dd3c7\" stroke=\"#000000\" d=\"M3102,-118C3102,-118 3072,-118 3072,-118 3066,-118 3060,-112 3060,-106 3060,-106 3060,-94 3060,-94 3060,-88 3066,-82 3072,-82 3072,-82 3102,-82 3102,-82 3108,-82 3114,-88 3114,-94 3114,-94 3114,-106 3114,-106 3114,-112 3108,-118 3102,-118\"/>\n<text text-anchor=\"middle\" x=\"3087\" y=\"-96.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">pool</text>\n</a>\n</g>\n</g>\n<!-- layer3_residual_add&#45;&gt;pool -->\n<g id=\"edge36\" class=\"edge\">\n<title>layer3_residual_add&#45;&gt;pool</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M3024.003,-100C3032.0277,-100 3040.9665,-100 3049.5309,-100\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"3049.7051,-103.5001 3059.705,-100 3049.705,-96.5001 3049.7051,-103.5001\"/>\n</g>\n<!-- classifier_flatten -->\n<g id=\"node35\" class=\"node\">\n<title>classifier_flatten</title>\n<g id=\"a_node35\"><a xlink:title=\"&lt;class &#39;__main__.Flatten&#39;&gt; {}\">\n<path fill=\"#b3de69\" stroke=\"#000000\" d=\"M3192,-118C3192,-118 3162,-118 3162,-118 3156,-118 3150,-112 3150,-106 3150,-106 3150,-94 3150,-94 3150,-88 3156,-82 3162,-82 3162,-82 3192,-82 3192,-82 3198,-82 3204,-88 3204,-94 3204,-94 3204,-106 3204,-106 3204,-112 3198,-118 3192,-118\"/>\n<text text-anchor=\"middle\" x=\"3177\" y=\"-96.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">flatten</text>\n</a>\n</g>\n</g>\n<!-- pool&#45;&gt;classifier_flatten -->\n<g id=\"edge37\" class=\"edge\">\n<title>pool&#45;&gt;classifier_flatten</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M3114.003,-100C3122.0277,-100 3130.9665,-100 3139.5309,-100\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"3139.7051,-103.5001 3149.705,-100 3139.705,-96.5001 3139.7051,-103.5001\"/>\n</g>\n<!-- classifier_conv -->\n<g id=\"node36\" class=\"node\">\n<title>classifier_conv</title>\n<g id=\"a_node36\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.linear.Linear&#39;&gt; {&#39;in_features&#39;: 512, &#39;out_features&#39;: 10, &#39;bias&#39;: False}\">\n<path fill=\"#fccde5\" stroke=\"#000000\" d=\"M3282,-118C3282,-118 3252,-118 3252,-118 3246,-118 3240,-112 3240,-106 3240,-106 3240,-94 3240,-94 3240,-88 3246,-82 3252,-82 3252,-82 3282,-82 3282,-82 3288,-82 3294,-88 3294,-94 3294,-94 3294,-106 3294,-106 3294,-112 3288,-118 3282,-118\"/>\n<text text-anchor=\"middle\" x=\"3267\" y=\"-96.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">conv</text>\n</a>\n</g>\n</g>\n<!-- classifier_flatten&#45;&gt;classifier_conv -->\n<g id=\"edge38\" class=\"edge\">\n<title>classifier_flatten&#45;&gt;classifier_conv</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M3204.003,-100C3212.0277,-100 3220.9665,-100 3229.5309,-100\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"3229.7051,-103.5001 3239.705,-100 3229.705,-96.5001 3229.7051,-103.5001\"/>\n</g>\n<!-- classifier_scale -->\n<g id=\"node37\" class=\"node\">\n<title>classifier_scale</title>\n<g id=\"a_node37\"><a xlink:title=\"&lt;class &#39;__main__.Mul&#39;&gt; {&#39;weight&#39;: 0.125}\">\n<path fill=\"#bc80bd\" stroke=\"#000000\" d=\"M3372,-118C3372,-118 3342,-118 3342,-118 3336,-118 3330,-112 3330,-106 3330,-106 3330,-94 3330,-94 3330,-88 3336,-82 3342,-82 3342,-82 3372,-82 3372,-82 3378,-82 3384,-88 3384,-94 3384,-94 3384,-106 3384,-106 3384,-112 3378,-118 3372,-118\"/>\n<text text-anchor=\"middle\" x=\"3357\" y=\"-96.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">scale</text>\n</a>\n</g>\n</g>\n<!-- classifier_conv&#45;&gt;classifier_scale -->\n<g id=\"edge39\" class=\"edge\">\n<title>classifier_conv&#45;&gt;classifier_scale</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M3294.003,-100C3302.0277,-100 3310.9665,-100 3319.5309,-100\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"3319.7051,-103.5001 3329.705,-100 3319.705,-96.5001 3319.7051,-103.5001\"/>\n</g>\n<!-- logits -->\n<g id=\"node38\" class=\"node\">\n<title>logits</title>\n<g id=\"a_node38\"><a xlink:title=\"&lt;class &#39;__main__.Identity&#39;&gt; {}\">\n<path fill=\"#80b1d3\" stroke=\"#000000\" d=\"M3462,-118C3462,-118 3432,-118 3432,-118 3426,-118 3420,-112 3420,-106 3420,-106 3420,-94 3420,-94 3420,-88 3426,-82 3432,-82 3432,-82 3462,-82 3462,-82 3468,-82 3474,-88 3474,-94 3474,-94 3474,-106 3474,-106 3474,-112 3468,-118 3462,-118\"/>\n<text text-anchor=\"middle\" x=\"3447\" y=\"-96.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">logits</text>\n</a>\n</g>\n</g>\n<!-- classifier_scale&#45;&gt;logits -->\n<g id=\"edge40\" class=\"edge\">\n<title>classifier_scale&#45;&gt;logits</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M3384.003,-100C3392.0277,-100 3400.9665,-100 3409.5309,-100\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"3409.7051,-103.5001 3419.705,-100 3409.705,-96.5001 3409.7051,-103.5001\"/>\n</g>\n<!-- input -->\n<g id=\"node39\" class=\"node\">\n<title>input</title>\n<path fill=\"#ffffff\" stroke=\"#000000\" d=\"M42,-88C42,-88 12,-88 12,-88 6,-88 0,-82 0,-76 0,-76 0,-64 0,-64 0,-58 6,-52 12,-52 12,-52 42,-52 42,-52 48,-52 54,-58 54,-64 54,-64 54,-76 54,-76 54,-82 48,-88 42,-88\"/>\n<text text-anchor=\"middle\" x=\"27\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">input</text>\n</g>\n<!-- input&#45;&gt;prep_conv -->\n<g id=\"edge1\" class=\"edge\">\n<title>input&#45;&gt;prep_conv</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M54.003,-70C62.0277,-70 70.9665,-70 79.5309,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"79.7051,-73.5001 89.705,-70 79.705,-66.5001 79.7051,-73.5001\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCx6niO29qtZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "5cf85745-06d0-4aea-e6ec-91a7ea5ba3b1"
      },
      "source": [
        "epochs, batch_size = 24, 512\n",
        "transforms = (Crop(32, 32), FlipLR(), Cutout(8, 8))\n",
        "opt_params = {'lr': lr_schedule([0, 5, epochs], [0.0, 0.4, 0.0], batch_size), 'weight_decay': Const(5e-4*batch_size), 'momentum': Const(0.9)}\n",
        "\n",
        "model = build_model(network(conv_pool_block=conv_pool_block_opt), x_ent_loss)\n",
        "logs, state, timer = Table(), {MODEL: model, OPTS: [SGD(trainable_params(model).values(), opt_params)]}, Timer(torch.cuda.synchronize)\n",
        "for epoch in range(epochs):\n",
        "    logs.append(union({'epoch': epoch+1}, train_epoch(state, timer, train_batches(batch_size, transforms), valid_batches(batch_size))))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       epoch   train time   train loss    train acc   valid time   valid loss    valid acc   total time\n",
            "           1      11.4292       1.6379       0.4110       0.6565       1.4023       0.5069      11.4292\n",
            "           2      11.4494       0.9442       0.6631       0.6545       0.8868       0.6935      22.8786\n",
            "           3      11.4371       0.7330       0.7443       0.6579       0.8003       0.7136      34.3157\n",
            "           4      11.4377       0.6226       0.7845       0.6561       0.7860       0.7456      45.7534\n",
            "           5      11.4311       0.5620       0.8066       0.6517       0.6762       0.7621      57.1845\n",
            "           6      11.3999       0.5015       0.8262       0.6527       0.5816       0.7969      68.5845\n",
            "           7      11.3954       0.4433       0.8477       0.6508       0.6133       0.7911      79.9799\n",
            "           8      11.3743       0.4145       0.8581       0.6520       0.4912       0.8248      91.3542\n",
            "           9      11.3325       0.3822       0.8691       0.6504       0.4811       0.8395     102.6867\n",
            "          10      11.3368       0.3644       0.8769       0.6503       0.5505       0.8129     114.0235\n",
            "          11      11.3353       0.3419       0.8843       0.6505       0.4676       0.8462     125.3588\n",
            "          12      11.3345       0.3273       0.8882       0.6498       0.4030       0.8640     136.6933\n",
            "          13      11.3300       0.3070       0.8962       0.6499       0.4369       0.8548     148.0233\n",
            "          14      11.3387       0.2852       0.9034       0.6500       0.3725       0.8758     159.3620\n",
            "          15      11.3350       0.2686       0.9096       0.6485       0.4012       0.8647     170.6970\n",
            "          16      11.3382       0.2523       0.9150       0.6447       0.4341       0.8552     182.0351\n",
            "          17      11.3481       0.2360       0.9199       0.6484       0.3935       0.8710     193.3832\n",
            "          18      11.3469       0.2097       0.9303       0.6461       0.3725       0.8718     204.7301\n",
            "          19      11.3677       0.1854       0.9397       0.6474       0.2694       0.9096     216.0979\n",
            "          20      11.3553       0.1648       0.9458       0.6489       0.3097       0.8990     227.4531\n",
            "          21      11.3333       0.1423       0.9533       0.6481       0.2300       0.9217     238.7864\n",
            "          22      11.3323       0.1135       0.9645       0.6491       0.2252       0.9265     250.1188\n",
            "          23      11.3210       0.0910       0.9729       0.6454       0.1951       0.9350     261.4398\n",
            "          24      11.3323       0.0754       0.9784       0.6466       0.1822       0.9402     272.7722\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpB6j6de7keL",
        "colab_type": "text"
      },
      "source": [
        "A further 3s off! \n",
        "\n",
        "Perhaps we should try something more radical and move max-pooling before batch norm. This will achieve a further efficiency gain but will change the network \n",
        "so we need to test the effect on training.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfDw9V35-1Ng",
        "colab_type": "code",
        "outputId": "c8894133-8412-4ca5-d44b-45326341afb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "conv_pool_block_pre = lambda c_in, c_out: reorder(conv_pool_block(c_in, c_out), ('conv', 'pool', 'norm', 'act'))\n",
        "\n",
        "maxpool_pre_net = network(conv_pool_block=conv_pool_block_pre)\n",
        "show(maxpool_pre_net)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<__main__.DotGraph at 0x7f7f27b7b940>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: G Pages: 1 -->\n<svg width=\"1080pt\" height=\"64pt\"\n viewBox=\"0.00 0.00 1080.00 64.20\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(.3102 .3102) rotate(0) translate(4 203)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-203 3478,-203 3478,4 -4,4\"/>\n<g id=\"clust1\" class=\"cluster\">\n<title>cluster_prep</title>\n<path fill=\"#777777\" fill-opacity=\"0.266667\" stroke=\"#000000\" d=\"M94,-44C94,-44 320,-44 320,-44 326,-44 332,-50 332,-56 332,-56 332,-107 332,-107 332,-113 326,-119 320,-119 320,-119 94,-119 94,-119 88,-119 82,-113 82,-107 82,-107 82,-56 82,-56 82,-50 88,-44 94,-44\"/>\n<text text-anchor=\"middle\" x=\"207\" y=\"-103.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">prep</text>\n</g>\n<g id=\"clust2\" class=\"cluster\">\n<title>cluster_layer1</title>\n<path fill=\"#777777\" fill-opacity=\"0.266667\" stroke=\"#000000\" d=\"M364,-8C364,-8 1498,-8 1498,-8 1504,-8 1510,-14 1510,-20 1510,-20 1510,-159 1510,-159 1510,-165 1504,-171 1498,-171 1498,-171 364,-171 364,-171 358,-171 352,-165 352,-159 352,-159 352,-20 352,-20 352,-14 358,-8 364,-8\"/>\n<text text-anchor=\"middle\" x=\"931\" y=\"-155.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">layer1</text>\n</g>\n<g id=\"clust3\" class=\"cluster\">\n<title>cluster_layer1_residual</title>\n<path fill=\"#777777\" fill-opacity=\"0.266667\" stroke=\"#000000\" d=\"M724,-16C724,-16 1490,-16 1490,-16 1496,-16 1502,-22 1502,-28 1502,-28 1502,-128 1502,-128 1502,-134 1496,-140 1490,-140 1490,-140 724,-140 724,-140 718,-140 712,-134 712,-128 712,-128 712,-28 712,-28 712,-22 718,-16 724,-16\"/>\n<text text-anchor=\"middle\" x=\"1107\" y=\"-124.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">residual</text>\n</g>\n<g id=\"clust4\" class=\"cluster\">\n<title>cluster_layer1_residual_res1</title>\n<path fill=\"#777777\" fill-opacity=\"0.266667\" stroke=\"#000000\" d=\"M814,-24C814,-24 1040,-24 1040,-24 1046,-24 1052,-30 1052,-36 1052,-36 1052,-87 1052,-87 1052,-93 1046,-99 1040,-99 1040,-99 814,-99 814,-99 808,-99 802,-93 802,-87 802,-87 802,-36 802,-36 802,-30 808,-24 814,-24\"/>\n<text text-anchor=\"middle\" x=\"927\" y=\"-83.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">res1</text>\n</g>\n<g id=\"clust5\" class=\"cluster\">\n<title>cluster_layer1_residual_res2</title>\n<path fill=\"#777777\" fill-opacity=\"0.266667\" stroke=\"#000000\" d=\"M1084,-24C1084,-24 1310,-24 1310,-24 1316,-24 1322,-30 1322,-36 1322,-36 1322,-87 1322,-87 1322,-93 1316,-99 1310,-99 1310,-99 1084,-99 1084,-99 1078,-99 1072,-93 1072,-87 1072,-87 1072,-36 1072,-36 1072,-30 1078,-24 1084,-24\"/>\n<text text-anchor=\"middle\" x=\"1197\" y=\"-83.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">res2</text>\n</g>\n<g id=\"clust6\" class=\"cluster\">\n<title>cluster_layer2</title>\n<path fill=\"#777777\" fill-opacity=\"0.266667\" stroke=\"#000000\" d=\"M1534,-54C1534,-54 1850,-54 1850,-54 1856,-54 1862,-60 1862,-66 1862,-66 1862,-117 1862,-117 1862,-123 1856,-129 1850,-129 1850,-129 1534,-129 1534,-129 1528,-129 1522,-123 1522,-117 1522,-117 1522,-66 1522,-66 1522,-60 1528,-54 1534,-54\"/>\n<text text-anchor=\"middle\" x=\"1692\" y=\"-113.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">layer2</text>\n</g>\n<g id=\"clust7\" class=\"cluster\">\n<title>cluster_layer3</title>\n<path fill=\"#777777\" fill-opacity=\"0.266667\" stroke=\"#000000\" d=\"M1894,-28C1894,-28 3028,-28 3028,-28 3034,-28 3040,-34 3040,-40 3040,-40 3040,-179 3040,-179 3040,-185 3034,-191 3028,-191 3028,-191 1894,-191 1894,-191 1888,-191 1882,-185 1882,-179 1882,-179 1882,-40 1882,-40 1882,-34 1888,-28 1894,-28\"/>\n<text text-anchor=\"middle\" x=\"2461\" y=\"-175.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">layer3</text>\n</g>\n<g id=\"clust8\" class=\"cluster\">\n<title>cluster_layer3_residual</title>\n<path fill=\"#777777\" fill-opacity=\"0.266667\" stroke=\"#000000\" d=\"M2254,-36C2254,-36 3020,-36 3020,-36 3026,-36 3032,-42 3032,-48 3032,-48 3032,-148 3032,-148 3032,-154 3026,-160 3020,-160 3020,-160 2254,-160 2254,-160 2248,-160 2242,-154 2242,-148 2242,-148 2242,-48 2242,-48 2242,-42 2248,-36 2254,-36\"/>\n<text text-anchor=\"middle\" x=\"2637\" y=\"-144.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">residual</text>\n</g>\n<g id=\"clust9\" class=\"cluster\">\n<title>cluster_layer3_residual_res1</title>\n<path fill=\"#777777\" fill-opacity=\"0.266667\" stroke=\"#000000\" d=\"M2344,-44C2344,-44 2570,-44 2570,-44 2576,-44 2582,-50 2582,-56 2582,-56 2582,-107 2582,-107 2582,-113 2576,-119 2570,-119 2570,-119 2344,-119 2344,-119 2338,-119 2332,-113 2332,-107 2332,-107 2332,-56 2332,-56 2332,-50 2338,-44 2344,-44\"/>\n<text text-anchor=\"middle\" x=\"2457\" y=\"-103.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">res1</text>\n</g>\n<g id=\"clust10\" class=\"cluster\">\n<title>cluster_layer3_residual_res2</title>\n<path fill=\"#777777\" fill-opacity=\"0.266667\" stroke=\"#000000\" d=\"M2614,-44C2614,-44 2840,-44 2840,-44 2846,-44 2852,-50 2852,-56 2852,-56 2852,-107 2852,-107 2852,-113 2846,-119 2840,-119 2840,-119 2614,-119 2614,-119 2608,-119 2602,-113 2602,-107 2602,-107 2602,-56 2602,-56 2602,-50 2608,-44 2614,-44\"/>\n<text text-anchor=\"middle\" x=\"2727\" y=\"-103.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">res2</text>\n</g>\n<g id=\"clust11\" class=\"cluster\">\n<title>cluster_classifier</title>\n<path fill=\"#777777\" fill-opacity=\"0.266667\" stroke=\"#000000\" d=\"M3154,-74C3154,-74 3380,-74 3380,-74 3386,-74 3392,-80 3392,-86 3392,-86 3392,-137 3392,-137 3392,-143 3386,-149 3380,-149 3380,-149 3154,-149 3154,-149 3148,-149 3142,-143 3142,-137 3142,-137 3142,-86 3142,-86 3142,-80 3148,-74 3154,-74\"/>\n<text text-anchor=\"middle\" x=\"3267\" y=\"-133.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">classifier</text>\n</g>\n<!-- prep_conv -->\n<g id=\"node1\" class=\"node\">\n<title>prep_conv</title>\n<g id=\"a_node1\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.conv.Conv2d&#39;&gt; {&#39;in_channels&#39;: 3, &#39;out_channels&#39;: 64, &#39;kernel_size&#39;: (3, 3), &#39;stride&#39;: (1, 1), &#39;padding&#39;: (1, 1), &#39;bias&#39;: False}\">\n<path fill=\"#bebada\" stroke=\"#000000\" d=\"M132,-88C132,-88 102,-88 102,-88 96,-88 90,-82 90,-76 90,-76 90,-64 90,-64 90,-58 96,-52 102,-52 102,-52 132,-52 132,-52 138,-52 144,-58 144,-64 144,-64 144,-76 144,-76 144,-82 138,-88 132,-88\"/>\n<text text-anchor=\"middle\" x=\"117\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">conv</text>\n</a>\n</g>\n</g>\n<!-- prep_norm -->\n<g id=\"node2\" class=\"node\">\n<title>prep_norm</title>\n<g id=\"a_node2\"><a xlink:title=\"&lt;class &#39;__main__.BatchNorm&#39;&gt; {&#39;num_features&#39;: 64}\">\n<path fill=\"#ffffb3\" stroke=\"#000000\" d=\"M222,-88C222,-88 192,-88 192,-88 186,-88 180,-82 180,-76 180,-76 180,-64 180,-64 180,-58 186,-52 192,-52 192,-52 222,-52 222,-52 228,-52 234,-58 234,-64 234,-64 234,-76 234,-76 234,-82 228,-88 222,-88\"/>\n<text text-anchor=\"middle\" x=\"207\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">norm</text>\n</a>\n</g>\n</g>\n<!-- prep_conv&#45;&gt;prep_norm -->\n<g id=\"edge2\" class=\"edge\">\n<title>prep_conv&#45;&gt;prep_norm</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M144.003,-70C152.0277,-70 160.9665,-70 169.5309,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"169.7051,-73.5001 179.705,-70 169.705,-66.5001 169.7051,-73.5001\"/>\n</g>\n<!-- prep_act -->\n<g id=\"node3\" class=\"node\">\n<title>prep_act</title>\n<g id=\"a_node3\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.activation.ReLU&#39;&gt; {}\">\n<path fill=\"#fb8072\" stroke=\"#000000\" d=\"M312,-88C312,-88 282,-88 282,-88 276,-88 270,-82 270,-76 270,-76 270,-64 270,-64 270,-58 276,-52 282,-52 282,-52 312,-52 312,-52 318,-52 324,-58 324,-64 324,-64 324,-76 324,-76 324,-82 318,-88 312,-88\"/>\n<text text-anchor=\"middle\" x=\"297\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">act</text>\n</a>\n</g>\n</g>\n<!-- prep_norm&#45;&gt;prep_act -->\n<g id=\"edge3\" class=\"edge\">\n<title>prep_norm&#45;&gt;prep_act</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M234.003,-70C242.0277,-70 250.9665,-70 259.5309,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"259.7051,-73.5001 269.705,-70 259.705,-66.5001 259.7051,-73.5001\"/>\n</g>\n<!-- layer1_conv -->\n<g id=\"node4\" class=\"node\">\n<title>layer1_conv</title>\n<g id=\"a_node4\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.conv.Conv2d&#39;&gt; {&#39;in_channels&#39;: 64, &#39;out_channels&#39;: 128, &#39;kernel_size&#39;: (3, 3), &#39;stride&#39;: (1, 1), &#39;padding&#39;: (1, 1), &#39;bias&#39;: False}\">\n<path fill=\"#bebada\" stroke=\"#000000\" d=\"M402,-88C402,-88 372,-88 372,-88 366,-88 360,-82 360,-76 360,-76 360,-64 360,-64 360,-58 366,-52 372,-52 372,-52 402,-52 402,-52 408,-52 414,-58 414,-64 414,-64 414,-76 414,-76 414,-82 408,-88 402,-88\"/>\n<text text-anchor=\"middle\" x=\"387\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">conv</text>\n</a>\n</g>\n</g>\n<!-- prep_act&#45;&gt;layer1_conv -->\n<g id=\"edge4\" class=\"edge\">\n<title>prep_act&#45;&gt;layer1_conv</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M324.003,-70C332.0277,-70 340.9665,-70 349.5309,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"349.7051,-73.5001 359.705,-70 349.705,-66.5001 349.7051,-73.5001\"/>\n</g>\n<!-- layer1_pool -->\n<g id=\"node5\" class=\"node\">\n<title>layer1_pool</title>\n<g id=\"a_node5\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.pooling.MaxPool2d&#39;&gt; {&#39;kernel_size&#39;: 2}\">\n<path fill=\"#8dd3c7\" stroke=\"#000000\" d=\"M492,-88C492,-88 462,-88 462,-88 456,-88 450,-82 450,-76 450,-76 450,-64 450,-64 450,-58 456,-52 462,-52 462,-52 492,-52 492,-52 498,-52 504,-58 504,-64 504,-64 504,-76 504,-76 504,-82 498,-88 492,-88\"/>\n<text text-anchor=\"middle\" x=\"477\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">pool</text>\n</a>\n</g>\n</g>\n<!-- layer1_conv&#45;&gt;layer1_pool -->\n<g id=\"edge5\" class=\"edge\">\n<title>layer1_conv&#45;&gt;layer1_pool</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M414.003,-70C422.0277,-70 430.9665,-70 439.5309,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"439.7051,-73.5001 449.705,-70 439.705,-66.5001 439.7051,-73.5001\"/>\n</g>\n<!-- layer1_norm -->\n<g id=\"node6\" class=\"node\">\n<title>layer1_norm</title>\n<g id=\"a_node6\"><a xlink:title=\"&lt;class &#39;__main__.BatchNorm&#39;&gt; {&#39;num_features&#39;: 128}\">\n<path fill=\"#ffffb3\" stroke=\"#000000\" d=\"M582,-88C582,-88 552,-88 552,-88 546,-88 540,-82 540,-76 540,-76 540,-64 540,-64 540,-58 546,-52 552,-52 552,-52 582,-52 582,-52 588,-52 594,-58 594,-64 594,-64 594,-76 594,-76 594,-82 588,-88 582,-88\"/>\n<text text-anchor=\"middle\" x=\"567\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">norm</text>\n</a>\n</g>\n</g>\n<!-- layer1_pool&#45;&gt;layer1_norm -->\n<g id=\"edge6\" class=\"edge\">\n<title>layer1_pool&#45;&gt;layer1_norm</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M504.003,-70C512.0277,-70 520.9665,-70 529.5309,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"529.7051,-73.5001 539.705,-70 529.705,-66.5001 529.7051,-73.5001\"/>\n</g>\n<!-- layer1_act -->\n<g id=\"node7\" class=\"node\">\n<title>layer1_act</title>\n<g id=\"a_node7\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.activation.ReLU&#39;&gt; {}\">\n<path fill=\"#fb8072\" stroke=\"#000000\" d=\"M672,-88C672,-88 642,-88 642,-88 636,-88 630,-82 630,-76 630,-76 630,-64 630,-64 630,-58 636,-52 642,-52 642,-52 672,-52 672,-52 678,-52 684,-58 684,-64 684,-64 684,-76 684,-76 684,-82 678,-88 672,-88\"/>\n<text text-anchor=\"middle\" x=\"657\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">act</text>\n</a>\n</g>\n</g>\n<!-- layer1_norm&#45;&gt;layer1_act -->\n<g id=\"edge7\" class=\"edge\">\n<title>layer1_norm&#45;&gt;layer1_act</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M594.003,-70C602.0277,-70 610.9665,-70 619.5309,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"619.7051,-73.5001 629.705,-70 619.705,-66.5001 619.7051,-73.5001\"/>\n</g>\n<!-- layer1_residual_in -->\n<g id=\"node8\" class=\"node\">\n<title>layer1_residual_in</title>\n<g id=\"a_node8\"><a xlink:title=\"&lt;class &#39;__main__.Identity&#39;&gt; {}\">\n<path fill=\"#80b1d3\" stroke=\"#000000\" d=\"M762,-88C762,-88 732,-88 732,-88 726,-88 720,-82 720,-76 720,-76 720,-64 720,-64 720,-58 726,-52 732,-52 732,-52 762,-52 762,-52 768,-52 774,-58 774,-64 774,-64 774,-76 774,-76 774,-82 768,-88 762,-88\"/>\n<text text-anchor=\"middle\" x=\"747\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">in</text>\n</a>\n</g>\n</g>\n<!-- layer1_act&#45;&gt;layer1_residual_in -->\n<g id=\"edge8\" class=\"edge\">\n<title>layer1_act&#45;&gt;layer1_residual_in</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M684.003,-70C692.0277,-70 700.9665,-70 709.5309,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"709.7051,-73.5001 719.705,-70 709.705,-66.5001 709.7051,-73.5001\"/>\n</g>\n<!-- layer1_residual_res1_conv -->\n<g id=\"node9\" class=\"node\">\n<title>layer1_residual_res1_conv</title>\n<g id=\"a_node9\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.conv.Conv2d&#39;&gt; {&#39;in_channels&#39;: 128, &#39;out_channels&#39;: 128, &#39;kernel_size&#39;: (3, 3), &#39;stride&#39;: (1, 1), &#39;padding&#39;: (1, 1), &#39;bias&#39;: False}\">\n<path fill=\"#bebada\" stroke=\"#000000\" d=\"M852,-68C852,-68 822,-68 822,-68 816,-68 810,-62 810,-56 810,-56 810,-44 810,-44 810,-38 816,-32 822,-32 822,-32 852,-32 852,-32 858,-32 864,-38 864,-44 864,-44 864,-56 864,-56 864,-62 858,-68 852,-68\"/>\n<text text-anchor=\"middle\" x=\"837\" y=\"-46.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">conv</text>\n</a>\n</g>\n</g>\n<!-- layer1_residual_in&#45;&gt;layer1_residual_res1_conv -->\n<g id=\"edge9\" class=\"edge\">\n<title>layer1_residual_in&#45;&gt;layer1_residual_res1_conv</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M774.003,-63.9993C782.1158,-62.1965 791.1631,-60.186 799.8131,-58.2638\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"800.7024,-61.6516 809.705,-56.0655 799.1839,-54.8183 800.7024,-61.6516\"/>\n</g>\n<!-- layer1_residual_add -->\n<g id=\"node16\" class=\"node\">\n<title>layer1_residual_add</title>\n<g id=\"a_node16\"><a xlink:title=\"&lt;class &#39;__main__.Add&#39;&gt; {}\">\n<path fill=\"#fdb462\" stroke=\"#000000\" d=\"M1482,-98C1482,-98 1452,-98 1452,-98 1446,-98 1440,-92 1440,-86 1440,-86 1440,-74 1440,-74 1440,-68 1446,-62 1452,-62 1452,-62 1482,-62 1482,-62 1488,-62 1494,-68 1494,-74 1494,-74 1494,-86 1494,-86 1494,-92 1488,-98 1482,-98\"/>\n<text text-anchor=\"middle\" x=\"1467\" y=\"-76.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">add</text>\n</a>\n</g>\n</g>\n<!-- layer1_residual_in&#45;&gt;layer1_residual_add -->\n<g id=\"edge16\" class=\"edge\">\n<title>layer1_residual_in&#45;&gt;layer1_residual_add</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M771.2203,-88.104C780.3892,-93.9663 791.2234,-99.7818 802,-103 855.2752,-118.9095 871.4,-108 927,-108 927,-108 927,-108 1287,-108 1336.7971,-108 1393.4324,-97.4074 1429.6554,-89.2525\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1430.8023,-92.5799 1439.7594,-86.9214 1429.2285,-85.7591 1430.8023,-92.5799\"/>\n</g>\n<!-- layer1_residual_res1_norm -->\n<g id=\"node10\" class=\"node\">\n<title>layer1_residual_res1_norm</title>\n<g id=\"a_node10\"><a xlink:title=\"&lt;class &#39;__main__.BatchNorm&#39;&gt; {&#39;num_features&#39;: 128}\">\n<path fill=\"#ffffb3\" stroke=\"#000000\" d=\"M942,-68C942,-68 912,-68 912,-68 906,-68 900,-62 900,-56 900,-56 900,-44 900,-44 900,-38 906,-32 912,-32 912,-32 942,-32 942,-32 948,-32 954,-38 954,-44 954,-44 954,-56 954,-56 954,-62 948,-68 942,-68\"/>\n<text text-anchor=\"middle\" x=\"927\" y=\"-46.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">norm</text>\n</a>\n</g>\n</g>\n<!-- layer1_residual_res1_conv&#45;&gt;layer1_residual_res1_norm -->\n<g id=\"edge10\" class=\"edge\">\n<title>layer1_residual_res1_conv&#45;&gt;layer1_residual_res1_norm</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M864.003,-50C872.0277,-50 880.9665,-50 889.5309,-50\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"889.7051,-53.5001 899.705,-50 889.705,-46.5001 889.7051,-53.5001\"/>\n</g>\n<!-- layer1_residual_res1_act -->\n<g id=\"node11\" class=\"node\">\n<title>layer1_residual_res1_act</title>\n<g id=\"a_node11\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.activation.ReLU&#39;&gt; {}\">\n<path fill=\"#fb8072\" stroke=\"#000000\" d=\"M1032,-68C1032,-68 1002,-68 1002,-68 996,-68 990,-62 990,-56 990,-56 990,-44 990,-44 990,-38 996,-32 1002,-32 1002,-32 1032,-32 1032,-32 1038,-32 1044,-38 1044,-44 1044,-44 1044,-56 1044,-56 1044,-62 1038,-68 1032,-68\"/>\n<text text-anchor=\"middle\" x=\"1017\" y=\"-46.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">act</text>\n</a>\n</g>\n</g>\n<!-- layer1_residual_res1_norm&#45;&gt;layer1_residual_res1_act -->\n<g id=\"edge11\" class=\"edge\">\n<title>layer1_residual_res1_norm&#45;&gt;layer1_residual_res1_act</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M954.003,-50C962.0277,-50 970.9665,-50 979.5309,-50\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"979.7051,-53.5001 989.705,-50 979.705,-46.5001 979.7051,-53.5001\"/>\n</g>\n<!-- layer1_residual_res2_conv -->\n<g id=\"node12\" class=\"node\">\n<title>layer1_residual_res2_conv</title>\n<g id=\"a_node12\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.conv.Conv2d&#39;&gt; {&#39;in_channels&#39;: 128, &#39;out_channels&#39;: 128, &#39;kernel_size&#39;: (3, 3), &#39;stride&#39;: (1, 1), &#39;padding&#39;: (1, 1), &#39;bias&#39;: False}\">\n<path fill=\"#bebada\" stroke=\"#000000\" d=\"M1122,-68C1122,-68 1092,-68 1092,-68 1086,-68 1080,-62 1080,-56 1080,-56 1080,-44 1080,-44 1080,-38 1086,-32 1092,-32 1092,-32 1122,-32 1122,-32 1128,-32 1134,-38 1134,-44 1134,-44 1134,-56 1134,-56 1134,-62 1128,-68 1122,-68\"/>\n<text text-anchor=\"middle\" x=\"1107\" y=\"-46.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">conv</text>\n</a>\n</g>\n</g>\n<!-- layer1_residual_res1_act&#45;&gt;layer1_residual_res2_conv -->\n<g id=\"edge12\" class=\"edge\">\n<title>layer1_residual_res1_act&#45;&gt;layer1_residual_res2_conv</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1044.003,-50C1052.0277,-50 1060.9665,-50 1069.5309,-50\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1069.7051,-53.5001 1079.705,-50 1069.705,-46.5001 1069.7051,-53.5001\"/>\n</g>\n<!-- layer1_residual_res2_norm -->\n<g id=\"node13\" class=\"node\">\n<title>layer1_residual_res2_norm</title>\n<g id=\"a_node13\"><a xlink:title=\"&lt;class &#39;__main__.BatchNorm&#39;&gt; {&#39;num_features&#39;: 128}\">\n<path fill=\"#ffffb3\" stroke=\"#000000\" d=\"M1212,-68C1212,-68 1182,-68 1182,-68 1176,-68 1170,-62 1170,-56 1170,-56 1170,-44 1170,-44 1170,-38 1176,-32 1182,-32 1182,-32 1212,-32 1212,-32 1218,-32 1224,-38 1224,-44 1224,-44 1224,-56 1224,-56 1224,-62 1218,-68 1212,-68\"/>\n<text text-anchor=\"middle\" x=\"1197\" y=\"-46.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">norm</text>\n</a>\n</g>\n</g>\n<!-- layer1_residual_res2_conv&#45;&gt;layer1_residual_res2_norm -->\n<g id=\"edge13\" class=\"edge\">\n<title>layer1_residual_res2_conv&#45;&gt;layer1_residual_res2_norm</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1134.003,-50C1142.0277,-50 1150.9665,-50 1159.5309,-50\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1159.7051,-53.5001 1169.705,-50 1159.705,-46.5001 1159.7051,-53.5001\"/>\n</g>\n<!-- layer1_residual_res2_act -->\n<g id=\"node14\" class=\"node\">\n<title>layer1_residual_res2_act</title>\n<g id=\"a_node14\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.activation.ReLU&#39;&gt; {}\">\n<path fill=\"#fb8072\" stroke=\"#000000\" d=\"M1302,-68C1302,-68 1272,-68 1272,-68 1266,-68 1260,-62 1260,-56 1260,-56 1260,-44 1260,-44 1260,-38 1266,-32 1272,-32 1272,-32 1302,-32 1302,-32 1308,-32 1314,-38 1314,-44 1314,-44 1314,-56 1314,-56 1314,-62 1308,-68 1302,-68\"/>\n<text text-anchor=\"middle\" x=\"1287\" y=\"-46.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">act</text>\n</a>\n</g>\n</g>\n<!-- layer1_residual_res2_norm&#45;&gt;layer1_residual_res2_act -->\n<g id=\"edge14\" class=\"edge\">\n<title>layer1_residual_res2_norm&#45;&gt;layer1_residual_res2_act</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1224.003,-50C1232.0277,-50 1240.9665,-50 1249.5309,-50\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1249.7051,-53.5001 1259.705,-50 1249.705,-46.5001 1249.7051,-53.5001\"/>\n</g>\n<!-- layer1_residual_out -->\n<g id=\"node15\" class=\"node\">\n<title>layer1_residual_out</title>\n<g id=\"a_node15\"><a xlink:title=\"&lt;class &#39;__main__.Identity&#39;&gt; {}\">\n<path fill=\"#80b1d3\" stroke=\"#000000\" d=\"M1392,-78C1392,-78 1362,-78 1362,-78 1356,-78 1350,-72 1350,-66 1350,-66 1350,-54 1350,-54 1350,-48 1356,-42 1362,-42 1362,-42 1392,-42 1392,-42 1398,-42 1404,-48 1404,-54 1404,-54 1404,-66 1404,-66 1404,-72 1398,-78 1392,-78\"/>\n<text text-anchor=\"middle\" x=\"1377\" y=\"-56.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">out</text>\n</a>\n</g>\n</g>\n<!-- layer1_residual_res2_act&#45;&gt;layer1_residual_out -->\n<g id=\"edge15\" class=\"edge\">\n<title>layer1_residual_res2_act&#45;&gt;layer1_residual_out</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1314.003,-53.0003C1322.0277,-53.892 1330.9665,-54.8852 1339.5309,-55.8368\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1339.3796,-59.3414 1349.705,-56.9672 1340.1527,-52.3842 1339.3796,-59.3414\"/>\n</g>\n<!-- layer1_residual_out&#45;&gt;layer1_residual_add -->\n<g id=\"edge17\" class=\"edge\">\n<title>layer1_residual_out&#45;&gt;layer1_residual_add</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1404.003,-66.0007C1412.1158,-67.8035 1421.1631,-69.814 1429.8131,-71.7362\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1429.1839,-75.1817 1439.705,-73.9345 1430.7024,-68.3484 1429.1839,-75.1817\"/>\n</g>\n<!-- layer2_conv -->\n<g id=\"node17\" class=\"node\">\n<title>layer2_conv</title>\n<g id=\"a_node17\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.conv.Conv2d&#39;&gt; {&#39;in_channels&#39;: 128, &#39;out_channels&#39;: 256, &#39;kernel_size&#39;: (3, 3), &#39;stride&#39;: (1, 1), &#39;padding&#39;: (1, 1), &#39;bias&#39;: False}\">\n<path fill=\"#bebada\" stroke=\"#000000\" d=\"M1572,-98C1572,-98 1542,-98 1542,-98 1536,-98 1530,-92 1530,-86 1530,-86 1530,-74 1530,-74 1530,-68 1536,-62 1542,-62 1542,-62 1572,-62 1572,-62 1578,-62 1584,-68 1584,-74 1584,-74 1584,-86 1584,-86 1584,-92 1578,-98 1572,-98\"/>\n<text text-anchor=\"middle\" x=\"1557\" y=\"-76.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">conv</text>\n</a>\n</g>\n</g>\n<!-- layer1_residual_add&#45;&gt;layer2_conv -->\n<g id=\"edge18\" class=\"edge\">\n<title>layer1_residual_add&#45;&gt;layer2_conv</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1494.003,-80C1502.0277,-80 1510.9665,-80 1519.5309,-80\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1519.7051,-83.5001 1529.705,-80 1519.705,-76.5001 1519.7051,-83.5001\"/>\n</g>\n<!-- layer2_pool -->\n<g id=\"node18\" class=\"node\">\n<title>layer2_pool</title>\n<g id=\"a_node18\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.pooling.MaxPool2d&#39;&gt; {&#39;kernel_size&#39;: 2}\">\n<path fill=\"#8dd3c7\" stroke=\"#000000\" d=\"M1662,-98C1662,-98 1632,-98 1632,-98 1626,-98 1620,-92 1620,-86 1620,-86 1620,-74 1620,-74 1620,-68 1626,-62 1632,-62 1632,-62 1662,-62 1662,-62 1668,-62 1674,-68 1674,-74 1674,-74 1674,-86 1674,-86 1674,-92 1668,-98 1662,-98\"/>\n<text text-anchor=\"middle\" x=\"1647\" y=\"-76.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">pool</text>\n</a>\n</g>\n</g>\n<!-- layer2_conv&#45;&gt;layer2_pool -->\n<g id=\"edge19\" class=\"edge\">\n<title>layer2_conv&#45;&gt;layer2_pool</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1584.003,-80C1592.0277,-80 1600.9665,-80 1609.5309,-80\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1609.7051,-83.5001 1619.705,-80 1609.705,-76.5001 1609.7051,-83.5001\"/>\n</g>\n<!-- layer2_norm -->\n<g id=\"node19\" class=\"node\">\n<title>layer2_norm</title>\n<g id=\"a_node19\"><a xlink:title=\"&lt;class &#39;__main__.BatchNorm&#39;&gt; {&#39;num_features&#39;: 256}\">\n<path fill=\"#ffffb3\" stroke=\"#000000\" d=\"M1752,-98C1752,-98 1722,-98 1722,-98 1716,-98 1710,-92 1710,-86 1710,-86 1710,-74 1710,-74 1710,-68 1716,-62 1722,-62 1722,-62 1752,-62 1752,-62 1758,-62 1764,-68 1764,-74 1764,-74 1764,-86 1764,-86 1764,-92 1758,-98 1752,-98\"/>\n<text text-anchor=\"middle\" x=\"1737\" y=\"-76.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">norm</text>\n</a>\n</g>\n</g>\n<!-- layer2_pool&#45;&gt;layer2_norm -->\n<g id=\"edge20\" class=\"edge\">\n<title>layer2_pool&#45;&gt;layer2_norm</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1674.003,-80C1682.0277,-80 1690.9665,-80 1699.5309,-80\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1699.7051,-83.5001 1709.705,-80 1699.705,-76.5001 1699.7051,-83.5001\"/>\n</g>\n<!-- layer2_act -->\n<g id=\"node20\" class=\"node\">\n<title>layer2_act</title>\n<g id=\"a_node20\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.activation.ReLU&#39;&gt; {}\">\n<path fill=\"#fb8072\" stroke=\"#000000\" d=\"M1842,-98C1842,-98 1812,-98 1812,-98 1806,-98 1800,-92 1800,-86 1800,-86 1800,-74 1800,-74 1800,-68 1806,-62 1812,-62 1812,-62 1842,-62 1842,-62 1848,-62 1854,-68 1854,-74 1854,-74 1854,-86 1854,-86 1854,-92 1848,-98 1842,-98\"/>\n<text text-anchor=\"middle\" x=\"1827\" y=\"-76.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">act</text>\n</a>\n</g>\n</g>\n<!-- layer2_norm&#45;&gt;layer2_act -->\n<g id=\"edge21\" class=\"edge\">\n<title>layer2_norm&#45;&gt;layer2_act</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1764.003,-80C1772.0277,-80 1780.9665,-80 1789.5309,-80\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1789.7051,-83.5001 1799.705,-80 1789.705,-76.5001 1789.7051,-83.5001\"/>\n</g>\n<!-- layer3_conv -->\n<g id=\"node21\" class=\"node\">\n<title>layer3_conv</title>\n<g id=\"a_node21\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.conv.Conv2d&#39;&gt; {&#39;in_channels&#39;: 256, &#39;out_channels&#39;: 512, &#39;kernel_size&#39;: (3, 3), &#39;stride&#39;: (1, 1), &#39;padding&#39;: (1, 1), &#39;bias&#39;: False}\">\n<path fill=\"#bebada\" stroke=\"#000000\" d=\"M1932,-98C1932,-98 1902,-98 1902,-98 1896,-98 1890,-92 1890,-86 1890,-86 1890,-74 1890,-74 1890,-68 1896,-62 1902,-62 1902,-62 1932,-62 1932,-62 1938,-62 1944,-68 1944,-74 1944,-74 1944,-86 1944,-86 1944,-92 1938,-98 1932,-98\"/>\n<text text-anchor=\"middle\" x=\"1917\" y=\"-76.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">conv</text>\n</a>\n</g>\n</g>\n<!-- layer2_act&#45;&gt;layer3_conv -->\n<g id=\"edge22\" class=\"edge\">\n<title>layer2_act&#45;&gt;layer3_conv</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1854.003,-80C1862.0277,-80 1870.9665,-80 1879.5309,-80\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1879.7051,-83.5001 1889.705,-80 1879.705,-76.5001 1879.7051,-83.5001\"/>\n</g>\n<!-- layer3_pool -->\n<g id=\"node22\" class=\"node\">\n<title>layer3_pool</title>\n<g id=\"a_node22\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.pooling.MaxPool2d&#39;&gt; {&#39;kernel_size&#39;: 2}\">\n<path fill=\"#8dd3c7\" stroke=\"#000000\" d=\"M2022,-98C2022,-98 1992,-98 1992,-98 1986,-98 1980,-92 1980,-86 1980,-86 1980,-74 1980,-74 1980,-68 1986,-62 1992,-62 1992,-62 2022,-62 2022,-62 2028,-62 2034,-68 2034,-74 2034,-74 2034,-86 2034,-86 2034,-92 2028,-98 2022,-98\"/>\n<text text-anchor=\"middle\" x=\"2007\" y=\"-76.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">pool</text>\n</a>\n</g>\n</g>\n<!-- layer3_conv&#45;&gt;layer3_pool -->\n<g id=\"edge23\" class=\"edge\">\n<title>layer3_conv&#45;&gt;layer3_pool</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1944.003,-80C1952.0277,-80 1960.9665,-80 1969.5309,-80\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1969.7051,-83.5001 1979.705,-80 1969.705,-76.5001 1969.7051,-83.5001\"/>\n</g>\n<!-- layer3_norm -->\n<g id=\"node23\" class=\"node\">\n<title>layer3_norm</title>\n<g id=\"a_node23\"><a xlink:title=\"&lt;class &#39;__main__.BatchNorm&#39;&gt; {&#39;num_features&#39;: 512}\">\n<path fill=\"#ffffb3\" stroke=\"#000000\" d=\"M2112,-98C2112,-98 2082,-98 2082,-98 2076,-98 2070,-92 2070,-86 2070,-86 2070,-74 2070,-74 2070,-68 2076,-62 2082,-62 2082,-62 2112,-62 2112,-62 2118,-62 2124,-68 2124,-74 2124,-74 2124,-86 2124,-86 2124,-92 2118,-98 2112,-98\"/>\n<text text-anchor=\"middle\" x=\"2097\" y=\"-76.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">norm</text>\n</a>\n</g>\n</g>\n<!-- layer3_pool&#45;&gt;layer3_norm -->\n<g id=\"edge24\" class=\"edge\">\n<title>layer3_pool&#45;&gt;layer3_norm</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2034.003,-80C2042.0277,-80 2050.9665,-80 2059.5309,-80\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2059.7051,-83.5001 2069.705,-80 2059.705,-76.5001 2059.7051,-83.5001\"/>\n</g>\n<!-- layer3_act -->\n<g id=\"node24\" class=\"node\">\n<title>layer3_act</title>\n<g id=\"a_node24\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.activation.ReLU&#39;&gt; {}\">\n<path fill=\"#fb8072\" stroke=\"#000000\" d=\"M2202,-98C2202,-98 2172,-98 2172,-98 2166,-98 2160,-92 2160,-86 2160,-86 2160,-74 2160,-74 2160,-68 2166,-62 2172,-62 2172,-62 2202,-62 2202,-62 2208,-62 2214,-68 2214,-74 2214,-74 2214,-86 2214,-86 2214,-92 2208,-98 2202,-98\"/>\n<text text-anchor=\"middle\" x=\"2187\" y=\"-76.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">act</text>\n</a>\n</g>\n</g>\n<!-- layer3_norm&#45;&gt;layer3_act -->\n<g id=\"edge25\" class=\"edge\">\n<title>layer3_norm&#45;&gt;layer3_act</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2124.003,-80C2132.0277,-80 2140.9665,-80 2149.5309,-80\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2149.7051,-83.5001 2159.705,-80 2149.705,-76.5001 2149.7051,-83.5001\"/>\n</g>\n<!-- layer3_residual_in -->\n<g id=\"node25\" class=\"node\">\n<title>layer3_residual_in</title>\n<g id=\"a_node25\"><a xlink:title=\"&lt;class &#39;__main__.Identity&#39;&gt; {}\">\n<path fill=\"#80b1d3\" stroke=\"#000000\" d=\"M2292,-98C2292,-98 2262,-98 2262,-98 2256,-98 2250,-92 2250,-86 2250,-86 2250,-74 2250,-74 2250,-68 2256,-62 2262,-62 2262,-62 2292,-62 2292,-62 2298,-62 2304,-68 2304,-74 2304,-74 2304,-86 2304,-86 2304,-92 2298,-98 2292,-98\"/>\n<text text-anchor=\"middle\" x=\"2277\" y=\"-76.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">in</text>\n</a>\n</g>\n</g>\n<!-- layer3_act&#45;&gt;layer3_residual_in -->\n<g id=\"edge26\" class=\"edge\">\n<title>layer3_act&#45;&gt;layer3_residual_in</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2214.003,-80C2222.0277,-80 2230.9665,-80 2239.5309,-80\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2239.7051,-83.5001 2249.705,-80 2239.705,-76.5001 2239.7051,-83.5001\"/>\n</g>\n<!-- layer3_residual_res1_conv -->\n<g id=\"node26\" class=\"node\">\n<title>layer3_residual_res1_conv</title>\n<g id=\"a_node26\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.conv.Conv2d&#39;&gt; {&#39;in_channels&#39;: 512, &#39;out_channels&#39;: 512, &#39;kernel_size&#39;: (3, 3), &#39;stride&#39;: (1, 1), &#39;padding&#39;: (1, 1), &#39;bias&#39;: False}\">\n<path fill=\"#bebada\" stroke=\"#000000\" d=\"M2382,-88C2382,-88 2352,-88 2352,-88 2346,-88 2340,-82 2340,-76 2340,-76 2340,-64 2340,-64 2340,-58 2346,-52 2352,-52 2352,-52 2382,-52 2382,-52 2388,-52 2394,-58 2394,-64 2394,-64 2394,-76 2394,-76 2394,-82 2388,-88 2382,-88\"/>\n<text text-anchor=\"middle\" x=\"2367\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">conv</text>\n</a>\n</g>\n</g>\n<!-- layer3_residual_in&#45;&gt;layer3_residual_res1_conv -->\n<g id=\"edge27\" class=\"edge\">\n<title>layer3_residual_in&#45;&gt;layer3_residual_res1_conv</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2304.003,-76.9997C2312.0277,-76.108 2320.9665,-75.1148 2329.5309,-74.1632\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2330.1527,-77.6158 2339.705,-73.0328 2329.3796,-70.6586 2330.1527,-77.6158\"/>\n</g>\n<!-- layer3_residual_add -->\n<g id=\"node33\" class=\"node\">\n<title>layer3_residual_add</title>\n<g id=\"a_node33\"><a xlink:title=\"&lt;class &#39;__main__.Add&#39;&gt; {}\">\n<path fill=\"#fdb462\" stroke=\"#000000\" d=\"M3012,-118C3012,-118 2982,-118 2982,-118 2976,-118 2970,-112 2970,-106 2970,-106 2970,-94 2970,-94 2970,-88 2976,-82 2982,-82 2982,-82 3012,-82 3012,-82 3018,-82 3024,-88 3024,-94 3024,-94 3024,-106 3024,-106 3024,-112 3018,-118 3012,-118\"/>\n<text text-anchor=\"middle\" x=\"2997\" y=\"-96.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">add</text>\n</a>\n</g>\n</g>\n<!-- layer3_residual_in&#45;&gt;layer3_residual_add -->\n<g id=\"edge34\" class=\"edge\">\n<title>layer3_residual_in&#45;&gt;layer3_residual_add</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2294.5351,-98.3771C2304.5459,-107.5711 2317.8909,-117.8215 2332,-123 2384.1953,-142.1574 2401.4,-128 2457,-128 2457,-128 2457,-128 2817,-128 2866.7971,-128 2923.4324,-117.4074 2959.6554,-109.2525\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2960.8023,-112.5799 2969.7594,-106.9214 2959.2285,-105.7591 2960.8023,-112.5799\"/>\n</g>\n<!-- layer3_residual_res1_norm -->\n<g id=\"node27\" class=\"node\">\n<title>layer3_residual_res1_norm</title>\n<g id=\"a_node27\"><a xlink:title=\"&lt;class &#39;__main__.BatchNorm&#39;&gt; {&#39;num_features&#39;: 512}\">\n<path fill=\"#ffffb3\" stroke=\"#000000\" d=\"M2472,-88C2472,-88 2442,-88 2442,-88 2436,-88 2430,-82 2430,-76 2430,-76 2430,-64 2430,-64 2430,-58 2436,-52 2442,-52 2442,-52 2472,-52 2472,-52 2478,-52 2484,-58 2484,-64 2484,-64 2484,-76 2484,-76 2484,-82 2478,-88 2472,-88\"/>\n<text text-anchor=\"middle\" x=\"2457\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">norm</text>\n</a>\n</g>\n</g>\n<!-- layer3_residual_res1_conv&#45;&gt;layer3_residual_res1_norm -->\n<g id=\"edge28\" class=\"edge\">\n<title>layer3_residual_res1_conv&#45;&gt;layer3_residual_res1_norm</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2394.003,-70C2402.0277,-70 2410.9665,-70 2419.5309,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2419.7051,-73.5001 2429.705,-70 2419.705,-66.5001 2419.7051,-73.5001\"/>\n</g>\n<!-- layer3_residual_res1_act -->\n<g id=\"node28\" class=\"node\">\n<title>layer3_residual_res1_act</title>\n<g id=\"a_node28\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.activation.ReLU&#39;&gt; {}\">\n<path fill=\"#fb8072\" stroke=\"#000000\" d=\"M2562,-88C2562,-88 2532,-88 2532,-88 2526,-88 2520,-82 2520,-76 2520,-76 2520,-64 2520,-64 2520,-58 2526,-52 2532,-52 2532,-52 2562,-52 2562,-52 2568,-52 2574,-58 2574,-64 2574,-64 2574,-76 2574,-76 2574,-82 2568,-88 2562,-88\"/>\n<text text-anchor=\"middle\" x=\"2547\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">act</text>\n</a>\n</g>\n</g>\n<!-- layer3_residual_res1_norm&#45;&gt;layer3_residual_res1_act -->\n<g id=\"edge29\" class=\"edge\">\n<title>layer3_residual_res1_norm&#45;&gt;layer3_residual_res1_act</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2484.003,-70C2492.0277,-70 2500.9665,-70 2509.5309,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2509.7051,-73.5001 2519.705,-70 2509.705,-66.5001 2509.7051,-73.5001\"/>\n</g>\n<!-- layer3_residual_res2_conv -->\n<g id=\"node29\" class=\"node\">\n<title>layer3_residual_res2_conv</title>\n<g id=\"a_node29\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.conv.Conv2d&#39;&gt; {&#39;in_channels&#39;: 512, &#39;out_channels&#39;: 512, &#39;kernel_size&#39;: (3, 3), &#39;stride&#39;: (1, 1), &#39;padding&#39;: (1, 1), &#39;bias&#39;: False}\">\n<path fill=\"#bebada\" stroke=\"#000000\" d=\"M2652,-88C2652,-88 2622,-88 2622,-88 2616,-88 2610,-82 2610,-76 2610,-76 2610,-64 2610,-64 2610,-58 2616,-52 2622,-52 2622,-52 2652,-52 2652,-52 2658,-52 2664,-58 2664,-64 2664,-64 2664,-76 2664,-76 2664,-82 2658,-88 2652,-88\"/>\n<text text-anchor=\"middle\" x=\"2637\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">conv</text>\n</a>\n</g>\n</g>\n<!-- layer3_residual_res1_act&#45;&gt;layer3_residual_res2_conv -->\n<g id=\"edge30\" class=\"edge\">\n<title>layer3_residual_res1_act&#45;&gt;layer3_residual_res2_conv</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2574.003,-70C2582.0277,-70 2590.9665,-70 2599.5309,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2599.7051,-73.5001 2609.705,-70 2599.705,-66.5001 2599.7051,-73.5001\"/>\n</g>\n<!-- layer3_residual_res2_norm -->\n<g id=\"node30\" class=\"node\">\n<title>layer3_residual_res2_norm</title>\n<g id=\"a_node30\"><a xlink:title=\"&lt;class &#39;__main__.BatchNorm&#39;&gt; {&#39;num_features&#39;: 512}\">\n<path fill=\"#ffffb3\" stroke=\"#000000\" d=\"M2742,-88C2742,-88 2712,-88 2712,-88 2706,-88 2700,-82 2700,-76 2700,-76 2700,-64 2700,-64 2700,-58 2706,-52 2712,-52 2712,-52 2742,-52 2742,-52 2748,-52 2754,-58 2754,-64 2754,-64 2754,-76 2754,-76 2754,-82 2748,-88 2742,-88\"/>\n<text text-anchor=\"middle\" x=\"2727\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">norm</text>\n</a>\n</g>\n</g>\n<!-- layer3_residual_res2_conv&#45;&gt;layer3_residual_res2_norm -->\n<g id=\"edge31\" class=\"edge\">\n<title>layer3_residual_res2_conv&#45;&gt;layer3_residual_res2_norm</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2664.003,-70C2672.0277,-70 2680.9665,-70 2689.5309,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2689.7051,-73.5001 2699.705,-70 2689.705,-66.5001 2689.7051,-73.5001\"/>\n</g>\n<!-- layer3_residual_res2_act -->\n<g id=\"node31\" class=\"node\">\n<title>layer3_residual_res2_act</title>\n<g id=\"a_node31\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.activation.ReLU&#39;&gt; {}\">\n<path fill=\"#fb8072\" stroke=\"#000000\" d=\"M2832,-88C2832,-88 2802,-88 2802,-88 2796,-88 2790,-82 2790,-76 2790,-76 2790,-64 2790,-64 2790,-58 2796,-52 2802,-52 2802,-52 2832,-52 2832,-52 2838,-52 2844,-58 2844,-64 2844,-64 2844,-76 2844,-76 2844,-82 2838,-88 2832,-88\"/>\n<text text-anchor=\"middle\" x=\"2817\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">act</text>\n</a>\n</g>\n</g>\n<!-- layer3_residual_res2_norm&#45;&gt;layer3_residual_res2_act -->\n<g id=\"edge32\" class=\"edge\">\n<title>layer3_residual_res2_norm&#45;&gt;layer3_residual_res2_act</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2754.003,-70C2762.0277,-70 2770.9665,-70 2779.5309,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2779.7051,-73.5001 2789.705,-70 2779.705,-66.5001 2779.7051,-73.5001\"/>\n</g>\n<!-- layer3_residual_out -->\n<g id=\"node32\" class=\"node\">\n<title>layer3_residual_out</title>\n<g id=\"a_node32\"><a xlink:title=\"&lt;class &#39;__main__.Identity&#39;&gt; {}\">\n<path fill=\"#80b1d3\" stroke=\"#000000\" d=\"M2922,-98C2922,-98 2892,-98 2892,-98 2886,-98 2880,-92 2880,-86 2880,-86 2880,-74 2880,-74 2880,-68 2886,-62 2892,-62 2892,-62 2922,-62 2922,-62 2928,-62 2934,-68 2934,-74 2934,-74 2934,-86 2934,-86 2934,-92 2928,-98 2922,-98\"/>\n<text text-anchor=\"middle\" x=\"2907\" y=\"-76.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">out</text>\n</a>\n</g>\n</g>\n<!-- layer3_residual_res2_act&#45;&gt;layer3_residual_out -->\n<g id=\"edge33\" class=\"edge\">\n<title>layer3_residual_res2_act&#45;&gt;layer3_residual_out</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2844.003,-73.0003C2852.0277,-73.892 2860.9665,-74.8852 2869.5309,-75.8368\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2869.3796,-79.3414 2879.705,-76.9672 2870.1527,-72.3842 2869.3796,-79.3414\"/>\n</g>\n<!-- layer3_residual_out&#45;&gt;layer3_residual_add -->\n<g id=\"edge35\" class=\"edge\">\n<title>layer3_residual_out&#45;&gt;layer3_residual_add</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2934.003,-86.0007C2942.1158,-87.8035 2951.1631,-89.814 2959.8131,-91.7362\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2959.1839,-95.1817 2969.705,-93.9345 2960.7024,-88.3484 2959.1839,-95.1817\"/>\n</g>\n<!-- pool -->\n<g id=\"node34\" class=\"node\">\n<title>pool</title>\n<g id=\"a_node34\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.pooling.MaxPool2d&#39;&gt; {&#39;kernel_size&#39;: 4}\">\n<path fill=\"#8dd3c7\" stroke=\"#000000\" d=\"M3102,-118C3102,-118 3072,-118 3072,-118 3066,-118 3060,-112 3060,-106 3060,-106 3060,-94 3060,-94 3060,-88 3066,-82 3072,-82 3072,-82 3102,-82 3102,-82 3108,-82 3114,-88 3114,-94 3114,-94 3114,-106 3114,-106 3114,-112 3108,-118 3102,-118\"/>\n<text text-anchor=\"middle\" x=\"3087\" y=\"-96.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">pool</text>\n</a>\n</g>\n</g>\n<!-- layer3_residual_add&#45;&gt;pool -->\n<g id=\"edge36\" class=\"edge\">\n<title>layer3_residual_add&#45;&gt;pool</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M3024.003,-100C3032.0277,-100 3040.9665,-100 3049.5309,-100\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"3049.7051,-103.5001 3059.705,-100 3049.705,-96.5001 3049.7051,-103.5001\"/>\n</g>\n<!-- classifier_flatten -->\n<g id=\"node35\" class=\"node\">\n<title>classifier_flatten</title>\n<g id=\"a_node35\"><a xlink:title=\"&lt;class &#39;__main__.Flatten&#39;&gt; {}\">\n<path fill=\"#b3de69\" stroke=\"#000000\" d=\"M3192,-118C3192,-118 3162,-118 3162,-118 3156,-118 3150,-112 3150,-106 3150,-106 3150,-94 3150,-94 3150,-88 3156,-82 3162,-82 3162,-82 3192,-82 3192,-82 3198,-82 3204,-88 3204,-94 3204,-94 3204,-106 3204,-106 3204,-112 3198,-118 3192,-118\"/>\n<text text-anchor=\"middle\" x=\"3177\" y=\"-96.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">flatten</text>\n</a>\n</g>\n</g>\n<!-- pool&#45;&gt;classifier_flatten -->\n<g id=\"edge37\" class=\"edge\">\n<title>pool&#45;&gt;classifier_flatten</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M3114.003,-100C3122.0277,-100 3130.9665,-100 3139.5309,-100\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"3139.7051,-103.5001 3149.705,-100 3139.705,-96.5001 3139.7051,-103.5001\"/>\n</g>\n<!-- classifier_conv -->\n<g id=\"node36\" class=\"node\">\n<title>classifier_conv</title>\n<g id=\"a_node36\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.linear.Linear&#39;&gt; {&#39;in_features&#39;: 512, &#39;out_features&#39;: 10, &#39;bias&#39;: False}\">\n<path fill=\"#fccde5\" stroke=\"#000000\" d=\"M3282,-118C3282,-118 3252,-118 3252,-118 3246,-118 3240,-112 3240,-106 3240,-106 3240,-94 3240,-94 3240,-88 3246,-82 3252,-82 3252,-82 3282,-82 3282,-82 3288,-82 3294,-88 3294,-94 3294,-94 3294,-106 3294,-106 3294,-112 3288,-118 3282,-118\"/>\n<text text-anchor=\"middle\" x=\"3267\" y=\"-96.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">conv</text>\n</a>\n</g>\n</g>\n<!-- classifier_flatten&#45;&gt;classifier_conv -->\n<g id=\"edge38\" class=\"edge\">\n<title>classifier_flatten&#45;&gt;classifier_conv</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M3204.003,-100C3212.0277,-100 3220.9665,-100 3229.5309,-100\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"3229.7051,-103.5001 3239.705,-100 3229.705,-96.5001 3229.7051,-103.5001\"/>\n</g>\n<!-- classifier_scale -->\n<g id=\"node37\" class=\"node\">\n<title>classifier_scale</title>\n<g id=\"a_node37\"><a xlink:title=\"&lt;class &#39;__main__.Mul&#39;&gt; {&#39;weight&#39;: 0.125}\">\n<path fill=\"#bc80bd\" stroke=\"#000000\" d=\"M3372,-118C3372,-118 3342,-118 3342,-118 3336,-118 3330,-112 3330,-106 3330,-106 3330,-94 3330,-94 3330,-88 3336,-82 3342,-82 3342,-82 3372,-82 3372,-82 3378,-82 3384,-88 3384,-94 3384,-94 3384,-106 3384,-106 3384,-112 3378,-118 3372,-118\"/>\n<text text-anchor=\"middle\" x=\"3357\" y=\"-96.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">scale</text>\n</a>\n</g>\n</g>\n<!-- classifier_conv&#45;&gt;classifier_scale -->\n<g id=\"edge39\" class=\"edge\">\n<title>classifier_conv&#45;&gt;classifier_scale</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M3294.003,-100C3302.0277,-100 3310.9665,-100 3319.5309,-100\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"3319.7051,-103.5001 3329.705,-100 3319.705,-96.5001 3319.7051,-103.5001\"/>\n</g>\n<!-- logits -->\n<g id=\"node38\" class=\"node\">\n<title>logits</title>\n<g id=\"a_node38\"><a xlink:title=\"&lt;class &#39;__main__.Identity&#39;&gt; {}\">\n<path fill=\"#80b1d3\" stroke=\"#000000\" d=\"M3462,-118C3462,-118 3432,-118 3432,-118 3426,-118 3420,-112 3420,-106 3420,-106 3420,-94 3420,-94 3420,-88 3426,-82 3432,-82 3432,-82 3462,-82 3462,-82 3468,-82 3474,-88 3474,-94 3474,-94 3474,-106 3474,-106 3474,-112 3468,-118 3462,-118\"/>\n<text text-anchor=\"middle\" x=\"3447\" y=\"-96.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">logits</text>\n</a>\n</g>\n</g>\n<!-- classifier_scale&#45;&gt;logits -->\n<g id=\"edge40\" class=\"edge\">\n<title>classifier_scale&#45;&gt;logits</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M3384.003,-100C3392.0277,-100 3400.9665,-100 3409.5309,-100\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"3409.7051,-103.5001 3419.705,-100 3409.705,-96.5001 3409.7051,-103.5001\"/>\n</g>\n<!-- input -->\n<g id=\"node39\" class=\"node\">\n<title>input</title>\n<path fill=\"#ffffff\" stroke=\"#000000\" d=\"M42,-88C42,-88 12,-88 12,-88 6,-88 0,-82 0,-76 0,-76 0,-64 0,-64 0,-58 6,-52 12,-52 12,-52 42,-52 42,-52 48,-52 54,-58 54,-64 54,-64 54,-76 54,-76 54,-82 48,-88 42,-88\"/>\n<text text-anchor=\"middle\" x=\"27\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">input</text>\n</g>\n<!-- input&#45;&gt;prep_conv -->\n<g id=\"edge1\" class=\"edge\">\n<title>input&#45;&gt;prep_conv</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M54.003,-70C62.0277,-70 70.9665,-70 79.5309,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"79.7051,-73.5001 89.705,-70 79.705,-66.5001 79.7051,-73.5001\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0eblbuB2_vCh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "outputId": "136d903a-cdb6-458f-fb0d-dfb5af432afc"
      },
      "source": [
        "epochs, batch_size = 24, 512\n",
        "transforms = (Crop(32, 32), FlipLR(), Cutout(8, 8))\n",
        "opt_params = {'lr': lr_schedule([0, 5, epochs], [0.0, 0.4, 0.0], batch_size), 'weight_decay': Const(5e-4*batch_size), 'momentum': Const(0.9)}\n",
        "\n",
        "logs = Table(report=every(epochs,'epoch'))\n",
        "for run in range(N_RUNS):\n",
        "    model = build_model(maxpool_pre_net, x_ent_loss)\n",
        "    state, timer = {MODEL: model, OPTS: [SGD(trainable_params(model).values(), opt_params)]}, Timer(torch.cuda.synchronize)\n",
        "    for epoch in range(epochs):\n",
        "        logs.append(union({'run': run+1, 'epoch': epoch+1}, train_epoch(state, timer, train_batches(batch_size, transforms), valid_batches(batch_size))))       \n",
        "summary(logs)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         run        epoch   train time   train loss    train acc   valid time   valid loss    valid acc   total time\n",
            "           1           24      10.4237       0.0660       0.9820       0.6099       0.1809       0.9414     250.5627\n",
            "           2           24      10.4258       0.0658       0.9821       0.6095       0.1817       0.9405     250.6676\n",
            "           3           24      10.4267       0.0666       0.9816       0.6126       0.1930       0.9384     250.7598\n",
            "           4           24      10.4261       0.0685       0.9809       0.6091       0.1854       0.9399     250.6845\n",
            "           5           24      10.4269       0.0672       0.9810       0.6098       0.1829       0.9406     250.8183\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>min</th>\n",
              "      <th>max</th>\n",
              "      <th>std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>valid_acc</th>\n",
              "      <td>5</td>\n",
              "      <td>0.94016</td>\n",
              "      <td>0.9384</td>\n",
              "      <td>0.9414</td>\n",
              "      <td>0.001119</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           count     mean     min     max       std\n",
              "valid_acc      5  0.94016  0.9384  0.9414  0.001119"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5elIHYXi7AVz",
        "colab_type": "text"
      },
      "source": [
        "The results show a small negative effect on test accuracy to 94.0% (mean of 50 runs) compared to our baseline of 94.1%. They also show a substantial 5s reduction in training time! We can restore the previous accuracy by adding an extra epoch to training. This is the only time in the post that we select an 'improvement' that leads to worse accuracy! The 5s gain from a more efficient network more than compensates the 2.5s loss from the extra training epoch. The net effect brings our time to 64s, up to third place on the leaderboard."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7ecJCjI1SJV",
        "colab_type": "text"
      },
      "source": [
        "### Label smoothing (59s)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NqB3aXtWoel",
        "colab_type": "text"
      },
      "source": [
        "[Label smoothing](https://arxiv.org/abs/1512.00567) is a well-established trick for improving the training speed and generalization of neural nets in classification problems. It involves blending the one-hot target probabilities with a uniform distribution over class labels inside the cross entropy loss. This helps to stabilise the output distribution and prevents the network from making overconfident predictions which might inhibit further training. Let's give it a try - the label smoothing parameter of 0.2 has been very roughly hand-optimised but the result is not too sensitive to a range of choices."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8UjTsDLul0D",
        "colab_type": "code",
        "outputId": "ab208ab8-82ef-48f7-a762-94971d87ac50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "show(label_smoothing_loss(alpha=0.2), size=2)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<__main__.DotGraph at 0x7f7ecbeb6390>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: G Pages: 1 -->\n<svg width=\"144pt\" height=\"50pt\"\n viewBox=\"0.00 0.00 144.00 50.36\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(.4162 .4162) rotate(0) translate(4 117)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-117 342,-117 342,4 -4,4\"/>\n<!-- logprobs -->\n<g id=\"node1\" class=\"node\">\n<title>logprobs</title>\n<g id=\"a_node1\"><a xlink:title=\"&lt;class &#39;__main__.LogSoftmax&#39;&gt; LogSoftmax(dim=1)\">\n<path fill=\"#ccebc5\" stroke=\"#000000\" d=\"M146,-36C146,-36 102,-36 102,-36 96,-36 90,-30 90,-24 90,-24 90,-12 90,-12 90,-6 96,0 102,0 102,0 146,0 146,0 152,0 158,-6 158,-12 158,-12 158,-24 158,-24 158,-30 152,-36 146,-36\"/>\n<text text-anchor=\"middle\" x=\"124\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">logprobs</text>\n</a>\n</g>\n</g>\n<!-- KL -->\n<g id=\"node2\" class=\"node\">\n<title>KL</title>\n<g id=\"a_node2\"><a xlink:title=\"&lt;class &#39;__main__.KLLoss&#39;&gt; KLLoss()\">\n<path fill=\"#ffed6f\" stroke=\"#000000\" d=\"M236,-36C236,-36 206,-36 206,-36 200,-36 194,-30 194,-24 194,-24 194,-12 194,-12 194,-6 200,0 206,0 206,0 236,0 236,0 242,0 248,-6 248,-12 248,-12 248,-24 248,-24 248,-30 242,-36 236,-36\"/>\n<text text-anchor=\"middle\" x=\"221\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">KL</text>\n</a>\n</g>\n</g>\n<!-- logprobs&#45;&gt;KL -->\n<g id=\"edge2\" class=\"edge\">\n<title>logprobs&#45;&gt;KL</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M158.1986,-18C166.4058,-18 175.2132,-18 183.559,-18\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"183.8037,-21.5001 193.8037,-18 183.8037,-14.5001 183.8037,-21.5001\"/>\n</g>\n<!-- xent -->\n<g id=\"node3\" class=\"node\">\n<title>xent</title>\n<g id=\"a_node3\"><a xlink:title=\"&lt;class &#39;__main__.CrossEntropyLoss&#39;&gt; CrossEntropyLoss()\">\n<path fill=\"#1f78b4\" stroke=\"#000000\" d=\"M236,-90C236,-90 206,-90 206,-90 200,-90 194,-84 194,-78 194,-78 194,-66 194,-66 194,-60 200,-54 206,-54 206,-54 236,-54 236,-54 242,-54 248,-60 248,-66 248,-66 248,-78 248,-78 248,-84 242,-90 236,-90\"/>\n<text text-anchor=\"middle\" x=\"221\" y=\"-68.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">xent</text>\n</a>\n</g>\n</g>\n<!-- logprobs&#45;&gt;xent -->\n<g id=\"edge3\" class=\"edge\">\n<title>logprobs&#45;&gt;xent</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M156.5694,-36.1314C165.6507,-41.187 175.5703,-46.7092 184.8447,-51.8723\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"183.4093,-55.079 193.8491,-56.8851 186.8142,-48.9629 183.4093,-55.079\"/>\n</g>\n<!-- loss -->\n<g id=\"node4\" class=\"node\">\n<title>loss</title>\n<g id=\"a_node4\"><a xlink:title=\"&lt;class &#39;__main__.AddWeighted&#39;&gt; AddWeighted(wx=0.8, wy=0.2)\">\n<path fill=\"#33a02c\" stroke=\"#000000\" d=\"M326,-63C326,-63 296,-63 296,-63 290,-63 284,-57 284,-51 284,-51 284,-39 284,-39 284,-33 290,-27 296,-27 296,-27 326,-27 326,-27 332,-27 338,-33 338,-39 338,-39 338,-51 338,-51 338,-57 332,-63 326,-63\"/>\n<text text-anchor=\"middle\" x=\"311\" y=\"-41.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">loss</text>\n</a>\n</g>\n</g>\n<!-- KL&#45;&gt;loss -->\n<g id=\"edge6\" class=\"edge\">\n<title>KL&#45;&gt;loss</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M248.003,-26.1009C256.204,-28.5612 265.3599,-31.308 274.095,-33.9285\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"273.121,-37.2904 283.705,-36.8115 275.1325,-30.5856 273.121,-37.2904\"/>\n</g>\n<!-- xent&#45;&gt;loss -->\n<g id=\"edge5\" class=\"edge\">\n<title>xent&#45;&gt;loss</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M248.003,-63.8991C256.204,-61.4388 265.3599,-58.692 274.095,-56.0715\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"275.1325,-59.4144 283.705,-53.1885 273.121,-52.7096 275.1325,-59.4144\"/>\n</g>\n<!-- acc -->\n<g id=\"node5\" class=\"node\">\n<title>acc</title>\n<g id=\"a_node5\"><a xlink:title=\"&lt;class &#39;__main__.Correct&#39;&gt; Correct()\">\n<path fill=\"#e31a1c\" stroke=\"#000000\" d=\"M139,-90C139,-90 109,-90 109,-90 103,-90 97,-84 97,-78 97,-78 97,-66 97,-66 97,-60 103,-54 109,-54 109,-54 139,-54 139,-54 145,-54 151,-60 151,-66 151,-66 151,-78 151,-78 151,-84 145,-90 139,-90\"/>\n<text text-anchor=\"middle\" x=\"124\" y=\"-68.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">acc</text>\n</a>\n</g>\n</g>\n<!-- logits -->\n<g id=\"node6\" class=\"node\">\n<title>logits</title>\n<path fill=\"#ffffff\" stroke=\"#000000\" d=\"M42,-36C42,-36 12,-36 12,-36 6,-36 0,-30 0,-24 0,-24 0,-12 0,-12 0,-6 6,0 12,0 12,0 42,0 42,0 48,0 54,-6 54,-12 54,-12 54,-24 54,-24 54,-30 48,-36 42,-36\"/>\n<text text-anchor=\"middle\" x=\"27\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">logits</text>\n</g>\n<!-- logits&#45;&gt;logprobs -->\n<g id=\"edge1\" class=\"edge\">\n<title>logits&#45;&gt;logprobs</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M54.0199,-18C61.9976,-18 70.947,-18 79.7116,-18\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"79.8462,-21.5001 89.8462,-18 79.8462,-14.5001 79.8462,-21.5001\"/>\n</g>\n<!-- logits&#45;&gt;acc -->\n<g id=\"edge7\" class=\"edge\">\n<title>logits&#45;&gt;acc</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M54.0199,-33.042C64.5474,-38.9027 76.7669,-45.7053 88.0209,-51.9704\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"86.3488,-55.0453 96.7886,-56.8514 89.7537,-48.9292 86.3488,-55.0453\"/>\n</g>\n<!-- target -->\n<g id=\"node7\" class=\"node\">\n<title>target</title>\n<path fill=\"#ffffff\" stroke=\"#000000\" d=\"M42,-113C42,-113 12,-113 12,-113 6,-113 0,-107 0,-101 0,-101 0,-89 0,-89 0,-83 6,-77 12,-77 12,-77 42,-77 42,-77 48,-77 54,-83 54,-89 54,-89 54,-101 54,-101 54,-107 48,-113 42,-113\"/>\n<text text-anchor=\"middle\" x=\"27\" y=\"-91.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">target</text>\n</g>\n<!-- target&#45;&gt;xent -->\n<g id=\"edge4\" class=\"edge\">\n<title>target&#45;&gt;xent</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M54.1585,-99.4542C80.8731,-102.9901 122.672,-106.2513 158,-99 166.8927,-97.1747 176.0801,-94.0395 184.5968,-90.5373\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"186.1175,-93.6923 193.876,-86.4774 183.3116,-87.2793 186.1175,-93.6923\"/>\n</g>\n<!-- target&#45;&gt;acc -->\n<g id=\"edge8\" class=\"edge\">\n<title>target&#45;&gt;acc</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M54.0199,-88.5932C64.2347,-86.1712 76.0425,-83.3714 87.0155,-80.7695\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"87.8659,-84.165 96.7886,-78.4522 86.2508,-77.3539 87.8659,-84.165\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofLeJMTpbJVc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "outputId": "54925ecb-fa64-48f8-8cc7-6f2c5dff9c54"
      },
      "source": [
        "epochs, batch_size = 25, 512\n",
        "transforms = (Crop(32, 32), FlipLR(), Cutout(8, 8))\n",
        "opt_params = {'lr': lr_schedule([0, epochs/5, epochs], [0.0, 0.4, 0.0], batch_size), 'weight_decay': Const(5e-4*batch_size), 'momentum': Const(0.9)}\n",
        "\n",
        "logs = Table(report=every(epochs,'epoch'))\n",
        "for run in range(N_RUNS):\n",
        "    model = build_model(maxpool_pre_net, label_smoothing_loss(0.2))\n",
        "    state, timer = {MODEL: model, OPTS: [SGD(trainable_params(model).values(), opt_params)]}, Timer(torch.cuda.synchronize)\n",
        "    for epoch in range(epochs):\n",
        "        logs.append(union({'run': run+1, 'epoch': epoch+1}, train_epoch(state, timer, train_batches(batch_size, transforms), valid_batches(batch_size))))\n",
        "summary(logs)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         run        epoch   train time   train loss    train acc   valid time   valid loss    valid acc   total time\n",
            "           1           25      10.4321       0.9173       0.9828       0.6115       0.9799       0.9426     261.3181\n",
            "           2           25      10.4316       0.9165       0.9842       0.6092       0.9855       0.9408     261.2543\n",
            "           3           25      10.4334       0.9173       0.9837       0.6084       0.9799       0.9433     261.4610\n",
            "           4           25      10.4289       0.9158       0.9839       0.6094       0.9783       0.9448     261.2904\n",
            "           5           25      10.4276       0.9170       0.9835       0.6127       0.9791       0.9457     261.3528\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>min</th>\n",
              "      <th>max</th>\n",
              "      <th>std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>valid_acc</th>\n",
              "      <td>5</td>\n",
              "      <td>0.94344</td>\n",
              "      <td>0.9408</td>\n",
              "      <td>0.9457</td>\n",
              "      <td>0.001914</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           count     mean     min     max       std\n",
              "valid_acc      5  0.94344  0.9408  0.9457  0.001914"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nc5w9r2HSof1",
        "colab_type": "text"
      },
      "source": [
        "Test accuracy improves to 94.2% (mean of 50 runs.) We can trade this for training time by reducing the number of epochs. As a rule of thumb, we reduce training by one epoch for each 0.1% of test accuracy improvement, since this roughly tracks the gain from an extra epoch of training. We reduce the warmup period - during which learning rates increase linearly - in proportion to the overall number of epochs. \n",
        "\n",
        "Accuracy for 23 epochs of training is 94.1% and training time has dipped under a minute!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ug1Qk7-YyJW",
        "colab_type": "text"
      },
      "source": [
        "### CELU activations (52s)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EyAlk-aa9l8E",
        "colab_type": "text"
      },
      "source": [
        "We might hope to help the optimisation process by using a smooth activation function, rather than ReLU with its delta-function of curvature at the origin. This may also help generalisation since smoothed functions lead to a less expressive function class - in the large smoothing limit we recover a linear network. \n",
        "\n",
        "We are otherwise happy with ReLU so we're going to pick a simple smoothed-out alternative. Our choice is the Continuously Differentiable Exponential Linear Unit or [CELU](https://arxiv.org/abs/1704.07483) activation since it is smooth (unlike ELU) and the PyTorch implementation is faster than that of the otherwise perfectly adequate Softplus activation. In addition to smoothing, CELU applies an x- and y-shift to ReLU as shown below, but these are largely irrelevant given our use of batch norm."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7g9dIFu1jB_",
        "colab_type": "code",
        "outputId": "b4cc1904-e682-420e-d44d-8f22d1ebcaca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        }
      },
      "source": [
        "alpha = 0.075\n",
        "\n",
        "funcs = {\n",
        "    'CELU(x; Î±)': nn.CELU(alpha),\n",
        "    'ReLU(x+Î±)-Î±': lambda x: torch.nn.functional.relu(x+alpha) - alpha,\n",
        "}\n",
        "\n",
        "xs = torch.tensor(np.arange(-1, 1, 0.01))\n",
        "data = pd.DataFrame([{'func': k, 'x': float(to_numpy(x)), 'y': float(to_numpy(f(x)))} for x in xs for k,f in funcs.items()])\n",
        "alt.Chart(data).mark_line().encode(x='x', y='y', color='func')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "alt.Chart(...)"
            ],
            "text/html": [
              "<!DOCTYPE html>\n",
              "<html>\n",
              "<head>\n",
              "  <style>\n",
              "    .vega-actions a {\n",
              "        margin-right: 12px;\n",
              "        color: #757575;\n",
              "        font-weight: normal;\n",
              "        font-size: 13px;\n",
              "    }\n",
              "    .error {\n",
              "        color: red;\n",
              "    }\n",
              "  </style>\n",
              "  <script type=\"text/javascript\" src=\"https://cdn.jsdelivr.net/npm//vega@5\"></script>\n",
              "  <script type=\"text/javascript\" src=\"https://cdn.jsdelivr.net/npm//vega-lite@3.4.0\"></script>\n",
              "  <script type=\"text/javascript\" src=\"https://cdn.jsdelivr.net/npm//vega-embed@4\"></script>\n",
              "</head>\n",
              "<body>\n",
              "  <div id=\"altair-viz\"></div>\n",
              "  <script>\n",
              "    (function(vegaEmbed) {\n",
              "      var spec = {\"config\": {\"view\": {\"width\": 400, \"height\": 300}, \"mark\": {\"tooltip\": null}}, \"data\": {\"name\": \"data-e340a0773542cdd52e6083e2ac95ca3d\"}, \"mark\": \"line\", \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"func\"}, \"x\": {\"type\": \"quantitative\", \"field\": \"x\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"y\"}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v3.4.0.json\", \"datasets\": {\"data-e340a0773542cdd52e6083e2ac95ca3d\": [{\"func\": \"CELU(x; \\u03b1)\", \"x\": -1.0, \"y\": -0.07499987853024057}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -1.0, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.99, \"y\": -0.07499986120491017}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.99, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.98, \"y\": -0.07499984140845384}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.98, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.97, \"y\": -0.07499981878841287}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.97, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.96, \"y\": -0.0749997929420571}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.96, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.95, \"y\": -0.0749997634092146}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.95, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.94, \"y\": -0.07499972966407882}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.94, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.9299999999999999, \"y\": -0.07499969110584694}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.9299999999999999, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.9199999999999999, \"y\": -0.07499964704802312}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.9199999999999999, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.9099999999999999, \"y\": -0.07499959670619613}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.9099999999999999, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.8999999999999999, \"y\": -0.0749995391840735}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.8999999999999999, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.8899999999999999, \"y\": -0.07499947345752381}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.8899999999999999, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.8799999999999999, \"y\": -0.07499939835634299}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.8799999999999999, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.8699999999999999, \"y\": -0.07499931254341978}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.8699999999999999, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.8599999999999999, \"y\": -0.07499921449092967}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.8599999999999999, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.8499999999999999, \"y\": -0.07499910245313329}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.8499999999999999, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.8399999999999999, \"y\": -0.07499897443529507}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.8399999999999999, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.8299999999999998, \"y\": -0.07499882815816866}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.8299999999999998, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.8199999999999998, \"y\": -0.07499866101741696}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.8199999999999998, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.8099999999999998, \"y\": -0.07499847003724416}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.8099999999999998, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.7999999999999998, \"y\": -0.07499825181741428}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.7999999999999998, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.7899999999999998, \"y\": -0.0749980024727129}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.7899999999999998, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.7799999999999998, \"y\": -0.07499771756377437}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.7799999999999998, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.7699999999999998, \"y\": -0.07499739201804263}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.7699999999999998, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.7599999999999998, \"y\": -0.0749970200394589}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.7599999999999998, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.7499999999999998, \"y\": -0.07499659500526781}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.7499999999999998, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.7399999999999998, \"y\": -0.074996109348105}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.7399999999999998, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.7299999999999998, \"y\": -0.0749955544212668}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.7299999999999998, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.7199999999999998, \"y\": -0.07499492034476318}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.7199999999999998, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.7099999999999997, \"y\": -0.07499419582941311}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.7099999999999997, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.6999999999999997, \"y\": -0.0749933679758505}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.6999999999999997, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.6899999999999997, \"y\": -0.07499242204486221}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.6899999999999997, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.6799999999999997, \"y\": -0.07499134119496915}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.6799999999999997, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.6699999999999997, \"y\": -0.07499010618257844}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.6699999999999997, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.6599999999999997, \"y\": -0.07498869501936783}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.6599999999999997, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.6499999999999997, \"y\": -0.07498708258080293}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.6499999999999997, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.6399999999999997, \"y\": -0.07498524015881655}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.6399999999999997, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.6299999999999997, \"y\": -0.07498313495068659}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.6299999999999997, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.6199999999999997, \"y\": -0.07498072947501204}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.6199999999999997, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.6099999999999997, \"y\": -0.07497798090438927}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.6099999999999997, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.5999999999999996, \"y\": -0.07497484030290731}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.5999999999999996, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.5899999999999996, \"y\": -0.07497125175488645}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.5899999999999996, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.5799999999999996, \"y\": -0.0749671513693482}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.5799999999999996, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.5699999999999996, \"y\": -0.07496246614249195}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.5699999999999996, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.5599999999999996, \"y\": -0.07495711265792575}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.5599999999999996, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.5499999999999996, \"y\": -0.07495099560150995}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.5499999999999996, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.5399999999999996, \"y\": -0.07494400606437174}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.5399999999999996, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.5299999999999996, \"y\": -0.07493601960387745}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.5299999999999996, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.5199999999999996, \"y\": -0.07492689402803948}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.5199999999999996, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.5099999999999996, \"y\": -0.07491646686391164}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.5099999999999996, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.49999999999999956, \"y\": -0.07490455246489951}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.49999999999999956, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.48999999999999955, \"y\": -0.07489093870548423}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.48999999999999955, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.47999999999999954, \"y\": -0.07487538320451195}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.47999999999999954, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.46999999999999953, \"y\": -0.0748576090098081}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.46999999999999953, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.4599999999999995, \"y\": -0.07483729966728464}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.4599999999999995, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.4499999999999995, \"y\": -0.07481409358675002}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.4499999999999995, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.4399999999999995, \"y\": -0.07478757760411014}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.4399999999999995, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.4299999999999995, \"y\": -0.07475727962534078}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.4299999999999995, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.4199999999999995, \"y\": -0.07472266022126378}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.4199999999999995, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.4099999999999995, \"y\": -0.07468310302347939}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.4099999999999995, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.39999999999999947, \"y\": -0.07463790375046263}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.39999999999999947, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.38999999999999946, \"y\": -0.07458625766844294}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.38999999999999946, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.37999999999999945, \"y\": -0.0745272452638187}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.37999999999999945, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.36999999999999944, \"y\": -0.07445981587201689}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.36999999999999944, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.35999999999999943, \"y\": -0.07438276897132348}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.35999999999999943, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.3499999999999994, \"y\": -0.07429473280863785}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.3499999999999994, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.3399999999999994, \"y\": -0.07419413997660099}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.3399999999999994, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.3299999999999994, \"y\": -0.07407919950726985}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.3299999999999994, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.3199999999999994, \"y\": -0.07394786498548986}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.3199999999999994, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.3099999999999994, \"y\": -0.07379779811425158}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.3099999999999994, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.2999999999999994, \"y\": -0.07362632708334492}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.2999999999999994, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.28999999999999937, \"y\": -0.07343039900010061}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.28999999999999937, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.27999999999999936, \"y\": -0.07320652553528958}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.27999999999999936, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.26999999999999935, \"y\": -0.07295072081645304}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.26999999999999935, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.25999999999999934, \"y\": -0.07265843046290767}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.25999999999999934, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.24999999999999933, \"y\": -0.07232445049895604}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.24999999999999933, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.23999999999999932, \"y\": -0.07194283470162251}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.23999999999999932, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.22999999999999932, \"y\": -0.07150678873332121}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.22999999999999932, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.2199999999999993, \"y\": -0.07100854917458085}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.2199999999999993, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.2099999999999993, \"y\": -0.0704392453031086}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.2099999999999993, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.1999999999999993, \"y\": -0.06978874115828983}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.1999999999999993, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.18999999999999928, \"y\": -0.06904545507921908}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.18999999999999928, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.17999999999999927, \"y\": -0.068196153503294}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.17999999999999927, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.16999999999999926, \"y\": -0.06722571535413534}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.16999999999999926, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.15999999999999925, \"y\": -0.06611686282396463}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.15999999999999925, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.14999999999999925, \"y\": -0.06484985375725394}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.14999999999999925, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.13999999999999924, \"y\": -0.06340213015880578}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.13999999999999924, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.12999999999999923, \"y\": -0.06174791656825511}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.12999999999999923, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.11999999999999922, \"y\": -0.05985776115040069}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.11999999999999922, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.10999999999999921, \"y\": -0.057698011330877604}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.10999999999999921, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.0999999999999992, \"y\": -0.05523021464132028}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.0999999999999992, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.08999999999999919, \"y\": -0.0524104341065846}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.08999999999999919, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.07999999999999918, \"y\": -0.04918846598509379}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.07999999999999918, \"y\": -0.075}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.06999999999999917, \"y\": -0.045506945934854805}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.06999999999999917, \"y\": -0.06999999999999917}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.059999999999999165, \"y\": -0.041300327691208005}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.059999999999999165, \"y\": -0.059999999999999165}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.049999999999999156, \"y\": -0.036493716072555166}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.049999999999999156, \"y\": -0.049999999999999156}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.03999999999999915, \"y\": -0.031001533536747113}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.03999999999999915, \"y\": -0.03999999999999915}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.02999999999999914, \"y\": -0.024725996547326476}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.02999999999999914, \"y\": -0.02999999999999914}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.01999999999999913, \"y\": -0.017555374622650683}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.01999999999999913, \"y\": -0.01999999999999913}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": -0.00999999999999912, \"y\": -0.009362001071778172}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": -0.00999999999999912, \"y\": -0.00999999999999912}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 8.881784197001252e-16, \"y\": 8.881784197001252e-16}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 8.881784197001252e-16, \"y\": 8.881784197001252e-16}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.010000000000000897, \"y\": 0.010000000000000897}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.010000000000000897, \"y\": 0.010000000000000897}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.020000000000000906, \"y\": 0.020000000000000906}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.020000000000000906, \"y\": 0.020000000000000906}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.030000000000000915, \"y\": 0.030000000000000915}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.030000000000000915, \"y\": 0.030000000000000915}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.040000000000000924, \"y\": 0.040000000000000924}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.040000000000000924, \"y\": 0.040000000000000924}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.05000000000000093, \"y\": 0.05000000000000093}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.05000000000000093, \"y\": 0.050000000000000946}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.06000000000000094, \"y\": 0.06000000000000094}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.06000000000000094, \"y\": 0.060000000000000955}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.07000000000000095, \"y\": 0.07000000000000095}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.07000000000000095, \"y\": 0.07000000000000096}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.08000000000000096, \"y\": 0.08000000000000096}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.08000000000000096, \"y\": 0.08000000000000097}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.09000000000000097, \"y\": 0.09000000000000097}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.09000000000000097, \"y\": 0.09000000000000098}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.10000000000000098, \"y\": 0.10000000000000098}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.10000000000000098, \"y\": 0.10000000000000099}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.11000000000000099, \"y\": 0.11000000000000099}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.11000000000000099, \"y\": 0.110000000000001}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.120000000000001, \"y\": 0.120000000000001}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.120000000000001, \"y\": 0.12000000000000101}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.130000000000001, \"y\": 0.130000000000001}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.130000000000001, \"y\": 0.130000000000001}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.140000000000001, \"y\": 0.140000000000001}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.140000000000001, \"y\": 0.140000000000001}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.15000000000000102, \"y\": 0.15000000000000102}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.15000000000000102, \"y\": 0.15000000000000102}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.16000000000000103, \"y\": 0.16000000000000103}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.16000000000000103, \"y\": 0.16000000000000103}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.17000000000000104, \"y\": 0.17000000000000104}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.17000000000000104, \"y\": 0.17000000000000104}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.18000000000000105, \"y\": 0.18000000000000105}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.18000000000000105, \"y\": 0.18000000000000105}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.19000000000000106, \"y\": 0.19000000000000106}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.19000000000000106, \"y\": 0.19000000000000106}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.20000000000000107, \"y\": 0.20000000000000107}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.20000000000000107, \"y\": 0.20000000000000107}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.21000000000000107, \"y\": 0.21000000000000107}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.21000000000000107, \"y\": 0.21000000000000107}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.22000000000000108, \"y\": 0.22000000000000108}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.22000000000000108, \"y\": 0.22000000000000108}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.2300000000000011, \"y\": 0.2300000000000011}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.2300000000000011, \"y\": 0.2300000000000011}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.2400000000000011, \"y\": 0.2400000000000011}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.2400000000000011, \"y\": 0.2400000000000011}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.2500000000000011, \"y\": 0.2500000000000011}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.2500000000000011, \"y\": 0.2500000000000011}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.2600000000000011, \"y\": 0.2600000000000011}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.2600000000000011, \"y\": 0.2600000000000011}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.27000000000000113, \"y\": 0.27000000000000113}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.27000000000000113, \"y\": 0.27000000000000113}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.28000000000000114, \"y\": 0.28000000000000114}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.28000000000000114, \"y\": 0.28000000000000114}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.29000000000000115, \"y\": 0.29000000000000115}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.29000000000000115, \"y\": 0.29000000000000115}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.30000000000000115, \"y\": 0.30000000000000115}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.30000000000000115, \"y\": 0.30000000000000115}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.31000000000000116, \"y\": 0.31000000000000116}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.31000000000000116, \"y\": 0.31000000000000116}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.3200000000000012, \"y\": 0.3200000000000012}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.3200000000000012, \"y\": 0.3200000000000012}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.3300000000000012, \"y\": 0.3300000000000012}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.3300000000000012, \"y\": 0.3300000000000012}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.3400000000000012, \"y\": 0.3400000000000012}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.3400000000000012, \"y\": 0.3400000000000012}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.3500000000000012, \"y\": 0.3500000000000012}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.3500000000000012, \"y\": 0.3500000000000012}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.3600000000000012, \"y\": 0.3600000000000012}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.3600000000000012, \"y\": 0.3600000000000012}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.3700000000000012, \"y\": 0.3700000000000012}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.3700000000000012, \"y\": 0.3700000000000012}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.3800000000000012, \"y\": 0.3800000000000012}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.3800000000000012, \"y\": 0.3800000000000012}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.39000000000000123, \"y\": 0.39000000000000123}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.39000000000000123, \"y\": 0.39000000000000123}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.40000000000000124, \"y\": 0.40000000000000124}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.40000000000000124, \"y\": 0.40000000000000124}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.41000000000000125, \"y\": 0.41000000000000125}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.41000000000000125, \"y\": 0.41000000000000125}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.42000000000000126, \"y\": 0.42000000000000126}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.42000000000000126, \"y\": 0.42000000000000126}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.43000000000000127, \"y\": 0.43000000000000127}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.43000000000000127, \"y\": 0.4300000000000012}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.4400000000000013, \"y\": 0.4400000000000013}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.4400000000000013, \"y\": 0.4400000000000012}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.4500000000000013, \"y\": 0.4500000000000013}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.4500000000000013, \"y\": 0.45000000000000123}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.4600000000000013, \"y\": 0.4600000000000013}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.4600000000000013, \"y\": 0.46000000000000124}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.4700000000000013, \"y\": 0.4700000000000013}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.4700000000000013, \"y\": 0.47000000000000125}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.4800000000000013, \"y\": 0.4800000000000013}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.4800000000000013, \"y\": 0.48000000000000126}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.4900000000000013, \"y\": 0.4900000000000013}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.4900000000000013, \"y\": 0.49000000000000127}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.5000000000000013, \"y\": 0.5000000000000013}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.5000000000000013, \"y\": 0.5000000000000013}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.5100000000000013, \"y\": 0.5100000000000013}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.5100000000000013, \"y\": 0.5100000000000013}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.5200000000000014, \"y\": 0.5200000000000014}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.5200000000000014, \"y\": 0.5200000000000014}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.5300000000000014, \"y\": 0.5300000000000014}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.5300000000000014, \"y\": 0.5300000000000014}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.5400000000000014, \"y\": 0.5400000000000014}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.5400000000000014, \"y\": 0.5400000000000014}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.5500000000000014, \"y\": 0.5500000000000014}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.5500000000000014, \"y\": 0.5500000000000014}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.5600000000000014, \"y\": 0.5600000000000014}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.5600000000000014, \"y\": 0.5600000000000014}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.5700000000000014, \"y\": 0.5700000000000014}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.5700000000000014, \"y\": 0.5700000000000014}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.5800000000000014, \"y\": 0.5800000000000014}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.5800000000000014, \"y\": 0.5800000000000014}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.5900000000000014, \"y\": 0.5900000000000014}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.5900000000000014, \"y\": 0.5900000000000014}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.6000000000000014, \"y\": 0.6000000000000014}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.6000000000000014, \"y\": 0.6000000000000014}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.6100000000000014, \"y\": 0.6100000000000014}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.6100000000000014, \"y\": 0.6100000000000014}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.6200000000000014, \"y\": 0.6200000000000014}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.6200000000000014, \"y\": 0.6200000000000014}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.6300000000000014, \"y\": 0.6300000000000014}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.6300000000000014, \"y\": 0.6300000000000014}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.6400000000000015, \"y\": 0.6400000000000015}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.6400000000000015, \"y\": 0.6400000000000015}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.6500000000000015, \"y\": 0.6500000000000015}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.6500000000000015, \"y\": 0.6500000000000015}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.6600000000000015, \"y\": 0.6600000000000015}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.6600000000000015, \"y\": 0.6600000000000015}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.6700000000000015, \"y\": 0.6700000000000015}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.6700000000000015, \"y\": 0.6700000000000015}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.6800000000000015, \"y\": 0.6800000000000015}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.6800000000000015, \"y\": 0.6800000000000015}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.6900000000000015, \"y\": 0.6900000000000015}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.6900000000000015, \"y\": 0.6900000000000015}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.7000000000000015, \"y\": 0.7000000000000015}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.7000000000000015, \"y\": 0.7000000000000015}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.7100000000000015, \"y\": 0.7100000000000015}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.7100000000000015, \"y\": 0.7100000000000015}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.7200000000000015, \"y\": 0.7200000000000015}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.7200000000000015, \"y\": 0.7200000000000015}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.7300000000000015, \"y\": 0.7300000000000015}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.7300000000000015, \"y\": 0.7300000000000015}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.7400000000000015, \"y\": 0.7400000000000015}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.7400000000000015, \"y\": 0.7400000000000015}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.7500000000000016, \"y\": 0.7500000000000016}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.7500000000000016, \"y\": 0.7500000000000016}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.7600000000000016, \"y\": 0.7600000000000016}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.7600000000000016, \"y\": 0.7600000000000016}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.7700000000000016, \"y\": 0.7700000000000016}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.7700000000000016, \"y\": 0.7700000000000016}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.7800000000000016, \"y\": 0.7800000000000016}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.7800000000000016, \"y\": 0.7800000000000016}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.7900000000000016, \"y\": 0.7900000000000016}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.7900000000000016, \"y\": 0.7900000000000016}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.8000000000000016, \"y\": 0.8000000000000016}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.8000000000000016, \"y\": 0.8000000000000016}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.8100000000000016, \"y\": 0.8100000000000016}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.8100000000000016, \"y\": 0.8100000000000016}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.8200000000000016, \"y\": 0.8200000000000016}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.8200000000000016, \"y\": 0.8200000000000016}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.8300000000000016, \"y\": 0.8300000000000016}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.8300000000000016, \"y\": 0.8300000000000016}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.8400000000000016, \"y\": 0.8400000000000016}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.8400000000000016, \"y\": 0.8400000000000016}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.8500000000000016, \"y\": 0.8500000000000016}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.8500000000000016, \"y\": 0.8500000000000016}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.8600000000000017, \"y\": 0.8600000000000017}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.8600000000000017, \"y\": 0.8600000000000017}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.8700000000000017, \"y\": 0.8700000000000017}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.8700000000000017, \"y\": 0.8700000000000017}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.8800000000000017, \"y\": 0.8800000000000017}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.8800000000000017, \"y\": 0.8800000000000017}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.8900000000000017, \"y\": 0.8900000000000017}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.8900000000000017, \"y\": 0.8900000000000017}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.9000000000000017, \"y\": 0.9000000000000017}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.9000000000000017, \"y\": 0.9000000000000017}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.9100000000000017, \"y\": 0.9100000000000017}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.9100000000000017, \"y\": 0.9100000000000017}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.9200000000000017, \"y\": 0.9200000000000017}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.9200000000000017, \"y\": 0.9200000000000017}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.9300000000000017, \"y\": 0.9300000000000017}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.9300000000000017, \"y\": 0.9300000000000017}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.9400000000000017, \"y\": 0.9400000000000017}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.9400000000000017, \"y\": 0.9400000000000017}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.9500000000000017, \"y\": 0.9500000000000017}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.9500000000000017, \"y\": 0.9500000000000017}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.9600000000000017, \"y\": 0.9600000000000017}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.9600000000000017, \"y\": 0.9600000000000017}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.9700000000000017, \"y\": 0.9700000000000017}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.9700000000000017, \"y\": 0.9700000000000017}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.9800000000000018, \"y\": 0.9800000000000018}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.9800000000000018, \"y\": 0.9800000000000018}, {\"func\": \"CELU(x; \\u03b1)\", \"x\": 0.9900000000000018, \"y\": 0.9900000000000018}, {\"func\": \"ReLU(x+\\u03b1)-\\u03b1\", \"x\": 0.9900000000000018, \"y\": 0.9900000000000018}]}};\n",
              "      var embedOpt = {\"mode\": \"vega-lite\"};\n",
              "\n",
              "      function showError(el, error){\n",
              "          el.innerHTML = ('<div class=\"error\" style=\"color:red;\">'\n",
              "                          + '<p>JavaScript Error: ' + error.message + '</p>'\n",
              "                          + \"<p>This usually means there's a typo in your chart specification. \"\n",
              "                          + \"See the javascript console for the full traceback.</p>\"\n",
              "                          + '</div>');\n",
              "          throw error;\n",
              "      }\n",
              "      const el = document.getElementById('altair-viz');\n",
              "      vegaEmbed(\"#altair-viz\", spec, embedOpt)\n",
              "        .catch(error => showError(el, error));\n",
              "    })(vegaEmbed);\n",
              "\n",
              "  </script>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-28Zj2A3chKd",
        "colab_type": "text"
      },
      "source": [
        "Let's see how it works  - as usual the smoothing parameter $\\alpha$ has been roughly manually tuned."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8KwIQjrGQlR",
        "colab_type": "code",
        "outputId": "b4450850-381b-4dc2-d5ef-d3c9329a2548",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "celu_net = network(conv_pool_block=conv_pool_block_pre, types={nn.ReLU: partial(nn.CELU, alpha=0.075)})\n",
        "show(celu_net)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<__main__.DotGraph at 0x7f7f20b26c50>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: G Pages: 1 -->\n<svg width=\"1080pt\" height=\"64pt\"\n viewBox=\"0.00 0.00 1080.00 64.20\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(.3102 .3102) rotate(0) translate(4 203)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-203 3478,-203 3478,4 -4,4\"/>\n<g id=\"clust1\" class=\"cluster\">\n<title>cluster_prep</title>\n<path fill=\"#777777\" fill-opacity=\"0.266667\" stroke=\"#000000\" d=\"M94,-44C94,-44 320,-44 320,-44 326,-44 332,-50 332,-56 332,-56 332,-107 332,-107 332,-113 326,-119 320,-119 320,-119 94,-119 94,-119 88,-119 82,-113 82,-107 82,-107 82,-56 82,-56 82,-50 88,-44 94,-44\"/>\n<text text-anchor=\"middle\" x=\"207\" y=\"-103.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">prep</text>\n</g>\n<g id=\"clust2\" class=\"cluster\">\n<title>cluster_layer1</title>\n<path fill=\"#777777\" fill-opacity=\"0.266667\" stroke=\"#000000\" d=\"M364,-8C364,-8 1498,-8 1498,-8 1504,-8 1510,-14 1510,-20 1510,-20 1510,-159 1510,-159 1510,-165 1504,-171 1498,-171 1498,-171 364,-171 364,-171 358,-171 352,-165 352,-159 352,-159 352,-20 352,-20 352,-14 358,-8 364,-8\"/>\n<text text-anchor=\"middle\" x=\"931\" y=\"-155.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">layer1</text>\n</g>\n<g id=\"clust3\" class=\"cluster\">\n<title>cluster_layer1_residual</title>\n<path fill=\"#777777\" fill-opacity=\"0.266667\" stroke=\"#000000\" d=\"M724,-16C724,-16 1490,-16 1490,-16 1496,-16 1502,-22 1502,-28 1502,-28 1502,-128 1502,-128 1502,-134 1496,-140 1490,-140 1490,-140 724,-140 724,-140 718,-140 712,-134 712,-128 712,-128 712,-28 712,-28 712,-22 718,-16 724,-16\"/>\n<text text-anchor=\"middle\" x=\"1107\" y=\"-124.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">residual</text>\n</g>\n<g id=\"clust4\" class=\"cluster\">\n<title>cluster_layer1_residual_res1</title>\n<path fill=\"#777777\" fill-opacity=\"0.266667\" stroke=\"#000000\" d=\"M814,-24C814,-24 1040,-24 1040,-24 1046,-24 1052,-30 1052,-36 1052,-36 1052,-87 1052,-87 1052,-93 1046,-99 1040,-99 1040,-99 814,-99 814,-99 808,-99 802,-93 802,-87 802,-87 802,-36 802,-36 802,-30 808,-24 814,-24\"/>\n<text text-anchor=\"middle\" x=\"927\" y=\"-83.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">res1</text>\n</g>\n<g id=\"clust5\" class=\"cluster\">\n<title>cluster_layer1_residual_res2</title>\n<path fill=\"#777777\" fill-opacity=\"0.266667\" stroke=\"#000000\" d=\"M1084,-24C1084,-24 1310,-24 1310,-24 1316,-24 1322,-30 1322,-36 1322,-36 1322,-87 1322,-87 1322,-93 1316,-99 1310,-99 1310,-99 1084,-99 1084,-99 1078,-99 1072,-93 1072,-87 1072,-87 1072,-36 1072,-36 1072,-30 1078,-24 1084,-24\"/>\n<text text-anchor=\"middle\" x=\"1197\" y=\"-83.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">res2</text>\n</g>\n<g id=\"clust6\" class=\"cluster\">\n<title>cluster_layer2</title>\n<path fill=\"#777777\" fill-opacity=\"0.266667\" stroke=\"#000000\" d=\"M1534,-54C1534,-54 1850,-54 1850,-54 1856,-54 1862,-60 1862,-66 1862,-66 1862,-117 1862,-117 1862,-123 1856,-129 1850,-129 1850,-129 1534,-129 1534,-129 1528,-129 1522,-123 1522,-117 1522,-117 1522,-66 1522,-66 1522,-60 1528,-54 1534,-54\"/>\n<text text-anchor=\"middle\" x=\"1692\" y=\"-113.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">layer2</text>\n</g>\n<g id=\"clust7\" class=\"cluster\">\n<title>cluster_layer3</title>\n<path fill=\"#777777\" fill-opacity=\"0.266667\" stroke=\"#000000\" d=\"M1894,-28C1894,-28 3028,-28 3028,-28 3034,-28 3040,-34 3040,-40 3040,-40 3040,-179 3040,-179 3040,-185 3034,-191 3028,-191 3028,-191 1894,-191 1894,-191 1888,-191 1882,-185 1882,-179 1882,-179 1882,-40 1882,-40 1882,-34 1888,-28 1894,-28\"/>\n<text text-anchor=\"middle\" x=\"2461\" y=\"-175.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">layer3</text>\n</g>\n<g id=\"clust8\" class=\"cluster\">\n<title>cluster_layer3_residual</title>\n<path fill=\"#777777\" fill-opacity=\"0.266667\" stroke=\"#000000\" d=\"M2254,-36C2254,-36 3020,-36 3020,-36 3026,-36 3032,-42 3032,-48 3032,-48 3032,-148 3032,-148 3032,-154 3026,-160 3020,-160 3020,-160 2254,-160 2254,-160 2248,-160 2242,-154 2242,-148 2242,-148 2242,-48 2242,-48 2242,-42 2248,-36 2254,-36\"/>\n<text text-anchor=\"middle\" x=\"2637\" y=\"-144.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">residual</text>\n</g>\n<g id=\"clust9\" class=\"cluster\">\n<title>cluster_layer3_residual_res1</title>\n<path fill=\"#777777\" fill-opacity=\"0.266667\" stroke=\"#000000\" d=\"M2344,-44C2344,-44 2570,-44 2570,-44 2576,-44 2582,-50 2582,-56 2582,-56 2582,-107 2582,-107 2582,-113 2576,-119 2570,-119 2570,-119 2344,-119 2344,-119 2338,-119 2332,-113 2332,-107 2332,-107 2332,-56 2332,-56 2332,-50 2338,-44 2344,-44\"/>\n<text text-anchor=\"middle\" x=\"2457\" y=\"-103.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">res1</text>\n</g>\n<g id=\"clust10\" class=\"cluster\">\n<title>cluster_layer3_residual_res2</title>\n<path fill=\"#777777\" fill-opacity=\"0.266667\" stroke=\"#000000\" d=\"M2614,-44C2614,-44 2840,-44 2840,-44 2846,-44 2852,-50 2852,-56 2852,-56 2852,-107 2852,-107 2852,-113 2846,-119 2840,-119 2840,-119 2614,-119 2614,-119 2608,-119 2602,-113 2602,-107 2602,-107 2602,-56 2602,-56 2602,-50 2608,-44 2614,-44\"/>\n<text text-anchor=\"middle\" x=\"2727\" y=\"-103.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">res2</text>\n</g>\n<g id=\"clust11\" class=\"cluster\">\n<title>cluster_classifier</title>\n<path fill=\"#777777\" fill-opacity=\"0.266667\" stroke=\"#000000\" d=\"M3154,-74C3154,-74 3380,-74 3380,-74 3386,-74 3392,-80 3392,-86 3392,-86 3392,-137 3392,-137 3392,-143 3386,-149 3380,-149 3380,-149 3154,-149 3154,-149 3148,-149 3142,-143 3142,-137 3142,-137 3142,-86 3142,-86 3142,-80 3148,-74 3154,-74\"/>\n<text text-anchor=\"middle\" x=\"3267\" y=\"-133.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">classifier</text>\n</g>\n<!-- prep_conv -->\n<g id=\"node1\" class=\"node\">\n<title>prep_conv</title>\n<g id=\"a_node1\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.conv.Conv2d&#39;&gt; {&#39;in_channels&#39;: 3, &#39;out_channels&#39;: 64, &#39;kernel_size&#39;: (3, 3), &#39;stride&#39;: (1, 1), &#39;padding&#39;: (1, 1), &#39;bias&#39;: False}\">\n<path fill=\"#bebada\" stroke=\"#000000\" d=\"M132,-88C132,-88 102,-88 102,-88 96,-88 90,-82 90,-76 90,-76 90,-64 90,-64 90,-58 96,-52 102,-52 102,-52 132,-52 132,-52 138,-52 144,-58 144,-64 144,-64 144,-76 144,-76 144,-82 138,-88 132,-88\"/>\n<text text-anchor=\"middle\" x=\"117\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">conv</text>\n</a>\n</g>\n</g>\n<!-- prep_norm -->\n<g id=\"node2\" class=\"node\">\n<title>prep_norm</title>\n<g id=\"a_node2\"><a xlink:title=\"&lt;class &#39;__main__.BatchNorm&#39;&gt; {&#39;num_features&#39;: 64}\">\n<path fill=\"#ffffb3\" stroke=\"#000000\" d=\"M222,-88C222,-88 192,-88 192,-88 186,-88 180,-82 180,-76 180,-76 180,-64 180,-64 180,-58 186,-52 192,-52 192,-52 222,-52 222,-52 228,-52 234,-58 234,-64 234,-64 234,-76 234,-76 234,-82 228,-88 222,-88\"/>\n<text text-anchor=\"middle\" x=\"207\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">norm</text>\n</a>\n</g>\n</g>\n<!-- prep_conv&#45;&gt;prep_norm -->\n<g id=\"edge2\" class=\"edge\">\n<title>prep_conv&#45;&gt;prep_norm</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M144.003,-70C152.0277,-70 160.9665,-70 169.5309,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"169.7051,-73.5001 179.705,-70 169.705,-66.5001 169.7051,-73.5001\"/>\n</g>\n<!-- prep_act -->\n<g id=\"node3\" class=\"node\">\n<title>prep_act</title>\n<g id=\"a_node3\"><a xlink:title=\"functools.partial(&lt;class &#39;torch.nn.modules.activation.CELU&#39;&gt;, alpha=0.075) {}\">\n<path fill=\"#ff7f00\" stroke=\"#000000\" d=\"M312,-88C312,-88 282,-88 282,-88 276,-88 270,-82 270,-76 270,-76 270,-64 270,-64 270,-58 276,-52 282,-52 282,-52 312,-52 312,-52 318,-52 324,-58 324,-64 324,-64 324,-76 324,-76 324,-82 318,-88 312,-88\"/>\n<text text-anchor=\"middle\" x=\"297\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">act</text>\n</a>\n</g>\n</g>\n<!-- prep_norm&#45;&gt;prep_act -->\n<g id=\"edge3\" class=\"edge\">\n<title>prep_norm&#45;&gt;prep_act</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M234.003,-70C242.0277,-70 250.9665,-70 259.5309,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"259.7051,-73.5001 269.705,-70 259.705,-66.5001 259.7051,-73.5001\"/>\n</g>\n<!-- layer1_conv -->\n<g id=\"node4\" class=\"node\">\n<title>layer1_conv</title>\n<g id=\"a_node4\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.conv.Conv2d&#39;&gt; {&#39;in_channels&#39;: 64, &#39;out_channels&#39;: 128, &#39;kernel_size&#39;: (3, 3), &#39;stride&#39;: (1, 1), &#39;padding&#39;: (1, 1), &#39;bias&#39;: False}\">\n<path fill=\"#bebada\" stroke=\"#000000\" d=\"M402,-88C402,-88 372,-88 372,-88 366,-88 360,-82 360,-76 360,-76 360,-64 360,-64 360,-58 366,-52 372,-52 372,-52 402,-52 402,-52 408,-52 414,-58 414,-64 414,-64 414,-76 414,-76 414,-82 408,-88 402,-88\"/>\n<text text-anchor=\"middle\" x=\"387\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">conv</text>\n</a>\n</g>\n</g>\n<!-- prep_act&#45;&gt;layer1_conv -->\n<g id=\"edge4\" class=\"edge\">\n<title>prep_act&#45;&gt;layer1_conv</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M324.003,-70C332.0277,-70 340.9665,-70 349.5309,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"349.7051,-73.5001 359.705,-70 349.705,-66.5001 349.7051,-73.5001\"/>\n</g>\n<!-- layer1_pool -->\n<g id=\"node5\" class=\"node\">\n<title>layer1_pool</title>\n<g id=\"a_node5\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.pooling.MaxPool2d&#39;&gt; {&#39;kernel_size&#39;: 2}\">\n<path fill=\"#8dd3c7\" stroke=\"#000000\" d=\"M492,-88C492,-88 462,-88 462,-88 456,-88 450,-82 450,-76 450,-76 450,-64 450,-64 450,-58 456,-52 462,-52 462,-52 492,-52 492,-52 498,-52 504,-58 504,-64 504,-64 504,-76 504,-76 504,-82 498,-88 492,-88\"/>\n<text text-anchor=\"middle\" x=\"477\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">pool</text>\n</a>\n</g>\n</g>\n<!-- layer1_conv&#45;&gt;layer1_pool -->\n<g id=\"edge5\" class=\"edge\">\n<title>layer1_conv&#45;&gt;layer1_pool</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M414.003,-70C422.0277,-70 430.9665,-70 439.5309,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"439.7051,-73.5001 449.705,-70 439.705,-66.5001 439.7051,-73.5001\"/>\n</g>\n<!-- layer1_norm -->\n<g id=\"node6\" class=\"node\">\n<title>layer1_norm</title>\n<g id=\"a_node6\"><a xlink:title=\"&lt;class &#39;__main__.BatchNorm&#39;&gt; {&#39;num_features&#39;: 128}\">\n<path fill=\"#ffffb3\" stroke=\"#000000\" d=\"M582,-88C582,-88 552,-88 552,-88 546,-88 540,-82 540,-76 540,-76 540,-64 540,-64 540,-58 546,-52 552,-52 552,-52 582,-52 582,-52 588,-52 594,-58 594,-64 594,-64 594,-76 594,-76 594,-82 588,-88 582,-88\"/>\n<text text-anchor=\"middle\" x=\"567\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">norm</text>\n</a>\n</g>\n</g>\n<!-- layer1_pool&#45;&gt;layer1_norm -->\n<g id=\"edge6\" class=\"edge\">\n<title>layer1_pool&#45;&gt;layer1_norm</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M504.003,-70C512.0277,-70 520.9665,-70 529.5309,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"529.7051,-73.5001 539.705,-70 529.705,-66.5001 529.7051,-73.5001\"/>\n</g>\n<!-- layer1_act -->\n<g id=\"node7\" class=\"node\">\n<title>layer1_act</title>\n<g id=\"a_node7\"><a xlink:title=\"functools.partial(&lt;class &#39;torch.nn.modules.activation.CELU&#39;&gt;, alpha=0.075) {}\">\n<path fill=\"#ff7f00\" stroke=\"#000000\" d=\"M672,-88C672,-88 642,-88 642,-88 636,-88 630,-82 630,-76 630,-76 630,-64 630,-64 630,-58 636,-52 642,-52 642,-52 672,-52 672,-52 678,-52 684,-58 684,-64 684,-64 684,-76 684,-76 684,-82 678,-88 672,-88\"/>\n<text text-anchor=\"middle\" x=\"657\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">act</text>\n</a>\n</g>\n</g>\n<!-- layer1_norm&#45;&gt;layer1_act -->\n<g id=\"edge7\" class=\"edge\">\n<title>layer1_norm&#45;&gt;layer1_act</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M594.003,-70C602.0277,-70 610.9665,-70 619.5309,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"619.7051,-73.5001 629.705,-70 619.705,-66.5001 619.7051,-73.5001\"/>\n</g>\n<!-- layer1_residual_in -->\n<g id=\"node8\" class=\"node\">\n<title>layer1_residual_in</title>\n<g id=\"a_node8\"><a xlink:title=\"&lt;class &#39;__main__.Identity&#39;&gt; {}\">\n<path fill=\"#80b1d3\" stroke=\"#000000\" d=\"M762,-88C762,-88 732,-88 732,-88 726,-88 720,-82 720,-76 720,-76 720,-64 720,-64 720,-58 726,-52 732,-52 732,-52 762,-52 762,-52 768,-52 774,-58 774,-64 774,-64 774,-76 774,-76 774,-82 768,-88 762,-88\"/>\n<text text-anchor=\"middle\" x=\"747\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">in</text>\n</a>\n</g>\n</g>\n<!-- layer1_act&#45;&gt;layer1_residual_in -->\n<g id=\"edge8\" class=\"edge\">\n<title>layer1_act&#45;&gt;layer1_residual_in</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M684.003,-70C692.0277,-70 700.9665,-70 709.5309,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"709.7051,-73.5001 719.705,-70 709.705,-66.5001 709.7051,-73.5001\"/>\n</g>\n<!-- layer1_residual_res1_conv -->\n<g id=\"node9\" class=\"node\">\n<title>layer1_residual_res1_conv</title>\n<g id=\"a_node9\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.conv.Conv2d&#39;&gt; {&#39;in_channels&#39;: 128, &#39;out_channels&#39;: 128, &#39;kernel_size&#39;: (3, 3), &#39;stride&#39;: (1, 1), &#39;padding&#39;: (1, 1), &#39;bias&#39;: False}\">\n<path fill=\"#bebada\" stroke=\"#000000\" d=\"M852,-68C852,-68 822,-68 822,-68 816,-68 810,-62 810,-56 810,-56 810,-44 810,-44 810,-38 816,-32 822,-32 822,-32 852,-32 852,-32 858,-32 864,-38 864,-44 864,-44 864,-56 864,-56 864,-62 858,-68 852,-68\"/>\n<text text-anchor=\"middle\" x=\"837\" y=\"-46.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">conv</text>\n</a>\n</g>\n</g>\n<!-- layer1_residual_in&#45;&gt;layer1_residual_res1_conv -->\n<g id=\"edge9\" class=\"edge\">\n<title>layer1_residual_in&#45;&gt;layer1_residual_res1_conv</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M774.003,-63.9993C782.1158,-62.1965 791.1631,-60.186 799.8131,-58.2638\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"800.7024,-61.6516 809.705,-56.0655 799.1839,-54.8183 800.7024,-61.6516\"/>\n</g>\n<!-- layer1_residual_add -->\n<g id=\"node16\" class=\"node\">\n<title>layer1_residual_add</title>\n<g id=\"a_node16\"><a xlink:title=\"&lt;class &#39;__main__.Add&#39;&gt; {}\">\n<path fill=\"#fdb462\" stroke=\"#000000\" d=\"M1482,-98C1482,-98 1452,-98 1452,-98 1446,-98 1440,-92 1440,-86 1440,-86 1440,-74 1440,-74 1440,-68 1446,-62 1452,-62 1452,-62 1482,-62 1482,-62 1488,-62 1494,-68 1494,-74 1494,-74 1494,-86 1494,-86 1494,-92 1488,-98 1482,-98\"/>\n<text text-anchor=\"middle\" x=\"1467\" y=\"-76.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">add</text>\n</a>\n</g>\n</g>\n<!-- layer1_residual_in&#45;&gt;layer1_residual_add -->\n<g id=\"edge16\" class=\"edge\">\n<title>layer1_residual_in&#45;&gt;layer1_residual_add</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M771.2203,-88.104C780.3892,-93.9663 791.2234,-99.7818 802,-103 855.2752,-118.9095 871.4,-108 927,-108 927,-108 927,-108 1287,-108 1336.7971,-108 1393.4324,-97.4074 1429.6554,-89.2525\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1430.8023,-92.5799 1439.7594,-86.9214 1429.2285,-85.7591 1430.8023,-92.5799\"/>\n</g>\n<!-- layer1_residual_res1_norm -->\n<g id=\"node10\" class=\"node\">\n<title>layer1_residual_res1_norm</title>\n<g id=\"a_node10\"><a xlink:title=\"&lt;class &#39;__main__.BatchNorm&#39;&gt; {&#39;num_features&#39;: 128}\">\n<path fill=\"#ffffb3\" stroke=\"#000000\" d=\"M942,-68C942,-68 912,-68 912,-68 906,-68 900,-62 900,-56 900,-56 900,-44 900,-44 900,-38 906,-32 912,-32 912,-32 942,-32 942,-32 948,-32 954,-38 954,-44 954,-44 954,-56 954,-56 954,-62 948,-68 942,-68\"/>\n<text text-anchor=\"middle\" x=\"927\" y=\"-46.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">norm</text>\n</a>\n</g>\n</g>\n<!-- layer1_residual_res1_conv&#45;&gt;layer1_residual_res1_norm -->\n<g id=\"edge10\" class=\"edge\">\n<title>layer1_residual_res1_conv&#45;&gt;layer1_residual_res1_norm</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M864.003,-50C872.0277,-50 880.9665,-50 889.5309,-50\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"889.7051,-53.5001 899.705,-50 889.705,-46.5001 889.7051,-53.5001\"/>\n</g>\n<!-- layer1_residual_res1_act -->\n<g id=\"node11\" class=\"node\">\n<title>layer1_residual_res1_act</title>\n<g id=\"a_node11\"><a xlink:title=\"functools.partial(&lt;class &#39;torch.nn.modules.activation.CELU&#39;&gt;, alpha=0.075) {}\">\n<path fill=\"#ff7f00\" stroke=\"#000000\" d=\"M1032,-68C1032,-68 1002,-68 1002,-68 996,-68 990,-62 990,-56 990,-56 990,-44 990,-44 990,-38 996,-32 1002,-32 1002,-32 1032,-32 1032,-32 1038,-32 1044,-38 1044,-44 1044,-44 1044,-56 1044,-56 1044,-62 1038,-68 1032,-68\"/>\n<text text-anchor=\"middle\" x=\"1017\" y=\"-46.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">act</text>\n</a>\n</g>\n</g>\n<!-- layer1_residual_res1_norm&#45;&gt;layer1_residual_res1_act -->\n<g id=\"edge11\" class=\"edge\">\n<title>layer1_residual_res1_norm&#45;&gt;layer1_residual_res1_act</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M954.003,-50C962.0277,-50 970.9665,-50 979.5309,-50\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"979.7051,-53.5001 989.705,-50 979.705,-46.5001 979.7051,-53.5001\"/>\n</g>\n<!-- layer1_residual_res2_conv -->\n<g id=\"node12\" class=\"node\">\n<title>layer1_residual_res2_conv</title>\n<g id=\"a_node12\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.conv.Conv2d&#39;&gt; {&#39;in_channels&#39;: 128, &#39;out_channels&#39;: 128, &#39;kernel_size&#39;: (3, 3), &#39;stride&#39;: (1, 1), &#39;padding&#39;: (1, 1), &#39;bias&#39;: False}\">\n<path fill=\"#bebada\" stroke=\"#000000\" d=\"M1122,-68C1122,-68 1092,-68 1092,-68 1086,-68 1080,-62 1080,-56 1080,-56 1080,-44 1080,-44 1080,-38 1086,-32 1092,-32 1092,-32 1122,-32 1122,-32 1128,-32 1134,-38 1134,-44 1134,-44 1134,-56 1134,-56 1134,-62 1128,-68 1122,-68\"/>\n<text text-anchor=\"middle\" x=\"1107\" y=\"-46.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">conv</text>\n</a>\n</g>\n</g>\n<!-- layer1_residual_res1_act&#45;&gt;layer1_residual_res2_conv -->\n<g id=\"edge12\" class=\"edge\">\n<title>layer1_residual_res1_act&#45;&gt;layer1_residual_res2_conv</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1044.003,-50C1052.0277,-50 1060.9665,-50 1069.5309,-50\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1069.7051,-53.5001 1079.705,-50 1069.705,-46.5001 1069.7051,-53.5001\"/>\n</g>\n<!-- layer1_residual_res2_norm -->\n<g id=\"node13\" class=\"node\">\n<title>layer1_residual_res2_norm</title>\n<g id=\"a_node13\"><a xlink:title=\"&lt;class &#39;__main__.BatchNorm&#39;&gt; {&#39;num_features&#39;: 128}\">\n<path fill=\"#ffffb3\" stroke=\"#000000\" d=\"M1212,-68C1212,-68 1182,-68 1182,-68 1176,-68 1170,-62 1170,-56 1170,-56 1170,-44 1170,-44 1170,-38 1176,-32 1182,-32 1182,-32 1212,-32 1212,-32 1218,-32 1224,-38 1224,-44 1224,-44 1224,-56 1224,-56 1224,-62 1218,-68 1212,-68\"/>\n<text text-anchor=\"middle\" x=\"1197\" y=\"-46.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">norm</text>\n</a>\n</g>\n</g>\n<!-- layer1_residual_res2_conv&#45;&gt;layer1_residual_res2_norm -->\n<g id=\"edge13\" class=\"edge\">\n<title>layer1_residual_res2_conv&#45;&gt;layer1_residual_res2_norm</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1134.003,-50C1142.0277,-50 1150.9665,-50 1159.5309,-50\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1159.7051,-53.5001 1169.705,-50 1159.705,-46.5001 1159.7051,-53.5001\"/>\n</g>\n<!-- layer1_residual_res2_act -->\n<g id=\"node14\" class=\"node\">\n<title>layer1_residual_res2_act</title>\n<g id=\"a_node14\"><a xlink:title=\"functools.partial(&lt;class &#39;torch.nn.modules.activation.CELU&#39;&gt;, alpha=0.075) {}\">\n<path fill=\"#ff7f00\" stroke=\"#000000\" d=\"M1302,-68C1302,-68 1272,-68 1272,-68 1266,-68 1260,-62 1260,-56 1260,-56 1260,-44 1260,-44 1260,-38 1266,-32 1272,-32 1272,-32 1302,-32 1302,-32 1308,-32 1314,-38 1314,-44 1314,-44 1314,-56 1314,-56 1314,-62 1308,-68 1302,-68\"/>\n<text text-anchor=\"middle\" x=\"1287\" y=\"-46.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">act</text>\n</a>\n</g>\n</g>\n<!-- layer1_residual_res2_norm&#45;&gt;layer1_residual_res2_act -->\n<g id=\"edge14\" class=\"edge\">\n<title>layer1_residual_res2_norm&#45;&gt;layer1_residual_res2_act</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1224.003,-50C1232.0277,-50 1240.9665,-50 1249.5309,-50\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1249.7051,-53.5001 1259.705,-50 1249.705,-46.5001 1249.7051,-53.5001\"/>\n</g>\n<!-- layer1_residual_out -->\n<g id=\"node15\" class=\"node\">\n<title>layer1_residual_out</title>\n<g id=\"a_node15\"><a xlink:title=\"&lt;class &#39;__main__.Identity&#39;&gt; {}\">\n<path fill=\"#80b1d3\" stroke=\"#000000\" d=\"M1392,-78C1392,-78 1362,-78 1362,-78 1356,-78 1350,-72 1350,-66 1350,-66 1350,-54 1350,-54 1350,-48 1356,-42 1362,-42 1362,-42 1392,-42 1392,-42 1398,-42 1404,-48 1404,-54 1404,-54 1404,-66 1404,-66 1404,-72 1398,-78 1392,-78\"/>\n<text text-anchor=\"middle\" x=\"1377\" y=\"-56.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">out</text>\n</a>\n</g>\n</g>\n<!-- layer1_residual_res2_act&#45;&gt;layer1_residual_out -->\n<g id=\"edge15\" class=\"edge\">\n<title>layer1_residual_res2_act&#45;&gt;layer1_residual_out</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1314.003,-53.0003C1322.0277,-53.892 1330.9665,-54.8852 1339.5309,-55.8368\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1339.3796,-59.3414 1349.705,-56.9672 1340.1527,-52.3842 1339.3796,-59.3414\"/>\n</g>\n<!-- layer1_residual_out&#45;&gt;layer1_residual_add -->\n<g id=\"edge17\" class=\"edge\">\n<title>layer1_residual_out&#45;&gt;layer1_residual_add</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1404.003,-66.0007C1412.1158,-67.8035 1421.1631,-69.814 1429.8131,-71.7362\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1429.1839,-75.1817 1439.705,-73.9345 1430.7024,-68.3484 1429.1839,-75.1817\"/>\n</g>\n<!-- layer2_conv -->\n<g id=\"node17\" class=\"node\">\n<title>layer2_conv</title>\n<g id=\"a_node17\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.conv.Conv2d&#39;&gt; {&#39;in_channels&#39;: 128, &#39;out_channels&#39;: 256, &#39;kernel_size&#39;: (3, 3), &#39;stride&#39;: (1, 1), &#39;padding&#39;: (1, 1), &#39;bias&#39;: False}\">\n<path fill=\"#bebada\" stroke=\"#000000\" d=\"M1572,-98C1572,-98 1542,-98 1542,-98 1536,-98 1530,-92 1530,-86 1530,-86 1530,-74 1530,-74 1530,-68 1536,-62 1542,-62 1542,-62 1572,-62 1572,-62 1578,-62 1584,-68 1584,-74 1584,-74 1584,-86 1584,-86 1584,-92 1578,-98 1572,-98\"/>\n<text text-anchor=\"middle\" x=\"1557\" y=\"-76.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">conv</text>\n</a>\n</g>\n</g>\n<!-- layer1_residual_add&#45;&gt;layer2_conv -->\n<g id=\"edge18\" class=\"edge\">\n<title>layer1_residual_add&#45;&gt;layer2_conv</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1494.003,-80C1502.0277,-80 1510.9665,-80 1519.5309,-80\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1519.7051,-83.5001 1529.705,-80 1519.705,-76.5001 1519.7051,-83.5001\"/>\n</g>\n<!-- layer2_pool -->\n<g id=\"node18\" class=\"node\">\n<title>layer2_pool</title>\n<g id=\"a_node18\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.pooling.MaxPool2d&#39;&gt; {&#39;kernel_size&#39;: 2}\">\n<path fill=\"#8dd3c7\" stroke=\"#000000\" d=\"M1662,-98C1662,-98 1632,-98 1632,-98 1626,-98 1620,-92 1620,-86 1620,-86 1620,-74 1620,-74 1620,-68 1626,-62 1632,-62 1632,-62 1662,-62 1662,-62 1668,-62 1674,-68 1674,-74 1674,-74 1674,-86 1674,-86 1674,-92 1668,-98 1662,-98\"/>\n<text text-anchor=\"middle\" x=\"1647\" y=\"-76.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">pool</text>\n</a>\n</g>\n</g>\n<!-- layer2_conv&#45;&gt;layer2_pool -->\n<g id=\"edge19\" class=\"edge\">\n<title>layer2_conv&#45;&gt;layer2_pool</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1584.003,-80C1592.0277,-80 1600.9665,-80 1609.5309,-80\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1609.7051,-83.5001 1619.705,-80 1609.705,-76.5001 1609.7051,-83.5001\"/>\n</g>\n<!-- layer2_norm -->\n<g id=\"node19\" class=\"node\">\n<title>layer2_norm</title>\n<g id=\"a_node19\"><a xlink:title=\"&lt;class &#39;__main__.BatchNorm&#39;&gt; {&#39;num_features&#39;: 256}\">\n<path fill=\"#ffffb3\" stroke=\"#000000\" d=\"M1752,-98C1752,-98 1722,-98 1722,-98 1716,-98 1710,-92 1710,-86 1710,-86 1710,-74 1710,-74 1710,-68 1716,-62 1722,-62 1722,-62 1752,-62 1752,-62 1758,-62 1764,-68 1764,-74 1764,-74 1764,-86 1764,-86 1764,-92 1758,-98 1752,-98\"/>\n<text text-anchor=\"middle\" x=\"1737\" y=\"-76.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">norm</text>\n</a>\n</g>\n</g>\n<!-- layer2_pool&#45;&gt;layer2_norm -->\n<g id=\"edge20\" class=\"edge\">\n<title>layer2_pool&#45;&gt;layer2_norm</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1674.003,-80C1682.0277,-80 1690.9665,-80 1699.5309,-80\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1699.7051,-83.5001 1709.705,-80 1699.705,-76.5001 1699.7051,-83.5001\"/>\n</g>\n<!-- layer2_act -->\n<g id=\"node20\" class=\"node\">\n<title>layer2_act</title>\n<g id=\"a_node20\"><a xlink:title=\"functools.partial(&lt;class &#39;torch.nn.modules.activation.CELU&#39;&gt;, alpha=0.075) {}\">\n<path fill=\"#ff7f00\" stroke=\"#000000\" d=\"M1842,-98C1842,-98 1812,-98 1812,-98 1806,-98 1800,-92 1800,-86 1800,-86 1800,-74 1800,-74 1800,-68 1806,-62 1812,-62 1812,-62 1842,-62 1842,-62 1848,-62 1854,-68 1854,-74 1854,-74 1854,-86 1854,-86 1854,-92 1848,-98 1842,-98\"/>\n<text text-anchor=\"middle\" x=\"1827\" y=\"-76.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">act</text>\n</a>\n</g>\n</g>\n<!-- layer2_norm&#45;&gt;layer2_act -->\n<g id=\"edge21\" class=\"edge\">\n<title>layer2_norm&#45;&gt;layer2_act</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1764.003,-80C1772.0277,-80 1780.9665,-80 1789.5309,-80\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1789.7051,-83.5001 1799.705,-80 1789.705,-76.5001 1789.7051,-83.5001\"/>\n</g>\n<!-- layer3_conv -->\n<g id=\"node21\" class=\"node\">\n<title>layer3_conv</title>\n<g id=\"a_node21\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.conv.Conv2d&#39;&gt; {&#39;in_channels&#39;: 256, &#39;out_channels&#39;: 512, &#39;kernel_size&#39;: (3, 3), &#39;stride&#39;: (1, 1), &#39;padding&#39;: (1, 1), &#39;bias&#39;: False}\">\n<path fill=\"#bebada\" stroke=\"#000000\" d=\"M1932,-98C1932,-98 1902,-98 1902,-98 1896,-98 1890,-92 1890,-86 1890,-86 1890,-74 1890,-74 1890,-68 1896,-62 1902,-62 1902,-62 1932,-62 1932,-62 1938,-62 1944,-68 1944,-74 1944,-74 1944,-86 1944,-86 1944,-92 1938,-98 1932,-98\"/>\n<text text-anchor=\"middle\" x=\"1917\" y=\"-76.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">conv</text>\n</a>\n</g>\n</g>\n<!-- layer2_act&#45;&gt;layer3_conv -->\n<g id=\"edge22\" class=\"edge\">\n<title>layer2_act&#45;&gt;layer3_conv</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1854.003,-80C1862.0277,-80 1870.9665,-80 1879.5309,-80\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1879.7051,-83.5001 1889.705,-80 1879.705,-76.5001 1879.7051,-83.5001\"/>\n</g>\n<!-- layer3_pool -->\n<g id=\"node22\" class=\"node\">\n<title>layer3_pool</title>\n<g id=\"a_node22\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.pooling.MaxPool2d&#39;&gt; {&#39;kernel_size&#39;: 2}\">\n<path fill=\"#8dd3c7\" stroke=\"#000000\" d=\"M2022,-98C2022,-98 1992,-98 1992,-98 1986,-98 1980,-92 1980,-86 1980,-86 1980,-74 1980,-74 1980,-68 1986,-62 1992,-62 1992,-62 2022,-62 2022,-62 2028,-62 2034,-68 2034,-74 2034,-74 2034,-86 2034,-86 2034,-92 2028,-98 2022,-98\"/>\n<text text-anchor=\"middle\" x=\"2007\" y=\"-76.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">pool</text>\n</a>\n</g>\n</g>\n<!-- layer3_conv&#45;&gt;layer3_pool -->\n<g id=\"edge23\" class=\"edge\">\n<title>layer3_conv&#45;&gt;layer3_pool</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1944.003,-80C1952.0277,-80 1960.9665,-80 1969.5309,-80\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1969.7051,-83.5001 1979.705,-80 1969.705,-76.5001 1969.7051,-83.5001\"/>\n</g>\n<!-- layer3_norm -->\n<g id=\"node23\" class=\"node\">\n<title>layer3_norm</title>\n<g id=\"a_node23\"><a xlink:title=\"&lt;class &#39;__main__.BatchNorm&#39;&gt; {&#39;num_features&#39;: 512}\">\n<path fill=\"#ffffb3\" stroke=\"#000000\" d=\"M2112,-98C2112,-98 2082,-98 2082,-98 2076,-98 2070,-92 2070,-86 2070,-86 2070,-74 2070,-74 2070,-68 2076,-62 2082,-62 2082,-62 2112,-62 2112,-62 2118,-62 2124,-68 2124,-74 2124,-74 2124,-86 2124,-86 2124,-92 2118,-98 2112,-98\"/>\n<text text-anchor=\"middle\" x=\"2097\" y=\"-76.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">norm</text>\n</a>\n</g>\n</g>\n<!-- layer3_pool&#45;&gt;layer3_norm -->\n<g id=\"edge24\" class=\"edge\">\n<title>layer3_pool&#45;&gt;layer3_norm</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2034.003,-80C2042.0277,-80 2050.9665,-80 2059.5309,-80\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2059.7051,-83.5001 2069.705,-80 2059.705,-76.5001 2059.7051,-83.5001\"/>\n</g>\n<!-- layer3_act -->\n<g id=\"node24\" class=\"node\">\n<title>layer3_act</title>\n<g id=\"a_node24\"><a xlink:title=\"functools.partial(&lt;class &#39;torch.nn.modules.activation.CELU&#39;&gt;, alpha=0.075) {}\">\n<path fill=\"#ff7f00\" stroke=\"#000000\" d=\"M2202,-98C2202,-98 2172,-98 2172,-98 2166,-98 2160,-92 2160,-86 2160,-86 2160,-74 2160,-74 2160,-68 2166,-62 2172,-62 2172,-62 2202,-62 2202,-62 2208,-62 2214,-68 2214,-74 2214,-74 2214,-86 2214,-86 2214,-92 2208,-98 2202,-98\"/>\n<text text-anchor=\"middle\" x=\"2187\" y=\"-76.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">act</text>\n</a>\n</g>\n</g>\n<!-- layer3_norm&#45;&gt;layer3_act -->\n<g id=\"edge25\" class=\"edge\">\n<title>layer3_norm&#45;&gt;layer3_act</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2124.003,-80C2132.0277,-80 2140.9665,-80 2149.5309,-80\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2149.7051,-83.5001 2159.705,-80 2149.705,-76.5001 2149.7051,-83.5001\"/>\n</g>\n<!-- layer3_residual_in -->\n<g id=\"node25\" class=\"node\">\n<title>layer3_residual_in</title>\n<g id=\"a_node25\"><a xlink:title=\"&lt;class &#39;__main__.Identity&#39;&gt; {}\">\n<path fill=\"#80b1d3\" stroke=\"#000000\" d=\"M2292,-98C2292,-98 2262,-98 2262,-98 2256,-98 2250,-92 2250,-86 2250,-86 2250,-74 2250,-74 2250,-68 2256,-62 2262,-62 2262,-62 2292,-62 2292,-62 2298,-62 2304,-68 2304,-74 2304,-74 2304,-86 2304,-86 2304,-92 2298,-98 2292,-98\"/>\n<text text-anchor=\"middle\" x=\"2277\" y=\"-76.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">in</text>\n</a>\n</g>\n</g>\n<!-- layer3_act&#45;&gt;layer3_residual_in -->\n<g id=\"edge26\" class=\"edge\">\n<title>layer3_act&#45;&gt;layer3_residual_in</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2214.003,-80C2222.0277,-80 2230.9665,-80 2239.5309,-80\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2239.7051,-83.5001 2249.705,-80 2239.705,-76.5001 2239.7051,-83.5001\"/>\n</g>\n<!-- layer3_residual_res1_conv -->\n<g id=\"node26\" class=\"node\">\n<title>layer3_residual_res1_conv</title>\n<g id=\"a_node26\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.conv.Conv2d&#39;&gt; {&#39;in_channels&#39;: 512, &#39;out_channels&#39;: 512, &#39;kernel_size&#39;: (3, 3), &#39;stride&#39;: (1, 1), &#39;padding&#39;: (1, 1), &#39;bias&#39;: False}\">\n<path fill=\"#bebada\" stroke=\"#000000\" d=\"M2382,-88C2382,-88 2352,-88 2352,-88 2346,-88 2340,-82 2340,-76 2340,-76 2340,-64 2340,-64 2340,-58 2346,-52 2352,-52 2352,-52 2382,-52 2382,-52 2388,-52 2394,-58 2394,-64 2394,-64 2394,-76 2394,-76 2394,-82 2388,-88 2382,-88\"/>\n<text text-anchor=\"middle\" x=\"2367\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">conv</text>\n</a>\n</g>\n</g>\n<!-- layer3_residual_in&#45;&gt;layer3_residual_res1_conv -->\n<g id=\"edge27\" class=\"edge\">\n<title>layer3_residual_in&#45;&gt;layer3_residual_res1_conv</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2304.003,-76.9997C2312.0277,-76.108 2320.9665,-75.1148 2329.5309,-74.1632\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2330.1527,-77.6158 2339.705,-73.0328 2329.3796,-70.6586 2330.1527,-77.6158\"/>\n</g>\n<!-- layer3_residual_add -->\n<g id=\"node33\" class=\"node\">\n<title>layer3_residual_add</title>\n<g id=\"a_node33\"><a xlink:title=\"&lt;class &#39;__main__.Add&#39;&gt; {}\">\n<path fill=\"#fdb462\" stroke=\"#000000\" d=\"M3012,-118C3012,-118 2982,-118 2982,-118 2976,-118 2970,-112 2970,-106 2970,-106 2970,-94 2970,-94 2970,-88 2976,-82 2982,-82 2982,-82 3012,-82 3012,-82 3018,-82 3024,-88 3024,-94 3024,-94 3024,-106 3024,-106 3024,-112 3018,-118 3012,-118\"/>\n<text text-anchor=\"middle\" x=\"2997\" y=\"-96.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">add</text>\n</a>\n</g>\n</g>\n<!-- layer3_residual_in&#45;&gt;layer3_residual_add -->\n<g id=\"edge34\" class=\"edge\">\n<title>layer3_residual_in&#45;&gt;layer3_residual_add</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2294.5351,-98.3771C2304.5459,-107.5711 2317.8909,-117.8215 2332,-123 2384.1953,-142.1574 2401.4,-128 2457,-128 2457,-128 2457,-128 2817,-128 2866.7971,-128 2923.4324,-117.4074 2959.6554,-109.2525\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2960.8023,-112.5799 2969.7594,-106.9214 2959.2285,-105.7591 2960.8023,-112.5799\"/>\n</g>\n<!-- layer3_residual_res1_norm -->\n<g id=\"node27\" class=\"node\">\n<title>layer3_residual_res1_norm</title>\n<g id=\"a_node27\"><a xlink:title=\"&lt;class &#39;__main__.BatchNorm&#39;&gt; {&#39;num_features&#39;: 512}\">\n<path fill=\"#ffffb3\" stroke=\"#000000\" d=\"M2472,-88C2472,-88 2442,-88 2442,-88 2436,-88 2430,-82 2430,-76 2430,-76 2430,-64 2430,-64 2430,-58 2436,-52 2442,-52 2442,-52 2472,-52 2472,-52 2478,-52 2484,-58 2484,-64 2484,-64 2484,-76 2484,-76 2484,-82 2478,-88 2472,-88\"/>\n<text text-anchor=\"middle\" x=\"2457\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">norm</text>\n</a>\n</g>\n</g>\n<!-- layer3_residual_res1_conv&#45;&gt;layer3_residual_res1_norm -->\n<g id=\"edge28\" class=\"edge\">\n<title>layer3_residual_res1_conv&#45;&gt;layer3_residual_res1_norm</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2394.003,-70C2402.0277,-70 2410.9665,-70 2419.5309,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2419.7051,-73.5001 2429.705,-70 2419.705,-66.5001 2419.7051,-73.5001\"/>\n</g>\n<!-- layer3_residual_res1_act -->\n<g id=\"node28\" class=\"node\">\n<title>layer3_residual_res1_act</title>\n<g id=\"a_node28\"><a xlink:title=\"functools.partial(&lt;class &#39;torch.nn.modules.activation.CELU&#39;&gt;, alpha=0.075) {}\">\n<path fill=\"#ff7f00\" stroke=\"#000000\" d=\"M2562,-88C2562,-88 2532,-88 2532,-88 2526,-88 2520,-82 2520,-76 2520,-76 2520,-64 2520,-64 2520,-58 2526,-52 2532,-52 2532,-52 2562,-52 2562,-52 2568,-52 2574,-58 2574,-64 2574,-64 2574,-76 2574,-76 2574,-82 2568,-88 2562,-88\"/>\n<text text-anchor=\"middle\" x=\"2547\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">act</text>\n</a>\n</g>\n</g>\n<!-- layer3_residual_res1_norm&#45;&gt;layer3_residual_res1_act -->\n<g id=\"edge29\" class=\"edge\">\n<title>layer3_residual_res1_norm&#45;&gt;layer3_residual_res1_act</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2484.003,-70C2492.0277,-70 2500.9665,-70 2509.5309,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2509.7051,-73.5001 2519.705,-70 2509.705,-66.5001 2509.7051,-73.5001\"/>\n</g>\n<!-- layer3_residual_res2_conv -->\n<g id=\"node29\" class=\"node\">\n<title>layer3_residual_res2_conv</title>\n<g id=\"a_node29\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.conv.Conv2d&#39;&gt; {&#39;in_channels&#39;: 512, &#39;out_channels&#39;: 512, &#39;kernel_size&#39;: (3, 3), &#39;stride&#39;: (1, 1), &#39;padding&#39;: (1, 1), &#39;bias&#39;: False}\">\n<path fill=\"#bebada\" stroke=\"#000000\" d=\"M2652,-88C2652,-88 2622,-88 2622,-88 2616,-88 2610,-82 2610,-76 2610,-76 2610,-64 2610,-64 2610,-58 2616,-52 2622,-52 2622,-52 2652,-52 2652,-52 2658,-52 2664,-58 2664,-64 2664,-64 2664,-76 2664,-76 2664,-82 2658,-88 2652,-88\"/>\n<text text-anchor=\"middle\" x=\"2637\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">conv</text>\n</a>\n</g>\n</g>\n<!-- layer3_residual_res1_act&#45;&gt;layer3_residual_res2_conv -->\n<g id=\"edge30\" class=\"edge\">\n<title>layer3_residual_res1_act&#45;&gt;layer3_residual_res2_conv</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2574.003,-70C2582.0277,-70 2590.9665,-70 2599.5309,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2599.7051,-73.5001 2609.705,-70 2599.705,-66.5001 2599.7051,-73.5001\"/>\n</g>\n<!-- layer3_residual_res2_norm -->\n<g id=\"node30\" class=\"node\">\n<title>layer3_residual_res2_norm</title>\n<g id=\"a_node30\"><a xlink:title=\"&lt;class &#39;__main__.BatchNorm&#39;&gt; {&#39;num_features&#39;: 512}\">\n<path fill=\"#ffffb3\" stroke=\"#000000\" d=\"M2742,-88C2742,-88 2712,-88 2712,-88 2706,-88 2700,-82 2700,-76 2700,-76 2700,-64 2700,-64 2700,-58 2706,-52 2712,-52 2712,-52 2742,-52 2742,-52 2748,-52 2754,-58 2754,-64 2754,-64 2754,-76 2754,-76 2754,-82 2748,-88 2742,-88\"/>\n<text text-anchor=\"middle\" x=\"2727\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">norm</text>\n</a>\n</g>\n</g>\n<!-- layer3_residual_res2_conv&#45;&gt;layer3_residual_res2_norm -->\n<g id=\"edge31\" class=\"edge\">\n<title>layer3_residual_res2_conv&#45;&gt;layer3_residual_res2_norm</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2664.003,-70C2672.0277,-70 2680.9665,-70 2689.5309,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2689.7051,-73.5001 2699.705,-70 2689.705,-66.5001 2689.7051,-73.5001\"/>\n</g>\n<!-- layer3_residual_res2_act -->\n<g id=\"node31\" class=\"node\">\n<title>layer3_residual_res2_act</title>\n<g id=\"a_node31\"><a xlink:title=\"functools.partial(&lt;class &#39;torch.nn.modules.activation.CELU&#39;&gt;, alpha=0.075) {}\">\n<path fill=\"#ff7f00\" stroke=\"#000000\" d=\"M2832,-88C2832,-88 2802,-88 2802,-88 2796,-88 2790,-82 2790,-76 2790,-76 2790,-64 2790,-64 2790,-58 2796,-52 2802,-52 2802,-52 2832,-52 2832,-52 2838,-52 2844,-58 2844,-64 2844,-64 2844,-76 2844,-76 2844,-82 2838,-88 2832,-88\"/>\n<text text-anchor=\"middle\" x=\"2817\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">act</text>\n</a>\n</g>\n</g>\n<!-- layer3_residual_res2_norm&#45;&gt;layer3_residual_res2_act -->\n<g id=\"edge32\" class=\"edge\">\n<title>layer3_residual_res2_norm&#45;&gt;layer3_residual_res2_act</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2754.003,-70C2762.0277,-70 2770.9665,-70 2779.5309,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2779.7051,-73.5001 2789.705,-70 2779.705,-66.5001 2779.7051,-73.5001\"/>\n</g>\n<!-- layer3_residual_out -->\n<g id=\"node32\" class=\"node\">\n<title>layer3_residual_out</title>\n<g id=\"a_node32\"><a xlink:title=\"&lt;class &#39;__main__.Identity&#39;&gt; {}\">\n<path fill=\"#80b1d3\" stroke=\"#000000\" d=\"M2922,-98C2922,-98 2892,-98 2892,-98 2886,-98 2880,-92 2880,-86 2880,-86 2880,-74 2880,-74 2880,-68 2886,-62 2892,-62 2892,-62 2922,-62 2922,-62 2928,-62 2934,-68 2934,-74 2934,-74 2934,-86 2934,-86 2934,-92 2928,-98 2922,-98\"/>\n<text text-anchor=\"middle\" x=\"2907\" y=\"-76.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">out</text>\n</a>\n</g>\n</g>\n<!-- layer3_residual_res2_act&#45;&gt;layer3_residual_out -->\n<g id=\"edge33\" class=\"edge\">\n<title>layer3_residual_res2_act&#45;&gt;layer3_residual_out</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2844.003,-73.0003C2852.0277,-73.892 2860.9665,-74.8852 2869.5309,-75.8368\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2869.3796,-79.3414 2879.705,-76.9672 2870.1527,-72.3842 2869.3796,-79.3414\"/>\n</g>\n<!-- layer3_residual_out&#45;&gt;layer3_residual_add -->\n<g id=\"edge35\" class=\"edge\">\n<title>layer3_residual_out&#45;&gt;layer3_residual_add</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2934.003,-86.0007C2942.1158,-87.8035 2951.1631,-89.814 2959.8131,-91.7362\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2959.1839,-95.1817 2969.705,-93.9345 2960.7024,-88.3484 2959.1839,-95.1817\"/>\n</g>\n<!-- pool -->\n<g id=\"node34\" class=\"node\">\n<title>pool</title>\n<g id=\"a_node34\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.pooling.MaxPool2d&#39;&gt; {&#39;kernel_size&#39;: 4}\">\n<path fill=\"#8dd3c7\" stroke=\"#000000\" d=\"M3102,-118C3102,-118 3072,-118 3072,-118 3066,-118 3060,-112 3060,-106 3060,-106 3060,-94 3060,-94 3060,-88 3066,-82 3072,-82 3072,-82 3102,-82 3102,-82 3108,-82 3114,-88 3114,-94 3114,-94 3114,-106 3114,-106 3114,-112 3108,-118 3102,-118\"/>\n<text text-anchor=\"middle\" x=\"3087\" y=\"-96.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">pool</text>\n</a>\n</g>\n</g>\n<!-- layer3_residual_add&#45;&gt;pool -->\n<g id=\"edge36\" class=\"edge\">\n<title>layer3_residual_add&#45;&gt;pool</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M3024.003,-100C3032.0277,-100 3040.9665,-100 3049.5309,-100\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"3049.7051,-103.5001 3059.705,-100 3049.705,-96.5001 3049.7051,-103.5001\"/>\n</g>\n<!-- classifier_flatten -->\n<g id=\"node35\" class=\"node\">\n<title>classifier_flatten</title>\n<g id=\"a_node35\"><a xlink:title=\"&lt;class &#39;__main__.Flatten&#39;&gt; {}\">\n<path fill=\"#b3de69\" stroke=\"#000000\" d=\"M3192,-118C3192,-118 3162,-118 3162,-118 3156,-118 3150,-112 3150,-106 3150,-106 3150,-94 3150,-94 3150,-88 3156,-82 3162,-82 3162,-82 3192,-82 3192,-82 3198,-82 3204,-88 3204,-94 3204,-94 3204,-106 3204,-106 3204,-112 3198,-118 3192,-118\"/>\n<text text-anchor=\"middle\" x=\"3177\" y=\"-96.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">flatten</text>\n</a>\n</g>\n</g>\n<!-- pool&#45;&gt;classifier_flatten -->\n<g id=\"edge37\" class=\"edge\">\n<title>pool&#45;&gt;classifier_flatten</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M3114.003,-100C3122.0277,-100 3130.9665,-100 3139.5309,-100\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"3139.7051,-103.5001 3149.705,-100 3139.705,-96.5001 3139.7051,-103.5001\"/>\n</g>\n<!-- classifier_conv -->\n<g id=\"node36\" class=\"node\">\n<title>classifier_conv</title>\n<g id=\"a_node36\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.linear.Linear&#39;&gt; {&#39;in_features&#39;: 512, &#39;out_features&#39;: 10, &#39;bias&#39;: False}\">\n<path fill=\"#fccde5\" stroke=\"#000000\" d=\"M3282,-118C3282,-118 3252,-118 3252,-118 3246,-118 3240,-112 3240,-106 3240,-106 3240,-94 3240,-94 3240,-88 3246,-82 3252,-82 3252,-82 3282,-82 3282,-82 3288,-82 3294,-88 3294,-94 3294,-94 3294,-106 3294,-106 3294,-112 3288,-118 3282,-118\"/>\n<text text-anchor=\"middle\" x=\"3267\" y=\"-96.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">conv</text>\n</a>\n</g>\n</g>\n<!-- classifier_flatten&#45;&gt;classifier_conv -->\n<g id=\"edge38\" class=\"edge\">\n<title>classifier_flatten&#45;&gt;classifier_conv</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M3204.003,-100C3212.0277,-100 3220.9665,-100 3229.5309,-100\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"3229.7051,-103.5001 3239.705,-100 3229.705,-96.5001 3229.7051,-103.5001\"/>\n</g>\n<!-- classifier_scale -->\n<g id=\"node37\" class=\"node\">\n<title>classifier_scale</title>\n<g id=\"a_node37\"><a xlink:title=\"&lt;class &#39;__main__.Mul&#39;&gt; {&#39;weight&#39;: 0.125}\">\n<path fill=\"#bc80bd\" stroke=\"#000000\" d=\"M3372,-118C3372,-118 3342,-118 3342,-118 3336,-118 3330,-112 3330,-106 3330,-106 3330,-94 3330,-94 3330,-88 3336,-82 3342,-82 3342,-82 3372,-82 3372,-82 3378,-82 3384,-88 3384,-94 3384,-94 3384,-106 3384,-106 3384,-112 3378,-118 3372,-118\"/>\n<text text-anchor=\"middle\" x=\"3357\" y=\"-96.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">scale</text>\n</a>\n</g>\n</g>\n<!-- classifier_conv&#45;&gt;classifier_scale -->\n<g id=\"edge39\" class=\"edge\">\n<title>classifier_conv&#45;&gt;classifier_scale</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M3294.003,-100C3302.0277,-100 3310.9665,-100 3319.5309,-100\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"3319.7051,-103.5001 3329.705,-100 3319.705,-96.5001 3319.7051,-103.5001\"/>\n</g>\n<!-- logits -->\n<g id=\"node38\" class=\"node\">\n<title>logits</title>\n<g id=\"a_node38\"><a xlink:title=\"&lt;class &#39;__main__.Identity&#39;&gt; {}\">\n<path fill=\"#80b1d3\" stroke=\"#000000\" d=\"M3462,-118C3462,-118 3432,-118 3432,-118 3426,-118 3420,-112 3420,-106 3420,-106 3420,-94 3420,-94 3420,-88 3426,-82 3432,-82 3432,-82 3462,-82 3462,-82 3468,-82 3474,-88 3474,-94 3474,-94 3474,-106 3474,-106 3474,-112 3468,-118 3462,-118\"/>\n<text text-anchor=\"middle\" x=\"3447\" y=\"-96.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">logits</text>\n</a>\n</g>\n</g>\n<!-- classifier_scale&#45;&gt;logits -->\n<g id=\"edge40\" class=\"edge\">\n<title>classifier_scale&#45;&gt;logits</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M3384.003,-100C3392.0277,-100 3400.9665,-100 3409.5309,-100\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"3409.7051,-103.5001 3419.705,-100 3409.705,-96.5001 3409.7051,-103.5001\"/>\n</g>\n<!-- input -->\n<g id=\"node39\" class=\"node\">\n<title>input</title>\n<path fill=\"#ffffff\" stroke=\"#000000\" d=\"M42,-88C42,-88 12,-88 12,-88 6,-88 0,-82 0,-76 0,-76 0,-64 0,-64 0,-58 6,-52 12,-52 12,-52 42,-52 42,-52 48,-52 54,-58 54,-64 54,-64 54,-76 54,-76 54,-82 48,-88 42,-88\"/>\n<text text-anchor=\"middle\" x=\"27\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">input</text>\n</g>\n<!-- input&#45;&gt;prep_conv -->\n<g id=\"edge1\" class=\"edge\">\n<title>input&#45;&gt;prep_conv</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M54.003,-70C62.0277,-70 70.9665,-70 79.5309,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"79.7051,-73.5001 89.705,-70 79.705,-66.5001 79.7051,-73.5001\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cH7GrPu5dWna",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "outputId": "ced7fdb2-c9b7-45a6-882b-d5e53a44f6f8"
      },
      "source": [
        "epochs, batch_size = 23, 512\n",
        "transforms = (Crop(32, 32), FlipLR(), Cutout(8, 8))\n",
        "opt_params = {'lr': lr_schedule([0, epochs/5, epochs], [0.0, 0.4, 0.0], batch_size), 'weight_decay': Const(5e-4*batch_size), 'momentum': Const(0.9)}\n",
        "\n",
        "logs = Table(report=every(epochs,'epoch'))\n",
        "for run in range(N_RUNS):\n",
        "    model = build_model(celu_net, label_smoothing_loss(0.2))\n",
        "    state, timer = {MODEL: model, OPTS: [SGD(trainable_params(model).values(), opt_params)]}, Timer(torch.cuda.synchronize)\n",
        "    for epoch in range(epochs):\n",
        "        logs.append(union({'run': run+1, 'epoch': epoch+1}, train_epoch(state, timer, train_batches(batch_size, transforms), valid_batches(batch_size))))\n",
        "summary(logs)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         run        epoch   train time   train loss    train acc   valid time   valid loss    valid acc   total time\n",
            "           1           23      10.6558       0.9249       0.9812       0.6388       0.9866       0.9422     244.9611\n",
            "           2           23      10.6488       0.9257       0.9811       0.6407       0.9828       0.9437     244.8438\n",
            "           3           23      10.6403       0.9246       0.9817       0.6380       0.9848       0.9436     244.3678\n",
            "           4           23      10.6499       0.9235       0.9823       0.6392       0.9835       0.9440     244.8399\n",
            "           5           23      10.6436       0.9237       0.9824       0.6436       0.9850       0.9399     244.6211\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>min</th>\n",
              "      <th>max</th>\n",
              "      <th>std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>valid_acc</th>\n",
              "      <td>5</td>\n",
              "      <td>0.94268</td>\n",
              "      <td>0.9399</td>\n",
              "      <td>0.944</td>\n",
              "      <td>0.001702</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           count     mean     min    max       std\n",
              "valid_acc      5  0.94268  0.9399  0.944  0.001702"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uu5xtfMc1gK",
        "colab_type": "text"
      },
      "source": [
        "This gives an impressive improvement to 94.3% test accuracy (mean of 50 runs) allowing a further 3 epoch reduction in training and a 20 epoch time of 52s for 94.1% accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HoNA_JwSkC_",
        "colab_type": "text"
      },
      "source": [
        "### Ghost batch norm (46s)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1F8M7LfV8dE",
        "colab_type": "text"
      },
      "source": [
        "Batch norm seems to work best with batch size of around 32. The reasons presumably have to do with noise in the batch statistics and specifically a balance between a beneficial regularising effect at intermediate batch sizes and an excess of noise at small batches.\n",
        "\n",
        "Our batches are of size 512 and we can't afford to reduce them without taking a serious hit on training times, but we can apply batch norm separately to subsets of a training batch. This technique, known as 'ghost' batch norm, is usually used in a distributed setting but is just as useful when using large batches on a single node. It isn't supported directly in PyTorch but we can roll our own easily enough."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwmZ3fJZT6sP",
        "colab_type": "code",
        "outputId": "06dbebf3-b808-4dbb-eafc-7e92328dc92f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "ghost_bn_net = network(conv_pool_block=conv_pool_block_pre, types={\n",
        "    nn.ReLU: partial(nn.CELU, 0.075), \n",
        "    BatchNorm: partial(GhostBatchNorm, num_splits=16)\n",
        "})\n",
        "show(ghost_bn_net)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<__main__.DotGraph at 0x7f7f20b26ef0>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: G Pages: 1 -->\n<svg width=\"1080pt\" height=\"64pt\"\n viewBox=\"0.00 0.00 1080.00 64.20\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(.3102 .3102) rotate(0) translate(4 203)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-203 3478,-203 3478,4 -4,4\"/>\n<g id=\"clust1\" class=\"cluster\">\n<title>cluster_prep</title>\n<path fill=\"#777777\" fill-opacity=\"0.266667\" stroke=\"#000000\" d=\"M94,-44C94,-44 320,-44 320,-44 326,-44 332,-50 332,-56 332,-56 332,-107 332,-107 332,-113 326,-119 320,-119 320,-119 94,-119 94,-119 88,-119 82,-113 82,-107 82,-107 82,-56 82,-56 82,-50 88,-44 94,-44\"/>\n<text text-anchor=\"middle\" x=\"207\" y=\"-103.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">prep</text>\n</g>\n<g id=\"clust2\" class=\"cluster\">\n<title>cluster_layer1</title>\n<path fill=\"#777777\" fill-opacity=\"0.266667\" stroke=\"#000000\" d=\"M364,-8C364,-8 1498,-8 1498,-8 1504,-8 1510,-14 1510,-20 1510,-20 1510,-159 1510,-159 1510,-165 1504,-171 1498,-171 1498,-171 364,-171 364,-171 358,-171 352,-165 352,-159 352,-159 352,-20 352,-20 352,-14 358,-8 364,-8\"/>\n<text text-anchor=\"middle\" x=\"931\" y=\"-155.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">layer1</text>\n</g>\n<g id=\"clust3\" class=\"cluster\">\n<title>cluster_layer1_residual</title>\n<path fill=\"#777777\" fill-opacity=\"0.266667\" stroke=\"#000000\" d=\"M724,-16C724,-16 1490,-16 1490,-16 1496,-16 1502,-22 1502,-28 1502,-28 1502,-128 1502,-128 1502,-134 1496,-140 1490,-140 1490,-140 724,-140 724,-140 718,-140 712,-134 712,-128 712,-128 712,-28 712,-28 712,-22 718,-16 724,-16\"/>\n<text text-anchor=\"middle\" x=\"1107\" y=\"-124.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">residual</text>\n</g>\n<g id=\"clust4\" class=\"cluster\">\n<title>cluster_layer1_residual_res1</title>\n<path fill=\"#777777\" fill-opacity=\"0.266667\" stroke=\"#000000\" d=\"M814,-24C814,-24 1040,-24 1040,-24 1046,-24 1052,-30 1052,-36 1052,-36 1052,-87 1052,-87 1052,-93 1046,-99 1040,-99 1040,-99 814,-99 814,-99 808,-99 802,-93 802,-87 802,-87 802,-36 802,-36 802,-30 808,-24 814,-24\"/>\n<text text-anchor=\"middle\" x=\"927\" y=\"-83.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">res1</text>\n</g>\n<g id=\"clust5\" class=\"cluster\">\n<title>cluster_layer1_residual_res2</title>\n<path fill=\"#777777\" fill-opacity=\"0.266667\" stroke=\"#000000\" d=\"M1084,-24C1084,-24 1310,-24 1310,-24 1316,-24 1322,-30 1322,-36 1322,-36 1322,-87 1322,-87 1322,-93 1316,-99 1310,-99 1310,-99 1084,-99 1084,-99 1078,-99 1072,-93 1072,-87 1072,-87 1072,-36 1072,-36 1072,-30 1078,-24 1084,-24\"/>\n<text text-anchor=\"middle\" x=\"1197\" y=\"-83.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">res2</text>\n</g>\n<g id=\"clust6\" class=\"cluster\">\n<title>cluster_layer2</title>\n<path fill=\"#777777\" fill-opacity=\"0.266667\" stroke=\"#000000\" d=\"M1534,-54C1534,-54 1850,-54 1850,-54 1856,-54 1862,-60 1862,-66 1862,-66 1862,-117 1862,-117 1862,-123 1856,-129 1850,-129 1850,-129 1534,-129 1534,-129 1528,-129 1522,-123 1522,-117 1522,-117 1522,-66 1522,-66 1522,-60 1528,-54 1534,-54\"/>\n<text text-anchor=\"middle\" x=\"1692\" y=\"-113.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">layer2</text>\n</g>\n<g id=\"clust7\" class=\"cluster\">\n<title>cluster_layer3</title>\n<path fill=\"#777777\" fill-opacity=\"0.266667\" stroke=\"#000000\" d=\"M1894,-28C1894,-28 3028,-28 3028,-28 3034,-28 3040,-34 3040,-40 3040,-40 3040,-179 3040,-179 3040,-185 3034,-191 3028,-191 3028,-191 1894,-191 1894,-191 1888,-191 1882,-185 1882,-179 1882,-179 1882,-40 1882,-40 1882,-34 1888,-28 1894,-28\"/>\n<text text-anchor=\"middle\" x=\"2461\" y=\"-175.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">layer3</text>\n</g>\n<g id=\"clust8\" class=\"cluster\">\n<title>cluster_layer3_residual</title>\n<path fill=\"#777777\" fill-opacity=\"0.266667\" stroke=\"#000000\" d=\"M2254,-36C2254,-36 3020,-36 3020,-36 3026,-36 3032,-42 3032,-48 3032,-48 3032,-148 3032,-148 3032,-154 3026,-160 3020,-160 3020,-160 2254,-160 2254,-160 2248,-160 2242,-154 2242,-148 2242,-148 2242,-48 2242,-48 2242,-42 2248,-36 2254,-36\"/>\n<text text-anchor=\"middle\" x=\"2637\" y=\"-144.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">residual</text>\n</g>\n<g id=\"clust9\" class=\"cluster\">\n<title>cluster_layer3_residual_res1</title>\n<path fill=\"#777777\" fill-opacity=\"0.266667\" stroke=\"#000000\" d=\"M2344,-44C2344,-44 2570,-44 2570,-44 2576,-44 2582,-50 2582,-56 2582,-56 2582,-107 2582,-107 2582,-113 2576,-119 2570,-119 2570,-119 2344,-119 2344,-119 2338,-119 2332,-113 2332,-107 2332,-107 2332,-56 2332,-56 2332,-50 2338,-44 2344,-44\"/>\n<text text-anchor=\"middle\" x=\"2457\" y=\"-103.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">res1</text>\n</g>\n<g id=\"clust10\" class=\"cluster\">\n<title>cluster_layer3_residual_res2</title>\n<path fill=\"#777777\" fill-opacity=\"0.266667\" stroke=\"#000000\" d=\"M2614,-44C2614,-44 2840,-44 2840,-44 2846,-44 2852,-50 2852,-56 2852,-56 2852,-107 2852,-107 2852,-113 2846,-119 2840,-119 2840,-119 2614,-119 2614,-119 2608,-119 2602,-113 2602,-107 2602,-107 2602,-56 2602,-56 2602,-50 2608,-44 2614,-44\"/>\n<text text-anchor=\"middle\" x=\"2727\" y=\"-103.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">res2</text>\n</g>\n<g id=\"clust11\" class=\"cluster\">\n<title>cluster_classifier</title>\n<path fill=\"#777777\" fill-opacity=\"0.266667\" stroke=\"#000000\" d=\"M3154,-74C3154,-74 3380,-74 3380,-74 3386,-74 3392,-80 3392,-86 3392,-86 3392,-137 3392,-137 3392,-143 3386,-149 3380,-149 3380,-149 3154,-149 3154,-149 3148,-149 3142,-143 3142,-137 3142,-137 3142,-86 3142,-86 3142,-80 3148,-74 3154,-74\"/>\n<text text-anchor=\"middle\" x=\"3267\" y=\"-133.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">classifier</text>\n</g>\n<!-- prep_conv -->\n<g id=\"node1\" class=\"node\">\n<title>prep_conv</title>\n<g id=\"a_node1\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.conv.Conv2d&#39;&gt; {&#39;in_channels&#39;: 3, &#39;out_channels&#39;: 64, &#39;kernel_size&#39;: (3, 3), &#39;stride&#39;: (1, 1), &#39;padding&#39;: (1, 1), &#39;bias&#39;: False}\">\n<path fill=\"#bebada\" stroke=\"#000000\" d=\"M132,-88C132,-88 102,-88 102,-88 96,-88 90,-82 90,-76 90,-76 90,-64 90,-64 90,-58 96,-52 102,-52 102,-52 132,-52 132,-52 138,-52 144,-58 144,-64 144,-64 144,-76 144,-76 144,-82 138,-88 132,-88\"/>\n<text text-anchor=\"middle\" x=\"117\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">conv</text>\n</a>\n</g>\n</g>\n<!-- prep_norm -->\n<g id=\"node2\" class=\"node\">\n<title>prep_norm</title>\n<g id=\"a_node2\"><a xlink:title=\"functools.partial(&lt;class &#39;__main__.GhostBatchNorm&#39;&gt;, num_splits=16) {&#39;num_features&#39;: 64}\">\n<path fill=\"#4dddf8\" stroke=\"#000000\" d=\"M222,-88C222,-88 192,-88 192,-88 186,-88 180,-82 180,-76 180,-76 180,-64 180,-64 180,-58 186,-52 192,-52 192,-52 222,-52 222,-52 228,-52 234,-58 234,-64 234,-64 234,-76 234,-76 234,-82 228,-88 222,-88\"/>\n<text text-anchor=\"middle\" x=\"207\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">norm</text>\n</a>\n</g>\n</g>\n<!-- prep_conv&#45;&gt;prep_norm -->\n<g id=\"edge2\" class=\"edge\">\n<title>prep_conv&#45;&gt;prep_norm</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M144.003,-70C152.0277,-70 160.9665,-70 169.5309,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"169.7051,-73.5001 179.705,-70 169.705,-66.5001 169.7051,-73.5001\"/>\n</g>\n<!-- prep_act -->\n<g id=\"node3\" class=\"node\">\n<title>prep_act</title>\n<g id=\"a_node3\"><a xlink:title=\"functools.partial(&lt;class &#39;torch.nn.modules.activation.CELU&#39;&gt;, 0.075) {}\">\n<path fill=\"#e66493\" stroke=\"#000000\" d=\"M312,-88C312,-88 282,-88 282,-88 276,-88 270,-82 270,-76 270,-76 270,-64 270,-64 270,-58 276,-52 282,-52 282,-52 312,-52 312,-52 318,-52 324,-58 324,-64 324,-64 324,-76 324,-76 324,-82 318,-88 312,-88\"/>\n<text text-anchor=\"middle\" x=\"297\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">act</text>\n</a>\n</g>\n</g>\n<!-- prep_norm&#45;&gt;prep_act -->\n<g id=\"edge3\" class=\"edge\">\n<title>prep_norm&#45;&gt;prep_act</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M234.003,-70C242.0277,-70 250.9665,-70 259.5309,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"259.7051,-73.5001 269.705,-70 259.705,-66.5001 259.7051,-73.5001\"/>\n</g>\n<!-- layer1_conv -->\n<g id=\"node4\" class=\"node\">\n<title>layer1_conv</title>\n<g id=\"a_node4\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.conv.Conv2d&#39;&gt; {&#39;in_channels&#39;: 64, &#39;out_channels&#39;: 128, &#39;kernel_size&#39;: (3, 3), &#39;stride&#39;: (1, 1), &#39;padding&#39;: (1, 1), &#39;bias&#39;: False}\">\n<path fill=\"#bebada\" stroke=\"#000000\" d=\"M402,-88C402,-88 372,-88 372,-88 366,-88 360,-82 360,-76 360,-76 360,-64 360,-64 360,-58 366,-52 372,-52 372,-52 402,-52 402,-52 408,-52 414,-58 414,-64 414,-64 414,-76 414,-76 414,-82 408,-88 402,-88\"/>\n<text text-anchor=\"middle\" x=\"387\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">conv</text>\n</a>\n</g>\n</g>\n<!-- prep_act&#45;&gt;layer1_conv -->\n<g id=\"edge4\" class=\"edge\">\n<title>prep_act&#45;&gt;layer1_conv</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M324.003,-70C332.0277,-70 340.9665,-70 349.5309,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"349.7051,-73.5001 359.705,-70 349.705,-66.5001 349.7051,-73.5001\"/>\n</g>\n<!-- layer1_pool -->\n<g id=\"node5\" class=\"node\">\n<title>layer1_pool</title>\n<g id=\"a_node5\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.pooling.MaxPool2d&#39;&gt; {&#39;kernel_size&#39;: 2}\">\n<path fill=\"#8dd3c7\" stroke=\"#000000\" d=\"M492,-88C492,-88 462,-88 462,-88 456,-88 450,-82 450,-76 450,-76 450,-64 450,-64 450,-58 456,-52 462,-52 462,-52 492,-52 492,-52 498,-52 504,-58 504,-64 504,-64 504,-76 504,-76 504,-82 498,-88 492,-88\"/>\n<text text-anchor=\"middle\" x=\"477\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">pool</text>\n</a>\n</g>\n</g>\n<!-- layer1_conv&#45;&gt;layer1_pool -->\n<g id=\"edge5\" class=\"edge\">\n<title>layer1_conv&#45;&gt;layer1_pool</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M414.003,-70C422.0277,-70 430.9665,-70 439.5309,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"439.7051,-73.5001 449.705,-70 439.705,-66.5001 439.7051,-73.5001\"/>\n</g>\n<!-- layer1_norm -->\n<g id=\"node6\" class=\"node\">\n<title>layer1_norm</title>\n<g id=\"a_node6\"><a xlink:title=\"functools.partial(&lt;class &#39;__main__.GhostBatchNorm&#39;&gt;, num_splits=16) {&#39;num_features&#39;: 128}\">\n<path fill=\"#4dddf8\" stroke=\"#000000\" d=\"M582,-88C582,-88 552,-88 552,-88 546,-88 540,-82 540,-76 540,-76 540,-64 540,-64 540,-58 546,-52 552,-52 552,-52 582,-52 582,-52 588,-52 594,-58 594,-64 594,-64 594,-76 594,-76 594,-82 588,-88 582,-88\"/>\n<text text-anchor=\"middle\" x=\"567\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">norm</text>\n</a>\n</g>\n</g>\n<!-- layer1_pool&#45;&gt;layer1_norm -->\n<g id=\"edge6\" class=\"edge\">\n<title>layer1_pool&#45;&gt;layer1_norm</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M504.003,-70C512.0277,-70 520.9665,-70 529.5309,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"529.7051,-73.5001 539.705,-70 529.705,-66.5001 529.7051,-73.5001\"/>\n</g>\n<!-- layer1_act -->\n<g id=\"node7\" class=\"node\">\n<title>layer1_act</title>\n<g id=\"a_node7\"><a xlink:title=\"functools.partial(&lt;class &#39;torch.nn.modules.activation.CELU&#39;&gt;, 0.075) {}\">\n<path fill=\"#e66493\" stroke=\"#000000\" d=\"M672,-88C672,-88 642,-88 642,-88 636,-88 630,-82 630,-76 630,-76 630,-64 630,-64 630,-58 636,-52 642,-52 642,-52 672,-52 672,-52 678,-52 684,-58 684,-64 684,-64 684,-76 684,-76 684,-82 678,-88 672,-88\"/>\n<text text-anchor=\"middle\" x=\"657\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">act</text>\n</a>\n</g>\n</g>\n<!-- layer1_norm&#45;&gt;layer1_act -->\n<g id=\"edge7\" class=\"edge\">\n<title>layer1_norm&#45;&gt;layer1_act</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M594.003,-70C602.0277,-70 610.9665,-70 619.5309,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"619.7051,-73.5001 629.705,-70 619.705,-66.5001 619.7051,-73.5001\"/>\n</g>\n<!-- layer1_residual_in -->\n<g id=\"node8\" class=\"node\">\n<title>layer1_residual_in</title>\n<g id=\"a_node8\"><a xlink:title=\"&lt;class &#39;__main__.Identity&#39;&gt; {}\">\n<path fill=\"#80b1d3\" stroke=\"#000000\" d=\"M762,-88C762,-88 732,-88 732,-88 726,-88 720,-82 720,-76 720,-76 720,-64 720,-64 720,-58 726,-52 732,-52 732,-52 762,-52 762,-52 768,-52 774,-58 774,-64 774,-64 774,-76 774,-76 774,-82 768,-88 762,-88\"/>\n<text text-anchor=\"middle\" x=\"747\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">in</text>\n</a>\n</g>\n</g>\n<!-- layer1_act&#45;&gt;layer1_residual_in -->\n<g id=\"edge8\" class=\"edge\">\n<title>layer1_act&#45;&gt;layer1_residual_in</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M684.003,-70C692.0277,-70 700.9665,-70 709.5309,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"709.7051,-73.5001 719.705,-70 709.705,-66.5001 709.7051,-73.5001\"/>\n</g>\n<!-- layer1_residual_res1_conv -->\n<g id=\"node9\" class=\"node\">\n<title>layer1_residual_res1_conv</title>\n<g id=\"a_node9\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.conv.Conv2d&#39;&gt; {&#39;in_channels&#39;: 128, &#39;out_channels&#39;: 128, &#39;kernel_size&#39;: (3, 3), &#39;stride&#39;: (1, 1), &#39;padding&#39;: (1, 1), &#39;bias&#39;: False}\">\n<path fill=\"#bebada\" stroke=\"#000000\" d=\"M852,-68C852,-68 822,-68 822,-68 816,-68 810,-62 810,-56 810,-56 810,-44 810,-44 810,-38 816,-32 822,-32 822,-32 852,-32 852,-32 858,-32 864,-38 864,-44 864,-44 864,-56 864,-56 864,-62 858,-68 852,-68\"/>\n<text text-anchor=\"middle\" x=\"837\" y=\"-46.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">conv</text>\n</a>\n</g>\n</g>\n<!-- layer1_residual_in&#45;&gt;layer1_residual_res1_conv -->\n<g id=\"edge9\" class=\"edge\">\n<title>layer1_residual_in&#45;&gt;layer1_residual_res1_conv</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M774.003,-63.9993C782.1158,-62.1965 791.1631,-60.186 799.8131,-58.2638\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"800.7024,-61.6516 809.705,-56.0655 799.1839,-54.8183 800.7024,-61.6516\"/>\n</g>\n<!-- layer1_residual_add -->\n<g id=\"node16\" class=\"node\">\n<title>layer1_residual_add</title>\n<g id=\"a_node16\"><a xlink:title=\"&lt;class &#39;__main__.Add&#39;&gt; {}\">\n<path fill=\"#fdb462\" stroke=\"#000000\" d=\"M1482,-98C1482,-98 1452,-98 1452,-98 1446,-98 1440,-92 1440,-86 1440,-86 1440,-74 1440,-74 1440,-68 1446,-62 1452,-62 1452,-62 1482,-62 1482,-62 1488,-62 1494,-68 1494,-74 1494,-74 1494,-86 1494,-86 1494,-92 1488,-98 1482,-98\"/>\n<text text-anchor=\"middle\" x=\"1467\" y=\"-76.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">add</text>\n</a>\n</g>\n</g>\n<!-- layer1_residual_in&#45;&gt;layer1_residual_add -->\n<g id=\"edge16\" class=\"edge\">\n<title>layer1_residual_in&#45;&gt;layer1_residual_add</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M771.2203,-88.104C780.3892,-93.9663 791.2234,-99.7818 802,-103 855.2752,-118.9095 871.4,-108 927,-108 927,-108 927,-108 1287,-108 1336.7971,-108 1393.4324,-97.4074 1429.6554,-89.2525\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1430.8023,-92.5799 1439.7594,-86.9214 1429.2285,-85.7591 1430.8023,-92.5799\"/>\n</g>\n<!-- layer1_residual_res1_norm -->\n<g id=\"node10\" class=\"node\">\n<title>layer1_residual_res1_norm</title>\n<g id=\"a_node10\"><a xlink:title=\"functools.partial(&lt;class &#39;__main__.GhostBatchNorm&#39;&gt;, num_splits=16) {&#39;num_features&#39;: 128}\">\n<path fill=\"#4dddf8\" stroke=\"#000000\" d=\"M942,-68C942,-68 912,-68 912,-68 906,-68 900,-62 900,-56 900,-56 900,-44 900,-44 900,-38 906,-32 912,-32 912,-32 942,-32 942,-32 948,-32 954,-38 954,-44 954,-44 954,-56 954,-56 954,-62 948,-68 942,-68\"/>\n<text text-anchor=\"middle\" x=\"927\" y=\"-46.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">norm</text>\n</a>\n</g>\n</g>\n<!-- layer1_residual_res1_conv&#45;&gt;layer1_residual_res1_norm -->\n<g id=\"edge10\" class=\"edge\">\n<title>layer1_residual_res1_conv&#45;&gt;layer1_residual_res1_norm</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M864.003,-50C872.0277,-50 880.9665,-50 889.5309,-50\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"889.7051,-53.5001 899.705,-50 889.705,-46.5001 889.7051,-53.5001\"/>\n</g>\n<!-- layer1_residual_res1_act -->\n<g id=\"node11\" class=\"node\">\n<title>layer1_residual_res1_act</title>\n<g id=\"a_node11\"><a xlink:title=\"functools.partial(&lt;class &#39;torch.nn.modules.activation.CELU&#39;&gt;, 0.075) {}\">\n<path fill=\"#e66493\" stroke=\"#000000\" d=\"M1032,-68C1032,-68 1002,-68 1002,-68 996,-68 990,-62 990,-56 990,-56 990,-44 990,-44 990,-38 996,-32 1002,-32 1002,-32 1032,-32 1032,-32 1038,-32 1044,-38 1044,-44 1044,-44 1044,-56 1044,-56 1044,-62 1038,-68 1032,-68\"/>\n<text text-anchor=\"middle\" x=\"1017\" y=\"-46.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">act</text>\n</a>\n</g>\n</g>\n<!-- layer1_residual_res1_norm&#45;&gt;layer1_residual_res1_act -->\n<g id=\"edge11\" class=\"edge\">\n<title>layer1_residual_res1_norm&#45;&gt;layer1_residual_res1_act</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M954.003,-50C962.0277,-50 970.9665,-50 979.5309,-50\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"979.7051,-53.5001 989.705,-50 979.705,-46.5001 979.7051,-53.5001\"/>\n</g>\n<!-- layer1_residual_res2_conv -->\n<g id=\"node12\" class=\"node\">\n<title>layer1_residual_res2_conv</title>\n<g id=\"a_node12\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.conv.Conv2d&#39;&gt; {&#39;in_channels&#39;: 128, &#39;out_channels&#39;: 128, &#39;kernel_size&#39;: (3, 3), &#39;stride&#39;: (1, 1), &#39;padding&#39;: (1, 1), &#39;bias&#39;: False}\">\n<path fill=\"#bebada\" stroke=\"#000000\" d=\"M1122,-68C1122,-68 1092,-68 1092,-68 1086,-68 1080,-62 1080,-56 1080,-56 1080,-44 1080,-44 1080,-38 1086,-32 1092,-32 1092,-32 1122,-32 1122,-32 1128,-32 1134,-38 1134,-44 1134,-44 1134,-56 1134,-56 1134,-62 1128,-68 1122,-68\"/>\n<text text-anchor=\"middle\" x=\"1107\" y=\"-46.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">conv</text>\n</a>\n</g>\n</g>\n<!-- layer1_residual_res1_act&#45;&gt;layer1_residual_res2_conv -->\n<g id=\"edge12\" class=\"edge\">\n<title>layer1_residual_res1_act&#45;&gt;layer1_residual_res2_conv</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1044.003,-50C1052.0277,-50 1060.9665,-50 1069.5309,-50\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1069.7051,-53.5001 1079.705,-50 1069.705,-46.5001 1069.7051,-53.5001\"/>\n</g>\n<!-- layer1_residual_res2_norm -->\n<g id=\"node13\" class=\"node\">\n<title>layer1_residual_res2_norm</title>\n<g id=\"a_node13\"><a xlink:title=\"functools.partial(&lt;class &#39;__main__.GhostBatchNorm&#39;&gt;, num_splits=16) {&#39;num_features&#39;: 128}\">\n<path fill=\"#4dddf8\" stroke=\"#000000\" d=\"M1212,-68C1212,-68 1182,-68 1182,-68 1176,-68 1170,-62 1170,-56 1170,-56 1170,-44 1170,-44 1170,-38 1176,-32 1182,-32 1182,-32 1212,-32 1212,-32 1218,-32 1224,-38 1224,-44 1224,-44 1224,-56 1224,-56 1224,-62 1218,-68 1212,-68\"/>\n<text text-anchor=\"middle\" x=\"1197\" y=\"-46.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">norm</text>\n</a>\n</g>\n</g>\n<!-- layer1_residual_res2_conv&#45;&gt;layer1_residual_res2_norm -->\n<g id=\"edge13\" class=\"edge\">\n<title>layer1_residual_res2_conv&#45;&gt;layer1_residual_res2_norm</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1134.003,-50C1142.0277,-50 1150.9665,-50 1159.5309,-50\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1159.7051,-53.5001 1169.705,-50 1159.705,-46.5001 1159.7051,-53.5001\"/>\n</g>\n<!-- layer1_residual_res2_act -->\n<g id=\"node14\" class=\"node\">\n<title>layer1_residual_res2_act</title>\n<g id=\"a_node14\"><a xlink:title=\"functools.partial(&lt;class &#39;torch.nn.modules.activation.CELU&#39;&gt;, 0.075) {}\">\n<path fill=\"#e66493\" stroke=\"#000000\" d=\"M1302,-68C1302,-68 1272,-68 1272,-68 1266,-68 1260,-62 1260,-56 1260,-56 1260,-44 1260,-44 1260,-38 1266,-32 1272,-32 1272,-32 1302,-32 1302,-32 1308,-32 1314,-38 1314,-44 1314,-44 1314,-56 1314,-56 1314,-62 1308,-68 1302,-68\"/>\n<text text-anchor=\"middle\" x=\"1287\" y=\"-46.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">act</text>\n</a>\n</g>\n</g>\n<!-- layer1_residual_res2_norm&#45;&gt;layer1_residual_res2_act -->\n<g id=\"edge14\" class=\"edge\">\n<title>layer1_residual_res2_norm&#45;&gt;layer1_residual_res2_act</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1224.003,-50C1232.0277,-50 1240.9665,-50 1249.5309,-50\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1249.7051,-53.5001 1259.705,-50 1249.705,-46.5001 1249.7051,-53.5001\"/>\n</g>\n<!-- layer1_residual_out -->\n<g id=\"node15\" class=\"node\">\n<title>layer1_residual_out</title>\n<g id=\"a_node15\"><a xlink:title=\"&lt;class &#39;__main__.Identity&#39;&gt; {}\">\n<path fill=\"#80b1d3\" stroke=\"#000000\" d=\"M1392,-78C1392,-78 1362,-78 1362,-78 1356,-78 1350,-72 1350,-66 1350,-66 1350,-54 1350,-54 1350,-48 1356,-42 1362,-42 1362,-42 1392,-42 1392,-42 1398,-42 1404,-48 1404,-54 1404,-54 1404,-66 1404,-66 1404,-72 1398,-78 1392,-78\"/>\n<text text-anchor=\"middle\" x=\"1377\" y=\"-56.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">out</text>\n</a>\n</g>\n</g>\n<!-- layer1_residual_res2_act&#45;&gt;layer1_residual_out -->\n<g id=\"edge15\" class=\"edge\">\n<title>layer1_residual_res2_act&#45;&gt;layer1_residual_out</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1314.003,-53.0003C1322.0277,-53.892 1330.9665,-54.8852 1339.5309,-55.8368\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1339.3796,-59.3414 1349.705,-56.9672 1340.1527,-52.3842 1339.3796,-59.3414\"/>\n</g>\n<!-- layer1_residual_out&#45;&gt;layer1_residual_add -->\n<g id=\"edge17\" class=\"edge\">\n<title>layer1_residual_out&#45;&gt;layer1_residual_add</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1404.003,-66.0007C1412.1158,-67.8035 1421.1631,-69.814 1429.8131,-71.7362\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1429.1839,-75.1817 1439.705,-73.9345 1430.7024,-68.3484 1429.1839,-75.1817\"/>\n</g>\n<!-- layer2_conv -->\n<g id=\"node17\" class=\"node\">\n<title>layer2_conv</title>\n<g id=\"a_node17\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.conv.Conv2d&#39;&gt; {&#39;in_channels&#39;: 128, &#39;out_channels&#39;: 256, &#39;kernel_size&#39;: (3, 3), &#39;stride&#39;: (1, 1), &#39;padding&#39;: (1, 1), &#39;bias&#39;: False}\">\n<path fill=\"#bebada\" stroke=\"#000000\" d=\"M1572,-98C1572,-98 1542,-98 1542,-98 1536,-98 1530,-92 1530,-86 1530,-86 1530,-74 1530,-74 1530,-68 1536,-62 1542,-62 1542,-62 1572,-62 1572,-62 1578,-62 1584,-68 1584,-74 1584,-74 1584,-86 1584,-86 1584,-92 1578,-98 1572,-98\"/>\n<text text-anchor=\"middle\" x=\"1557\" y=\"-76.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">conv</text>\n</a>\n</g>\n</g>\n<!-- layer1_residual_add&#45;&gt;layer2_conv -->\n<g id=\"edge18\" class=\"edge\">\n<title>layer1_residual_add&#45;&gt;layer2_conv</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1494.003,-80C1502.0277,-80 1510.9665,-80 1519.5309,-80\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1519.7051,-83.5001 1529.705,-80 1519.705,-76.5001 1519.7051,-83.5001\"/>\n</g>\n<!-- layer2_pool -->\n<g id=\"node18\" class=\"node\">\n<title>layer2_pool</title>\n<g id=\"a_node18\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.pooling.MaxPool2d&#39;&gt; {&#39;kernel_size&#39;: 2}\">\n<path fill=\"#8dd3c7\" stroke=\"#000000\" d=\"M1662,-98C1662,-98 1632,-98 1632,-98 1626,-98 1620,-92 1620,-86 1620,-86 1620,-74 1620,-74 1620,-68 1626,-62 1632,-62 1632,-62 1662,-62 1662,-62 1668,-62 1674,-68 1674,-74 1674,-74 1674,-86 1674,-86 1674,-92 1668,-98 1662,-98\"/>\n<text text-anchor=\"middle\" x=\"1647\" y=\"-76.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">pool</text>\n</a>\n</g>\n</g>\n<!-- layer2_conv&#45;&gt;layer2_pool -->\n<g id=\"edge19\" class=\"edge\">\n<title>layer2_conv&#45;&gt;layer2_pool</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1584.003,-80C1592.0277,-80 1600.9665,-80 1609.5309,-80\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1609.7051,-83.5001 1619.705,-80 1609.705,-76.5001 1609.7051,-83.5001\"/>\n</g>\n<!-- layer2_norm -->\n<g id=\"node19\" class=\"node\">\n<title>layer2_norm</title>\n<g id=\"a_node19\"><a xlink:title=\"functools.partial(&lt;class &#39;__main__.GhostBatchNorm&#39;&gt;, num_splits=16) {&#39;num_features&#39;: 256}\">\n<path fill=\"#4dddf8\" stroke=\"#000000\" d=\"M1752,-98C1752,-98 1722,-98 1722,-98 1716,-98 1710,-92 1710,-86 1710,-86 1710,-74 1710,-74 1710,-68 1716,-62 1722,-62 1722,-62 1752,-62 1752,-62 1758,-62 1764,-68 1764,-74 1764,-74 1764,-86 1764,-86 1764,-92 1758,-98 1752,-98\"/>\n<text text-anchor=\"middle\" x=\"1737\" y=\"-76.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">norm</text>\n</a>\n</g>\n</g>\n<!-- layer2_pool&#45;&gt;layer2_norm -->\n<g id=\"edge20\" class=\"edge\">\n<title>layer2_pool&#45;&gt;layer2_norm</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1674.003,-80C1682.0277,-80 1690.9665,-80 1699.5309,-80\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1699.7051,-83.5001 1709.705,-80 1699.705,-76.5001 1699.7051,-83.5001\"/>\n</g>\n<!-- layer2_act -->\n<g id=\"node20\" class=\"node\">\n<title>layer2_act</title>\n<g id=\"a_node20\"><a xlink:title=\"functools.partial(&lt;class &#39;torch.nn.modules.activation.CELU&#39;&gt;, 0.075) {}\">\n<path fill=\"#e66493\" stroke=\"#000000\" d=\"M1842,-98C1842,-98 1812,-98 1812,-98 1806,-98 1800,-92 1800,-86 1800,-86 1800,-74 1800,-74 1800,-68 1806,-62 1812,-62 1812,-62 1842,-62 1842,-62 1848,-62 1854,-68 1854,-74 1854,-74 1854,-86 1854,-86 1854,-92 1848,-98 1842,-98\"/>\n<text text-anchor=\"middle\" x=\"1827\" y=\"-76.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">act</text>\n</a>\n</g>\n</g>\n<!-- layer2_norm&#45;&gt;layer2_act -->\n<g id=\"edge21\" class=\"edge\">\n<title>layer2_norm&#45;&gt;layer2_act</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1764.003,-80C1772.0277,-80 1780.9665,-80 1789.5309,-80\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1789.7051,-83.5001 1799.705,-80 1789.705,-76.5001 1789.7051,-83.5001\"/>\n</g>\n<!-- layer3_conv -->\n<g id=\"node21\" class=\"node\">\n<title>layer3_conv</title>\n<g id=\"a_node21\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.conv.Conv2d&#39;&gt; {&#39;in_channels&#39;: 256, &#39;out_channels&#39;: 512, &#39;kernel_size&#39;: (3, 3), &#39;stride&#39;: (1, 1), &#39;padding&#39;: (1, 1), &#39;bias&#39;: False}\">\n<path fill=\"#bebada\" stroke=\"#000000\" d=\"M1932,-98C1932,-98 1902,-98 1902,-98 1896,-98 1890,-92 1890,-86 1890,-86 1890,-74 1890,-74 1890,-68 1896,-62 1902,-62 1902,-62 1932,-62 1932,-62 1938,-62 1944,-68 1944,-74 1944,-74 1944,-86 1944,-86 1944,-92 1938,-98 1932,-98\"/>\n<text text-anchor=\"middle\" x=\"1917\" y=\"-76.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">conv</text>\n</a>\n</g>\n</g>\n<!-- layer2_act&#45;&gt;layer3_conv -->\n<g id=\"edge22\" class=\"edge\">\n<title>layer2_act&#45;&gt;layer3_conv</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1854.003,-80C1862.0277,-80 1870.9665,-80 1879.5309,-80\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1879.7051,-83.5001 1889.705,-80 1879.705,-76.5001 1879.7051,-83.5001\"/>\n</g>\n<!-- layer3_pool -->\n<g id=\"node22\" class=\"node\">\n<title>layer3_pool</title>\n<g id=\"a_node22\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.pooling.MaxPool2d&#39;&gt; {&#39;kernel_size&#39;: 2}\">\n<path fill=\"#8dd3c7\" stroke=\"#000000\" d=\"M2022,-98C2022,-98 1992,-98 1992,-98 1986,-98 1980,-92 1980,-86 1980,-86 1980,-74 1980,-74 1980,-68 1986,-62 1992,-62 1992,-62 2022,-62 2022,-62 2028,-62 2034,-68 2034,-74 2034,-74 2034,-86 2034,-86 2034,-92 2028,-98 2022,-98\"/>\n<text text-anchor=\"middle\" x=\"2007\" y=\"-76.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">pool</text>\n</a>\n</g>\n</g>\n<!-- layer3_conv&#45;&gt;layer3_pool -->\n<g id=\"edge23\" class=\"edge\">\n<title>layer3_conv&#45;&gt;layer3_pool</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1944.003,-80C1952.0277,-80 1960.9665,-80 1969.5309,-80\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1969.7051,-83.5001 1979.705,-80 1969.705,-76.5001 1969.7051,-83.5001\"/>\n</g>\n<!-- layer3_norm -->\n<g id=\"node23\" class=\"node\">\n<title>layer3_norm</title>\n<g id=\"a_node23\"><a xlink:title=\"functools.partial(&lt;class &#39;__main__.GhostBatchNorm&#39;&gt;, num_splits=16) {&#39;num_features&#39;: 512}\">\n<path fill=\"#4dddf8\" stroke=\"#000000\" d=\"M2112,-98C2112,-98 2082,-98 2082,-98 2076,-98 2070,-92 2070,-86 2070,-86 2070,-74 2070,-74 2070,-68 2076,-62 2082,-62 2082,-62 2112,-62 2112,-62 2118,-62 2124,-68 2124,-74 2124,-74 2124,-86 2124,-86 2124,-92 2118,-98 2112,-98\"/>\n<text text-anchor=\"middle\" x=\"2097\" y=\"-76.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">norm</text>\n</a>\n</g>\n</g>\n<!-- layer3_pool&#45;&gt;layer3_norm -->\n<g id=\"edge24\" class=\"edge\">\n<title>layer3_pool&#45;&gt;layer3_norm</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2034.003,-80C2042.0277,-80 2050.9665,-80 2059.5309,-80\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2059.7051,-83.5001 2069.705,-80 2059.705,-76.5001 2059.7051,-83.5001\"/>\n</g>\n<!-- layer3_act -->\n<g id=\"node24\" class=\"node\">\n<title>layer3_act</title>\n<g id=\"a_node24\"><a xlink:title=\"functools.partial(&lt;class &#39;torch.nn.modules.activation.CELU&#39;&gt;, 0.075) {}\">\n<path fill=\"#e66493\" stroke=\"#000000\" d=\"M2202,-98C2202,-98 2172,-98 2172,-98 2166,-98 2160,-92 2160,-86 2160,-86 2160,-74 2160,-74 2160,-68 2166,-62 2172,-62 2172,-62 2202,-62 2202,-62 2208,-62 2214,-68 2214,-74 2214,-74 2214,-86 2214,-86 2214,-92 2208,-98 2202,-98\"/>\n<text text-anchor=\"middle\" x=\"2187\" y=\"-76.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">act</text>\n</a>\n</g>\n</g>\n<!-- layer3_norm&#45;&gt;layer3_act -->\n<g id=\"edge25\" class=\"edge\">\n<title>layer3_norm&#45;&gt;layer3_act</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2124.003,-80C2132.0277,-80 2140.9665,-80 2149.5309,-80\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2149.7051,-83.5001 2159.705,-80 2149.705,-76.5001 2149.7051,-83.5001\"/>\n</g>\n<!-- layer3_residual_in -->\n<g id=\"node25\" class=\"node\">\n<title>layer3_residual_in</title>\n<g id=\"a_node25\"><a xlink:title=\"&lt;class &#39;__main__.Identity&#39;&gt; {}\">\n<path fill=\"#80b1d3\" stroke=\"#000000\" d=\"M2292,-98C2292,-98 2262,-98 2262,-98 2256,-98 2250,-92 2250,-86 2250,-86 2250,-74 2250,-74 2250,-68 2256,-62 2262,-62 2262,-62 2292,-62 2292,-62 2298,-62 2304,-68 2304,-74 2304,-74 2304,-86 2304,-86 2304,-92 2298,-98 2292,-98\"/>\n<text text-anchor=\"middle\" x=\"2277\" y=\"-76.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">in</text>\n</a>\n</g>\n</g>\n<!-- layer3_act&#45;&gt;layer3_residual_in -->\n<g id=\"edge26\" class=\"edge\">\n<title>layer3_act&#45;&gt;layer3_residual_in</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2214.003,-80C2222.0277,-80 2230.9665,-80 2239.5309,-80\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2239.7051,-83.5001 2249.705,-80 2239.705,-76.5001 2239.7051,-83.5001\"/>\n</g>\n<!-- layer3_residual_res1_conv -->\n<g id=\"node26\" class=\"node\">\n<title>layer3_residual_res1_conv</title>\n<g id=\"a_node26\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.conv.Conv2d&#39;&gt; {&#39;in_channels&#39;: 512, &#39;out_channels&#39;: 512, &#39;kernel_size&#39;: (3, 3), &#39;stride&#39;: (1, 1), &#39;padding&#39;: (1, 1), &#39;bias&#39;: False}\">\n<path fill=\"#bebada\" stroke=\"#000000\" d=\"M2382,-88C2382,-88 2352,-88 2352,-88 2346,-88 2340,-82 2340,-76 2340,-76 2340,-64 2340,-64 2340,-58 2346,-52 2352,-52 2352,-52 2382,-52 2382,-52 2388,-52 2394,-58 2394,-64 2394,-64 2394,-76 2394,-76 2394,-82 2388,-88 2382,-88\"/>\n<text text-anchor=\"middle\" x=\"2367\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">conv</text>\n</a>\n</g>\n</g>\n<!-- layer3_residual_in&#45;&gt;layer3_residual_res1_conv -->\n<g id=\"edge27\" class=\"edge\">\n<title>layer3_residual_in&#45;&gt;layer3_residual_res1_conv</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2304.003,-76.9997C2312.0277,-76.108 2320.9665,-75.1148 2329.5309,-74.1632\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2330.1527,-77.6158 2339.705,-73.0328 2329.3796,-70.6586 2330.1527,-77.6158\"/>\n</g>\n<!-- layer3_residual_add -->\n<g id=\"node33\" class=\"node\">\n<title>layer3_residual_add</title>\n<g id=\"a_node33\"><a xlink:title=\"&lt;class &#39;__main__.Add&#39;&gt; {}\">\n<path fill=\"#fdb462\" stroke=\"#000000\" d=\"M3012,-118C3012,-118 2982,-118 2982,-118 2976,-118 2970,-112 2970,-106 2970,-106 2970,-94 2970,-94 2970,-88 2976,-82 2982,-82 2982,-82 3012,-82 3012,-82 3018,-82 3024,-88 3024,-94 3024,-94 3024,-106 3024,-106 3024,-112 3018,-118 3012,-118\"/>\n<text text-anchor=\"middle\" x=\"2997\" y=\"-96.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">add</text>\n</a>\n</g>\n</g>\n<!-- layer3_residual_in&#45;&gt;layer3_residual_add -->\n<g id=\"edge34\" class=\"edge\">\n<title>layer3_residual_in&#45;&gt;layer3_residual_add</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2294.5351,-98.3771C2304.5459,-107.5711 2317.8909,-117.8215 2332,-123 2384.1953,-142.1574 2401.4,-128 2457,-128 2457,-128 2457,-128 2817,-128 2866.7971,-128 2923.4324,-117.4074 2959.6554,-109.2525\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2960.8023,-112.5799 2969.7594,-106.9214 2959.2285,-105.7591 2960.8023,-112.5799\"/>\n</g>\n<!-- layer3_residual_res1_norm -->\n<g id=\"node27\" class=\"node\">\n<title>layer3_residual_res1_norm</title>\n<g id=\"a_node27\"><a xlink:title=\"functools.partial(&lt;class &#39;__main__.GhostBatchNorm&#39;&gt;, num_splits=16) {&#39;num_features&#39;: 512}\">\n<path fill=\"#4dddf8\" stroke=\"#000000\" d=\"M2472,-88C2472,-88 2442,-88 2442,-88 2436,-88 2430,-82 2430,-76 2430,-76 2430,-64 2430,-64 2430,-58 2436,-52 2442,-52 2442,-52 2472,-52 2472,-52 2478,-52 2484,-58 2484,-64 2484,-64 2484,-76 2484,-76 2484,-82 2478,-88 2472,-88\"/>\n<text text-anchor=\"middle\" x=\"2457\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">norm</text>\n</a>\n</g>\n</g>\n<!-- layer3_residual_res1_conv&#45;&gt;layer3_residual_res1_norm -->\n<g id=\"edge28\" class=\"edge\">\n<title>layer3_residual_res1_conv&#45;&gt;layer3_residual_res1_norm</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2394.003,-70C2402.0277,-70 2410.9665,-70 2419.5309,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2419.7051,-73.5001 2429.705,-70 2419.705,-66.5001 2419.7051,-73.5001\"/>\n</g>\n<!-- layer3_residual_res1_act -->\n<g id=\"node28\" class=\"node\">\n<title>layer3_residual_res1_act</title>\n<g id=\"a_node28\"><a xlink:title=\"functools.partial(&lt;class &#39;torch.nn.modules.activation.CELU&#39;&gt;, 0.075) {}\">\n<path fill=\"#e66493\" stroke=\"#000000\" d=\"M2562,-88C2562,-88 2532,-88 2532,-88 2526,-88 2520,-82 2520,-76 2520,-76 2520,-64 2520,-64 2520,-58 2526,-52 2532,-52 2532,-52 2562,-52 2562,-52 2568,-52 2574,-58 2574,-64 2574,-64 2574,-76 2574,-76 2574,-82 2568,-88 2562,-88\"/>\n<text text-anchor=\"middle\" x=\"2547\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">act</text>\n</a>\n</g>\n</g>\n<!-- layer3_residual_res1_norm&#45;&gt;layer3_residual_res1_act -->\n<g id=\"edge29\" class=\"edge\">\n<title>layer3_residual_res1_norm&#45;&gt;layer3_residual_res1_act</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2484.003,-70C2492.0277,-70 2500.9665,-70 2509.5309,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2509.7051,-73.5001 2519.705,-70 2509.705,-66.5001 2509.7051,-73.5001\"/>\n</g>\n<!-- layer3_residual_res2_conv -->\n<g id=\"node29\" class=\"node\">\n<title>layer3_residual_res2_conv</title>\n<g id=\"a_node29\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.conv.Conv2d&#39;&gt; {&#39;in_channels&#39;: 512, &#39;out_channels&#39;: 512, &#39;kernel_size&#39;: (3, 3), &#39;stride&#39;: (1, 1), &#39;padding&#39;: (1, 1), &#39;bias&#39;: False}\">\n<path fill=\"#bebada\" stroke=\"#000000\" d=\"M2652,-88C2652,-88 2622,-88 2622,-88 2616,-88 2610,-82 2610,-76 2610,-76 2610,-64 2610,-64 2610,-58 2616,-52 2622,-52 2622,-52 2652,-52 2652,-52 2658,-52 2664,-58 2664,-64 2664,-64 2664,-76 2664,-76 2664,-82 2658,-88 2652,-88\"/>\n<text text-anchor=\"middle\" x=\"2637\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">conv</text>\n</a>\n</g>\n</g>\n<!-- layer3_residual_res1_act&#45;&gt;layer3_residual_res2_conv -->\n<g id=\"edge30\" class=\"edge\">\n<title>layer3_residual_res1_act&#45;&gt;layer3_residual_res2_conv</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2574.003,-70C2582.0277,-70 2590.9665,-70 2599.5309,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2599.7051,-73.5001 2609.705,-70 2599.705,-66.5001 2599.7051,-73.5001\"/>\n</g>\n<!-- layer3_residual_res2_norm -->\n<g id=\"node30\" class=\"node\">\n<title>layer3_residual_res2_norm</title>\n<g id=\"a_node30\"><a xlink:title=\"functools.partial(&lt;class &#39;__main__.GhostBatchNorm&#39;&gt;, num_splits=16) {&#39;num_features&#39;: 512}\">\n<path fill=\"#4dddf8\" stroke=\"#000000\" d=\"M2742,-88C2742,-88 2712,-88 2712,-88 2706,-88 2700,-82 2700,-76 2700,-76 2700,-64 2700,-64 2700,-58 2706,-52 2712,-52 2712,-52 2742,-52 2742,-52 2748,-52 2754,-58 2754,-64 2754,-64 2754,-76 2754,-76 2754,-82 2748,-88 2742,-88\"/>\n<text text-anchor=\"middle\" x=\"2727\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">norm</text>\n</a>\n</g>\n</g>\n<!-- layer3_residual_res2_conv&#45;&gt;layer3_residual_res2_norm -->\n<g id=\"edge31\" class=\"edge\">\n<title>layer3_residual_res2_conv&#45;&gt;layer3_residual_res2_norm</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2664.003,-70C2672.0277,-70 2680.9665,-70 2689.5309,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2689.7051,-73.5001 2699.705,-70 2689.705,-66.5001 2689.7051,-73.5001\"/>\n</g>\n<!-- layer3_residual_res2_act -->\n<g id=\"node31\" class=\"node\">\n<title>layer3_residual_res2_act</title>\n<g id=\"a_node31\"><a xlink:title=\"functools.partial(&lt;class &#39;torch.nn.modules.activation.CELU&#39;&gt;, 0.075) {}\">\n<path fill=\"#e66493\" stroke=\"#000000\" d=\"M2832,-88C2832,-88 2802,-88 2802,-88 2796,-88 2790,-82 2790,-76 2790,-76 2790,-64 2790,-64 2790,-58 2796,-52 2802,-52 2802,-52 2832,-52 2832,-52 2838,-52 2844,-58 2844,-64 2844,-64 2844,-76 2844,-76 2844,-82 2838,-88 2832,-88\"/>\n<text text-anchor=\"middle\" x=\"2817\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">act</text>\n</a>\n</g>\n</g>\n<!-- layer3_residual_res2_norm&#45;&gt;layer3_residual_res2_act -->\n<g id=\"edge32\" class=\"edge\">\n<title>layer3_residual_res2_norm&#45;&gt;layer3_residual_res2_act</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2754.003,-70C2762.0277,-70 2770.9665,-70 2779.5309,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2779.7051,-73.5001 2789.705,-70 2779.705,-66.5001 2779.7051,-73.5001\"/>\n</g>\n<!-- layer3_residual_out -->\n<g id=\"node32\" class=\"node\">\n<title>layer3_residual_out</title>\n<g id=\"a_node32\"><a xlink:title=\"&lt;class &#39;__main__.Identity&#39;&gt; {}\">\n<path fill=\"#80b1d3\" stroke=\"#000000\" d=\"M2922,-98C2922,-98 2892,-98 2892,-98 2886,-98 2880,-92 2880,-86 2880,-86 2880,-74 2880,-74 2880,-68 2886,-62 2892,-62 2892,-62 2922,-62 2922,-62 2928,-62 2934,-68 2934,-74 2934,-74 2934,-86 2934,-86 2934,-92 2928,-98 2922,-98\"/>\n<text text-anchor=\"middle\" x=\"2907\" y=\"-76.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">out</text>\n</a>\n</g>\n</g>\n<!-- layer3_residual_res2_act&#45;&gt;layer3_residual_out -->\n<g id=\"edge33\" class=\"edge\">\n<title>layer3_residual_res2_act&#45;&gt;layer3_residual_out</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2844.003,-73.0003C2852.0277,-73.892 2860.9665,-74.8852 2869.5309,-75.8368\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2869.3796,-79.3414 2879.705,-76.9672 2870.1527,-72.3842 2869.3796,-79.3414\"/>\n</g>\n<!-- layer3_residual_out&#45;&gt;layer3_residual_add -->\n<g id=\"edge35\" class=\"edge\">\n<title>layer3_residual_out&#45;&gt;layer3_residual_add</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2934.003,-86.0007C2942.1158,-87.8035 2951.1631,-89.814 2959.8131,-91.7362\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2959.1839,-95.1817 2969.705,-93.9345 2960.7024,-88.3484 2959.1839,-95.1817\"/>\n</g>\n<!-- pool -->\n<g id=\"node34\" class=\"node\">\n<title>pool</title>\n<g id=\"a_node34\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.pooling.MaxPool2d&#39;&gt; {&#39;kernel_size&#39;: 4}\">\n<path fill=\"#8dd3c7\" stroke=\"#000000\" d=\"M3102,-118C3102,-118 3072,-118 3072,-118 3066,-118 3060,-112 3060,-106 3060,-106 3060,-94 3060,-94 3060,-88 3066,-82 3072,-82 3072,-82 3102,-82 3102,-82 3108,-82 3114,-88 3114,-94 3114,-94 3114,-106 3114,-106 3114,-112 3108,-118 3102,-118\"/>\n<text text-anchor=\"middle\" x=\"3087\" y=\"-96.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">pool</text>\n</a>\n</g>\n</g>\n<!-- layer3_residual_add&#45;&gt;pool -->\n<g id=\"edge36\" class=\"edge\">\n<title>layer3_residual_add&#45;&gt;pool</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M3024.003,-100C3032.0277,-100 3040.9665,-100 3049.5309,-100\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"3049.7051,-103.5001 3059.705,-100 3049.705,-96.5001 3049.7051,-103.5001\"/>\n</g>\n<!-- classifier_flatten -->\n<g id=\"node35\" class=\"node\">\n<title>classifier_flatten</title>\n<g id=\"a_node35\"><a xlink:title=\"&lt;class &#39;__main__.Flatten&#39;&gt; {}\">\n<path fill=\"#b3de69\" stroke=\"#000000\" d=\"M3192,-118C3192,-118 3162,-118 3162,-118 3156,-118 3150,-112 3150,-106 3150,-106 3150,-94 3150,-94 3150,-88 3156,-82 3162,-82 3162,-82 3192,-82 3192,-82 3198,-82 3204,-88 3204,-94 3204,-94 3204,-106 3204,-106 3204,-112 3198,-118 3192,-118\"/>\n<text text-anchor=\"middle\" x=\"3177\" y=\"-96.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">flatten</text>\n</a>\n</g>\n</g>\n<!-- pool&#45;&gt;classifier_flatten -->\n<g id=\"edge37\" class=\"edge\">\n<title>pool&#45;&gt;classifier_flatten</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M3114.003,-100C3122.0277,-100 3130.9665,-100 3139.5309,-100\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"3139.7051,-103.5001 3149.705,-100 3139.705,-96.5001 3139.7051,-103.5001\"/>\n</g>\n<!-- classifier_conv -->\n<g id=\"node36\" class=\"node\">\n<title>classifier_conv</title>\n<g id=\"a_node36\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.linear.Linear&#39;&gt; {&#39;in_features&#39;: 512, &#39;out_features&#39;: 10, &#39;bias&#39;: False}\">\n<path fill=\"#fccde5\" stroke=\"#000000\" d=\"M3282,-118C3282,-118 3252,-118 3252,-118 3246,-118 3240,-112 3240,-106 3240,-106 3240,-94 3240,-94 3240,-88 3246,-82 3252,-82 3252,-82 3282,-82 3282,-82 3288,-82 3294,-88 3294,-94 3294,-94 3294,-106 3294,-106 3294,-112 3288,-118 3282,-118\"/>\n<text text-anchor=\"middle\" x=\"3267\" y=\"-96.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">conv</text>\n</a>\n</g>\n</g>\n<!-- classifier_flatten&#45;&gt;classifier_conv -->\n<g id=\"edge38\" class=\"edge\">\n<title>classifier_flatten&#45;&gt;classifier_conv</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M3204.003,-100C3212.0277,-100 3220.9665,-100 3229.5309,-100\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"3229.7051,-103.5001 3239.705,-100 3229.705,-96.5001 3229.7051,-103.5001\"/>\n</g>\n<!-- classifier_scale -->\n<g id=\"node37\" class=\"node\">\n<title>classifier_scale</title>\n<g id=\"a_node37\"><a xlink:title=\"&lt;class &#39;__main__.Mul&#39;&gt; {&#39;weight&#39;: 0.125}\">\n<path fill=\"#bc80bd\" stroke=\"#000000\" d=\"M3372,-118C3372,-118 3342,-118 3342,-118 3336,-118 3330,-112 3330,-106 3330,-106 3330,-94 3330,-94 3330,-88 3336,-82 3342,-82 3342,-82 3372,-82 3372,-82 3378,-82 3384,-88 3384,-94 3384,-94 3384,-106 3384,-106 3384,-112 3378,-118 3372,-118\"/>\n<text text-anchor=\"middle\" x=\"3357\" y=\"-96.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">scale</text>\n</a>\n</g>\n</g>\n<!-- classifier_conv&#45;&gt;classifier_scale -->\n<g id=\"edge39\" class=\"edge\">\n<title>classifier_conv&#45;&gt;classifier_scale</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M3294.003,-100C3302.0277,-100 3310.9665,-100 3319.5309,-100\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"3319.7051,-103.5001 3329.705,-100 3319.705,-96.5001 3319.7051,-103.5001\"/>\n</g>\n<!-- logits -->\n<g id=\"node38\" class=\"node\">\n<title>logits</title>\n<g id=\"a_node38\"><a xlink:title=\"&lt;class &#39;__main__.Identity&#39;&gt; {}\">\n<path fill=\"#80b1d3\" stroke=\"#000000\" d=\"M3462,-118C3462,-118 3432,-118 3432,-118 3426,-118 3420,-112 3420,-106 3420,-106 3420,-94 3420,-94 3420,-88 3426,-82 3432,-82 3432,-82 3462,-82 3462,-82 3468,-82 3474,-88 3474,-94 3474,-94 3474,-106 3474,-106 3474,-112 3468,-118 3462,-118\"/>\n<text text-anchor=\"middle\" x=\"3447\" y=\"-96.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">logits</text>\n</a>\n</g>\n</g>\n<!-- classifier_scale&#45;&gt;logits -->\n<g id=\"edge40\" class=\"edge\">\n<title>classifier_scale&#45;&gt;logits</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M3384.003,-100C3392.0277,-100 3400.9665,-100 3409.5309,-100\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"3409.7051,-103.5001 3419.705,-100 3409.705,-96.5001 3409.7051,-103.5001\"/>\n</g>\n<!-- input -->\n<g id=\"node39\" class=\"node\">\n<title>input</title>\n<path fill=\"#ffffff\" stroke=\"#000000\" d=\"M42,-88C42,-88 12,-88 12,-88 6,-88 0,-82 0,-76 0,-76 0,-64 0,-64 0,-58 6,-52 12,-52 12,-52 42,-52 42,-52 48,-52 54,-58 54,-64 54,-64 54,-76 54,-76 54,-82 48,-88 42,-88\"/>\n<text text-anchor=\"middle\" x=\"27\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">input</text>\n</g>\n<!-- input&#45;&gt;prep_conv -->\n<g id=\"edge1\" class=\"edge\">\n<title>input&#45;&gt;prep_conv</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M54.003,-70C62.0277,-70 70.9665,-70 79.5309,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"79.7051,-73.5001 89.705,-70 79.705,-66.5001 79.7051,-73.5001\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAUyBrtqN7gj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "outputId": "55a4bbf7-7434-457f-f60d-8c4c500410dd"
      },
      "source": [
        "epochs, batch_size = 20, 512\n",
        "transforms = (Crop(32, 32), FlipLR(), Cutout(8, 8))\n",
        "opt_params = {'lr': lr_schedule([0, epochs/5, epochs], [0.0, 0.4, 0.0], batch_size), 'weight_decay': Const(5e-4*batch_size), 'momentum': Const(0.9)}\n",
        "\n",
        "logs = Table(report=every(epochs, 'epoch'))\n",
        "for run in range(N_RUNS):\n",
        "    model = build_model(ghost_bn_net, label_smoothing_loss(0.2))\n",
        "    state, timer = {MODEL: model, OPTS: [SGD(trainable_params(model).values(), opt_params)]}, Timer(torch.cuda.synchronize)\n",
        "    for epoch in range(epochs):\n",
        "        logs.append(union({'run': run+1, 'epoch': epoch+1}, train_epoch(state, timer, train_batches(batch_size, transforms), valid_batches(batch_size))))\n",
        "summary(logs)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         run        epoch   train time   train loss    train acc   valid time   valid loss    valid acc   total time\n",
            "           1           20      10.5906       0.9521       0.9699       0.6386       0.9887       0.9424     211.5602\n",
            "           2           20      10.5897       0.9513       0.9704       0.6422       0.9903       0.9410     211.5964\n",
            "           3           20      10.5899       0.9511       0.9707       0.6432       0.9888       0.9427     211.7180\n",
            "           4           20      10.5975       0.9493       0.9720       0.6403       0.9909       0.9403     211.5474\n",
            "           5           20      10.5985       0.9528       0.9699       0.6412       0.9878       0.9448     211.5743\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>min</th>\n",
              "      <th>max</th>\n",
              "      <th>std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>valid_acc</th>\n",
              "      <td>5</td>\n",
              "      <td>0.94224</td>\n",
              "      <td>0.9403</td>\n",
              "      <td>0.9448</td>\n",
              "      <td>0.001739</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           count     mean     min     max       std\n",
              "valid_acc      5  0.94224  0.9403  0.9448  0.001739"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyvPyD2xc77U",
        "colab_type": "text"
      },
      "source": [
        "This gives a healthy boost to the 20 epoch test accuracy of 94.2%. As training becomes ever shorter, it is occasionally helpful to increase the learning rate to compensate. If we raise the max learning rate by 50% we can achieve 94.1% accuracy in 18 epochs and a training time of 46s."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-gEHrSYp94Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "outputId": "41c62329-93c1-49f3-89a9-de560944d90a"
      },
      "source": [
        "epochs, batch_size = 18, 512\n",
        "transforms = (Crop(32, 32), FlipLR(), Cutout(8, 8))\n",
        "opt_params = {'lr': lr_schedule([0, epochs/5, epochs], [0.0, 0.6, 0.0], batch_size), 'weight_decay': Const(5e-4*batch_size), 'momentum': Const(0.9)}\n",
        "\n",
        "logs = Table(report=every(epochs, 'epoch'))\n",
        "for run in range(N_RUNS):\n",
        "    model = build_model(ghost_bn_net, label_smoothing_loss(0.2))\n",
        "    state, timer = {MODEL: model, OPTS: [SGD(trainable_params(model).values(), opt_params)]}, Timer(torch.cuda.synchronize)\n",
        "    for epoch in range(epochs):\n",
        "        logs.append(union({'run': run+1, 'epoch': epoch+1}, train_epoch(state, timer, train_batches(batch_size, transforms), valid_batches(batch_size))))\n",
        "summary(logs)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         run        epoch   train time   train loss    train acc   valid time   valid loss    valid acc   total time\n",
            "           1           18      10.6049       0.9646       0.9629       0.6423       0.9913       0.9417     190.6019\n",
            "           2           18      10.6122       0.9643       0.9627       0.6414       0.9932       0.9377     190.7071\n",
            "           3           18      10.5570       0.9675       0.9618       0.6378       0.9927       0.9394     190.0716\n",
            "           4           18      10.5636       0.9660       0.9629       0.6398       0.9923       0.9400     189.8733\n",
            "           5           18      10.5547       0.9649       0.9634       0.6389       0.9925       0.9401     189.7025\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>min</th>\n",
              "      <th>max</th>\n",
              "      <th>std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>valid_acc</th>\n",
              "      <td>5</td>\n",
              "      <td>0.93978</td>\n",
              "      <td>0.9377</td>\n",
              "      <td>0.9417</td>\n",
              "      <td>0.001441</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           count     mean     min     max       std\n",
              "valid_acc      5  0.93978  0.9377  0.9417  0.001441"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRrXu8g5eoQ1",
        "colab_type": "text"
      },
      "source": [
        "### Frozen batch norm scales (43s)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbafQdo_er-7",
        "colab_type": "text"
      },
      "source": [
        "Batch norm standardises the mean and variance of each channel but is followed by a learnable scale and bias. Our batch norm layers are succeeded by ReLUs, so the learnable biases could allow the network to optimise the level of sparsity per channel. On the other hand, if channel scales vary substantially this might reduce the effective number of channels and introduce a bottleneck. Let's have a look at the dynamics of these parameters during training:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KbCvLxqq8VI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "outputId": "0d70b81c-a1f8-4ba3-9d9d-aca40f695375"
      },
      "source": [
        "epochs, batch_size = 18, 512\n",
        "transforms = (Crop(32, 32), FlipLR(), Cutout(8, 8))\n",
        "opt_params = {'lr': lr_schedule([0, epochs/5, epochs], [0.0, 0.6, 0.0], batch_size), 'weight_decay': Const(5e-4*batch_size), 'momentum': Const(0.9)}\n",
        "\n",
        "model = build_model(ghost_bn_net, label_smoothing_loss(0.2))\n",
        "state, timer, logs = {MODEL: model, OPTS: [SGD(trainable_params(model).values(), opt_params)]}, Timer(torch.cuda.synchronize), Table(report=every(epochs, 'epoch'))\n",
        "for epoch in range(epochs):\n",
        "    logs.append(union({'epoch': epoch+1}, train_epoch(state, timer, train_batches(batch_size, transforms), valid_batches(batch_size), \n",
        "                                                      on_epoch_end=partial(log_weights, weights={k: v for k,v in trainable_params(model).items() if 'norm' in k}))))\n",
        "data = pd.DataFrame([{'epoch': epoch, 'type': weight.split('.')[1], 'layer': weight.split('_norm')[0], 'channel': channel, 'value': value} \n",
        "                     for epoch, epoch_vals in enumerate(state[WEIGHT_LOG], 1) \n",
        "                     for weight, weight_vals in epoch_vals.items() \n",
        "                     for channel, value in enumerate(weight_vals[:8], 1)])\n",
        "\n",
        "alt.Chart(data).mark_line(opacity=0.7).encode(x='epoch', y='value', color=alt.Color('layer', sort=['prep']), detail='channel', column='type').resolve_scale(y='independent')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       epoch   train time   train loss    train acc   valid time   valid loss    valid acc   total time\n",
            "          18      10.5658       0.9637       0.9639       0.6408       0.9915       0.9422     189.8385\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "alt.Chart(...)"
            ],
            "text/html": [
              "<!DOCTYPE html>\n",
              "<html>\n",
              "<head>\n",
              "  <style>\n",
              "    .vega-actions a {\n",
              "        margin-right: 12px;\n",
              "        color: #757575;\n",
              "        font-weight: normal;\n",
              "        font-size: 13px;\n",
              "    }\n",
              "    .error {\n",
              "        color: red;\n",
              "    }\n",
              "  </style>\n",
              "  <script type=\"text/javascript\" src=\"https://cdn.jsdelivr.net/npm//vega@5\"></script>\n",
              "  <script type=\"text/javascript\" src=\"https://cdn.jsdelivr.net/npm//vega-lite@3.4.0\"></script>\n",
              "  <script type=\"text/javascript\" src=\"https://cdn.jsdelivr.net/npm//vega-embed@4\"></script>\n",
              "</head>\n",
              "<body>\n",
              "  <div id=\"altair-viz\"></div>\n",
              "  <script>\n",
              "    (function(vegaEmbed) {\n",
              "      var spec = {\"config\": {\"view\": {\"width\": 400, \"height\": 300}, \"mark\": {\"tooltip\": null}}, \"data\": {\"name\": \"data-6a87e00ef69fdb23e29dd63318ab470b\"}, \"mark\": {\"type\": \"line\", \"opacity\": 0.7}, \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"layer\", \"sort\": [\"prep\"]}, \"column\": {\"type\": \"nominal\", \"field\": \"type\"}, \"detail\": {\"type\": \"quantitative\", \"field\": \"channel\"}, \"x\": {\"type\": \"quantitative\", \"field\": \"epoch\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"value\"}}, \"resolve\": {\"scale\": {\"y\": \"independent\"}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v3.4.0.json\", \"datasets\": {\"data-6a87e00ef69fdb23e29dd63318ab470b\": [{\"channel\": 1, \"epoch\": 1, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.9979352951049805}, {\"channel\": 2, \"epoch\": 1, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 1.0074814558029175}, {\"channel\": 3, \"epoch\": 1, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.9315043687820435}, {\"channel\": 4, \"epoch\": 1, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.9330807328224182}, {\"channel\": 5, \"epoch\": 1, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.9303207397460938}, {\"channel\": 6, \"epoch\": 1, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.9472681283950806}, {\"channel\": 7, \"epoch\": 1, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 1.0303021669387817}, {\"channel\": 8, \"epoch\": 1, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.9522773027420044}, {\"channel\": 1, \"epoch\": 1, \"layer\": \"prep\", \"type\": \"bias\", \"value\": 0.031386639922857285}, {\"channel\": 2, \"epoch\": 1, \"layer\": \"prep\", \"type\": \"bias\", \"value\": 0.04836820065975189}, {\"channel\": 3, \"epoch\": 1, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.025163015350699425}, {\"channel\": 4, \"epoch\": 1, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.02439008839428425}, {\"channel\": 5, \"epoch\": 1, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.021813033148646355}, {\"channel\": 6, \"epoch\": 1, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.011454639956355095}, {\"channel\": 7, \"epoch\": 1, \"layer\": \"prep\", \"type\": \"bias\", \"value\": 0.08172452449798584}, {\"channel\": 8, \"epoch\": 1, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.01255525927990675}, {\"channel\": 1, \"epoch\": 1, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.9626896381378174}, {\"channel\": 2, \"epoch\": 1, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.9623119831085205}, {\"channel\": 3, \"epoch\": 1, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.9634504914283752}, {\"channel\": 4, \"epoch\": 1, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.9502421617507935}, {\"channel\": 5, \"epoch\": 1, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.9611961841583252}, {\"channel\": 6, \"epoch\": 1, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.9793742299079895}, {\"channel\": 7, \"epoch\": 1, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.9917089939117432}, {\"channel\": 8, \"epoch\": 1, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.9645397663116455}, {\"channel\": 1, \"epoch\": 1, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": 0.0016598883084952831}, {\"channel\": 2, \"epoch\": 1, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": 0.0003260586818214506}, {\"channel\": 3, \"epoch\": 1, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.015075411647558212}, {\"channel\": 4, \"epoch\": 1, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.011304708197712898}, {\"channel\": 5, \"epoch\": 1, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": 0.001333876047283411}, {\"channel\": 6, \"epoch\": 1, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": 0.00748361786827445}, {\"channel\": 7, \"epoch\": 1, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": 0.01734907366335392}, {\"channel\": 8, \"epoch\": 1, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": 0.006179154384881258}, {\"channel\": 1, \"epoch\": 1, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.9619312882423401}, {\"channel\": 2, \"epoch\": 1, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.9619879722595215}, {\"channel\": 3, \"epoch\": 1, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.9638650417327881}, {\"channel\": 4, \"epoch\": 1, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.9713250994682312}, {\"channel\": 5, \"epoch\": 1, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.9586375951766968}, {\"channel\": 6, \"epoch\": 1, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.9629227519035339}, {\"channel\": 7, \"epoch\": 1, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.9649797081947327}, {\"channel\": 8, \"epoch\": 1, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.9655294418334961}, {\"channel\": 1, \"epoch\": 1, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.0028094842564314604}, {\"channel\": 2, \"epoch\": 1, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.0030110145453363657}, {\"channel\": 3, \"epoch\": 1, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.0030431358609348536}, {\"channel\": 4, \"epoch\": 1, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": 0.007443471346050501}, {\"channel\": 5, \"epoch\": 1, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.005273491609841585}, {\"channel\": 6, \"epoch\": 1, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.00035459271748550236}, {\"channel\": 7, \"epoch\": 1, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.0012361238477751613}, {\"channel\": 8, \"epoch\": 1, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.00047221200657077134}, {\"channel\": 1, \"epoch\": 1, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.9632671475410461}, {\"channel\": 2, \"epoch\": 1, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.9707356691360474}, {\"channel\": 3, \"epoch\": 1, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.9659459590911865}, {\"channel\": 4, \"epoch\": 1, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.972224235534668}, {\"channel\": 5, \"epoch\": 1, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.9638360142707825}, {\"channel\": 6, \"epoch\": 1, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.9585522413253784}, {\"channel\": 7, \"epoch\": 1, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.9581354260444641}, {\"channel\": 8, \"epoch\": 1, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.9593965411186218}, {\"channel\": 1, \"epoch\": 1, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.002778661670163274}, {\"channel\": 2, \"epoch\": 1, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": 0.0023124495055526495}, {\"channel\": 3, \"epoch\": 1, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.00341546512208879}, {\"channel\": 4, \"epoch\": 1, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": 0.00038786412915214896}, {\"channel\": 5, \"epoch\": 1, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": 0.0010698012774810195}, {\"channel\": 6, \"epoch\": 1, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.0007359303999692202}, {\"channel\": 7, \"epoch\": 1, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.0024277979973703623}, {\"channel\": 8, \"epoch\": 1, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.0037816434632986784}, {\"channel\": 1, \"epoch\": 1, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.9718310236930847}, {\"channel\": 2, \"epoch\": 1, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.9622320532798767}, {\"channel\": 3, \"epoch\": 1, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.9634758830070496}, {\"channel\": 4, \"epoch\": 1, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.9650052189826965}, {\"channel\": 5, \"epoch\": 1, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.9595390558242798}, {\"channel\": 6, \"epoch\": 1, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.9667181968688965}, {\"channel\": 7, \"epoch\": 1, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.9674758315086365}, {\"channel\": 8, \"epoch\": 1, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.9639065861701965}, {\"channel\": 1, \"epoch\": 1, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": 0.005047992803156376}, {\"channel\": 2, \"epoch\": 1, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.0028646287973970175}, {\"channel\": 3, \"epoch\": 1, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": 0.0005256222793832421}, {\"channel\": 4, \"epoch\": 1, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.00023406300169881433}, {\"channel\": 5, \"epoch\": 1, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.005395879969000816}, {\"channel\": 6, \"epoch\": 1, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": 0.001898636226542294}, {\"channel\": 7, \"epoch\": 1, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.0003998159081675112}, {\"channel\": 8, \"epoch\": 1, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": 0.000971140107139945}, {\"channel\": 1, \"epoch\": 1, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.9664199948310852}, {\"channel\": 2, \"epoch\": 1, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.9649538993835449}, {\"channel\": 3, \"epoch\": 1, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.9670096635818481}, {\"channel\": 4, \"epoch\": 1, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.9697743058204651}, {\"channel\": 5, \"epoch\": 1, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.9657281637191772}, {\"channel\": 6, \"epoch\": 1, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.9635205864906311}, {\"channel\": 7, \"epoch\": 1, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.963073194026947}, {\"channel\": 8, \"epoch\": 1, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.9714191555976868}, {\"channel\": 1, \"epoch\": 1, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": 0.00014079392713028938}, {\"channel\": 2, \"epoch\": 1, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.0026260176673531532}, {\"channel\": 3, \"epoch\": 1, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": 6.165683589642867e-05}, {\"channel\": 4, \"epoch\": 1, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": 0.0019232536433264613}, {\"channel\": 5, \"epoch\": 1, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.0038390527479350567}, {\"channel\": 6, \"epoch\": 1, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": 2.8922222554683685e-06}, {\"channel\": 7, \"epoch\": 1, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.002446786966174841}, {\"channel\": 8, \"epoch\": 1, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.0019005618523806334}, {\"channel\": 1, \"epoch\": 1, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.9689109921455383}, {\"channel\": 2, \"epoch\": 1, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.9653904438018799}, {\"channel\": 3, \"epoch\": 1, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.9662571549415588}, {\"channel\": 4, \"epoch\": 1, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.9688211679458618}, {\"channel\": 5, \"epoch\": 1, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.9652891159057617}, {\"channel\": 6, \"epoch\": 1, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.9650659561157227}, {\"channel\": 7, \"epoch\": 1, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.9661931395530701}, {\"channel\": 8, \"epoch\": 1, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.9656031131744385}, {\"channel\": 1, \"epoch\": 1, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.0005740086198784411}, {\"channel\": 2, \"epoch\": 1, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": 0.00018118316074833274}, {\"channel\": 3, \"epoch\": 1, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": 0.002102564089000225}, {\"channel\": 4, \"epoch\": 1, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": 0.0014050438767299056}, {\"channel\": 5, \"epoch\": 1, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": 0.0001133498881245032}, {\"channel\": 6, \"epoch\": 1, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.00016611895989626646}, {\"channel\": 7, \"epoch\": 1, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.00032164776348508894}, {\"channel\": 8, \"epoch\": 1, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.00042119444697164}, {\"channel\": 1, \"epoch\": 1, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.9661318063735962}, {\"channel\": 2, \"epoch\": 1, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.969700813293457}, {\"channel\": 3, \"epoch\": 1, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.9665670394897461}, {\"channel\": 4, \"epoch\": 1, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.9731079339981079}, {\"channel\": 5, \"epoch\": 1, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.9679703712463379}, {\"channel\": 6, \"epoch\": 1, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.9659972190856934}, {\"channel\": 7, \"epoch\": 1, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.9726470112800598}, {\"channel\": 8, \"epoch\": 1, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.9707742929458618}, {\"channel\": 1, \"epoch\": 1, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.0006205695681273937}, {\"channel\": 2, \"epoch\": 1, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.0009827414760366082}, {\"channel\": 3, \"epoch\": 1, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.0002540092682465911}, {\"channel\": 4, \"epoch\": 1, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": 0.0016925226664170623}, {\"channel\": 5, \"epoch\": 1, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.0010569922160357237}, {\"channel\": 6, \"epoch\": 1, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": 0.000145703466841951}, {\"channel\": 7, \"epoch\": 1, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": 0.0005114208906888962}, {\"channel\": 8, \"epoch\": 1, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.0011843217071145773}, {\"channel\": 1, \"epoch\": 2, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.9228179454803467}, {\"channel\": 2, \"epoch\": 2, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.8591781258583069}, {\"channel\": 3, \"epoch\": 2, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.7069457173347473}, {\"channel\": 4, \"epoch\": 2, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.7417460083961487}, {\"channel\": 5, \"epoch\": 2, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.734748363494873}, {\"channel\": 6, \"epoch\": 2, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.7621743083000183}, {\"channel\": 7, \"epoch\": 2, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.9939265251159668}, {\"channel\": 8, \"epoch\": 2, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.8351004719734192}, {\"channel\": 1, \"epoch\": 2, \"layer\": \"prep\", \"type\": \"bias\", \"value\": 0.11292378604412079}, {\"channel\": 2, \"epoch\": 2, \"layer\": \"prep\", \"type\": \"bias\", \"value\": 0.04658972844481468}, {\"channel\": 3, \"epoch\": 2, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.11600357294082642}, {\"channel\": 4, \"epoch\": 2, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.09562399238348007}, {\"channel\": 5, \"epoch\": 2, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.10752935707569122}, {\"channel\": 6, \"epoch\": 2, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.0748860239982605}, {\"channel\": 7, \"epoch\": 2, \"layer\": \"prep\", \"type\": \"bias\", \"value\": 0.3017948865890503}, {\"channel\": 8, \"epoch\": 2, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.011049565859138966}, {\"channel\": 1, \"epoch\": 2, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.8259072303771973}, {\"channel\": 2, \"epoch\": 2, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.8597094416618347}, {\"channel\": 3, \"epoch\": 2, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.8797056078910828}, {\"channel\": 4, \"epoch\": 2, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.8141778111457825}, {\"channel\": 5, \"epoch\": 2, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.8688773512840271}, {\"channel\": 6, \"epoch\": 2, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.871345043182373}, {\"channel\": 7, \"epoch\": 2, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.9604889750480652}, {\"channel\": 8, \"epoch\": 2, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.8480201363563538}, {\"channel\": 1, \"epoch\": 2, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.039967041462659836}, {\"channel\": 2, \"epoch\": 2, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.036669064313173294}, {\"channel\": 3, \"epoch\": 2, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.022981084883213043}, {\"channel\": 4, \"epoch\": 2, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.034156013280153275}, {\"channel\": 5, \"epoch\": 2, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": 0.021659547463059425}, {\"channel\": 6, \"epoch\": 2, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.014928570948541164}, {\"channel\": 7, \"epoch\": 2, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": 0.11307394504547119}, {\"channel\": 8, \"epoch\": 2, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.007529762107878923}, {\"channel\": 1, \"epoch\": 2, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.8539353609085083}, {\"channel\": 2, \"epoch\": 2, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.8511063456535339}, {\"channel\": 3, \"epoch\": 2, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.8543104529380798}, {\"channel\": 4, \"epoch\": 2, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.8735756278038025}, {\"channel\": 5, \"epoch\": 2, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.838748037815094}, {\"channel\": 6, \"epoch\": 2, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.8657744526863098}, {\"channel\": 7, \"epoch\": 2, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.8423041701316833}, {\"channel\": 8, \"epoch\": 2, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.8566309809684753}, {\"channel\": 1, \"epoch\": 2, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.01727936789393425}, {\"channel\": 2, \"epoch\": 2, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.014273813925683498}, {\"channel\": 3, \"epoch\": 2, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.020362509414553642}, {\"channel\": 4, \"epoch\": 2, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.0056250011548399925}, {\"channel\": 5, \"epoch\": 2, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.02400033175945282}, {\"channel\": 6, \"epoch\": 2, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.0038469843566417694}, {\"channel\": 7, \"epoch\": 2, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.024876581504940987}, {\"channel\": 8, \"epoch\": 2, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.018577566370368004}, {\"channel\": 1, \"epoch\": 2, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.8624790906906128}, {\"channel\": 2, \"epoch\": 2, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.8757579326629639}, {\"channel\": 3, \"epoch\": 2, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.8515079021453857}, {\"channel\": 4, \"epoch\": 2, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.8769511580467224}, {\"channel\": 5, \"epoch\": 2, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.8628896474838257}, {\"channel\": 6, \"epoch\": 2, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.8636876344680786}, {\"channel\": 7, \"epoch\": 2, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.8445107340812683}, {\"channel\": 8, \"epoch\": 2, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.8453178405761719}, {\"channel\": 1, \"epoch\": 2, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.008825303055346012}, {\"channel\": 2, \"epoch\": 2, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.010740269906818867}, {\"channel\": 3, \"epoch\": 2, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.012053434737026691}, {\"channel\": 4, \"epoch\": 2, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": 0.0028347880579531193}, {\"channel\": 5, \"epoch\": 2, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": 0.0010638876119628549}, {\"channel\": 6, \"epoch\": 2, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": 0.0020597230177372694}, {\"channel\": 7, \"epoch\": 2, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.011197315528988838}, {\"channel\": 8, \"epoch\": 2, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.013835159130394459}, {\"channel\": 1, \"epoch\": 2, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.8590804934501648}, {\"channel\": 2, \"epoch\": 2, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.8721497058868408}, {\"channel\": 3, \"epoch\": 2, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.8547372817993164}, {\"channel\": 4, \"epoch\": 2, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.8653812408447266}, {\"channel\": 5, \"epoch\": 2, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.8376365900039673}, {\"channel\": 6, \"epoch\": 2, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.8691743612289429}, {\"channel\": 7, \"epoch\": 2, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.8677008748054504}, {\"channel\": 8, \"epoch\": 2, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.852547287940979}, {\"channel\": 1, \"epoch\": 2, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.0023342666681855917}, {\"channel\": 2, \"epoch\": 2, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.0049928296357393265}, {\"channel\": 3, \"epoch\": 2, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.010612046346068382}, {\"channel\": 4, \"epoch\": 2, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.0032784035429358482}, {\"channel\": 5, \"epoch\": 2, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.00935819000005722}, {\"channel\": 6, \"epoch\": 2, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.0019799130968749523}, {\"channel\": 7, \"epoch\": 2, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.007870150730013847}, {\"channel\": 8, \"epoch\": 2, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.004944619722664356}, {\"channel\": 1, \"epoch\": 2, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.8507772088050842}, {\"channel\": 2, \"epoch\": 2, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.8458123803138733}, {\"channel\": 3, \"epoch\": 2, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.8561981916427612}, {\"channel\": 4, \"epoch\": 2, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.8544211387634277}, {\"channel\": 5, \"epoch\": 2, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.8534585237503052}, {\"channel\": 6, \"epoch\": 2, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.8557189702987671}, {\"channel\": 7, \"epoch\": 2, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.8438385725021362}, {\"channel\": 8, \"epoch\": 2, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.8721856474876404}, {\"channel\": 1, \"epoch\": 2, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.01331854984164238}, {\"channel\": 2, \"epoch\": 2, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.022770915180444717}, {\"channel\": 3, \"epoch\": 2, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.013940309174358845}, {\"channel\": 4, \"epoch\": 2, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.008444256149232388}, {\"channel\": 5, \"epoch\": 2, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.013659300282597542}, {\"channel\": 6, \"epoch\": 2, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.011591317132115364}, {\"channel\": 7, \"epoch\": 2, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.022715378552675247}, {\"channel\": 8, \"epoch\": 2, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.018160494044423103}, {\"channel\": 1, \"epoch\": 2, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.8715776801109314}, {\"channel\": 2, \"epoch\": 2, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.8585132360458374}, {\"channel\": 3, \"epoch\": 2, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.8643626570701599}, {\"channel\": 4, \"epoch\": 2, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.8677743673324585}, {\"channel\": 5, \"epoch\": 2, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.8554612994194031}, {\"channel\": 6, \"epoch\": 2, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.857680082321167}, {\"channel\": 7, \"epoch\": 2, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.8598127961158752}, {\"channel\": 8, \"epoch\": 2, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.8623505234718323}, {\"channel\": 1, \"epoch\": 2, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.008050555363297462}, {\"channel\": 2, \"epoch\": 2, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.0012678657658398151}, {\"channel\": 3, \"epoch\": 2, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": 0.0014819212956354022}, {\"channel\": 4, \"epoch\": 2, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.0010618313681334257}, {\"channel\": 5, \"epoch\": 2, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.0032944525592029095}, {\"channel\": 6, \"epoch\": 2, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.0038512912578880787}, {\"channel\": 7, \"epoch\": 2, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.003062404226511717}, {\"channel\": 8, \"epoch\": 2, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.0019918347243219614}, {\"channel\": 1, \"epoch\": 2, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.8577794432640076}, {\"channel\": 2, \"epoch\": 2, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.8641868233680725}, {\"channel\": 3, \"epoch\": 2, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.8554157018661499}, {\"channel\": 4, \"epoch\": 2, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.8736715316772461}, {\"channel\": 5, \"epoch\": 2, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.8581103086471558}, {\"channel\": 6, \"epoch\": 2, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.8514342308044434}, {\"channel\": 7, \"epoch\": 2, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.8681565523147583}, {\"channel\": 8, \"epoch\": 2, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.8642085194587708}, {\"channel\": 1, \"epoch\": 2, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.005442627239972353}, {\"channel\": 2, \"epoch\": 2, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.008032807148993015}, {\"channel\": 3, \"epoch\": 2, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.005934870336204767}, {\"channel\": 4, \"epoch\": 2, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.009200675413012505}, {\"channel\": 5, \"epoch\": 2, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.008913831785321236}, {\"channel\": 6, \"epoch\": 2, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.0066665541380643845}, {\"channel\": 7, \"epoch\": 2, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.010561441071331501}, {\"channel\": 8, \"epoch\": 2, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.010457265190780163}, {\"channel\": 1, \"epoch\": 3, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.785481870174408}, {\"channel\": 2, \"epoch\": 3, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.7348591685295105}, {\"channel\": 3, \"epoch\": 3, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.4726283550262451}, {\"channel\": 4, \"epoch\": 3, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.5186326503753662}, {\"channel\": 5, \"epoch\": 3, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.49135923385620117}, {\"channel\": 6, \"epoch\": 3, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.5853118300437927}, {\"channel\": 7, \"epoch\": 3, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.8329402208328247}, {\"channel\": 8, \"epoch\": 3, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.6976882219314575}, {\"channel\": 1, \"epoch\": 3, \"layer\": \"prep\", \"type\": \"bias\", \"value\": 0.18577121198177338}, {\"channel\": 2, \"epoch\": 3, \"layer\": \"prep\", \"type\": \"bias\", \"value\": 0.10367400199174881}, {\"channel\": 3, \"epoch\": 3, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.18935620784759521}, {\"channel\": 4, \"epoch\": 3, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.16671821475028992}, {\"channel\": 5, \"epoch\": 3, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.1484638899564743}, {\"channel\": 6, \"epoch\": 3, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.07901228219270706}, {\"channel\": 7, \"epoch\": 3, \"layer\": \"prep\", \"type\": \"bias\", \"value\": 0.3992566764354706}, {\"channel\": 8, \"epoch\": 3, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.0007861086633056402}, {\"channel\": 1, \"epoch\": 3, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.6328262090682983}, {\"channel\": 2, \"epoch\": 3, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.6881831288337708}, {\"channel\": 3, \"epoch\": 3, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.7347532510757446}, {\"channel\": 4, \"epoch\": 3, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.6297982931137085}, {\"channel\": 5, \"epoch\": 3, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.7052084803581238}, {\"channel\": 6, \"epoch\": 3, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.6974307298660278}, {\"channel\": 7, \"epoch\": 3, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.8602022528648376}, {\"channel\": 8, \"epoch\": 3, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.691006600856781}, {\"channel\": 1, \"epoch\": 3, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.07937958836555481}, {\"channel\": 2, \"epoch\": 3, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.05067344754934311}, {\"channel\": 3, \"epoch\": 3, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.018009096384048462}, {\"channel\": 4, \"epoch\": 3, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.05646826699376106}, {\"channel\": 5, \"epoch\": 3, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": 0.046140577644109726}, {\"channel\": 6, \"epoch\": 3, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.0298975370824337}, {\"channel\": 7, \"epoch\": 3, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": 0.1839526742696762}, {\"channel\": 8, \"epoch\": 3, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.02175608091056347}, {\"channel\": 1, \"epoch\": 3, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.6894020438194275}, {\"channel\": 2, \"epoch\": 3, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.65268874168396}, {\"channel\": 3, \"epoch\": 3, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.6971504092216492}, {\"channel\": 4, \"epoch\": 3, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.739973783493042}, {\"channel\": 5, \"epoch\": 3, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.6629544496536255}, {\"channel\": 6, \"epoch\": 3, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.7309741377830505}, {\"channel\": 7, \"epoch\": 3, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.6813156604766846}, {\"channel\": 8, \"epoch\": 3, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.702919065952301}, {\"channel\": 1, \"epoch\": 3, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.04061805456876755}, {\"channel\": 2, \"epoch\": 3, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.054507702589035034}, {\"channel\": 3, \"epoch\": 3, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.04461337998509407}, {\"channel\": 4, \"epoch\": 3, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.04456431046128273}, {\"channel\": 5, \"epoch\": 3, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.061281800270080566}, {\"channel\": 6, \"epoch\": 3, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.011151391081511974}, {\"channel\": 7, \"epoch\": 3, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.04484909027814865}, {\"channel\": 8, \"epoch\": 3, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.028871852904558182}, {\"channel\": 1, \"epoch\": 3, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.711355447769165}, {\"channel\": 2, \"epoch\": 3, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.7152416110038757}, {\"channel\": 3, \"epoch\": 3, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.7038260102272034}, {\"channel\": 4, \"epoch\": 3, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.7182067632675171}, {\"channel\": 5, \"epoch\": 3, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.7221390604972839}, {\"channel\": 6, \"epoch\": 3, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.7265505790710449}, {\"channel\": 7, \"epoch\": 3, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.6814661026000977}, {\"channel\": 8, \"epoch\": 3, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.6922684907913208}, {\"channel\": 1, \"epoch\": 3, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.02173730731010437}, {\"channel\": 2, \"epoch\": 3, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.04735664278268814}, {\"channel\": 3, \"epoch\": 3, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.028170255944132805}, {\"channel\": 4, \"epoch\": 3, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.015236752107739449}, {\"channel\": 5, \"epoch\": 3, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.008902817033231258}, {\"channel\": 6, \"epoch\": 3, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.02551199123263359}, {\"channel\": 7, \"epoch\": 3, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.047301094979047775}, {\"channel\": 8, \"epoch\": 3, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.03559275344014168}, {\"channel\": 1, \"epoch\": 3, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.7267618179321289}, {\"channel\": 2, \"epoch\": 3, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.711353600025177}, {\"channel\": 3, \"epoch\": 3, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.7075174450874329}, {\"channel\": 4, \"epoch\": 3, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.6998319625854492}, {\"channel\": 5, \"epoch\": 3, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.6757186055183411}, {\"channel\": 6, \"epoch\": 3, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.7158421874046326}, {\"channel\": 7, \"epoch\": 3, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.7172528505325317}, {\"channel\": 8, \"epoch\": 3, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.6807984709739685}, {\"channel\": 1, \"epoch\": 3, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.026060285046696663}, {\"channel\": 2, \"epoch\": 3, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.014933559112250805}, {\"channel\": 3, \"epoch\": 3, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.029626138508319855}, {\"channel\": 4, \"epoch\": 3, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.02941189706325531}, {\"channel\": 5, \"epoch\": 3, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.030612144619226456}, {\"channel\": 6, \"epoch\": 3, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.021113580092787743}, {\"channel\": 7, \"epoch\": 3, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.03657232224941254}, {\"channel\": 8, \"epoch\": 3, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.03250058740377426}, {\"channel\": 1, \"epoch\": 3, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.6869210600852966}, {\"channel\": 2, \"epoch\": 3, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.69597327709198}, {\"channel\": 3, \"epoch\": 3, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.6842336058616638}, {\"channel\": 4, \"epoch\": 3, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.696343719959259}, {\"channel\": 5, \"epoch\": 3, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.6890844106674194}, {\"channel\": 6, \"epoch\": 3, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.6823617815971375}, {\"channel\": 7, \"epoch\": 3, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.6518456935882568}, {\"channel\": 8, \"epoch\": 3, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.7070213556289673}, {\"channel\": 1, \"epoch\": 3, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.0351502001285553}, {\"channel\": 2, \"epoch\": 3, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.0453764908015728}, {\"channel\": 3, \"epoch\": 3, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.03584017604589462}, {\"channel\": 4, \"epoch\": 3, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.031741514801979065}, {\"channel\": 5, \"epoch\": 3, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.04788115620613098}, {\"channel\": 6, \"epoch\": 3, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.04597334936261177}, {\"channel\": 7, \"epoch\": 3, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.05705566331744194}, {\"channel\": 8, \"epoch\": 3, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.058992899954319}, {\"channel\": 1, \"epoch\": 3, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.7219601273536682}, {\"channel\": 2, \"epoch\": 3, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.7062500715255737}, {\"channel\": 3, \"epoch\": 3, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.7132465839385986}, {\"channel\": 4, \"epoch\": 3, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.715587854385376}, {\"channel\": 5, \"epoch\": 3, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.6970887184143066}, {\"channel\": 6, \"epoch\": 3, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.7016944289207458}, {\"channel\": 7, \"epoch\": 3, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.702954888343811}, {\"channel\": 8, \"epoch\": 3, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.7054969072341919}, {\"channel\": 1, \"epoch\": 3, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.031226353719830513}, {\"channel\": 2, \"epoch\": 3, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.006741435267031193}, {\"channel\": 3, \"epoch\": 3, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.005696479231119156}, {\"channel\": 4, \"epoch\": 3, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.00860403198748827}, {\"channel\": 5, \"epoch\": 3, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.012420005165040493}, {\"channel\": 6, \"epoch\": 3, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.012847315520048141}, {\"channel\": 7, \"epoch\": 3, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.009772726334631443}, {\"channel\": 8, \"epoch\": 3, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.009482736699283123}, {\"channel\": 1, \"epoch\": 3, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.697510838508606}, {\"channel\": 2, \"epoch\": 3, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.7132100462913513}, {\"channel\": 3, \"epoch\": 3, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.6911759376525879}, {\"channel\": 4, \"epoch\": 3, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.7209305763244629}, {\"channel\": 5, \"epoch\": 3, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.7041676044464111}, {\"channel\": 6, \"epoch\": 3, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.6940100789070129}, {\"channel\": 7, \"epoch\": 3, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.7191281914710999}, {\"channel\": 8, \"epoch\": 3, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.7266228199005127}, {\"channel\": 1, \"epoch\": 3, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.0163991991430521}, {\"channel\": 2, \"epoch\": 3, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.02231920324265957}, {\"channel\": 3, \"epoch\": 3, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.018431032076478004}, {\"channel\": 4, \"epoch\": 3, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.02392766997218132}, {\"channel\": 5, \"epoch\": 3, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.01985788531601429}, {\"channel\": 6, \"epoch\": 3, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.019992973655462265}, {\"channel\": 7, \"epoch\": 3, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.024799175560474396}, {\"channel\": 8, \"epoch\": 3, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.029290568083524704}, {\"channel\": 1, \"epoch\": 4, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.5827886462211609}, {\"channel\": 2, \"epoch\": 4, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.5550310015678406}, {\"channel\": 3, \"epoch\": 4, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.3354262113571167}, {\"channel\": 4, \"epoch\": 4, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.39285793900489807}, {\"channel\": 5, \"epoch\": 4, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.36107248067855835}, {\"channel\": 6, \"epoch\": 4, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.42170020937919617}, {\"channel\": 7, \"epoch\": 4, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.6634990572929382}, {\"channel\": 8, \"epoch\": 4, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.5434971451759338}, {\"channel\": 1, \"epoch\": 4, \"layer\": \"prep\", \"type\": \"bias\", \"value\": 0.19358105957508087}, {\"channel\": 2, \"epoch\": 4, \"layer\": \"prep\", \"type\": \"bias\", \"value\": 0.05473749339580536}, {\"channel\": 3, \"epoch\": 4, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.20862552523612976}, {\"channel\": 4, \"epoch\": 4, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.1470022350549698}, {\"channel\": 5, \"epoch\": 4, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.10354627668857574}, {\"channel\": 6, \"epoch\": 4, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.03790421783924103}, {\"channel\": 7, \"epoch\": 4, \"layer\": \"prep\", \"type\": \"bias\", \"value\": 0.45810583233833313}, {\"channel\": 8, \"epoch\": 4, \"layer\": \"prep\", \"type\": \"bias\", \"value\": 0.018856996670365334}, {\"channel\": 1, \"epoch\": 4, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.4291445016860962}, {\"channel\": 2, \"epoch\": 4, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.5434869527816772}, {\"channel\": 3, \"epoch\": 4, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.5794706344604492}, {\"channel\": 4, \"epoch\": 4, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.44638535380363464}, {\"channel\": 5, \"epoch\": 4, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.5417755842208862}, {\"channel\": 6, \"epoch\": 4, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.5367536544799805}, {\"channel\": 7, \"epoch\": 4, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.6424243450164795}, {\"channel\": 8, \"epoch\": 4, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.5510595440864563}, {\"channel\": 1, \"epoch\": 4, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.11725765466690063}, {\"channel\": 2, \"epoch\": 4, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.07888609915971756}, {\"channel\": 3, \"epoch\": 4, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.013413313776254654}, {\"channel\": 4, \"epoch\": 4, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.07363274693489075}, {\"channel\": 5, \"epoch\": 4, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": 0.0700521469116211}, {\"channel\": 6, \"epoch\": 4, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.08253869414329529}, {\"channel\": 7, \"epoch\": 4, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": 0.27641573548316956}, {\"channel\": 8, \"epoch\": 4, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.05543728917837143}, {\"channel\": 1, \"epoch\": 4, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.497670978307724}, {\"channel\": 2, \"epoch\": 4, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.5134530663490295}, {\"channel\": 3, \"epoch\": 4, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.5273374915122986}, {\"channel\": 4, \"epoch\": 4, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.5713701844215393}, {\"channel\": 5, \"epoch\": 4, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.480459988117218}, {\"channel\": 6, \"epoch\": 4, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.5693064332008362}, {\"channel\": 7, \"epoch\": 4, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.48919856548309326}, {\"channel\": 8, \"epoch\": 4, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.5157291293144226}, {\"channel\": 1, \"epoch\": 4, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.07941866666078568}, {\"channel\": 2, \"epoch\": 4, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.05817272886633873}, {\"channel\": 3, \"epoch\": 4, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.06965941190719604}, {\"channel\": 4, \"epoch\": 4, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.07370119541883469}, {\"channel\": 5, \"epoch\": 4, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.07833030074834824}, {\"channel\": 6, \"epoch\": 4, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.04447667673230171}, {\"channel\": 7, \"epoch\": 4, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.0844968631863594}, {\"channel\": 8, \"epoch\": 4, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.06250088661909103}, {\"channel\": 1, \"epoch\": 4, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.5707847476005554}, {\"channel\": 2, \"epoch\": 4, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.5798195600509644}, {\"channel\": 3, \"epoch\": 4, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.5453053116798401}, {\"channel\": 4, \"epoch\": 4, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.5407477021217346}, {\"channel\": 5, \"epoch\": 4, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.5560902953147888}, {\"channel\": 6, \"epoch\": 4, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.5453123450279236}, {\"channel\": 7, \"epoch\": 4, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.5102490186691284}, {\"channel\": 8, \"epoch\": 4, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.5146540403366089}, {\"channel\": 1, \"epoch\": 4, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.0737861767411232}, {\"channel\": 2, \"epoch\": 4, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.1133265495300293}, {\"channel\": 3, \"epoch\": 4, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.04957727715373039}, {\"channel\": 4, \"epoch\": 4, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.02199270948767662}, {\"channel\": 5, \"epoch\": 4, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.027225425466895103}, {\"channel\": 6, \"epoch\": 4, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.07234732061624527}, {\"channel\": 7, \"epoch\": 4, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.05381517484784126}, {\"channel\": 8, \"epoch\": 4, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.05967958644032478}, {\"channel\": 1, \"epoch\": 4, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.5720621347427368}, {\"channel\": 2, \"epoch\": 4, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.5297632217407227}, {\"channel\": 3, \"epoch\": 4, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.5732566118240356}, {\"channel\": 4, \"epoch\": 4, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.5293118953704834}, {\"channel\": 5, \"epoch\": 4, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.4731914699077606}, {\"channel\": 6, \"epoch\": 4, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.5619349479675293}, {\"channel\": 7, \"epoch\": 4, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.5701722502708435}, {\"channel\": 8, \"epoch\": 4, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.49877411127090454}, {\"channel\": 1, \"epoch\": 4, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.048515014350414276}, {\"channel\": 2, \"epoch\": 4, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.04666511341929436}, {\"channel\": 3, \"epoch\": 4, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.06573285162448883}, {\"channel\": 4, \"epoch\": 4, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.05043889582157135}, {\"channel\": 5, \"epoch\": 4, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.07210598886013031}, {\"channel\": 6, \"epoch\": 4, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.06688437610864639}, {\"channel\": 7, \"epoch\": 4, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.08295270800590515}, {\"channel\": 8, \"epoch\": 4, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.04660875350236893}, {\"channel\": 1, \"epoch\": 4, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.5162686705589294}, {\"channel\": 2, \"epoch\": 4, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.5400245189666748}, {\"channel\": 3, \"epoch\": 4, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.5279766321182251}, {\"channel\": 4, \"epoch\": 4, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.5439353585243225}, {\"channel\": 5, \"epoch\": 4, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.5167180299758911}, {\"channel\": 6, \"epoch\": 4, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.5513333082199097}, {\"channel\": 7, \"epoch\": 4, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.4711788296699524}, {\"channel\": 8, \"epoch\": 4, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.5683996081352234}, {\"channel\": 1, \"epoch\": 4, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.06707353889942169}, {\"channel\": 2, \"epoch\": 4, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.07748455554246902}, {\"channel\": 3, \"epoch\": 4, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.06690224260091782}, {\"channel\": 4, \"epoch\": 4, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.07421403378248215}, {\"channel\": 5, \"epoch\": 4, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.08071450144052505}, {\"channel\": 6, \"epoch\": 4, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.06945710629224777}, {\"channel\": 7, \"epoch\": 4, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.10671515762805939}, {\"channel\": 8, \"epoch\": 4, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.10793273895978928}, {\"channel\": 1, \"epoch\": 4, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.5624366402626038}, {\"channel\": 2, \"epoch\": 4, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.5311800837516785}, {\"channel\": 3, \"epoch\": 4, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.540137529373169}, {\"channel\": 4, \"epoch\": 4, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.5518968105316162}, {\"channel\": 5, \"epoch\": 4, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.5224797129631042}, {\"channel\": 6, \"epoch\": 4, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.5309687852859497}, {\"channel\": 7, \"epoch\": 4, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.5332596898078918}, {\"channel\": 8, \"epoch\": 4, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.5269200801849365}, {\"channel\": 1, \"epoch\": 4, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.06816844642162323}, {\"channel\": 2, \"epoch\": 4, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.023915870115160942}, {\"channel\": 3, \"epoch\": 4, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.02041335590183735}, {\"channel\": 4, \"epoch\": 4, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.02283254638314247}, {\"channel\": 5, \"epoch\": 4, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.03386419266462326}, {\"channel\": 6, \"epoch\": 4, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.02770768478512764}, {\"channel\": 7, \"epoch\": 4, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.025880450382828712}, {\"channel\": 8, \"epoch\": 4, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.029803629964590073}, {\"channel\": 1, \"epoch\": 4, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.5480397939682007}, {\"channel\": 2, \"epoch\": 4, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.5962249636650085}, {\"channel\": 3, \"epoch\": 4, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.5252311825752258}, {\"channel\": 4, \"epoch\": 4, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.5961269736289978}, {\"channel\": 5, \"epoch\": 4, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.5574705004692078}, {\"channel\": 6, \"epoch\": 4, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.5463911890983582}, {\"channel\": 7, \"epoch\": 4, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.5753901600837708}, {\"channel\": 8, \"epoch\": 4, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.6025909185409546}, {\"channel\": 1, \"epoch\": 4, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.0204190444201231}, {\"channel\": 2, \"epoch\": 4, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.029101258143782616}, {\"channel\": 3, \"epoch\": 4, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.024434799328446388}, {\"channel\": 4, \"epoch\": 4, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.04017652943730354}, {\"channel\": 5, \"epoch\": 4, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.027464376762509346}, {\"channel\": 6, \"epoch\": 4, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.030353622511029243}, {\"channel\": 7, \"epoch\": 4, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.0405869260430336}, {\"channel\": 8, \"epoch\": 4, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.046893052756786346}, {\"channel\": 1, \"epoch\": 5, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.41758081316947937}, {\"channel\": 2, \"epoch\": 5, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.4808346927165985}, {\"channel\": 3, \"epoch\": 5, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.28128042817115784}, {\"channel\": 4, \"epoch\": 5, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.2574103772640228}, {\"channel\": 5, \"epoch\": 5, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.25621265172958374}, {\"channel\": 6, \"epoch\": 5, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.2909107506275177}, {\"channel\": 7, \"epoch\": 5, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.5956870913505554}, {\"channel\": 8, \"epoch\": 5, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.4467284083366394}, {\"channel\": 1, \"epoch\": 5, \"layer\": \"prep\", \"type\": \"bias\", \"value\": 0.15020594000816345}, {\"channel\": 2, \"epoch\": 5, \"layer\": \"prep\", \"type\": \"bias\", \"value\": 0.006131828296929598}, {\"channel\": 3, \"epoch\": 5, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.1941041797399521}, {\"channel\": 4, \"epoch\": 5, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.12449247390031815}, {\"channel\": 5, \"epoch\": 5, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.1601637750864029}, {\"channel\": 6, \"epoch\": 5, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.069737009704113}, {\"channel\": 7, \"epoch\": 5, \"layer\": \"prep\", \"type\": \"bias\", \"value\": 0.38990268111228943}, {\"channel\": 8, \"epoch\": 5, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.008737480267882347}, {\"channel\": 1, \"epoch\": 5, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.3563147783279419}, {\"channel\": 2, \"epoch\": 5, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.39330437779426575}, {\"channel\": 3, \"epoch\": 5, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.464937686920166}, {\"channel\": 4, \"epoch\": 5, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.32392746210098267}, {\"channel\": 5, \"epoch\": 5, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.3763456642627716}, {\"channel\": 6, \"epoch\": 5, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.3844153583049774}, {\"channel\": 7, \"epoch\": 5, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.5032069087028503}, {\"channel\": 8, \"epoch\": 5, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.38513582944869995}, {\"channel\": 1, \"epoch\": 5, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.06270453333854675}, {\"channel\": 2, \"epoch\": 5, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.051631368696689606}, {\"channel\": 3, \"epoch\": 5, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.03086986392736435}, {\"channel\": 4, \"epoch\": 5, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.08275586366653442}, {\"channel\": 5, \"epoch\": 5, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": 0.03982720524072647}, {\"channel\": 6, \"epoch\": 5, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.11371257901191711}, {\"channel\": 7, \"epoch\": 5, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": 0.2257923036813736}, {\"channel\": 8, \"epoch\": 5, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.06588669866323471}, {\"channel\": 1, \"epoch\": 5, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.35125571489334106}, {\"channel\": 2, \"epoch\": 5, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.3679952323436737}, {\"channel\": 3, \"epoch\": 5, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.39944201707839966}, {\"channel\": 4, \"epoch\": 5, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.45950090885162354}, {\"channel\": 5, \"epoch\": 5, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.34934794902801514}, {\"channel\": 6, \"epoch\": 5, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.4625084698200226}, {\"channel\": 7, \"epoch\": 5, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.37253043055534363}, {\"channel\": 8, \"epoch\": 5, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.4016167223453522}, {\"channel\": 1, \"epoch\": 5, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.10181162506341934}, {\"channel\": 2, \"epoch\": 5, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.10160662233829498}, {\"channel\": 3, \"epoch\": 5, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.08480530232191086}, {\"channel\": 4, \"epoch\": 5, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.13825704157352448}, {\"channel\": 5, \"epoch\": 5, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.0909518375992775}, {\"channel\": 6, \"epoch\": 5, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.07772211730480194}, {\"channel\": 7, \"epoch\": 5, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.09227053821086884}, {\"channel\": 8, \"epoch\": 5, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.0803527906537056}, {\"channel\": 1, \"epoch\": 5, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.5077861547470093}, {\"channel\": 2, \"epoch\": 5, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.4991675913333893}, {\"channel\": 3, \"epoch\": 5, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.42955875396728516}, {\"channel\": 4, \"epoch\": 5, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.43428146839141846}, {\"channel\": 5, \"epoch\": 5, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.4074590802192688}, {\"channel\": 6, \"epoch\": 5, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.406109482049942}, {\"channel\": 7, \"epoch\": 5, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.3334336280822754}, {\"channel\": 8, \"epoch\": 5, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.4074382781982422}, {\"channel\": 1, \"epoch\": 5, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.12267805635929108}, {\"channel\": 2, \"epoch\": 5, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.17174194753170013}, {\"channel\": 3, \"epoch\": 5, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.05908771604299545}, {\"channel\": 4, \"epoch\": 5, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.039135418832302094}, {\"channel\": 5, \"epoch\": 5, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.044986430555582047}, {\"channel\": 6, \"epoch\": 5, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.13562949001789093}, {\"channel\": 7, \"epoch\": 5, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.10841700434684753}, {\"channel\": 8, \"epoch\": 5, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.0619799941778183}, {\"channel\": 1, \"epoch\": 5, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.4345496594905853}, {\"channel\": 2, \"epoch\": 5, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.43034711480140686}, {\"channel\": 3, \"epoch\": 5, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.4600743055343628}, {\"channel\": 4, \"epoch\": 5, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.4327629506587982}, {\"channel\": 5, \"epoch\": 5, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.35551416873931885}, {\"channel\": 6, \"epoch\": 5, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.4578344225883484}, {\"channel\": 7, \"epoch\": 5, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.46471163630485535}, {\"channel\": 8, \"epoch\": 5, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.40140628814697266}, {\"channel\": 1, \"epoch\": 5, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.08683544397354126}, {\"channel\": 2, \"epoch\": 5, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.0867198184132576}, {\"channel\": 3, \"epoch\": 5, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.08588285744190216}, {\"channel\": 4, \"epoch\": 5, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.04695777967572212}, {\"channel\": 5, \"epoch\": 5, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.07271484285593033}, {\"channel\": 6, \"epoch\": 5, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.08409134298563004}, {\"channel\": 7, \"epoch\": 5, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.1063925251364708}, {\"channel\": 8, \"epoch\": 5, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.03969192877411842}, {\"channel\": 1, \"epoch\": 5, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.3821021616458893}, {\"channel\": 2, \"epoch\": 5, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.43851807713508606}, {\"channel\": 3, \"epoch\": 5, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.3985682427883148}, {\"channel\": 4, \"epoch\": 5, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.41986843943595886}, {\"channel\": 5, \"epoch\": 5, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.39934757351875305}, {\"channel\": 6, \"epoch\": 5, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.48673930764198303}, {\"channel\": 7, \"epoch\": 5, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.3259564936161041}, {\"channel\": 8, \"epoch\": 5, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.4621894955635071}, {\"channel\": 1, \"epoch\": 5, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.10832256823778152}, {\"channel\": 2, \"epoch\": 5, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.11005212366580963}, {\"channel\": 3, \"epoch\": 5, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.11488913744688034}, {\"channel\": 4, \"epoch\": 5, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.12173383682966232}, {\"channel\": 5, \"epoch\": 5, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.1118219718337059}, {\"channel\": 6, \"epoch\": 5, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.10312362760305405}, {\"channel\": 7, \"epoch\": 5, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.12859033048152924}, {\"channel\": 8, \"epoch\": 5, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.13590942323207855}, {\"channel\": 1, \"epoch\": 5, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.4357191324234009}, {\"channel\": 2, \"epoch\": 5, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.4030495285987854}, {\"channel\": 3, \"epoch\": 5, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.394229531288147}, {\"channel\": 4, \"epoch\": 5, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.43365776538848877}, {\"channel\": 5, \"epoch\": 5, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.3781299889087677}, {\"channel\": 6, \"epoch\": 5, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.3961338996887207}, {\"channel\": 7, \"epoch\": 5, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.4002441167831421}, {\"channel\": 8, \"epoch\": 5, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.38811686635017395}, {\"channel\": 1, \"epoch\": 5, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.10957400500774384}, {\"channel\": 2, \"epoch\": 5, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.04435979202389717}, {\"channel\": 3, \"epoch\": 5, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.06180049851536751}, {\"channel\": 4, \"epoch\": 5, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.05493181571364403}, {\"channel\": 5, \"epoch\": 5, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.05848166346549988}, {\"channel\": 6, \"epoch\": 5, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.043373748660087585}, {\"channel\": 7, \"epoch\": 5, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.05031329765915871}, {\"channel\": 8, \"epoch\": 5, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.04788370057940483}, {\"channel\": 1, \"epoch\": 5, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.4601626694202423}, {\"channel\": 2, \"epoch\": 5, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.5426028370857239}, {\"channel\": 3, \"epoch\": 5, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.4327232837677002}, {\"channel\": 4, \"epoch\": 5, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.5324947834014893}, {\"channel\": 5, \"epoch\": 5, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.4834538996219635}, {\"channel\": 6, \"epoch\": 5, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.45945417881011963}, {\"channel\": 7, \"epoch\": 5, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.5107887387275696}, {\"channel\": 8, \"epoch\": 5, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.5307719707489014}, {\"channel\": 1, \"epoch\": 5, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.016842862591147423}, {\"channel\": 2, \"epoch\": 5, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.02875056490302086}, {\"channel\": 3, \"epoch\": 5, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.022791817784309387}, {\"channel\": 4, \"epoch\": 5, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.04050159454345703}, {\"channel\": 5, \"epoch\": 5, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.024209532886743546}, {\"channel\": 6, \"epoch\": 5, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.034220773726701736}, {\"channel\": 7, \"epoch\": 5, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.04225727170705795}, {\"channel\": 8, \"epoch\": 5, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.05416933447122574}, {\"channel\": 1, \"epoch\": 6, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.37778815627098083}, {\"channel\": 2, \"epoch\": 6, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.3534640073776245}, {\"channel\": 3, \"epoch\": 6, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.26200759410858154}, {\"channel\": 4, \"epoch\": 6, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.2529049515724182}, {\"channel\": 5, \"epoch\": 6, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.24260006844997406}, {\"channel\": 6, \"epoch\": 6, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.20565249025821686}, {\"channel\": 7, \"epoch\": 6, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.4754718542098999}, {\"channel\": 8, \"epoch\": 6, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.3402111828327179}, {\"channel\": 1, \"epoch\": 6, \"layer\": \"prep\", \"type\": \"bias\", \"value\": 0.10880248993635178}, {\"channel\": 2, \"epoch\": 6, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.048116154968738556}, {\"channel\": 3, \"epoch\": 6, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.21191944181919098}, {\"channel\": 4, \"epoch\": 6, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.1203354224562645}, {\"channel\": 5, \"epoch\": 6, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.17248694598674774}, {\"channel\": 6, \"epoch\": 6, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.06537080556154251}, {\"channel\": 7, \"epoch\": 6, \"layer\": \"prep\", \"type\": \"bias\", \"value\": 0.30232957005500793}, {\"channel\": 8, \"epoch\": 6, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.042996179312467575}, {\"channel\": 1, \"epoch\": 6, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.24463647603988647}, {\"channel\": 2, \"epoch\": 6, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.3292016088962555}, {\"channel\": 3, \"epoch\": 6, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.3781604468822479}, {\"channel\": 4, \"epoch\": 6, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.257790744304657}, {\"channel\": 5, \"epoch\": 6, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.3192427158355713}, {\"channel\": 6, \"epoch\": 6, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.33177322149276733}, {\"channel\": 7, \"epoch\": 6, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.41032734513282776}, {\"channel\": 8, \"epoch\": 6, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.3352511525154114}, {\"channel\": 1, \"epoch\": 6, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.05563177168369293}, {\"channel\": 2, \"epoch\": 6, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.14689454436302185}, {\"channel\": 3, \"epoch\": 6, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.06743042916059494}, {\"channel\": 4, \"epoch\": 6, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.07019039243459702}, {\"channel\": 5, \"epoch\": 6, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": 0.03538431599736214}, {\"channel\": 6, \"epoch\": 6, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.09476305544376373}, {\"channel\": 7, \"epoch\": 6, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": 0.16530078649520874}, {\"channel\": 8, \"epoch\": 6, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.05077781155705452}, {\"channel\": 1, \"epoch\": 6, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.2613937556743622}, {\"channel\": 2, \"epoch\": 6, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.30232369899749756}, {\"channel\": 3, \"epoch\": 6, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.2926934063434601}, {\"channel\": 4, \"epoch\": 6, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.3683917820453644}, {\"channel\": 5, \"epoch\": 6, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.2636452615261078}, {\"channel\": 6, \"epoch\": 6, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.35731372237205505}, {\"channel\": 7, \"epoch\": 6, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.3018038272857666}, {\"channel\": 8, \"epoch\": 6, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.30093130469322205}, {\"channel\": 1, \"epoch\": 6, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.11937639117240906}, {\"channel\": 2, \"epoch\": 6, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.09756835550069809}, {\"channel\": 3, \"epoch\": 6, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.12275400012731552}, {\"channel\": 4, \"epoch\": 6, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.14042744040489197}, {\"channel\": 5, \"epoch\": 6, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.11151864379644394}, {\"channel\": 6, \"epoch\": 6, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.09083240479230881}, {\"channel\": 7, \"epoch\": 6, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.12999755144119263}, {\"channel\": 8, \"epoch\": 6, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.10599984228610992}, {\"channel\": 1, \"epoch\": 6, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.4327298402786255}, {\"channel\": 2, \"epoch\": 6, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.45016905665397644}, {\"channel\": 3, \"epoch\": 6, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.39344146847724915}, {\"channel\": 4, \"epoch\": 6, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.38039708137512207}, {\"channel\": 5, \"epoch\": 6, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.33359888195991516}, {\"channel\": 6, \"epoch\": 6, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.38729798793792725}, {\"channel\": 7, \"epoch\": 6, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.26665037870407104}, {\"channel\": 8, \"epoch\": 6, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.3262254297733307}, {\"channel\": 1, \"epoch\": 6, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.13395367562770844}, {\"channel\": 2, \"epoch\": 6, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.16211865842342377}, {\"channel\": 3, \"epoch\": 6, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.023777473717927933}, {\"channel\": 4, \"epoch\": 6, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.05239095911383629}, {\"channel\": 5, \"epoch\": 6, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.020565202459692955}, {\"channel\": 6, \"epoch\": 6, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.10311996936798096}, {\"channel\": 7, \"epoch\": 6, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.12482526898384094}, {\"channel\": 8, \"epoch\": 6, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.0737224742770195}, {\"channel\": 1, \"epoch\": 6, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.3613724112510681}, {\"channel\": 2, \"epoch\": 6, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.34723329544067383}, {\"channel\": 3, \"epoch\": 6, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.3358418941497803}, {\"channel\": 4, \"epoch\": 6, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.35023489594459534}, {\"channel\": 5, \"epoch\": 6, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.3254329562187195}, {\"channel\": 6, \"epoch\": 6, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.3518010079860687}, {\"channel\": 7, \"epoch\": 6, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.34350553154945374}, {\"channel\": 8, \"epoch\": 6, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.3148762285709381}, {\"channel\": 1, \"epoch\": 6, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.08619920909404755}, {\"channel\": 2, \"epoch\": 6, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.10800669342279434}, {\"channel\": 3, \"epoch\": 6, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.14170075953006744}, {\"channel\": 4, \"epoch\": 6, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.0536862276494503}, {\"channel\": 5, \"epoch\": 6, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.05617813766002655}, {\"channel\": 6, \"epoch\": 6, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.16203489899635315}, {\"channel\": 7, \"epoch\": 6, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.12437669187784195}, {\"channel\": 8, \"epoch\": 6, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.042698800563812256}, {\"channel\": 1, \"epoch\": 6, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.3307490050792694}, {\"channel\": 2, \"epoch\": 6, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.37053823471069336}, {\"channel\": 3, \"epoch\": 6, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.31989750266075134}, {\"channel\": 4, \"epoch\": 6, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.3736174404621124}, {\"channel\": 5, \"epoch\": 6, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.3299369215965271}, {\"channel\": 6, \"epoch\": 6, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.40569737553596497}, {\"channel\": 7, \"epoch\": 6, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.24531392753124237}, {\"channel\": 8, \"epoch\": 6, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.4206608831882477}, {\"channel\": 1, \"epoch\": 6, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.10639563947916031}, {\"channel\": 2, \"epoch\": 6, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.12434135377407074}, {\"channel\": 3, \"epoch\": 6, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.14963367581367493}, {\"channel\": 4, \"epoch\": 6, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.155521959066391}, {\"channel\": 5, \"epoch\": 6, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.11089416593313217}, {\"channel\": 6, \"epoch\": 6, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.147218719124794}, {\"channel\": 7, \"epoch\": 6, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.13630209863185883}, {\"channel\": 8, \"epoch\": 6, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.15195418894290924}, {\"channel\": 1, \"epoch\": 6, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.3332684338092804}, {\"channel\": 2, \"epoch\": 6, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.3132894039154053}, {\"channel\": 3, \"epoch\": 6, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.3016197085380554}, {\"channel\": 4, \"epoch\": 6, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.3485424220561981}, {\"channel\": 5, \"epoch\": 6, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.2813853621482849}, {\"channel\": 6, \"epoch\": 6, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.3073607087135315}, {\"channel\": 7, \"epoch\": 6, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.3163268566131592}, {\"channel\": 8, \"epoch\": 6, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.2898297905921936}, {\"channel\": 1, \"epoch\": 6, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.14161929488182068}, {\"channel\": 2, \"epoch\": 6, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.06118544191122055}, {\"channel\": 3, \"epoch\": 6, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.09295009821653366}, {\"channel\": 4, \"epoch\": 6, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.08872281759977341}, {\"channel\": 5, \"epoch\": 6, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.061213839799165726}, {\"channel\": 6, \"epoch\": 6, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.06537023186683655}, {\"channel\": 7, \"epoch\": 6, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.07844582945108414}, {\"channel\": 8, \"epoch\": 6, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.0630372017621994}, {\"channel\": 1, \"epoch\": 6, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.41773051023483276}, {\"channel\": 2, \"epoch\": 6, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.5217439532279968}, {\"channel\": 3, \"epoch\": 6, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.3911822438240051}, {\"channel\": 4, \"epoch\": 6, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.5000271201133728}, {\"channel\": 5, \"epoch\": 6, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.44096294045448303}, {\"channel\": 6, \"epoch\": 6, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.4221321940422058}, {\"channel\": 7, \"epoch\": 6, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.47282037138938904}, {\"channel\": 8, \"epoch\": 6, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.5086302757263184}, {\"channel\": 1, \"epoch\": 6, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.015728507190942764}, {\"channel\": 2, \"epoch\": 6, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.031329408288002014}, {\"channel\": 3, \"epoch\": 6, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.018881449475884438}, {\"channel\": 4, \"epoch\": 6, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.036864541471004486}, {\"channel\": 5, \"epoch\": 6, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.023016709834337234}, {\"channel\": 6, \"epoch\": 6, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.031092245131731033}, {\"channel\": 7, \"epoch\": 6, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.041573911905288696}, {\"channel\": 8, \"epoch\": 6, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.0514041967689991}, {\"channel\": 1, \"epoch\": 7, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.3533921539783478}, {\"channel\": 2, \"epoch\": 7, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.2745285928249359}, {\"channel\": 3, \"epoch\": 7, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.22737431526184082}, {\"channel\": 4, \"epoch\": 7, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.23948538303375244}, {\"channel\": 5, \"epoch\": 7, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.20038217306137085}, {\"channel\": 6, \"epoch\": 7, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.1881997287273407}, {\"channel\": 7, \"epoch\": 7, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.44857409596443176}, {\"channel\": 8, \"epoch\": 7, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.33073118329048157}, {\"channel\": 1, \"epoch\": 7, \"layer\": \"prep\", \"type\": \"bias\", \"value\": 0.07168466597795486}, {\"channel\": 2, \"epoch\": 7, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.009769512340426445}, {\"channel\": 3, \"epoch\": 7, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.20844422280788422}, {\"channel\": 4, \"epoch\": 7, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.11883312463760376}, {\"channel\": 5, \"epoch\": 7, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.09691895544528961}, {\"channel\": 6, \"epoch\": 7, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.029579248279333115}, {\"channel\": 7, \"epoch\": 7, \"layer\": \"prep\", \"type\": \"bias\", \"value\": 0.3402157425880432}, {\"channel\": 8, \"epoch\": 7, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.03433477506041527}, {\"channel\": 1, \"epoch\": 7, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.20625843107700348}, {\"channel\": 2, \"epoch\": 7, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.3052409291267395}, {\"channel\": 3, \"epoch\": 7, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.3536475896835327}, {\"channel\": 4, \"epoch\": 7, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.20613764226436615}, {\"channel\": 5, \"epoch\": 7, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.18649055063724518}, {\"channel\": 6, \"epoch\": 7, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.30782845616340637}, {\"channel\": 7, \"epoch\": 7, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.3155395984649658}, {\"channel\": 8, \"epoch\": 7, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.3173738718032837}, {\"channel\": 1, \"epoch\": 7, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.04455951601266861}, {\"channel\": 2, \"epoch\": 7, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.09226177632808685}, {\"channel\": 3, \"epoch\": 7, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.030380774289369583}, {\"channel\": 4, \"epoch\": 7, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.06054844707250595}, {\"channel\": 5, \"epoch\": 7, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": 0.08359377086162567}, {\"channel\": 6, \"epoch\": 7, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.09616714715957642}, {\"channel\": 7, \"epoch\": 7, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": 0.16263754665851593}, {\"channel\": 8, \"epoch\": 7, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.06485246866941452}, {\"channel\": 1, \"epoch\": 7, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.21494118869304657}, {\"channel\": 2, \"epoch\": 7, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.19943343102931976}, {\"channel\": 3, \"epoch\": 7, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.2660529613494873}, {\"channel\": 4, \"epoch\": 7, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.3114280104637146}, {\"channel\": 5, \"epoch\": 7, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.2455422431230545}, {\"channel\": 6, \"epoch\": 7, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.30987390875816345}, {\"channel\": 7, \"epoch\": 7, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.24727840721607208}, {\"channel\": 8, \"epoch\": 7, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.2606384754180908}, {\"channel\": 1, \"epoch\": 7, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.10797113925218582}, {\"channel\": 2, \"epoch\": 7, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.12973757088184357}, {\"channel\": 3, \"epoch\": 7, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.11526886373758316}, {\"channel\": 4, \"epoch\": 7, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.15628239512443542}, {\"channel\": 5, \"epoch\": 7, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.11055823415517807}, {\"channel\": 6, \"epoch\": 7, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.08713597059249878}, {\"channel\": 7, \"epoch\": 7, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.13356393575668335}, {\"channel\": 8, \"epoch\": 7, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.10280515998601913}, {\"channel\": 1, \"epoch\": 7, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.3835723400115967}, {\"channel\": 2, \"epoch\": 7, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.3970668613910675}, {\"channel\": 3, \"epoch\": 7, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.35226574540138245}, {\"channel\": 4, \"epoch\": 7, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.3234792649745941}, {\"channel\": 5, \"epoch\": 7, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.2934715747833252}, {\"channel\": 6, \"epoch\": 7, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.3356838822364807}, {\"channel\": 7, \"epoch\": 7, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.2211971879005432}, {\"channel\": 8, \"epoch\": 7, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.2963380813598633}, {\"channel\": 1, \"epoch\": 7, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.14869588613510132}, {\"channel\": 2, \"epoch\": 7, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.16746193170547485}, {\"channel\": 3, \"epoch\": 7, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.035867225378751755}, {\"channel\": 4, \"epoch\": 7, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.0523962676525116}, {\"channel\": 5, \"epoch\": 7, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.013170263729989529}, {\"channel\": 6, \"epoch\": 7, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.1423778533935547}, {\"channel\": 7, \"epoch\": 7, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.1355924755334854}, {\"channel\": 8, \"epoch\": 7, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.07072379440069199}, {\"channel\": 1, \"epoch\": 7, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.24944379925727844}, {\"channel\": 2, \"epoch\": 7, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.3044445812702179}, {\"channel\": 3, \"epoch\": 7, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.29819533228874207}, {\"channel\": 4, \"epoch\": 7, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.2991437315940857}, {\"channel\": 5, \"epoch\": 7, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.20848850905895233}, {\"channel\": 6, \"epoch\": 7, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.30275195837020874}, {\"channel\": 7, \"epoch\": 7, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.2799411714076996}, {\"channel\": 8, \"epoch\": 7, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.2870538532733917}, {\"channel\": 1, \"epoch\": 7, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.11131352186203003}, {\"channel\": 2, \"epoch\": 7, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.12983782589435577}, {\"channel\": 3, \"epoch\": 7, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.14453011751174927}, {\"channel\": 4, \"epoch\": 7, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.09337912499904633}, {\"channel\": 5, \"epoch\": 7, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.10381247103214264}, {\"channel\": 6, \"epoch\": 7, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.15046627819538116}, {\"channel\": 7, \"epoch\": 7, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.141160786151886}, {\"channel\": 8, \"epoch\": 7, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.08277279883623123}, {\"channel\": 1, \"epoch\": 7, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.26146990060806274}, {\"channel\": 2, \"epoch\": 7, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.342814177274704}, {\"channel\": 3, \"epoch\": 7, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.2846754789352417}, {\"channel\": 4, \"epoch\": 7, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.31580686569213867}, {\"channel\": 5, \"epoch\": 7, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.2777591347694397}, {\"channel\": 6, \"epoch\": 7, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.38452500104904175}, {\"channel\": 7, \"epoch\": 7, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.22247038781642914}, {\"channel\": 8, \"epoch\": 7, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.3809256851673126}, {\"channel\": 1, \"epoch\": 7, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.11601169407367706}, {\"channel\": 2, \"epoch\": 7, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.11991933733224869}, {\"channel\": 3, \"epoch\": 7, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.14176122844219208}, {\"channel\": 4, \"epoch\": 7, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.18907228112220764}, {\"channel\": 5, \"epoch\": 7, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.12596645951271057}, {\"channel\": 6, \"epoch\": 7, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.1733139008283615}, {\"channel\": 7, \"epoch\": 7, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.13651219010353088}, {\"channel\": 8, \"epoch\": 7, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.18351000547409058}, {\"channel\": 1, \"epoch\": 7, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.28592580556869507}, {\"channel\": 2, \"epoch\": 7, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.2430824339389801}, {\"channel\": 3, \"epoch\": 7, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.23189133405685425}, {\"channel\": 4, \"epoch\": 7, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.2776373624801636}, {\"channel\": 5, \"epoch\": 7, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.19554503262043}, {\"channel\": 6, \"epoch\": 7, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.2394658476114273}, {\"channel\": 7, \"epoch\": 7, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.24631470441818237}, {\"channel\": 8, \"epoch\": 7, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.21352753043174744}, {\"channel\": 1, \"epoch\": 7, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.16952002048492432}, {\"channel\": 2, \"epoch\": 7, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.08200330287218094}, {\"channel\": 3, \"epoch\": 7, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.12772385776042938}, {\"channel\": 4, \"epoch\": 7, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.12660878896713257}, {\"channel\": 5, \"epoch\": 7, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.08059307932853699}, {\"channel\": 6, \"epoch\": 7, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.09425777941942215}, {\"channel\": 7, \"epoch\": 7, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.10536079108715057}, {\"channel\": 8, \"epoch\": 7, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.0847918838262558}, {\"channel\": 1, \"epoch\": 7, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.3914446532726288}, {\"channel\": 2, \"epoch\": 7, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.5106095671653748}, {\"channel\": 3, \"epoch\": 7, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.35763663053512573}, {\"channel\": 4, \"epoch\": 7, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.4941059350967407}, {\"channel\": 5, \"epoch\": 7, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.4257100522518158}, {\"channel\": 6, \"epoch\": 7, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.3942122161388397}, {\"channel\": 7, \"epoch\": 7, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.4633183777332306}, {\"channel\": 8, \"epoch\": 7, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.48499804735183716}, {\"channel\": 1, \"epoch\": 7, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.013161301612854004}, {\"channel\": 2, \"epoch\": 7, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.0316375270485878}, {\"channel\": 3, \"epoch\": 7, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.016867564991116524}, {\"channel\": 4, \"epoch\": 7, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.03724135085940361}, {\"channel\": 5, \"epoch\": 7, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.018549403175711632}, {\"channel\": 6, \"epoch\": 7, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.027739644050598145}, {\"channel\": 7, \"epoch\": 7, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.03788229450583458}, {\"channel\": 8, \"epoch\": 7, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.049008794128894806}, {\"channel\": 1, \"epoch\": 8, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.31921643018722534}, {\"channel\": 2, \"epoch\": 8, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.2689581513404846}, {\"channel\": 3, \"epoch\": 8, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.22060751914978027}, {\"channel\": 4, \"epoch\": 8, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.2261410504579544}, {\"channel\": 5, \"epoch\": 8, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.2468857616186142}, {\"channel\": 6, \"epoch\": 8, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.14056681096553802}, {\"channel\": 7, \"epoch\": 8, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.3875470757484436}, {\"channel\": 8, \"epoch\": 8, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.29621726274490356}, {\"channel\": 1, \"epoch\": 8, \"layer\": \"prep\", \"type\": \"bias\", \"value\": 0.019457532092928886}, {\"channel\": 2, \"epoch\": 8, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.01678038388490677}, {\"channel\": 3, \"epoch\": 8, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.2158718705177307}, {\"channel\": 4, \"epoch\": 8, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.12294166535139084}, {\"channel\": 5, \"epoch\": 8, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.08923210203647614}, {\"channel\": 6, \"epoch\": 8, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.05242474004626274}, {\"channel\": 7, \"epoch\": 8, \"layer\": \"prep\", \"type\": \"bias\", \"value\": 0.277789831161499}, {\"channel\": 8, \"epoch\": 8, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.006657817400991917}, {\"channel\": 1, \"epoch\": 8, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.19444429874420166}, {\"channel\": 2, \"epoch\": 8, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.24513715505599976}, {\"channel\": 3, \"epoch\": 8, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.31540781259536743}, {\"channel\": 4, \"epoch\": 8, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.21117867529392242}, {\"channel\": 5, \"epoch\": 8, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.21087706089019775}, {\"channel\": 6, \"epoch\": 8, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.28670695424079895}, {\"channel\": 7, \"epoch\": 8, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.32762932777404785}, {\"channel\": 8, \"epoch\": 8, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.2624310553073883}, {\"channel\": 1, \"epoch\": 8, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.026183826848864555}, {\"channel\": 2, \"epoch\": 8, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.09862613677978516}, {\"channel\": 3, \"epoch\": 8, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.05558379739522934}, {\"channel\": 4, \"epoch\": 8, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.05337701737880707}, {\"channel\": 5, \"epoch\": 8, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": 0.050967469811439514}, {\"channel\": 6, \"epoch\": 8, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.04737681895494461}, {\"channel\": 7, \"epoch\": 8, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": 0.12871886789798737}, {\"channel\": 8, \"epoch\": 8, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.05698934942483902}, {\"channel\": 1, \"epoch\": 8, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.1850573867559433}, {\"channel\": 2, \"epoch\": 8, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.2023358941078186}, {\"channel\": 3, \"epoch\": 8, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.1987682729959488}, {\"channel\": 4, \"epoch\": 8, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.2641896605491638}, {\"channel\": 5, \"epoch\": 8, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.2156514972448349}, {\"channel\": 6, \"epoch\": 8, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.2710753381252289}, {\"channel\": 7, \"epoch\": 8, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.21575213968753815}, {\"channel\": 8, \"epoch\": 8, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.23182395100593567}, {\"channel\": 1, \"epoch\": 8, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.09711233526468277}, {\"channel\": 2, \"epoch\": 8, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.1268940269947052}, {\"channel\": 3, \"epoch\": 8, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.11103732883930206}, {\"channel\": 4, \"epoch\": 8, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.1556961089372635}, {\"channel\": 5, \"epoch\": 8, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.12810365855693817}, {\"channel\": 6, \"epoch\": 8, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.10406871140003204}, {\"channel\": 7, \"epoch\": 8, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.11831749230623245}, {\"channel\": 8, \"epoch\": 8, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.09969431161880493}, {\"channel\": 1, \"epoch\": 8, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.4047680199146271}, {\"channel\": 2, \"epoch\": 8, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.3816559910774231}, {\"channel\": 3, \"epoch\": 8, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.33825215697288513}, {\"channel\": 4, \"epoch\": 8, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.29807931184768677}, {\"channel\": 5, \"epoch\": 8, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.2378188818693161}, {\"channel\": 6, \"epoch\": 8, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.2909872233867645}, {\"channel\": 7, \"epoch\": 8, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.20084108412265778}, {\"channel\": 8, \"epoch\": 8, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.2900753319263458}, {\"channel\": 1, \"epoch\": 8, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.1583438217639923}, {\"channel\": 2, \"epoch\": 8, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.18430030345916748}, {\"channel\": 3, \"epoch\": 8, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.033682163804769516}, {\"channel\": 4, \"epoch\": 8, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.04618820548057556}, {\"channel\": 5, \"epoch\": 8, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.0623563677072525}, {\"channel\": 6, \"epoch\": 8, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.15089689195156097}, {\"channel\": 7, \"epoch\": 8, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.15410396456718445}, {\"channel\": 8, \"epoch\": 8, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.08277960866689682}, {\"channel\": 1, \"epoch\": 8, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.2604682147502899}, {\"channel\": 2, \"epoch\": 8, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.2714630663394928}, {\"channel\": 3, \"epoch\": 8, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.3110780715942383}, {\"channel\": 4, \"epoch\": 8, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.30009737610816956}, {\"channel\": 5, \"epoch\": 8, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.22534333169460297}, {\"channel\": 6, \"epoch\": 8, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.26897555589675903}, {\"channel\": 7, \"epoch\": 8, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.29235216975212097}, {\"channel\": 8, \"epoch\": 8, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.2821241319179535}, {\"channel\": 1, \"epoch\": 8, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.1031753420829773}, {\"channel\": 2, \"epoch\": 8, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.08743710815906525}, {\"channel\": 3, \"epoch\": 8, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.12801671028137207}, {\"channel\": 4, \"epoch\": 8, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.08736538887023926}, {\"channel\": 5, \"epoch\": 8, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.11931375414133072}, {\"channel\": 6, \"epoch\": 8, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.17864467203617096}, {\"channel\": 7, \"epoch\": 8, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.08895799517631531}, {\"channel\": 8, \"epoch\": 8, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.08895609527826309}, {\"channel\": 1, \"epoch\": 8, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.2501486837863922}, {\"channel\": 2, \"epoch\": 8, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.32499465346336365}, {\"channel\": 3, \"epoch\": 8, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.25473618507385254}, {\"channel\": 4, \"epoch\": 8, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.27623164653778076}, {\"channel\": 5, \"epoch\": 8, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.2620302438735962}, {\"channel\": 6, \"epoch\": 8, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.31659749150276184}, {\"channel\": 7, \"epoch\": 8, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.22638411819934845}, {\"channel\": 8, \"epoch\": 8, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.33152469992637634}, {\"channel\": 1, \"epoch\": 8, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.12383462488651276}, {\"channel\": 2, \"epoch\": 8, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.12417640537023544}, {\"channel\": 3, \"epoch\": 8, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.17185775935649872}, {\"channel\": 4, \"epoch\": 8, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.19136479496955872}, {\"channel\": 5, \"epoch\": 8, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.12038445472717285}, {\"channel\": 6, \"epoch\": 8, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.212754026055336}, {\"channel\": 7, \"epoch\": 8, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.14964886009693146}, {\"channel\": 8, \"epoch\": 8, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.19332456588745117}, {\"channel\": 1, \"epoch\": 8, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.23332001268863678}, {\"channel\": 2, \"epoch\": 8, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.18533508479595184}, {\"channel\": 3, \"epoch\": 8, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.18583011627197266}, {\"channel\": 4, \"epoch\": 8, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.26602330803871155}, {\"channel\": 5, \"epoch\": 8, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.1545453518629074}, {\"channel\": 6, \"epoch\": 8, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.2105826884508133}, {\"channel\": 7, \"epoch\": 8, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.20931677520275116}, {\"channel\": 8, \"epoch\": 8, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.18361611664295197}, {\"channel\": 1, \"epoch\": 8, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.19120270013809204}, {\"channel\": 2, \"epoch\": 8, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.09761293232440948}, {\"channel\": 3, \"epoch\": 8, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.1434081494808197}, {\"channel\": 4, \"epoch\": 8, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.14724718034267426}, {\"channel\": 5, \"epoch\": 8, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.08577442914247513}, {\"channel\": 6, \"epoch\": 8, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.12053680419921875}, {\"channel\": 7, \"epoch\": 8, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.11467831581830978}, {\"channel\": 8, \"epoch\": 8, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.09623083472251892}, {\"channel\": 1, \"epoch\": 8, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.364250510931015}, {\"channel\": 2, \"epoch\": 8, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.5022748708724976}, {\"channel\": 3, \"epoch\": 8, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.35584577918052673}, {\"channel\": 4, \"epoch\": 8, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.48711326718330383}, {\"channel\": 5, \"epoch\": 8, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.4203139543533325}, {\"channel\": 6, \"epoch\": 8, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.4040391743183136}, {\"channel\": 7, \"epoch\": 8, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.4605773687362671}, {\"channel\": 8, \"epoch\": 8, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.46611788868904114}, {\"channel\": 1, \"epoch\": 8, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.01346216257661581}, {\"channel\": 2, \"epoch\": 8, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.03307931870222092}, {\"channel\": 3, \"epoch\": 8, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.016421614214777946}, {\"channel\": 4, \"epoch\": 8, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.03539018705487251}, {\"channel\": 5, \"epoch\": 8, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.013850094750523567}, {\"channel\": 6, \"epoch\": 8, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.024474380537867546}, {\"channel\": 7, \"epoch\": 8, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.0361824557185173}, {\"channel\": 8, \"epoch\": 8, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.04473418742418289}, {\"channel\": 1, \"epoch\": 9, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.3191414773464203}, {\"channel\": 2, \"epoch\": 9, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.26992693543434143}, {\"channel\": 3, \"epoch\": 9, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.22556418180465698}, {\"channel\": 4, \"epoch\": 9, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.23283648490905762}, {\"channel\": 5, \"epoch\": 9, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.2516576647758484}, {\"channel\": 6, \"epoch\": 9, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.13056300580501556}, {\"channel\": 7, \"epoch\": 9, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.4710833430290222}, {\"channel\": 8, \"epoch\": 9, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.2725830674171448}, {\"channel\": 1, \"epoch\": 9, \"layer\": \"prep\", \"type\": \"bias\", \"value\": 0.04727233573794365}, {\"channel\": 2, \"epoch\": 9, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.026754576712846756}, {\"channel\": 3, \"epoch\": 9, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.21895061433315277}, {\"channel\": 4, \"epoch\": 9, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.1413809359073639}, {\"channel\": 5, \"epoch\": 9, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.13784129917621613}, {\"channel\": 6, \"epoch\": 9, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.022566210478544235}, {\"channel\": 7, \"epoch\": 9, \"layer\": \"prep\", \"type\": \"bias\", \"value\": 0.2861937880516052}, {\"channel\": 8, \"epoch\": 9, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.05422172322869301}, {\"channel\": 1, \"epoch\": 9, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.2249372899532318}, {\"channel\": 2, \"epoch\": 9, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.204903706908226}, {\"channel\": 3, \"epoch\": 9, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.29338836669921875}, {\"channel\": 4, \"epoch\": 9, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.2246774286031723}, {\"channel\": 5, \"epoch\": 9, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.2058907449245453}, {\"channel\": 6, \"epoch\": 9, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.2167806476354599}, {\"channel\": 7, \"epoch\": 9, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.2518344521522522}, {\"channel\": 8, \"epoch\": 9, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.2333201915025711}, {\"channel\": 1, \"epoch\": 9, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.02393393963575363}, {\"channel\": 2, \"epoch\": 9, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.13066336512565613}, {\"channel\": 3, \"epoch\": 9, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.030194487422704697}, {\"channel\": 4, \"epoch\": 9, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.07420521229505539}, {\"channel\": 5, \"epoch\": 9, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": 0.06440015137195587}, {\"channel\": 6, \"epoch\": 9, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.09033431112766266}, {\"channel\": 7, \"epoch\": 9, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": 0.1506337821483612}, {\"channel\": 8, \"epoch\": 9, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.05534528195858002}, {\"channel\": 1, \"epoch\": 9, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.16378186643123627}, {\"channel\": 2, \"epoch\": 9, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.20618855953216553}, {\"channel\": 3, \"epoch\": 9, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.19224150478839874}, {\"channel\": 4, \"epoch\": 9, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.24254941940307617}, {\"channel\": 5, \"epoch\": 9, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.19109806418418884}, {\"channel\": 6, \"epoch\": 9, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.2495851218700409}, {\"channel\": 7, \"epoch\": 9, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.22984547913074493}, {\"channel\": 8, \"epoch\": 9, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.24097822606563568}, {\"channel\": 1, \"epoch\": 9, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.10290025174617767}, {\"channel\": 2, \"epoch\": 9, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.12021401524543762}, {\"channel\": 3, \"epoch\": 9, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.09195850044488907}, {\"channel\": 4, \"epoch\": 9, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.16144651174545288}, {\"channel\": 5, \"epoch\": 9, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.1090073511004448}, {\"channel\": 6, \"epoch\": 9, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.08558045327663422}, {\"channel\": 7, \"epoch\": 9, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.08079491555690765}, {\"channel\": 8, \"epoch\": 9, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.11218253523111343}, {\"channel\": 1, \"epoch\": 9, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.416366308927536}, {\"channel\": 2, \"epoch\": 9, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.34804823994636536}, {\"channel\": 3, \"epoch\": 9, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.32460057735443115}, {\"channel\": 4, \"epoch\": 9, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.28822705149650574}, {\"channel\": 5, \"epoch\": 9, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.24386468529701233}, {\"channel\": 6, \"epoch\": 9, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.32034945487976074}, {\"channel\": 7, \"epoch\": 9, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.1777409464120865}, {\"channel\": 8, \"epoch\": 9, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.27103620767593384}, {\"channel\": 1, \"epoch\": 9, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.166946142911911}, {\"channel\": 2, \"epoch\": 9, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.1552448272705078}, {\"channel\": 3, \"epoch\": 9, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.02820155769586563}, {\"channel\": 4, \"epoch\": 9, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.03578101471066475}, {\"channel\": 5, \"epoch\": 9, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.030344467610120773}, {\"channel\": 6, \"epoch\": 9, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.12220937758684158}, {\"channel\": 7, \"epoch\": 9, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.10653813183307648}, {\"channel\": 8, \"epoch\": 9, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.10605045408010483}, {\"channel\": 1, \"epoch\": 9, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.26764801144599915}, {\"channel\": 2, \"epoch\": 9, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.26012060046195984}, {\"channel\": 3, \"epoch\": 9, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.2334233969449997}, {\"channel\": 4, \"epoch\": 9, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.18515262007713318}, {\"channel\": 5, \"epoch\": 9, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.24756474792957306}, {\"channel\": 6, \"epoch\": 9, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.2500775158405304}, {\"channel\": 7, \"epoch\": 9, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.24073843657970428}, {\"channel\": 8, \"epoch\": 9, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.2387758493423462}, {\"channel\": 1, \"epoch\": 9, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.11002252250909805}, {\"channel\": 2, \"epoch\": 9, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.09995473176240921}, {\"channel\": 3, \"epoch\": 9, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.15747328102588654}, {\"channel\": 4, \"epoch\": 9, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.13833752274513245}, {\"channel\": 5, \"epoch\": 9, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.1333639770746231}, {\"channel\": 6, \"epoch\": 9, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.1364099085330963}, {\"channel\": 7, \"epoch\": 9, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.1284656822681427}, {\"channel\": 8, \"epoch\": 9, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.16154971718788147}, {\"channel\": 1, \"epoch\": 9, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.2323731631040573}, {\"channel\": 2, \"epoch\": 9, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.31049051880836487}, {\"channel\": 3, \"epoch\": 9, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.2493465393781662}, {\"channel\": 4, \"epoch\": 9, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.264660120010376}, {\"channel\": 5, \"epoch\": 9, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.2207948863506317}, {\"channel\": 6, \"epoch\": 9, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.2734830975532532}, {\"channel\": 7, \"epoch\": 9, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.17067763209342957}, {\"channel\": 8, \"epoch\": 9, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.2593442499637604}, {\"channel\": 1, \"epoch\": 9, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.14761808514595032}, {\"channel\": 2, \"epoch\": 9, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.1313570737838745}, {\"channel\": 3, \"epoch\": 9, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.18985643982887268}, {\"channel\": 4, \"epoch\": 9, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.18311253190040588}, {\"channel\": 5, \"epoch\": 9, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.1254340261220932}, {\"channel\": 6, \"epoch\": 9, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.2673873007297516}, {\"channel\": 7, \"epoch\": 9, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.175816610455513}, {\"channel\": 8, \"epoch\": 9, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.22024142742156982}, {\"channel\": 1, \"epoch\": 9, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.23400413990020752}, {\"channel\": 2, \"epoch\": 9, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.17673887312412262}, {\"channel\": 3, \"epoch\": 9, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.1952674686908722}, {\"channel\": 4, \"epoch\": 9, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.24169081449508667}, {\"channel\": 5, \"epoch\": 9, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.12512880563735962}, {\"channel\": 6, \"epoch\": 9, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.1892387866973877}, {\"channel\": 7, \"epoch\": 9, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.17867372930049896}, {\"channel\": 8, \"epoch\": 9, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.14001967012882233}, {\"channel\": 1, \"epoch\": 9, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.1889587789773941}, {\"channel\": 2, \"epoch\": 9, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.0813240334391594}, {\"channel\": 3, \"epoch\": 9, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.14092668890953064}, {\"channel\": 4, \"epoch\": 9, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.15902850031852722}, {\"channel\": 5, \"epoch\": 9, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.08386692404747009}, {\"channel\": 6, \"epoch\": 9, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.1331426203250885}, {\"channel\": 7, \"epoch\": 9, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.14171762764453888}, {\"channel\": 8, \"epoch\": 9, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.0966082289814949}, {\"channel\": 1, \"epoch\": 9, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.3524688482284546}, {\"channel\": 2, \"epoch\": 9, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.49781811237335205}, {\"channel\": 3, \"epoch\": 9, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.3422049582004547}, {\"channel\": 4, \"epoch\": 9, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.4845890402793884}, {\"channel\": 5, \"epoch\": 9, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.4267652630805969}, {\"channel\": 6, \"epoch\": 9, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.401376873254776}, {\"channel\": 7, \"epoch\": 9, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.4531601369380951}, {\"channel\": 8, \"epoch\": 9, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.4591265022754669}, {\"channel\": 1, \"epoch\": 9, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.011884980835020542}, {\"channel\": 2, \"epoch\": 9, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.03370866924524307}, {\"channel\": 3, \"epoch\": 9, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.017985839396715164}, {\"channel\": 4, \"epoch\": 9, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.03196501359343529}, {\"channel\": 5, \"epoch\": 9, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.010116154327988625}, {\"channel\": 6, \"epoch\": 9, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.01718069054186344}, {\"channel\": 7, \"epoch\": 9, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.03926008194684982}, {\"channel\": 8, \"epoch\": 9, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.039245203137397766}, {\"channel\": 1, \"epoch\": 10, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.2584506869316101}, {\"channel\": 2, \"epoch\": 10, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.2371663749217987}, {\"channel\": 3, \"epoch\": 10, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.23672758042812347}, {\"channel\": 4, \"epoch\": 10, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.21901576220989227}, {\"channel\": 5, \"epoch\": 10, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.20654094219207764}, {\"channel\": 6, \"epoch\": 10, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.07080718129873276}, {\"channel\": 7, \"epoch\": 10, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.40781334042549133}, {\"channel\": 8, \"epoch\": 10, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.2523394823074341}, {\"channel\": 1, \"epoch\": 10, \"layer\": \"prep\", \"type\": \"bias\", \"value\": 0.05175330117344856}, {\"channel\": 2, \"epoch\": 10, \"layer\": \"prep\", \"type\": \"bias\", \"value\": 0.007574691437184811}, {\"channel\": 3, \"epoch\": 10, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.20511701703071594}, {\"channel\": 4, \"epoch\": 10, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.10753926634788513}, {\"channel\": 5, \"epoch\": 10, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.11598746478557587}, {\"channel\": 6, \"epoch\": 10, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.05404045432806015}, {\"channel\": 7, \"epoch\": 10, \"layer\": \"prep\", \"type\": \"bias\", \"value\": 0.2955419421195984}, {\"channel\": 8, \"epoch\": 10, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.027308085933327675}, {\"channel\": 1, \"epoch\": 10, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.20548558235168457}, {\"channel\": 2, \"epoch\": 10, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.23162727057933807}, {\"channel\": 3, \"epoch\": 10, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.25073039531707764}, {\"channel\": 4, \"epoch\": 10, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.19887515902519226}, {\"channel\": 5, \"epoch\": 10, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.19469551742076874}, {\"channel\": 6, \"epoch\": 10, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.24713796377182007}, {\"channel\": 7, \"epoch\": 10, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.27522191405296326}, {\"channel\": 8, \"epoch\": 10, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.2516563832759857}, {\"channel\": 1, \"epoch\": 10, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": 0.0033595093991607428}, {\"channel\": 2, \"epoch\": 10, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.09154773503541946}, {\"channel\": 3, \"epoch\": 10, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.0802738219499588}, {\"channel\": 4, \"epoch\": 10, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.07807732373476028}, {\"channel\": 5, \"epoch\": 10, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": 0.04418038949370384}, {\"channel\": 6, \"epoch\": 10, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.08774290978908539}, {\"channel\": 7, \"epoch\": 10, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": 0.11224795132875443}, {\"channel\": 8, \"epoch\": 10, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.057077597826719284}, {\"channel\": 1, \"epoch\": 10, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.15198643505573273}, {\"channel\": 2, \"epoch\": 10, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.19966349005699158}, {\"channel\": 3, \"epoch\": 10, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.17162100970745087}, {\"channel\": 4, \"epoch\": 10, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.2241441160440445}, {\"channel\": 5, \"epoch\": 10, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.14329704642295837}, {\"channel\": 6, \"epoch\": 10, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.23306262493133545}, {\"channel\": 7, \"epoch\": 10, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.19803045690059662}, {\"channel\": 8, \"epoch\": 10, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.23006393015384674}, {\"channel\": 1, \"epoch\": 10, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.11513280868530273}, {\"channel\": 2, \"epoch\": 10, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.14093714952468872}, {\"channel\": 3, \"epoch\": 10, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.11208879947662354}, {\"channel\": 4, \"epoch\": 10, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.18425141274929047}, {\"channel\": 5, \"epoch\": 10, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.1336536854505539}, {\"channel\": 6, \"epoch\": 10, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.08287887275218964}, {\"channel\": 7, \"epoch\": 10, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.07612089067697525}, {\"channel\": 8, \"epoch\": 10, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.1125795915722847}, {\"channel\": 1, \"epoch\": 10, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.4048369526863098}, {\"channel\": 2, \"epoch\": 10, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.3515109419822693}, {\"channel\": 3, \"epoch\": 10, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.3160460591316223}, {\"channel\": 4, \"epoch\": 10, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.25143441557884216}, {\"channel\": 5, \"epoch\": 10, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.20843572914600372}, {\"channel\": 6, \"epoch\": 10, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.24957691133022308}, {\"channel\": 7, \"epoch\": 10, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.22893521189689636}, {\"channel\": 8, \"epoch\": 10, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.2994646728038788}, {\"channel\": 1, \"epoch\": 10, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.18176834285259247}, {\"channel\": 2, \"epoch\": 10, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.12823958694934845}, {\"channel\": 3, \"epoch\": 10, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": 0.00777279119938612}, {\"channel\": 4, \"epoch\": 10, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.061460334807634354}, {\"channel\": 5, \"epoch\": 10, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.04888742044568062}, {\"channel\": 6, \"epoch\": 10, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.1300279200077057}, {\"channel\": 7, \"epoch\": 10, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.11693321913480759}, {\"channel\": 8, \"epoch\": 10, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.11733927577733994}, {\"channel\": 1, \"epoch\": 10, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.23248563706874847}, {\"channel\": 2, \"epoch\": 10, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.23255401849746704}, {\"channel\": 3, \"epoch\": 10, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.21331478655338287}, {\"channel\": 4, \"epoch\": 10, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.25628548860549927}, {\"channel\": 5, \"epoch\": 10, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.23827718198299408}, {\"channel\": 6, \"epoch\": 10, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.2593396306037903}, {\"channel\": 7, \"epoch\": 10, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.22208186984062195}, {\"channel\": 8, \"epoch\": 10, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.2701350152492523}, {\"channel\": 1, \"epoch\": 10, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.08253410458564758}, {\"channel\": 2, \"epoch\": 10, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.08959055691957474}, {\"channel\": 3, \"epoch\": 10, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.16644304990768433}, {\"channel\": 4, \"epoch\": 10, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.11145557463169098}, {\"channel\": 5, \"epoch\": 10, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.15441232919692993}, {\"channel\": 6, \"epoch\": 10, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.12093179672956467}, {\"channel\": 7, \"epoch\": 10, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.13562016189098358}, {\"channel\": 8, \"epoch\": 10, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.10897830128669739}, {\"channel\": 1, \"epoch\": 10, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.17993658781051636}, {\"channel\": 2, \"epoch\": 10, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.28260356187820435}, {\"channel\": 3, \"epoch\": 10, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.2223597913980484}, {\"channel\": 4, \"epoch\": 10, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.2696993947029114}, {\"channel\": 5, \"epoch\": 10, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.23582331836223602}, {\"channel\": 6, \"epoch\": 10, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.3144643008708954}, {\"channel\": 7, \"epoch\": 10, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.1628745198249817}, {\"channel\": 8, \"epoch\": 10, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.32026419043540955}, {\"channel\": 1, \"epoch\": 10, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.16134436428546906}, {\"channel\": 2, \"epoch\": 10, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.14772337675094604}, {\"channel\": 3, \"epoch\": 10, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.2049134075641632}, {\"channel\": 4, \"epoch\": 10, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.20504038035869598}, {\"channel\": 5, \"epoch\": 10, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.13268467783927917}, {\"channel\": 6, \"epoch\": 10, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.25838685035705566}, {\"channel\": 7, \"epoch\": 10, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.1679874211549759}, {\"channel\": 8, \"epoch\": 10, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.17625123262405396}, {\"channel\": 1, \"epoch\": 10, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.21211057901382446}, {\"channel\": 2, \"epoch\": 10, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.1528509259223938}, {\"channel\": 3, \"epoch\": 10, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.18069890141487122}, {\"channel\": 4, \"epoch\": 10, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.24905315041542053}, {\"channel\": 5, \"epoch\": 10, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.11114304512739182}, {\"channel\": 6, \"epoch\": 10, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.18442778289318085}, {\"channel\": 7, \"epoch\": 10, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.17623284459114075}, {\"channel\": 8, \"epoch\": 10, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.137245312333107}, {\"channel\": 1, \"epoch\": 10, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.19149401783943176}, {\"channel\": 2, \"epoch\": 10, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.09800033271312714}, {\"channel\": 3, \"epoch\": 10, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.15369707345962524}, {\"channel\": 4, \"epoch\": 10, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.1639522910118103}, {\"channel\": 5, \"epoch\": 10, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.0912148505449295}, {\"channel\": 6, \"epoch\": 10, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.13138358294963837}, {\"channel\": 7, \"epoch\": 10, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.13774380087852478}, {\"channel\": 8, \"epoch\": 10, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.09574665129184723}, {\"channel\": 1, \"epoch\": 10, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.3358558416366577}, {\"channel\": 2, \"epoch\": 10, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.5033829212188721}, {\"channel\": 3, \"epoch\": 10, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.34236446022987366}, {\"channel\": 4, \"epoch\": 10, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.47126898169517517}, {\"channel\": 5, \"epoch\": 10, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.4302520453929901}, {\"channel\": 6, \"epoch\": 10, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.40869319438934326}, {\"channel\": 7, \"epoch\": 10, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.44942420721054077}, {\"channel\": 8, \"epoch\": 10, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.4538358449935913}, {\"channel\": 1, \"epoch\": 10, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.010562817566096783}, {\"channel\": 2, \"epoch\": 10, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.03348886966705322}, {\"channel\": 3, \"epoch\": 10, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.01767560839653015}, {\"channel\": 4, \"epoch\": 10, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.026800911873579025}, {\"channel\": 5, \"epoch\": 10, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.007470118347555399}, {\"channel\": 6, \"epoch\": 10, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.012513847090303898}, {\"channel\": 7, \"epoch\": 10, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.039122410118579865}, {\"channel\": 8, \"epoch\": 10, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.03590782359242439}, {\"channel\": 1, \"epoch\": 11, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.32210928201675415}, {\"channel\": 2, \"epoch\": 11, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.24318620562553406}, {\"channel\": 3, \"epoch\": 11, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.23861360549926758}, {\"channel\": 4, \"epoch\": 11, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.20962652564048767}, {\"channel\": 5, \"epoch\": 11, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.20296992361545563}, {\"channel\": 6, \"epoch\": 11, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.11771222203969955}, {\"channel\": 7, \"epoch\": 11, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.3748917579650879}, {\"channel\": 8, \"epoch\": 11, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.23138299584388733}, {\"channel\": 1, \"epoch\": 11, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.011079099960625172}, {\"channel\": 2, \"epoch\": 11, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.014612819068133831}, {\"channel\": 3, \"epoch\": 11, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.1957632601261139}, {\"channel\": 4, \"epoch\": 11, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.08561830222606659}, {\"channel\": 5, \"epoch\": 11, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.10540536791086197}, {\"channel\": 6, \"epoch\": 11, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.03594522550702095}, {\"channel\": 7, \"epoch\": 11, \"layer\": \"prep\", \"type\": \"bias\", \"value\": 0.2561345100402832}, {\"channel\": 8, \"epoch\": 11, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.03576403483748436}, {\"channel\": 1, \"epoch\": 11, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.2131088376045227}, {\"channel\": 2, \"epoch\": 11, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.24535420536994934}, {\"channel\": 3, \"epoch\": 11, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.2809372842311859}, {\"channel\": 4, \"epoch\": 11, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.18117161095142365}, {\"channel\": 5, \"epoch\": 11, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.2176084667444229}, {\"channel\": 6, \"epoch\": 11, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.23940342664718628}, {\"channel\": 7, \"epoch\": 11, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.2580133080482483}, {\"channel\": 8, \"epoch\": 11, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.23487664759159088}, {\"channel\": 1, \"epoch\": 11, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": 0.0047754282131791115}, {\"channel\": 2, \"epoch\": 11, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.05675062537193298}, {\"channel\": 3, \"epoch\": 11, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.035106223076581955}, {\"channel\": 4, \"epoch\": 11, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.07041960209608078}, {\"channel\": 5, \"epoch\": 11, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": 0.027061687782406807}, {\"channel\": 6, \"epoch\": 11, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.09102857112884521}, {\"channel\": 7, \"epoch\": 11, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": 0.16013535857200623}, {\"channel\": 8, \"epoch\": 11, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.08120858669281006}, {\"channel\": 1, \"epoch\": 11, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.1403132975101471}, {\"channel\": 2, \"epoch\": 11, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.1652153879404068}, {\"channel\": 3, \"epoch\": 11, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.1666363775730133}, {\"channel\": 4, \"epoch\": 11, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.25539952516555786}, {\"channel\": 5, \"epoch\": 11, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.19417767226696014}, {\"channel\": 6, \"epoch\": 11, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.209640771150589}, {\"channel\": 7, \"epoch\": 11, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.18816277384757996}, {\"channel\": 8, \"epoch\": 11, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.20773999392986298}, {\"channel\": 1, \"epoch\": 11, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.11330242455005646}, {\"channel\": 2, \"epoch\": 11, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.12743782997131348}, {\"channel\": 3, \"epoch\": 11, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.09779029339551926}, {\"channel\": 4, \"epoch\": 11, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.1548515260219574}, {\"channel\": 5, \"epoch\": 11, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.09064055979251862}, {\"channel\": 6, \"epoch\": 11, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.06833421438932419}, {\"channel\": 7, \"epoch\": 11, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.10147351026535034}, {\"channel\": 8, \"epoch\": 11, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.13295258581638336}, {\"channel\": 1, \"epoch\": 11, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.3829837441444397}, {\"channel\": 2, \"epoch\": 11, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.3370887339115143}, {\"channel\": 3, \"epoch\": 11, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.3017490804195404}, {\"channel\": 4, \"epoch\": 11, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.26053178310394287}, {\"channel\": 5, \"epoch\": 11, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.19648240506649017}, {\"channel\": 6, \"epoch\": 11, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.2211838662624359}, {\"channel\": 7, \"epoch\": 11, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.21430476009845734}, {\"channel\": 8, \"epoch\": 11, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.25350937247276306}, {\"channel\": 1, \"epoch\": 11, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.18419155478477478}, {\"channel\": 2, \"epoch\": 11, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.12892064452171326}, {\"channel\": 3, \"epoch\": 11, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.005604011472314596}, {\"channel\": 4, \"epoch\": 11, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.0461638979613781}, {\"channel\": 5, \"epoch\": 11, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.06512578576803207}, {\"channel\": 6, \"epoch\": 11, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.12469319999217987}, {\"channel\": 7, \"epoch\": 11, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.13763108849525452}, {\"channel\": 8, \"epoch\": 11, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.15053915977478027}, {\"channel\": 1, \"epoch\": 11, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.20629148185253143}, {\"channel\": 2, \"epoch\": 11, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.23177418112754822}, {\"channel\": 3, \"epoch\": 11, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.23565109074115753}, {\"channel\": 4, \"epoch\": 11, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.240096777677536}, {\"channel\": 5, \"epoch\": 11, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.18937380611896515}, {\"channel\": 6, \"epoch\": 11, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.20230337977409363}, {\"channel\": 7, \"epoch\": 11, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.2493390440940857}, {\"channel\": 8, \"epoch\": 11, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.24792814254760742}, {\"channel\": 1, \"epoch\": 11, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.12112656980752945}, {\"channel\": 2, \"epoch\": 11, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.11494921147823334}, {\"channel\": 3, \"epoch\": 11, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.1467219740152359}, {\"channel\": 4, \"epoch\": 11, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.13575519621372223}, {\"channel\": 5, \"epoch\": 11, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.17262299358844757}, {\"channel\": 6, \"epoch\": 11, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.15376469492912292}, {\"channel\": 7, \"epoch\": 11, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.11953086405992508}, {\"channel\": 8, \"epoch\": 11, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.09369698911905289}, {\"channel\": 1, \"epoch\": 11, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.22017690539360046}, {\"channel\": 2, \"epoch\": 11, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.3028428852558136}, {\"channel\": 3, \"epoch\": 11, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.23971323668956757}, {\"channel\": 4, \"epoch\": 11, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.20778338611125946}, {\"channel\": 5, \"epoch\": 11, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.21611855924129486}, {\"channel\": 6, \"epoch\": 11, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.32095155119895935}, {\"channel\": 7, \"epoch\": 11, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.16175024211406708}, {\"channel\": 8, \"epoch\": 11, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.2543540298938751}, {\"channel\": 1, \"epoch\": 11, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.14425444602966309}, {\"channel\": 2, \"epoch\": 11, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.16271482408046722}, {\"channel\": 3, \"epoch\": 11, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.18058523535728455}, {\"channel\": 4, \"epoch\": 11, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.24843554198741913}, {\"channel\": 5, \"epoch\": 11, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.11599160730838776}, {\"channel\": 6, \"epoch\": 11, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.286571741104126}, {\"channel\": 7, \"epoch\": 11, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.15144729614257812}, {\"channel\": 8, \"epoch\": 11, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.18141880631446838}, {\"channel\": 1, \"epoch\": 11, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.22099338471889496}, {\"channel\": 2, \"epoch\": 11, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.14701299369335175}, {\"channel\": 3, \"epoch\": 11, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.1774676889181137}, {\"channel\": 4, \"epoch\": 11, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.2338041067123413}, {\"channel\": 5, \"epoch\": 11, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.1032276302576065}, {\"channel\": 6, \"epoch\": 11, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.16156065464019775}, {\"channel\": 7, \"epoch\": 11, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.1613892763853073}, {\"channel\": 8, \"epoch\": 11, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.11236865073442459}, {\"channel\": 1, \"epoch\": 11, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.2041441649198532}, {\"channel\": 2, \"epoch\": 11, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.10064519941806793}, {\"channel\": 3, \"epoch\": 11, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.17519377171993256}, {\"channel\": 4, \"epoch\": 11, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.17477448284626007}, {\"channel\": 5, \"epoch\": 11, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.09048409014940262}, {\"channel\": 6, \"epoch\": 11, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.13836491107940674}, {\"channel\": 7, \"epoch\": 11, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.15571510791778564}, {\"channel\": 8, \"epoch\": 11, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.10211215913295746}, {\"channel\": 1, \"epoch\": 11, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.3325679302215576}, {\"channel\": 2, \"epoch\": 11, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.5006733536720276}, {\"channel\": 3, \"epoch\": 11, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.3378969728946686}, {\"channel\": 4, \"epoch\": 11, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.4870856702327728}, {\"channel\": 5, \"epoch\": 11, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.4363758862018585}, {\"channel\": 6, \"epoch\": 11, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.4244178831577301}, {\"channel\": 7, \"epoch\": 11, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.4502427577972412}, {\"channel\": 8, \"epoch\": 11, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.4549098312854767}, {\"channel\": 1, \"epoch\": 11, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.009752525016665459}, {\"channel\": 2, \"epoch\": 11, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.03281217813491821}, {\"channel\": 3, \"epoch\": 11, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.014911027625203133}, {\"channel\": 4, \"epoch\": 11, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.024150416254997253}, {\"channel\": 5, \"epoch\": 11, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.006288220640271902}, {\"channel\": 6, \"epoch\": 11, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.010839112102985382}, {\"channel\": 7, \"epoch\": 11, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.03825651481747627}, {\"channel\": 8, \"epoch\": 11, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.03326690196990967}, {\"channel\": 1, \"epoch\": 12, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.2589428722858429}, {\"channel\": 2, \"epoch\": 12, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.22231847047805786}, {\"channel\": 3, \"epoch\": 12, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.209006205201149}, {\"channel\": 4, \"epoch\": 12, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.1945737600326538}, {\"channel\": 5, \"epoch\": 12, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.21470703184604645}, {\"channel\": 6, \"epoch\": 12, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.09959866851568222}, {\"channel\": 7, \"epoch\": 12, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.4277017116546631}, {\"channel\": 8, \"epoch\": 12, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.24189209938049316}, {\"channel\": 1, \"epoch\": 12, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.023791324347257614}, {\"channel\": 2, \"epoch\": 12, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.03145933523774147}, {\"channel\": 3, \"epoch\": 12, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.21032635867595673}, {\"channel\": 4, \"epoch\": 12, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.12355920672416687}, {\"channel\": 5, \"epoch\": 12, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.09110995382070541}, {\"channel\": 6, \"epoch\": 12, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.02994426339864731}, {\"channel\": 7, \"epoch\": 12, \"layer\": \"prep\", \"type\": \"bias\", \"value\": 0.2558504343032837}, {\"channel\": 8, \"epoch\": 12, \"layer\": \"prep\", \"type\": \"bias\", \"value\": 0.0032955543138086796}, {\"channel\": 1, \"epoch\": 12, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.1849018633365631}, {\"channel\": 2, \"epoch\": 12, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.20881958305835724}, {\"channel\": 3, \"epoch\": 12, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.23327770829200745}, {\"channel\": 4, \"epoch\": 12, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.163564532995224}, {\"channel\": 5, \"epoch\": 12, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.20365436375141144}, {\"channel\": 6, \"epoch\": 12, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.2342265248298645}, {\"channel\": 7, \"epoch\": 12, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.23109959065914154}, {\"channel\": 8, \"epoch\": 12, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.23011885583400726}, {\"channel\": 1, \"epoch\": 12, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": 0.03612836077809334}, {\"channel\": 2, \"epoch\": 12, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.05295915529131889}, {\"channel\": 3, \"epoch\": 12, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.0613744892179966}, {\"channel\": 4, \"epoch\": 12, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.07771852612495422}, {\"channel\": 5, \"epoch\": 12, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": 0.009502768516540527}, {\"channel\": 6, \"epoch\": 12, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.0686713308095932}, {\"channel\": 7, \"epoch\": 12, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": 0.12949399650096893}, {\"channel\": 8, \"epoch\": 12, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.0631316602230072}, {\"channel\": 1, \"epoch\": 12, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.17138655483722687}, {\"channel\": 2, \"epoch\": 12, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.195739284157753}, {\"channel\": 3, \"epoch\": 12, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.17644093930721283}, {\"channel\": 4, \"epoch\": 12, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.22782932221889496}, {\"channel\": 5, \"epoch\": 12, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.16656480729579926}, {\"channel\": 6, \"epoch\": 12, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.2106189727783203}, {\"channel\": 7, \"epoch\": 12, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.18708522617816925}, {\"channel\": 8, \"epoch\": 12, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.19958019256591797}, {\"channel\": 1, \"epoch\": 12, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.0850071832537651}, {\"channel\": 2, \"epoch\": 12, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.10865218192338943}, {\"channel\": 3, \"epoch\": 12, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.09507417678833008}, {\"channel\": 4, \"epoch\": 12, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.17026202380657196}, {\"channel\": 5, \"epoch\": 12, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.08452440053224564}, {\"channel\": 6, \"epoch\": 12, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.058708008378744125}, {\"channel\": 7, \"epoch\": 12, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.09082938730716705}, {\"channel\": 8, \"epoch\": 12, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.1260949671268463}, {\"channel\": 1, \"epoch\": 12, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.401196151971817}, {\"channel\": 2, \"epoch\": 12, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.3593296706676483}, {\"channel\": 3, \"epoch\": 12, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.27975592017173767}, {\"channel\": 4, \"epoch\": 12, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.2759076952934265}, {\"channel\": 5, \"epoch\": 12, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.20993110537528992}, {\"channel\": 6, \"epoch\": 12, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.1982787847518921}, {\"channel\": 7, \"epoch\": 12, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.21764321625232697}, {\"channel\": 8, \"epoch\": 12, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.2830447554588318}, {\"channel\": 1, \"epoch\": 12, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.19101151823997498}, {\"channel\": 2, \"epoch\": 12, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.13727353513240814}, {\"channel\": 3, \"epoch\": 12, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.025923052802681923}, {\"channel\": 4, \"epoch\": 12, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.015221849083900452}, {\"channel\": 5, \"epoch\": 12, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.059817563742399216}, {\"channel\": 6, \"epoch\": 12, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.11445580422878265}, {\"channel\": 7, \"epoch\": 12, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.1325473189353943}, {\"channel\": 8, \"epoch\": 12, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.1332097202539444}, {\"channel\": 1, \"epoch\": 12, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.18674258887767792}, {\"channel\": 2, \"epoch\": 12, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.21613401174545288}, {\"channel\": 3, \"epoch\": 12, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.2123141586780548}, {\"channel\": 4, \"epoch\": 12, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.23699074983596802}, {\"channel\": 5, \"epoch\": 12, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.2386132925748825}, {\"channel\": 6, \"epoch\": 12, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.25217780470848083}, {\"channel\": 7, \"epoch\": 12, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.2437199056148529}, {\"channel\": 8, \"epoch\": 12, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.2283390909433365}, {\"channel\": 1, \"epoch\": 12, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.1577591896057129}, {\"channel\": 2, \"epoch\": 12, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.13627712428569794}, {\"channel\": 3, \"epoch\": 12, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.15314561128616333}, {\"channel\": 4, \"epoch\": 12, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.1260252147912979}, {\"channel\": 5, \"epoch\": 12, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.18447525799274445}, {\"channel\": 6, \"epoch\": 12, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.14395348727703094}, {\"channel\": 7, \"epoch\": 12, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.13568586111068726}, {\"channel\": 8, \"epoch\": 12, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.09073924273252487}, {\"channel\": 1, \"epoch\": 12, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.17311467230319977}, {\"channel\": 2, \"epoch\": 12, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.3222019374370575}, {\"channel\": 3, \"epoch\": 12, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.2415960133075714}, {\"channel\": 4, \"epoch\": 12, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.21292820572853088}, {\"channel\": 5, \"epoch\": 12, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.18146131932735443}, {\"channel\": 6, \"epoch\": 12, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.26027318835258484}, {\"channel\": 7, \"epoch\": 12, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.14984223246574402}, {\"channel\": 8, \"epoch\": 12, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.26615092158317566}, {\"channel\": 1, \"epoch\": 12, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.16224505007266998}, {\"channel\": 2, \"epoch\": 12, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.17147816717624664}, {\"channel\": 3, \"epoch\": 12, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.18709245324134827}, {\"channel\": 4, \"epoch\": 12, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.24484534561634064}, {\"channel\": 5, \"epoch\": 12, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.1324501931667328}, {\"channel\": 6, \"epoch\": 12, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.2686688005924225}, {\"channel\": 7, \"epoch\": 12, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.15599922835826874}, {\"channel\": 8, \"epoch\": 12, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.16820523142814636}, {\"channel\": 1, \"epoch\": 12, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.2280471920967102}, {\"channel\": 2, \"epoch\": 12, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.1375143826007843}, {\"channel\": 3, \"epoch\": 12, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.1767287403345108}, {\"channel\": 4, \"epoch\": 12, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.2308453917503357}, {\"channel\": 5, \"epoch\": 12, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.11263054609298706}, {\"channel\": 6, \"epoch\": 12, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.17089812457561493}, {\"channel\": 7, \"epoch\": 12, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.15013138949871063}, {\"channel\": 8, \"epoch\": 12, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.12443546950817108}, {\"channel\": 1, \"epoch\": 12, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.21227218210697174}, {\"channel\": 2, \"epoch\": 12, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.10058829188346863}, {\"channel\": 3, \"epoch\": 12, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.1786486953496933}, {\"channel\": 4, \"epoch\": 12, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.18472319841384888}, {\"channel\": 5, \"epoch\": 12, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.09494666755199432}, {\"channel\": 6, \"epoch\": 12, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.12896399199962616}, {\"channel\": 7, \"epoch\": 12, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.1669916957616806}, {\"channel\": 8, \"epoch\": 12, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.09442105889320374}, {\"channel\": 1, \"epoch\": 12, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.33155399560928345}, {\"channel\": 2, \"epoch\": 12, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.49788764119148254}, {\"channel\": 3, \"epoch\": 12, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.3324587941169739}, {\"channel\": 4, \"epoch\": 12, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.483521044254303}, {\"channel\": 5, \"epoch\": 12, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.4440865218639374}, {\"channel\": 6, \"epoch\": 12, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.42960885167121887}, {\"channel\": 7, \"epoch\": 12, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.4530625343322754}, {\"channel\": 8, \"epoch\": 12, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.45535287261009216}, {\"channel\": 1, \"epoch\": 12, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.009459737688302994}, {\"channel\": 2, \"epoch\": 12, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.03379281982779503}, {\"channel\": 3, \"epoch\": 12, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.012578767724335194}, {\"channel\": 4, \"epoch\": 12, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.02179707959294319}, {\"channel\": 5, \"epoch\": 12, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.004566766321659088}, {\"channel\": 6, \"epoch\": 12, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.008510532788932323}, {\"channel\": 7, \"epoch\": 12, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.03547540307044983}, {\"channel\": 8, \"epoch\": 12, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.031112032011151314}, {\"channel\": 1, \"epoch\": 13, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.22611092031002045}, {\"channel\": 2, \"epoch\": 13, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.1996988207101822}, {\"channel\": 3, \"epoch\": 13, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.19716742634773254}, {\"channel\": 4, \"epoch\": 13, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.18812455236911774}, {\"channel\": 5, \"epoch\": 13, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.1939302384853363}, {\"channel\": 6, \"epoch\": 13, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.07342762500047684}, {\"channel\": 7, \"epoch\": 13, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.4118903875350952}, {\"channel\": 8, \"epoch\": 13, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.24325823783874512}, {\"channel\": 1, \"epoch\": 13, \"layer\": \"prep\", \"type\": \"bias\", \"value\": 0.009196839295327663}, {\"channel\": 2, \"epoch\": 13, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.013912531547248363}, {\"channel\": 3, \"epoch\": 13, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.229830801486969}, {\"channel\": 4, \"epoch\": 13, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.09310252219438553}, {\"channel\": 5, \"epoch\": 13, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.11003341525793076}, {\"channel\": 6, \"epoch\": 13, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.02854730747640133}, {\"channel\": 7, \"epoch\": 13, \"layer\": \"prep\", \"type\": \"bias\", \"value\": 0.2291380763053894}, {\"channel\": 8, \"epoch\": 13, \"layer\": \"prep\", \"type\": \"bias\", \"value\": 0.017831316217780113}, {\"channel\": 1, \"epoch\": 13, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.18395380675792694}, {\"channel\": 2, \"epoch\": 13, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.1880451738834381}, {\"channel\": 3, \"epoch\": 13, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.22734838724136353}, {\"channel\": 4, \"epoch\": 13, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.1889541894197464}, {\"channel\": 5, \"epoch\": 13, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.19801174104213715}, {\"channel\": 6, \"epoch\": 13, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.21790479123592377}, {\"channel\": 7, \"epoch\": 13, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.19385764002799988}, {\"channel\": 8, \"epoch\": 13, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.24239912629127502}, {\"channel\": 1, \"epoch\": 13, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": 0.021985992789268494}, {\"channel\": 2, \"epoch\": 13, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.08512286096811295}, {\"channel\": 3, \"epoch\": 13, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.025229519233107567}, {\"channel\": 4, \"epoch\": 13, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.07847695797681808}, {\"channel\": 5, \"epoch\": 13, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": 0.006412116345018148}, {\"channel\": 6, \"epoch\": 13, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.08973239362239838}, {\"channel\": 7, \"epoch\": 13, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": 0.13696396350860596}, {\"channel\": 8, \"epoch\": 13, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.05880136415362358}, {\"channel\": 1, \"epoch\": 13, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.14359763264656067}, {\"channel\": 2, \"epoch\": 13, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.19976182281970978}, {\"channel\": 3, \"epoch\": 13, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.19038990139961243}, {\"channel\": 4, \"epoch\": 13, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.2009388655424118}, {\"channel\": 5, \"epoch\": 13, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.16911423206329346}, {\"channel\": 6, \"epoch\": 13, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.2213299572467804}, {\"channel\": 7, \"epoch\": 13, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.17474955320358276}, {\"channel\": 8, \"epoch\": 13, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.19637024402618408}, {\"channel\": 1, \"epoch\": 13, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.10667926073074341}, {\"channel\": 2, \"epoch\": 13, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.09736156463623047}, {\"channel\": 3, \"epoch\": 13, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.09550328552722931}, {\"channel\": 4, \"epoch\": 13, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.15522190928459167}, {\"channel\": 5, \"epoch\": 13, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.08454180508852005}, {\"channel\": 6, \"epoch\": 13, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.05480491369962692}, {\"channel\": 7, \"epoch\": 13, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.09902370721101761}, {\"channel\": 8, \"epoch\": 13, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.12420070916414261}, {\"channel\": 1, \"epoch\": 13, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.39473074674606323}, {\"channel\": 2, \"epoch\": 13, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.34001922607421875}, {\"channel\": 3, \"epoch\": 13, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.27251774072647095}, {\"channel\": 4, \"epoch\": 13, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.2421967089176178}, {\"channel\": 5, \"epoch\": 13, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.22880971431732178}, {\"channel\": 6, \"epoch\": 13, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.1865168809890747}, {\"channel\": 7, \"epoch\": 13, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.15051838755607605}, {\"channel\": 8, \"epoch\": 13, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.25275057554244995}, {\"channel\": 1, \"epoch\": 13, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.1864955574274063}, {\"channel\": 2, \"epoch\": 13, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.16837842762470245}, {\"channel\": 3, \"epoch\": 13, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.020284386351704597}, {\"channel\": 4, \"epoch\": 13, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.03596038743853569}, {\"channel\": 5, \"epoch\": 13, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.07402733713388443}, {\"channel\": 6, \"epoch\": 13, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.10980274528265}, {\"channel\": 7, \"epoch\": 13, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.16189289093017578}, {\"channel\": 8, \"epoch\": 13, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.12274915724992752}, {\"channel\": 1, \"epoch\": 13, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.1890387237071991}, {\"channel\": 2, \"epoch\": 13, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.21660387516021729}, {\"channel\": 3, \"epoch\": 13, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.19331535696983337}, {\"channel\": 4, \"epoch\": 13, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.23509034514427185}, {\"channel\": 5, \"epoch\": 13, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.23129217326641083}, {\"channel\": 6, \"epoch\": 13, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.19371475279331207}, {\"channel\": 7, \"epoch\": 13, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.22712692618370056}, {\"channel\": 8, \"epoch\": 13, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.18712981045246124}, {\"channel\": 1, \"epoch\": 13, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.15582208335399628}, {\"channel\": 2, \"epoch\": 13, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.1528073400259018}, {\"channel\": 3, \"epoch\": 13, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.14814947545528412}, {\"channel\": 4, \"epoch\": 13, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.13783670961856842}, {\"channel\": 5, \"epoch\": 13, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.17978428304195404}, {\"channel\": 6, \"epoch\": 13, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.15278401970863342}, {\"channel\": 7, \"epoch\": 13, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.13774888217449188}, {\"channel\": 8, \"epoch\": 13, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.10399416089057922}, {\"channel\": 1, \"epoch\": 13, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.1788700968027115}, {\"channel\": 2, \"epoch\": 13, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.30166131258010864}, {\"channel\": 3, \"epoch\": 13, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.19061893224716187}, {\"channel\": 4, \"epoch\": 13, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.2438049465417862}, {\"channel\": 5, \"epoch\": 13, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.18823891878128052}, {\"channel\": 6, \"epoch\": 13, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.25666993856430054}, {\"channel\": 7, \"epoch\": 13, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.15967723727226257}, {\"channel\": 8, \"epoch\": 13, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.25820454955101013}, {\"channel\": 1, \"epoch\": 13, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.15237894654273987}, {\"channel\": 2, \"epoch\": 13, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.1890740990638733}, {\"channel\": 3, \"epoch\": 13, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.2251647412776947}, {\"channel\": 4, \"epoch\": 13, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.2179356962442398}, {\"channel\": 5, \"epoch\": 13, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.12676142156124115}, {\"channel\": 6, \"epoch\": 13, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.2483203411102295}, {\"channel\": 7, \"epoch\": 13, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.14488637447357178}, {\"channel\": 8, \"epoch\": 13, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.15702924132347107}, {\"channel\": 1, \"epoch\": 13, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.19108940660953522}, {\"channel\": 2, \"epoch\": 13, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.13027827441692352}, {\"channel\": 3, \"epoch\": 13, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.15931019186973572}, {\"channel\": 4, \"epoch\": 13, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.2419641762971878}, {\"channel\": 5, \"epoch\": 13, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.10457883030176163}, {\"channel\": 6, \"epoch\": 13, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.15118154883384705}, {\"channel\": 7, \"epoch\": 13, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.15621979534626007}, {\"channel\": 8, \"epoch\": 13, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.11113396286964417}, {\"channel\": 1, \"epoch\": 13, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.21732915937900543}, {\"channel\": 2, \"epoch\": 13, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.11309865862131119}, {\"channel\": 3, \"epoch\": 13, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.18494659662246704}, {\"channel\": 4, \"epoch\": 13, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.18848605453968048}, {\"channel\": 5, \"epoch\": 13, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.09573588520288467}, {\"channel\": 6, \"epoch\": 13, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.13920974731445312}, {\"channel\": 7, \"epoch\": 13, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.17170453071594238}, {\"channel\": 8, \"epoch\": 13, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.09813865274190903}, {\"channel\": 1, \"epoch\": 13, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.33080729842185974}, {\"channel\": 2, \"epoch\": 13, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.49572980403900146}, {\"channel\": 3, \"epoch\": 13, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.3281925320625305}, {\"channel\": 4, \"epoch\": 13, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.4756830632686615}, {\"channel\": 5, \"epoch\": 13, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.449550598859787}, {\"channel\": 6, \"epoch\": 13, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.4388282001018524}, {\"channel\": 7, \"epoch\": 13, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.4524703025817871}, {\"channel\": 8, \"epoch\": 13, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.45067882537841797}, {\"channel\": 1, \"epoch\": 13, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.008020401932299137}, {\"channel\": 2, \"epoch\": 13, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.032087091356515884}, {\"channel\": 3, \"epoch\": 13, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.010212955065071583}, {\"channel\": 4, \"epoch\": 13, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.017217835411429405}, {\"channel\": 5, \"epoch\": 13, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.004151515197008848}, {\"channel\": 6, \"epoch\": 13, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.006329817697405815}, {\"channel\": 7, \"epoch\": 13, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.03429397940635681}, {\"channel\": 8, \"epoch\": 13, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.028360504657030106}, {\"channel\": 1, \"epoch\": 14, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.25492849946022034}, {\"channel\": 2, \"epoch\": 14, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.21732273697853088}, {\"channel\": 3, \"epoch\": 14, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.21313439309597015}, {\"channel\": 4, \"epoch\": 14, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.20085038244724274}, {\"channel\": 5, \"epoch\": 14, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.18857517838478088}, {\"channel\": 6, \"epoch\": 14, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.09113632142543793}, {\"channel\": 7, \"epoch\": 14, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.3969494700431824}, {\"channel\": 8, \"epoch\": 14, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.23688019812107086}, {\"channel\": 1, \"epoch\": 14, \"layer\": \"prep\", \"type\": \"bias\", \"value\": 0.04786929115653038}, {\"channel\": 2, \"epoch\": 14, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.006978075951337814}, {\"channel\": 3, \"epoch\": 14, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.20463578402996063}, {\"channel\": 4, \"epoch\": 14, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.10176271945238113}, {\"channel\": 5, \"epoch\": 14, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.11862083524465561}, {\"channel\": 6, \"epoch\": 14, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.012637828476727009}, {\"channel\": 7, \"epoch\": 14, \"layer\": \"prep\", \"type\": \"bias\", \"value\": 0.22946740686893463}, {\"channel\": 8, \"epoch\": 14, \"layer\": \"prep\", \"type\": \"bias\", \"value\": 0.0026527431327849627}, {\"channel\": 1, \"epoch\": 14, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.16328777372837067}, {\"channel\": 2, \"epoch\": 14, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.20171883702278137}, {\"channel\": 3, \"epoch\": 14, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.2355968952178955}, {\"channel\": 4, \"epoch\": 14, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.1844342201948166}, {\"channel\": 5, \"epoch\": 14, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.18140797317028046}, {\"channel\": 6, \"epoch\": 14, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.2258474975824356}, {\"channel\": 7, \"epoch\": 14, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.21144691109657288}, {\"channel\": 8, \"epoch\": 14, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.2086978703737259}, {\"channel\": 1, \"epoch\": 14, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": 0.02027355507016182}, {\"channel\": 2, \"epoch\": 14, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.07438984513282776}, {\"channel\": 3, \"epoch\": 14, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.03063851408660412}, {\"channel\": 4, \"epoch\": 14, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.06470409780740738}, {\"channel\": 5, \"epoch\": 14, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.008705860003829002}, {\"channel\": 6, \"epoch\": 14, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.0661797896027565}, {\"channel\": 7, \"epoch\": 14, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": 0.15502454340457916}, {\"channel\": 8, \"epoch\": 14, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.08025467395782471}, {\"channel\": 1, \"epoch\": 14, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.1337505429983139}, {\"channel\": 2, \"epoch\": 14, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.1704963594675064}, {\"channel\": 3, \"epoch\": 14, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.17014984786510468}, {\"channel\": 4, \"epoch\": 14, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.216800257563591}, {\"channel\": 5, \"epoch\": 14, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.16698352992534637}, {\"channel\": 6, \"epoch\": 14, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.1945052295923233}, {\"channel\": 7, \"epoch\": 14, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.15689407289028168}, {\"channel\": 8, \"epoch\": 14, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.18750426173210144}, {\"channel\": 1, \"epoch\": 14, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.10987213253974915}, {\"channel\": 2, \"epoch\": 14, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.12541142106056213}, {\"channel\": 3, \"epoch\": 14, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.10899949073791504}, {\"channel\": 4, \"epoch\": 14, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.15495170652866364}, {\"channel\": 5, \"epoch\": 14, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.09281452745199203}, {\"channel\": 6, \"epoch\": 14, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.07716579735279083}, {\"channel\": 7, \"epoch\": 14, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.10599853843450546}, {\"channel\": 8, \"epoch\": 14, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.12141828238964081}, {\"channel\": 1, \"epoch\": 14, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.4004349708557129}, {\"channel\": 2, \"epoch\": 14, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.33549124002456665}, {\"channel\": 3, \"epoch\": 14, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.24812087416648865}, {\"channel\": 4, \"epoch\": 14, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.23182183504104614}, {\"channel\": 5, \"epoch\": 14, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.23118603229522705}, {\"channel\": 6, \"epoch\": 14, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.2212262898683548}, {\"channel\": 7, \"epoch\": 14, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.18346261978149414}, {\"channel\": 8, \"epoch\": 14, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.23630909621715546}, {\"channel\": 1, \"epoch\": 14, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.17887143790721893}, {\"channel\": 2, \"epoch\": 14, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.16025793552398682}, {\"channel\": 3, \"epoch\": 14, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.031048372387886047}, {\"channel\": 4, \"epoch\": 14, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.052055396139621735}, {\"channel\": 5, \"epoch\": 14, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.08196824043989182}, {\"channel\": 6, \"epoch\": 14, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.10825410485267639}, {\"channel\": 7, \"epoch\": 14, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.12499409168958664}, {\"channel\": 8, \"epoch\": 14, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.13372895121574402}, {\"channel\": 1, \"epoch\": 14, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.2300519049167633}, {\"channel\": 2, \"epoch\": 14, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.22629597783088684}, {\"channel\": 3, \"epoch\": 14, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.20990070700645447}, {\"channel\": 4, \"epoch\": 14, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.2280680537223816}, {\"channel\": 5, \"epoch\": 14, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.21521863341331482}, {\"channel\": 6, \"epoch\": 14, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.18005616962909698}, {\"channel\": 7, \"epoch\": 14, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.22683493793010712}, {\"channel\": 8, \"epoch\": 14, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.21135897934436798}, {\"channel\": 1, \"epoch\": 14, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.12311271578073502}, {\"channel\": 2, \"epoch\": 14, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.14541207253932953}, {\"channel\": 3, \"epoch\": 14, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.14941978454589844}, {\"channel\": 4, \"epoch\": 14, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.13204815983772278}, {\"channel\": 5, \"epoch\": 14, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.16230206191539764}, {\"channel\": 6, \"epoch\": 14, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.14011463522911072}, {\"channel\": 7, \"epoch\": 14, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.13511069118976593}, {\"channel\": 8, \"epoch\": 14, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.11632803082466125}, {\"channel\": 1, \"epoch\": 14, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.17263951897621155}, {\"channel\": 2, \"epoch\": 14, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.2881143093109131}, {\"channel\": 3, \"epoch\": 14, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.23065172135829926}, {\"channel\": 4, \"epoch\": 14, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.21270166337490082}, {\"channel\": 5, \"epoch\": 14, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.19913408160209656}, {\"channel\": 6, \"epoch\": 14, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.23356759548187256}, {\"channel\": 7, \"epoch\": 14, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.16428732872009277}, {\"channel\": 8, \"epoch\": 14, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.220343217253685}, {\"channel\": 1, \"epoch\": 14, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.1650409996509552}, {\"channel\": 2, \"epoch\": 14, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.19641360640525818}, {\"channel\": 3, \"epoch\": 14, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.20975543558597565}, {\"channel\": 4, \"epoch\": 14, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.23296214640140533}, {\"channel\": 5, \"epoch\": 14, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.119856096804142}, {\"channel\": 6, \"epoch\": 14, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.26208212971687317}, {\"channel\": 7, \"epoch\": 14, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.14175276458263397}, {\"channel\": 8, \"epoch\": 14, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.16561460494995117}, {\"channel\": 1, \"epoch\": 14, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.18686717748641968}, {\"channel\": 2, \"epoch\": 14, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.1189710795879364}, {\"channel\": 3, \"epoch\": 14, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.16640231013298035}, {\"channel\": 4, \"epoch\": 14, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.23587119579315186}, {\"channel\": 5, \"epoch\": 14, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.09799846261739731}, {\"channel\": 6, \"epoch\": 14, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.15047141909599304}, {\"channel\": 7, \"epoch\": 14, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.1657656729221344}, {\"channel\": 8, \"epoch\": 14, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.1173652857542038}, {\"channel\": 1, \"epoch\": 14, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.21418924629688263}, {\"channel\": 2, \"epoch\": 14, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.11932499706745148}, {\"channel\": 3, \"epoch\": 14, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.18926960229873657}, {\"channel\": 4, \"epoch\": 14, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.20453953742980957}, {\"channel\": 5, \"epoch\": 14, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.10096976906061172}, {\"channel\": 6, \"epoch\": 14, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.1406373679637909}, {\"channel\": 7, \"epoch\": 14, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.17493577301502228}, {\"channel\": 8, \"epoch\": 14, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.10339422523975372}, {\"channel\": 1, \"epoch\": 14, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.3280886709690094}, {\"channel\": 2, \"epoch\": 14, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.49100881814956665}, {\"channel\": 3, \"epoch\": 14, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.3246820569038391}, {\"channel\": 4, \"epoch\": 14, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.476097047328949}, {\"channel\": 5, \"epoch\": 14, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.45019441843032837}, {\"channel\": 6, \"epoch\": 14, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.44477707147598267}, {\"channel\": 7, \"epoch\": 14, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.45169785618782043}, {\"channel\": 8, \"epoch\": 14, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.4457288682460785}, {\"channel\": 1, \"epoch\": 14, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.007371385116130114}, {\"channel\": 2, \"epoch\": 14, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.03279530256986618}, {\"channel\": 3, \"epoch\": 14, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.008913176134228706}, {\"channel\": 4, \"epoch\": 14, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.015545707195997238}, {\"channel\": 5, \"epoch\": 14, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.0031276883091777563}, {\"channel\": 6, \"epoch\": 14, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.005482306703925133}, {\"channel\": 7, \"epoch\": 14, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.033559683710336685}, {\"channel\": 8, \"epoch\": 14, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.02697199583053589}, {\"channel\": 1, \"epoch\": 15, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.22943508625030518}, {\"channel\": 2, \"epoch\": 15, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.2198522984981537}, {\"channel\": 3, \"epoch\": 15, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.1852489560842514}, {\"channel\": 4, \"epoch\": 15, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.1936136931180954}, {\"channel\": 5, \"epoch\": 15, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.18075738847255707}, {\"channel\": 6, \"epoch\": 15, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.07367223501205444}, {\"channel\": 7, \"epoch\": 15, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.39862778782844543}, {\"channel\": 8, \"epoch\": 15, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.24267490208148956}, {\"channel\": 1, \"epoch\": 15, \"layer\": \"prep\", \"type\": \"bias\", \"value\": 0.02441713586449623}, {\"channel\": 2, \"epoch\": 15, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.010216720402240753}, {\"channel\": 3, \"epoch\": 15, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.2166730910539627}, {\"channel\": 4, \"epoch\": 15, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.1109839677810669}, {\"channel\": 5, \"epoch\": 15, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.10482930392026901}, {\"channel\": 6, \"epoch\": 15, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.016180353239178658}, {\"channel\": 7, \"epoch\": 15, \"layer\": \"prep\", \"type\": \"bias\", \"value\": 0.1888492852449417}, {\"channel\": 8, \"epoch\": 15, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.0036402300465852022}, {\"channel\": 1, \"epoch\": 15, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.15734681487083435}, {\"channel\": 2, \"epoch\": 15, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.17842993140220642}, {\"channel\": 3, \"epoch\": 15, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.22396600246429443}, {\"channel\": 4, \"epoch\": 15, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.17201584577560425}, {\"channel\": 5, \"epoch\": 15, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.16551101207733154}, {\"channel\": 6, \"epoch\": 15, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.22320564091205597}, {\"channel\": 7, \"epoch\": 15, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.2095509022474289}, {\"channel\": 8, \"epoch\": 15, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.22399389743804932}, {\"channel\": 1, \"epoch\": 15, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": 0.0269608274102211}, {\"channel\": 2, \"epoch\": 15, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.08745726943016052}, {\"channel\": 3, \"epoch\": 15, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.009711122140288353}, {\"channel\": 4, \"epoch\": 15, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.07566598057746887}, {\"channel\": 5, \"epoch\": 15, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": 0.012714086100459099}, {\"channel\": 6, \"epoch\": 15, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.06625635921955109}, {\"channel\": 7, \"epoch\": 15, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": 0.12196890264749527}, {\"channel\": 8, \"epoch\": 15, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.06024884060025215}, {\"channel\": 1, \"epoch\": 15, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.12987366318702698}, {\"channel\": 2, \"epoch\": 15, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.17407973110675812}, {\"channel\": 3, \"epoch\": 15, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.16724464297294617}, {\"channel\": 4, \"epoch\": 15, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.1941273808479309}, {\"channel\": 5, \"epoch\": 15, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.15428423881530762}, {\"channel\": 6, \"epoch\": 15, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.18344375491142273}, {\"channel\": 7, \"epoch\": 15, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.16016444563865662}, {\"channel\": 8, \"epoch\": 15, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.20692916214466095}, {\"channel\": 1, \"epoch\": 15, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.10865377634763718}, {\"channel\": 2, \"epoch\": 15, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.1232183426618576}, {\"channel\": 3, \"epoch\": 15, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.09913356602191925}, {\"channel\": 4, \"epoch\": 15, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.15363436937332153}, {\"channel\": 5, \"epoch\": 15, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.09565272182226181}, {\"channel\": 6, \"epoch\": 15, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.07838460803031921}, {\"channel\": 7, \"epoch\": 15, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.10010280460119247}, {\"channel\": 8, \"epoch\": 15, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.10771621763706207}, {\"channel\": 1, \"epoch\": 15, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.36381056904792786}, {\"channel\": 2, \"epoch\": 15, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.33257997035980225}, {\"channel\": 3, \"epoch\": 15, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.24929817020893097}, {\"channel\": 4, \"epoch\": 15, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.2345218062400818}, {\"channel\": 5, \"epoch\": 15, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.22942306101322174}, {\"channel\": 6, \"epoch\": 15, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.22376056015491486}, {\"channel\": 7, \"epoch\": 15, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.18583744764328003}, {\"channel\": 8, \"epoch\": 15, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.22447316348552704}, {\"channel\": 1, \"epoch\": 15, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.18122749030590057}, {\"channel\": 2, \"epoch\": 15, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.16443130373954773}, {\"channel\": 3, \"epoch\": 15, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.02131080813705921}, {\"channel\": 4, \"epoch\": 15, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.060095466673374176}, {\"channel\": 5, \"epoch\": 15, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.08646225929260254}, {\"channel\": 6, \"epoch\": 15, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.11034789681434631}, {\"channel\": 7, \"epoch\": 15, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.11413217335939407}, {\"channel\": 8, \"epoch\": 15, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.1357525736093521}, {\"channel\": 1, \"epoch\": 15, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.20704196393489838}, {\"channel\": 2, \"epoch\": 15, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.22938041388988495}, {\"channel\": 3, \"epoch\": 15, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.1692344844341278}, {\"channel\": 4, \"epoch\": 15, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.21141573786735535}, {\"channel\": 5, \"epoch\": 15, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.19617784023284912}, {\"channel\": 6, \"epoch\": 15, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.1882895827293396}, {\"channel\": 7, \"epoch\": 15, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.21001188457012177}, {\"channel\": 8, \"epoch\": 15, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.19838617742061615}, {\"channel\": 1, \"epoch\": 15, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.11709941923618317}, {\"channel\": 2, \"epoch\": 15, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.13673724234104156}, {\"channel\": 3, \"epoch\": 15, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.16193100810050964}, {\"channel\": 4, \"epoch\": 15, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.14127276837825775}, {\"channel\": 5, \"epoch\": 15, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.15896707773208618}, {\"channel\": 6, \"epoch\": 15, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.13331356644630432}, {\"channel\": 7, \"epoch\": 15, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.14879736304283142}, {\"channel\": 8, \"epoch\": 15, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.11247618496417999}, {\"channel\": 1, \"epoch\": 15, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.16781893372535706}, {\"channel\": 2, \"epoch\": 15, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.29821959137916565}, {\"channel\": 3, \"epoch\": 15, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.19601573050022125}, {\"channel\": 4, \"epoch\": 15, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.2181752622127533}, {\"channel\": 5, \"epoch\": 15, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.1857566237449646}, {\"channel\": 6, \"epoch\": 15, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.21518898010253906}, {\"channel\": 7, \"epoch\": 15, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.15582403540611267}, {\"channel\": 8, \"epoch\": 15, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.20402903854846954}, {\"channel\": 1, \"epoch\": 15, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.16263139247894287}, {\"channel\": 2, \"epoch\": 15, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.18385396897792816}, {\"channel\": 3, \"epoch\": 15, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.22020156681537628}, {\"channel\": 4, \"epoch\": 15, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.22669591009616852}, {\"channel\": 5, \"epoch\": 15, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.12145176529884338}, {\"channel\": 6, \"epoch\": 15, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.25338873267173767}, {\"channel\": 7, \"epoch\": 15, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.14276911318302155}, {\"channel\": 8, \"epoch\": 15, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.1449555605649948}, {\"channel\": 1, \"epoch\": 15, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.19953681528568268}, {\"channel\": 2, \"epoch\": 15, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.12460440397262573}, {\"channel\": 3, \"epoch\": 15, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.16863824427127838}, {\"channel\": 4, \"epoch\": 15, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.23871257901191711}, {\"channel\": 5, \"epoch\": 15, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.09089665114879608}, {\"channel\": 6, \"epoch\": 15, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.14962509274482727}, {\"channel\": 7, \"epoch\": 15, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.16530661284923553}, {\"channel\": 8, \"epoch\": 15, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.10502258688211441}, {\"channel\": 1, \"epoch\": 15, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.20736074447631836}, {\"channel\": 2, \"epoch\": 15, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.11400604993104935}, {\"channel\": 3, \"epoch\": 15, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.19116054475307465}, {\"channel\": 4, \"epoch\": 15, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.21538515388965607}, {\"channel\": 5, \"epoch\": 15, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.103969506919384}, {\"channel\": 6, \"epoch\": 15, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.13582901656627655}, {\"channel\": 7, \"epoch\": 15, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.17556974291801453}, {\"channel\": 8, \"epoch\": 15, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.1056331992149353}, {\"channel\": 1, \"epoch\": 15, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.32562506198883057}, {\"channel\": 2, \"epoch\": 15, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.4884519875049591}, {\"channel\": 3, \"epoch\": 15, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.3231695294380188}, {\"channel\": 4, \"epoch\": 15, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.4777410924434662}, {\"channel\": 5, \"epoch\": 15, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.45032811164855957}, {\"channel\": 6, \"epoch\": 15, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.44776639342308044}, {\"channel\": 7, \"epoch\": 15, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.45224517583847046}, {\"channel\": 8, \"epoch\": 15, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.4439488351345062}, {\"channel\": 1, \"epoch\": 15, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.0060729291290044785}, {\"channel\": 2, \"epoch\": 15, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.03225860744714737}, {\"channel\": 3, \"epoch\": 15, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.008004534989595413}, {\"channel\": 4, \"epoch\": 15, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.013225875794887543}, {\"channel\": 5, \"epoch\": 15, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.002863830653950572}, {\"channel\": 6, \"epoch\": 15, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.0036809786688536406}, {\"channel\": 7, \"epoch\": 15, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.03169359266757965}, {\"channel\": 8, \"epoch\": 15, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.025103602558374405}, {\"channel\": 1, \"epoch\": 16, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.22343628108501434}, {\"channel\": 2, \"epoch\": 16, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.2239566594362259}, {\"channel\": 3, \"epoch\": 16, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.20249058306217194}, {\"channel\": 4, \"epoch\": 16, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.18166866898536682}, {\"channel\": 5, \"epoch\": 16, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.1861637681722641}, {\"channel\": 6, \"epoch\": 16, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.07967162132263184}, {\"channel\": 7, \"epoch\": 16, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.4020199477672577}, {\"channel\": 8, \"epoch\": 16, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.22542202472686768}, {\"channel\": 1, \"epoch\": 16, \"layer\": \"prep\", \"type\": \"bias\", \"value\": 0.0043607112020254135}, {\"channel\": 2, \"epoch\": 16, \"layer\": \"prep\", \"type\": \"bias\", \"value\": 0.00550561398267746}, {\"channel\": 3, \"epoch\": 16, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.19737359881401062}, {\"channel\": 4, \"epoch\": 16, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.09871389716863632}, {\"channel\": 5, \"epoch\": 16, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.09571492671966553}, {\"channel\": 6, \"epoch\": 16, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.019260570406913757}, {\"channel\": 7, \"epoch\": 16, \"layer\": \"prep\", \"type\": \"bias\", \"value\": 0.18195326626300812}, {\"channel\": 8, \"epoch\": 16, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.025123637169599533}, {\"channel\": 1, \"epoch\": 16, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.14963217079639435}, {\"channel\": 2, \"epoch\": 16, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.17621752619743347}, {\"channel\": 3, \"epoch\": 16, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.1719985008239746}, {\"channel\": 4, \"epoch\": 16, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.18796394765377045}, {\"channel\": 5, \"epoch\": 16, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.18669763207435608}, {\"channel\": 6, \"epoch\": 16, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.2168966680765152}, {\"channel\": 7, \"epoch\": 16, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.19664418697357178}, {\"channel\": 8, \"epoch\": 16, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.20670855045318604}, {\"channel\": 1, \"epoch\": 16, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": 0.025617461651563644}, {\"channel\": 2, \"epoch\": 16, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.08345967531204224}, {\"channel\": 3, \"epoch\": 16, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.027957161888480186}, {\"channel\": 4, \"epoch\": 16, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.06982327252626419}, {\"channel\": 5, \"epoch\": 16, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": 0.009315322153270245}, {\"channel\": 6, \"epoch\": 16, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.06898678839206696}, {\"channel\": 7, \"epoch\": 16, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": 0.11034740507602692}, {\"channel\": 8, \"epoch\": 16, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.06463096290826797}, {\"channel\": 1, \"epoch\": 16, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.13404403626918793}, {\"channel\": 2, \"epoch\": 16, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.17475378513336182}, {\"channel\": 3, \"epoch\": 16, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.15701524913311005}, {\"channel\": 4, \"epoch\": 16, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.2087843269109726}, {\"channel\": 5, \"epoch\": 16, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.14858494699001312}, {\"channel\": 6, \"epoch\": 16, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.18960660696029663}, {\"channel\": 7, \"epoch\": 16, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.16619299352169037}, {\"channel\": 8, \"epoch\": 16, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.19203729927539825}, {\"channel\": 1, \"epoch\": 16, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.10034777969121933}, {\"channel\": 2, \"epoch\": 16, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.11714335530996323}, {\"channel\": 3, \"epoch\": 16, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.1081487312912941}, {\"channel\": 4, \"epoch\": 16, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.1529860496520996}, {\"channel\": 5, \"epoch\": 16, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.09372980147600174}, {\"channel\": 6, \"epoch\": 16, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.07484590262174606}, {\"channel\": 7, \"epoch\": 16, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.0955764427781105}, {\"channel\": 8, \"epoch\": 16, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.12870658934116364}, {\"channel\": 1, \"epoch\": 16, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.3604889214038849}, {\"channel\": 2, \"epoch\": 16, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.3218136429786682}, {\"channel\": 3, \"epoch\": 16, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.25887081027030945}, {\"channel\": 4, \"epoch\": 16, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.24208255112171173}, {\"channel\": 5, \"epoch\": 16, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.21900905668735504}, {\"channel\": 6, \"epoch\": 16, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.23009008169174194}, {\"channel\": 7, \"epoch\": 16, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.1656443476676941}, {\"channel\": 8, \"epoch\": 16, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.23295636475086212}, {\"channel\": 1, \"epoch\": 16, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.17705349624156952}, {\"channel\": 2, \"epoch\": 16, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.17114375531673431}, {\"channel\": 3, \"epoch\": 16, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.013865292072296143}, {\"channel\": 4, \"epoch\": 16, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.05164448916912079}, {\"channel\": 5, \"epoch\": 16, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.08479076623916626}, {\"channel\": 6, \"epoch\": 16, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.11194715648889542}, {\"channel\": 7, \"epoch\": 16, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.1368824541568756}, {\"channel\": 8, \"epoch\": 16, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.12570726871490479}, {\"channel\": 1, \"epoch\": 16, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.21723297238349915}, {\"channel\": 2, \"epoch\": 16, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.2346244901418686}, {\"channel\": 3, \"epoch\": 16, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.21828578412532806}, {\"channel\": 4, \"epoch\": 16, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.17639264464378357}, {\"channel\": 5, \"epoch\": 16, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.18323379755020142}, {\"channel\": 6, \"epoch\": 16, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.15715326368808746}, {\"channel\": 7, \"epoch\": 16, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.21717001497745514}, {\"channel\": 8, \"epoch\": 16, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.19506299495697021}, {\"channel\": 1, \"epoch\": 16, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.12675948441028595}, {\"channel\": 2, \"epoch\": 16, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.1426832228899002}, {\"channel\": 3, \"epoch\": 16, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.14528295397758484}, {\"channel\": 4, \"epoch\": 16, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.14315636456012726}, {\"channel\": 5, \"epoch\": 16, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.1608075201511383}, {\"channel\": 6, \"epoch\": 16, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.14112764596939087}, {\"channel\": 7, \"epoch\": 16, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.15136784315109253}, {\"channel\": 8, \"epoch\": 16, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.11582382023334503}, {\"channel\": 1, \"epoch\": 16, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.16780813038349152}, {\"channel\": 2, \"epoch\": 16, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.2857159376144409}, {\"channel\": 3, \"epoch\": 16, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.23086212575435638}, {\"channel\": 4, \"epoch\": 16, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.21313638985157013}, {\"channel\": 5, \"epoch\": 16, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.17541088163852692}, {\"channel\": 6, \"epoch\": 16, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.2254529893398285}, {\"channel\": 7, \"epoch\": 16, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.1624915897846222}, {\"channel\": 8, \"epoch\": 16, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.2147882878780365}, {\"channel\": 1, \"epoch\": 16, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.15114930272102356}, {\"channel\": 2, \"epoch\": 16, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.1848016083240509}, {\"channel\": 3, \"epoch\": 16, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.20064932107925415}, {\"channel\": 4, \"epoch\": 16, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.22915565967559814}, {\"channel\": 5, \"epoch\": 16, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.13055172562599182}, {\"channel\": 6, \"epoch\": 16, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.2427934855222702}, {\"channel\": 7, \"epoch\": 16, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.1492069661617279}, {\"channel\": 8, \"epoch\": 16, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.13769036531448364}, {\"channel\": 1, \"epoch\": 16, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.18028852343559265}, {\"channel\": 2, \"epoch\": 16, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.11886626482009888}, {\"channel\": 3, \"epoch\": 16, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.16330964863300323}, {\"channel\": 4, \"epoch\": 16, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.23239748179912567}, {\"channel\": 5, \"epoch\": 16, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.08686564862728119}, {\"channel\": 6, \"epoch\": 16, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.14348024129867554}, {\"channel\": 7, \"epoch\": 16, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.15612022578716278}, {\"channel\": 8, \"epoch\": 16, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.10121771693229675}, {\"channel\": 1, \"epoch\": 16, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.21463876962661743}, {\"channel\": 2, \"epoch\": 16, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.11532337218523026}, {\"channel\": 3, \"epoch\": 16, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.19250904023647308}, {\"channel\": 4, \"epoch\": 16, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.22568033635616302}, {\"channel\": 5, \"epoch\": 16, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.10354560613632202}, {\"channel\": 6, \"epoch\": 16, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.1402289867401123}, {\"channel\": 7, \"epoch\": 16, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.18281197547912598}, {\"channel\": 8, \"epoch\": 16, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.1051933765411377}, {\"channel\": 1, \"epoch\": 16, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.32377785444259644}, {\"channel\": 2, \"epoch\": 16, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.4834471046924591}, {\"channel\": 3, \"epoch\": 16, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.3203526735305786}, {\"channel\": 4, \"epoch\": 16, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.47711509466171265}, {\"channel\": 5, \"epoch\": 16, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.45162901282310486}, {\"channel\": 6, \"epoch\": 16, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.4496055543422699}, {\"channel\": 7, \"epoch\": 16, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.4524074196815491}, {\"channel\": 8, \"epoch\": 16, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.44224193692207336}, {\"channel\": 1, \"epoch\": 16, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.005719624925404787}, {\"channel\": 2, \"epoch\": 16, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.03277170658111572}, {\"channel\": 3, \"epoch\": 16, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.0072817010805010796}, {\"channel\": 4, \"epoch\": 16, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.012003320269286633}, {\"channel\": 5, \"epoch\": 16, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.0017050800379365683}, {\"channel\": 6, \"epoch\": 16, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.0038487911224365234}, {\"channel\": 7, \"epoch\": 16, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.030655736103653908}, {\"channel\": 8, \"epoch\": 16, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.02429049462080002}, {\"channel\": 1, \"epoch\": 17, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.22841088473796844}, {\"channel\": 2, \"epoch\": 17, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.21882084012031555}, {\"channel\": 3, \"epoch\": 17, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.19900637865066528}, {\"channel\": 4, \"epoch\": 17, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.17357248067855835}, {\"channel\": 5, \"epoch\": 17, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.19301439821720123}, {\"channel\": 6, \"epoch\": 17, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.07157778739929199}, {\"channel\": 7, \"epoch\": 17, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.4091925024986267}, {\"channel\": 8, \"epoch\": 17, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.23630866408348083}, {\"channel\": 1, \"epoch\": 17, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.002078797435387969}, {\"channel\": 2, \"epoch\": 17, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.007610204629600048}, {\"channel\": 3, \"epoch\": 17, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.19754664599895477}, {\"channel\": 4, \"epoch\": 17, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.09913349151611328}, {\"channel\": 5, \"epoch\": 17, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.09821783751249313}, {\"channel\": 6, \"epoch\": 17, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.01967276819050312}, {\"channel\": 7, \"epoch\": 17, \"layer\": \"prep\", \"type\": \"bias\", \"value\": 0.17154304683208466}, {\"channel\": 8, \"epoch\": 17, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.007329253014177084}, {\"channel\": 1, \"epoch\": 17, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.13817529380321503}, {\"channel\": 2, \"epoch\": 17, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.18142250180244446}, {\"channel\": 3, \"epoch\": 17, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.17555198073387146}, {\"channel\": 4, \"epoch\": 17, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.17254722118377686}, {\"channel\": 5, \"epoch\": 17, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.16960003972053528}, {\"channel\": 6, \"epoch\": 17, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.2122729867696762}, {\"channel\": 7, \"epoch\": 17, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.1774556189775467}, {\"channel\": 8, \"epoch\": 17, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.206711083650589}, {\"channel\": 1, \"epoch\": 17, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": 0.034394025802612305}, {\"channel\": 2, \"epoch\": 17, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.07413230836391449}, {\"channel\": 3, \"epoch\": 17, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.03261316567659378}, {\"channel\": 4, \"epoch\": 17, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.08392807841300964}, {\"channel\": 5, \"epoch\": 17, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": 0.00863291509449482}, {\"channel\": 6, \"epoch\": 17, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.07346170395612717}, {\"channel\": 7, \"epoch\": 17, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": 0.11402896791696548}, {\"channel\": 8, \"epoch\": 17, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.060233838856220245}, {\"channel\": 1, \"epoch\": 17, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.13271751999855042}, {\"channel\": 2, \"epoch\": 17, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.16326074302196503}, {\"channel\": 3, \"epoch\": 17, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.1567772775888443}, {\"channel\": 4, \"epoch\": 17, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.2022104412317276}, {\"channel\": 5, \"epoch\": 17, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.13697686791419983}, {\"channel\": 6, \"epoch\": 17, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.20609626173973083}, {\"channel\": 7, \"epoch\": 17, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.15426795184612274}, {\"channel\": 8, \"epoch\": 17, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.18470346927642822}, {\"channel\": 1, \"epoch\": 17, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.0987834557890892}, {\"channel\": 2, \"epoch\": 17, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.12219800800085068}, {\"channel\": 3, \"epoch\": 17, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.1085638776421547}, {\"channel\": 4, \"epoch\": 17, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.15189167857170105}, {\"channel\": 5, \"epoch\": 17, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.10154648870229721}, {\"channel\": 6, \"epoch\": 17, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.06016931310296059}, {\"channel\": 7, \"epoch\": 17, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.10063141584396362}, {\"channel\": 8, \"epoch\": 17, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.13069035112857819}, {\"channel\": 1, \"epoch\": 17, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.36179453134536743}, {\"channel\": 2, \"epoch\": 17, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.31890830397605896}, {\"channel\": 3, \"epoch\": 17, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.2586171329021454}, {\"channel\": 4, \"epoch\": 17, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.23770509660243988}, {\"channel\": 5, \"epoch\": 17, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.21618908643722534}, {\"channel\": 6, \"epoch\": 17, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.2138901799917221}, {\"channel\": 7, \"epoch\": 17, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.16938501596450806}, {\"channel\": 8, \"epoch\": 17, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.20990411937236786}, {\"channel\": 1, \"epoch\": 17, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.16345219314098358}, {\"channel\": 2, \"epoch\": 17, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.16541904211044312}, {\"channel\": 3, \"epoch\": 17, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.01297301147133112}, {\"channel\": 4, \"epoch\": 17, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.05204460024833679}, {\"channel\": 5, \"epoch\": 17, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.08238010853528976}, {\"channel\": 6, \"epoch\": 17, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.12491513043642044}, {\"channel\": 7, \"epoch\": 17, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.12931674718856812}, {\"channel\": 8, \"epoch\": 17, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.13756002485752106}, {\"channel\": 1, \"epoch\": 17, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.18327002227306366}, {\"channel\": 2, \"epoch\": 17, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.21907579898834229}, {\"channel\": 3, \"epoch\": 17, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.1999366283416748}, {\"channel\": 4, \"epoch\": 17, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.1915215402841568}, {\"channel\": 5, \"epoch\": 17, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.19201214611530304}, {\"channel\": 6, \"epoch\": 17, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.1569124013185501}, {\"channel\": 7, \"epoch\": 17, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.2101161926984787}, {\"channel\": 8, \"epoch\": 17, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.18813639879226685}, {\"channel\": 1, \"epoch\": 17, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.1422855705022812}, {\"channel\": 2, \"epoch\": 17, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.14554525911808014}, {\"channel\": 3, \"epoch\": 17, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.14847689867019653}, {\"channel\": 4, \"epoch\": 17, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.1370219737291336}, {\"channel\": 5, \"epoch\": 17, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.1584591269493103}, {\"channel\": 6, \"epoch\": 17, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.13087065517902374}, {\"channel\": 7, \"epoch\": 17, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.14900369942188263}, {\"channel\": 8, \"epoch\": 17, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.12056334316730499}, {\"channel\": 1, \"epoch\": 17, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.16725316643714905}, {\"channel\": 2, \"epoch\": 17, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.2918878495693207}, {\"channel\": 3, \"epoch\": 17, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.1969687044620514}, {\"channel\": 4, \"epoch\": 17, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.19467748701572418}, {\"channel\": 5, \"epoch\": 17, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.19040723145008087}, {\"channel\": 6, \"epoch\": 17, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.22373095154762268}, {\"channel\": 7, \"epoch\": 17, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.16010181605815887}, {\"channel\": 8, \"epoch\": 17, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.21386770904064178}, {\"channel\": 1, \"epoch\": 17, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.1454712599515915}, {\"channel\": 2, \"epoch\": 17, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.17790929973125458}, {\"channel\": 3, \"epoch\": 17, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.21387983858585358}, {\"channel\": 4, \"epoch\": 17, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.2370750457048416}, {\"channel\": 5, \"epoch\": 17, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.12017872929573059}, {\"channel\": 6, \"epoch\": 17, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.2393523007631302}, {\"channel\": 7, \"epoch\": 17, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.146477609872818}, {\"channel\": 8, \"epoch\": 17, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.13477353751659393}, {\"channel\": 1, \"epoch\": 17, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.18857045471668243}, {\"channel\": 2, \"epoch\": 17, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.1168300062417984}, {\"channel\": 3, \"epoch\": 17, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.1517290472984314}, {\"channel\": 4, \"epoch\": 17, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.22871385514736176}, {\"channel\": 5, \"epoch\": 17, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.08974649012088776}, {\"channel\": 6, \"epoch\": 17, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.14007006585597992}, {\"channel\": 7, \"epoch\": 17, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.15248030424118042}, {\"channel\": 8, \"epoch\": 17, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.1012338399887085}, {\"channel\": 1, \"epoch\": 17, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.20987066626548767}, {\"channel\": 2, \"epoch\": 17, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.11725518107414246}, {\"channel\": 3, \"epoch\": 17, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.19740162789821625}, {\"channel\": 4, \"epoch\": 17, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.23397237062454224}, {\"channel\": 5, \"epoch\": 17, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.10241270065307617}, {\"channel\": 6, \"epoch\": 17, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.14157074689865112}, {\"channel\": 7, \"epoch\": 17, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.18684647977352142}, {\"channel\": 8, \"epoch\": 17, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.10103940218687057}, {\"channel\": 1, \"epoch\": 17, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.3227504789829254}, {\"channel\": 2, \"epoch\": 17, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.482875257730484}, {\"channel\": 3, \"epoch\": 17, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.3188159465789795}, {\"channel\": 4, \"epoch\": 17, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.4769006073474884}, {\"channel\": 5, \"epoch\": 17, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.45061033964157104}, {\"channel\": 6, \"epoch\": 17, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.45226550102233887}, {\"channel\": 7, \"epoch\": 17, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.45195847749710083}, {\"channel\": 8, \"epoch\": 17, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.44182899594306946}, {\"channel\": 1, \"epoch\": 17, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.005184585694223642}, {\"channel\": 2, \"epoch\": 17, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.032093871384859085}, {\"channel\": 3, \"epoch\": 17, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.006651561241596937}, {\"channel\": 4, \"epoch\": 17, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.011312931776046753}, {\"channel\": 5, \"epoch\": 17, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.0012577878078445792}, {\"channel\": 6, \"epoch\": 17, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.003200851147994399}, {\"channel\": 7, \"epoch\": 17, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.02989114820957184}, {\"channel\": 8, \"epoch\": 17, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.02350373938679695}, {\"channel\": 1, \"epoch\": 18, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.22274835407733917}, {\"channel\": 2, \"epoch\": 18, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.2180391103029251}, {\"channel\": 3, \"epoch\": 18, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.19053125381469727}, {\"channel\": 4, \"epoch\": 18, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.1775391697883606}, {\"channel\": 5, \"epoch\": 18, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.20235545933246613}, {\"channel\": 6, \"epoch\": 18, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.07388070970773697}, {\"channel\": 7, \"epoch\": 18, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.39440110325813293}, {\"channel\": 8, \"epoch\": 18, \"layer\": \"prep\", \"type\": \"weight\", \"value\": 0.23350244760513306}, {\"channel\": 1, \"epoch\": 18, \"layer\": \"prep\", \"type\": \"bias\", \"value\": 0.0037428559735417366}, {\"channel\": 2, \"epoch\": 18, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.00804778654128313}, {\"channel\": 3, \"epoch\": 18, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.20014651119709015}, {\"channel\": 4, \"epoch\": 18, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.09298980981111526}, {\"channel\": 5, \"epoch\": 18, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.09505867213010788}, {\"channel\": 6, \"epoch\": 18, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.019477007910609245}, {\"channel\": 7, \"epoch\": 18, \"layer\": \"prep\", \"type\": \"bias\", \"value\": 0.16691593825817108}, {\"channel\": 8, \"epoch\": 18, \"layer\": \"prep\", \"type\": \"bias\", \"value\": -0.010530774481594563}, {\"channel\": 1, \"epoch\": 18, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.13457199931144714}, {\"channel\": 2, \"epoch\": 18, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.17690028250217438}, {\"channel\": 3, \"epoch\": 18, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.1799524575471878}, {\"channel\": 4, \"epoch\": 18, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.173513263463974}, {\"channel\": 5, \"epoch\": 18, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.1672847419977188}, {\"channel\": 6, \"epoch\": 18, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.21800337731838226}, {\"channel\": 7, \"epoch\": 18, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.16647253930568695}, {\"channel\": 8, \"epoch\": 18, \"layer\": \"layer1\", \"type\": \"weight\", \"value\": 0.200276181101799}, {\"channel\": 1, \"epoch\": 18, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": 0.03432203084230423}, {\"channel\": 2, \"epoch\": 18, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.07241136580705643}, {\"channel\": 3, \"epoch\": 18, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.02615738846361637}, {\"channel\": 4, \"epoch\": 18, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.08260820806026459}, {\"channel\": 5, \"epoch\": 18, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": 0.007528313435614109}, {\"channel\": 6, \"epoch\": 18, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.0673060342669487}, {\"channel\": 7, \"epoch\": 18, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": 0.11089719831943512}, {\"channel\": 8, \"epoch\": 18, \"layer\": \"layer1\", \"type\": \"bias\", \"value\": -0.062882199883461}, {\"channel\": 1, \"epoch\": 18, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.13039825856685638}, {\"channel\": 2, \"epoch\": 18, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.16363683342933655}, {\"channel\": 3, \"epoch\": 18, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.15161317586898804}, {\"channel\": 4, \"epoch\": 18, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.1941608488559723}, {\"channel\": 5, \"epoch\": 18, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.14118310809135437}, {\"channel\": 6, \"epoch\": 18, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.1975185126066208}, {\"channel\": 7, \"epoch\": 18, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.15011310577392578}, {\"channel\": 8, \"epoch\": 18, \"layer\": \"layer1_residual_res1\", \"type\": \"weight\", \"value\": 0.17661671340465546}, {\"channel\": 1, \"epoch\": 18, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.10087829828262329}, {\"channel\": 2, \"epoch\": 18, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.12363413721323013}, {\"channel\": 3, \"epoch\": 18, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.11089379340410233}, {\"channel\": 4, \"epoch\": 18, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.15236042439937592}, {\"channel\": 5, \"epoch\": 18, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.09972935914993286}, {\"channel\": 6, \"epoch\": 18, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.06606531143188477}, {\"channel\": 7, \"epoch\": 18, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.10280101001262665}, {\"channel\": 8, \"epoch\": 18, \"layer\": \"layer1_residual_res1\", \"type\": \"bias\", \"value\": -0.13627776503562927}, {\"channel\": 1, \"epoch\": 18, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.3524286150932312}, {\"channel\": 2, \"epoch\": 18, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.3217598497867584}, {\"channel\": 3, \"epoch\": 18, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.26055413484573364}, {\"channel\": 4, \"epoch\": 18, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.24079982936382294}, {\"channel\": 5, \"epoch\": 18, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.22050122916698456}, {\"channel\": 6, \"epoch\": 18, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.2168402075767517}, {\"channel\": 7, \"epoch\": 18, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.16720840334892273}, {\"channel\": 8, \"epoch\": 18, \"layer\": \"layer1_residual_res2\", \"type\": \"weight\", \"value\": 0.21573878824710846}, {\"channel\": 1, \"epoch\": 18, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.16637706756591797}, {\"channel\": 2, \"epoch\": 18, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.16111470758914948}, {\"channel\": 3, \"epoch\": 18, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.010504537262022495}, {\"channel\": 4, \"epoch\": 18, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.048102594912052155}, {\"channel\": 5, \"epoch\": 18, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.07877886295318604}, {\"channel\": 6, \"epoch\": 18, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.12131529301404953}, {\"channel\": 7, \"epoch\": 18, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.13045766949653625}, {\"channel\": 8, \"epoch\": 18, \"layer\": \"layer1_residual_res2\", \"type\": \"bias\", \"value\": -0.1315479576587677}, {\"channel\": 1, \"epoch\": 18, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.18271653354167938}, {\"channel\": 2, \"epoch\": 18, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.2157111018896103}, {\"channel\": 3, \"epoch\": 18, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.20187833905220032}, {\"channel\": 4, \"epoch\": 18, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.19516877830028534}, {\"channel\": 5, \"epoch\": 18, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.19382037222385406}, {\"channel\": 6, \"epoch\": 18, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.15575170516967773}, {\"channel\": 7, \"epoch\": 18, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.20725776255130768}, {\"channel\": 8, \"epoch\": 18, \"layer\": \"layer2\", \"type\": \"weight\", \"value\": 0.1922418624162674}, {\"channel\": 1, \"epoch\": 18, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.14183056354522705}, {\"channel\": 2, \"epoch\": 18, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.14460688829421997}, {\"channel\": 3, \"epoch\": 18, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.1447622925043106}, {\"channel\": 4, \"epoch\": 18, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.13378438353538513}, {\"channel\": 5, \"epoch\": 18, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.15755683183670044}, {\"channel\": 6, \"epoch\": 18, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.13057906925678253}, {\"channel\": 7, \"epoch\": 18, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.15199008584022522}, {\"channel\": 8, \"epoch\": 18, \"layer\": \"layer2\", \"type\": \"bias\", \"value\": -0.11564707010984421}, {\"channel\": 1, \"epoch\": 18, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.16846859455108643}, {\"channel\": 2, \"epoch\": 18, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.29586800932884216}, {\"channel\": 3, \"epoch\": 18, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.19705423712730408}, {\"channel\": 4, \"epoch\": 18, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.196377694606781}, {\"channel\": 5, \"epoch\": 18, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.18069599568843842}, {\"channel\": 6, \"epoch\": 18, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.21383032202720642}, {\"channel\": 7, \"epoch\": 18, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.15747997164726257}, {\"channel\": 8, \"epoch\": 18, \"layer\": \"layer3\", \"type\": \"weight\", \"value\": 0.20293797552585602}, {\"channel\": 1, \"epoch\": 18, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.14493481814861298}, {\"channel\": 2, \"epoch\": 18, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.17454659938812256}, {\"channel\": 3, \"epoch\": 18, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.21693985164165497}, {\"channel\": 4, \"epoch\": 18, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.23304101824760437}, {\"channel\": 5, \"epoch\": 18, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.12279292941093445}, {\"channel\": 6, \"epoch\": 18, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.23983928561210632}, {\"channel\": 7, \"epoch\": 18, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.14765504002571106}, {\"channel\": 8, \"epoch\": 18, \"layer\": \"layer3\", \"type\": \"bias\", \"value\": -0.13688963651657104}, {\"channel\": 1, \"epoch\": 18, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.18051613867282867}, {\"channel\": 2, \"epoch\": 18, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.11570826917886734}, {\"channel\": 3, \"epoch\": 18, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.14991435408592224}, {\"channel\": 4, \"epoch\": 18, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.22722287476062775}, {\"channel\": 5, \"epoch\": 18, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.08640944957733154}, {\"channel\": 6, \"epoch\": 18, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.13895058631896973}, {\"channel\": 7, \"epoch\": 18, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.15229879319667816}, {\"channel\": 8, \"epoch\": 18, \"layer\": \"layer3_residual_res1\", \"type\": \"weight\", \"value\": 0.09899508208036423}, {\"channel\": 1, \"epoch\": 18, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.2136429399251938}, {\"channel\": 2, \"epoch\": 18, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.11787057667970657}, {\"channel\": 3, \"epoch\": 18, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.1964341402053833}, {\"channel\": 4, \"epoch\": 18, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.23558370769023895}, {\"channel\": 5, \"epoch\": 18, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.10410035401582718}, {\"channel\": 6, \"epoch\": 18, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.14102865755558014}, {\"channel\": 7, \"epoch\": 18, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.18690542876720428}, {\"channel\": 8, \"epoch\": 18, \"layer\": \"layer3_residual_res1\", \"type\": \"bias\", \"value\": -0.10165248811244965}, {\"channel\": 1, \"epoch\": 18, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.3224475085735321}, {\"channel\": 2, \"epoch\": 18, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.48149752616882324}, {\"channel\": 3, \"epoch\": 18, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.3182159662246704}, {\"channel\": 4, \"epoch\": 18, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.4763014614582062}, {\"channel\": 5, \"epoch\": 18, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.45040661096572876}, {\"channel\": 6, \"epoch\": 18, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.4543524980545044}, {\"channel\": 7, \"epoch\": 18, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.4510810673236847}, {\"channel\": 8, \"epoch\": 18, \"layer\": \"layer3_residual_res2\", \"type\": \"weight\", \"value\": 0.4412938952445984}, {\"channel\": 1, \"epoch\": 18, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.005110809113830328}, {\"channel\": 2, \"epoch\": 18, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.03204818814992905}, {\"channel\": 3, \"epoch\": 18, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.0063445414416491985}, {\"channel\": 4, \"epoch\": 18, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.011341217905282974}, {\"channel\": 5, \"epoch\": 18, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.0008873272454366088}, {\"channel\": 6, \"epoch\": 18, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.003019833704456687}, {\"channel\": 7, \"epoch\": 18, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.029659481719136238}, {\"channel\": 8, \"epoch\": 18, \"layer\": \"layer3_residual_res2\", \"type\": \"bias\", \"value\": -0.023154838010668755}]}};\n",
              "      var embedOpt = {\"mode\": \"vega-lite\"};\n",
              "\n",
              "      function showError(el, error){\n",
              "          el.innerHTML = ('<div class=\"error\" style=\"color:red;\">'\n",
              "                          + '<p>JavaScript Error: ' + error.message + '</p>'\n",
              "                          + \"<p>This usually means there's a typo in your chart specification. \"\n",
              "                          + \"See the javascript console for the full traceback.</p>\"\n",
              "                          + '</div>');\n",
              "          throw error;\n",
              "      }\n",
              "      const el = document.getElementById('altair-viz');\n",
              "      vegaEmbed(\"#altair-viz\", spec, embedOpt)\n",
              "        .catch(error => showError(el, error));\n",
              "    })(vegaEmbed);\n",
              "\n",
              "  </script>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMvagTTwx1wO",
        "colab_type": "text"
      },
      "source": [
        "There's a lot going on in these plots, but one thing that sticks out is that the scales are not doing much learning and evolve largely under the control of weight decay. Let's try freezing these at a constant value of $1/4$ - roughly their average at the midpoint of training. The learnable scale for the final layer is somewhat larger but we can adjust the scaling of the network output to compensate. \n",
        "\n",
        "Actually we can fix the batch norm scales to $1$ instead if we rescale the $\\alpha$ parameter of CELU by a compensating factor of $4$ and the learning rate and weight decay for the batch norm biases by $4^2$ and $1/4^2$ respectively. We prefer to do things this way since it makes the impact of the channel scales on the learning rate dynamics of the biases more explicit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkSuchyvLSa4",
        "colab_type": "code",
        "outputId": "13bdc784-50f8-4435-94b2-f17f5916d65d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "frozen_bn_scale_net = network(conv_pool_block=conv_pool_block_pre, scale=1/16, types={\n",
        "    nn.ReLU: partial(nn.CELU, 0.3),\n",
        "    BatchNorm: partial(GhostBatchNorm, num_splits=16, weight=False)\n",
        "})\n",
        "show(frozen_bn_scale_net)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<__main__.DotGraph at 0x7f7f20debe10>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: G Pages: 1 -->\n<svg width=\"1080pt\" height=\"64pt\"\n viewBox=\"0.00 0.00 1080.00 64.20\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(.3102 .3102) rotate(0) translate(4 203)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-203 3478,-203 3478,4 -4,4\"/>\n<g id=\"clust1\" class=\"cluster\">\n<title>cluster_prep</title>\n<path fill=\"#777777\" fill-opacity=\"0.266667\" stroke=\"#000000\" d=\"M94,-44C94,-44 320,-44 320,-44 326,-44 332,-50 332,-56 332,-56 332,-107 332,-107 332,-113 326,-119 320,-119 320,-119 94,-119 94,-119 88,-119 82,-113 82,-107 82,-107 82,-56 82,-56 82,-50 88,-44 94,-44\"/>\n<text text-anchor=\"middle\" x=\"207\" y=\"-103.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">prep</text>\n</g>\n<g id=\"clust2\" class=\"cluster\">\n<title>cluster_layer1</title>\n<path fill=\"#777777\" fill-opacity=\"0.266667\" stroke=\"#000000\" d=\"M364,-8C364,-8 1498,-8 1498,-8 1504,-8 1510,-14 1510,-20 1510,-20 1510,-159 1510,-159 1510,-165 1504,-171 1498,-171 1498,-171 364,-171 364,-171 358,-171 352,-165 352,-159 352,-159 352,-20 352,-20 352,-14 358,-8 364,-8\"/>\n<text text-anchor=\"middle\" x=\"931\" y=\"-155.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">layer1</text>\n</g>\n<g id=\"clust3\" class=\"cluster\">\n<title>cluster_layer1_residual</title>\n<path fill=\"#777777\" fill-opacity=\"0.266667\" stroke=\"#000000\" d=\"M724,-16C724,-16 1490,-16 1490,-16 1496,-16 1502,-22 1502,-28 1502,-28 1502,-128 1502,-128 1502,-134 1496,-140 1490,-140 1490,-140 724,-140 724,-140 718,-140 712,-134 712,-128 712,-128 712,-28 712,-28 712,-22 718,-16 724,-16\"/>\n<text text-anchor=\"middle\" x=\"1107\" y=\"-124.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">residual</text>\n</g>\n<g id=\"clust4\" class=\"cluster\">\n<title>cluster_layer1_residual_res1</title>\n<path fill=\"#777777\" fill-opacity=\"0.266667\" stroke=\"#000000\" d=\"M814,-24C814,-24 1040,-24 1040,-24 1046,-24 1052,-30 1052,-36 1052,-36 1052,-87 1052,-87 1052,-93 1046,-99 1040,-99 1040,-99 814,-99 814,-99 808,-99 802,-93 802,-87 802,-87 802,-36 802,-36 802,-30 808,-24 814,-24\"/>\n<text text-anchor=\"middle\" x=\"927\" y=\"-83.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">res1</text>\n</g>\n<g id=\"clust5\" class=\"cluster\">\n<title>cluster_layer1_residual_res2</title>\n<path fill=\"#777777\" fill-opacity=\"0.266667\" stroke=\"#000000\" d=\"M1084,-24C1084,-24 1310,-24 1310,-24 1316,-24 1322,-30 1322,-36 1322,-36 1322,-87 1322,-87 1322,-93 1316,-99 1310,-99 1310,-99 1084,-99 1084,-99 1078,-99 1072,-93 1072,-87 1072,-87 1072,-36 1072,-36 1072,-30 1078,-24 1084,-24\"/>\n<text text-anchor=\"middle\" x=\"1197\" y=\"-83.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">res2</text>\n</g>\n<g id=\"clust6\" class=\"cluster\">\n<title>cluster_layer2</title>\n<path fill=\"#777777\" fill-opacity=\"0.266667\" stroke=\"#000000\" d=\"M1534,-54C1534,-54 1850,-54 1850,-54 1856,-54 1862,-60 1862,-66 1862,-66 1862,-117 1862,-117 1862,-123 1856,-129 1850,-129 1850,-129 1534,-129 1534,-129 1528,-129 1522,-123 1522,-117 1522,-117 1522,-66 1522,-66 1522,-60 1528,-54 1534,-54\"/>\n<text text-anchor=\"middle\" x=\"1692\" y=\"-113.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">layer2</text>\n</g>\n<g id=\"clust7\" class=\"cluster\">\n<title>cluster_layer3</title>\n<path fill=\"#777777\" fill-opacity=\"0.266667\" stroke=\"#000000\" d=\"M1894,-28C1894,-28 3028,-28 3028,-28 3034,-28 3040,-34 3040,-40 3040,-40 3040,-179 3040,-179 3040,-185 3034,-191 3028,-191 3028,-191 1894,-191 1894,-191 1888,-191 1882,-185 1882,-179 1882,-179 1882,-40 1882,-40 1882,-34 1888,-28 1894,-28\"/>\n<text text-anchor=\"middle\" x=\"2461\" y=\"-175.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">layer3</text>\n</g>\n<g id=\"clust8\" class=\"cluster\">\n<title>cluster_layer3_residual</title>\n<path fill=\"#777777\" fill-opacity=\"0.266667\" stroke=\"#000000\" d=\"M2254,-36C2254,-36 3020,-36 3020,-36 3026,-36 3032,-42 3032,-48 3032,-48 3032,-148 3032,-148 3032,-154 3026,-160 3020,-160 3020,-160 2254,-160 2254,-160 2248,-160 2242,-154 2242,-148 2242,-148 2242,-48 2242,-48 2242,-42 2248,-36 2254,-36\"/>\n<text text-anchor=\"middle\" x=\"2637\" y=\"-144.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">residual</text>\n</g>\n<g id=\"clust9\" class=\"cluster\">\n<title>cluster_layer3_residual_res1</title>\n<path fill=\"#777777\" fill-opacity=\"0.266667\" stroke=\"#000000\" d=\"M2344,-44C2344,-44 2570,-44 2570,-44 2576,-44 2582,-50 2582,-56 2582,-56 2582,-107 2582,-107 2582,-113 2576,-119 2570,-119 2570,-119 2344,-119 2344,-119 2338,-119 2332,-113 2332,-107 2332,-107 2332,-56 2332,-56 2332,-50 2338,-44 2344,-44\"/>\n<text text-anchor=\"middle\" x=\"2457\" y=\"-103.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">res1</text>\n</g>\n<g id=\"clust10\" class=\"cluster\">\n<title>cluster_layer3_residual_res2</title>\n<path fill=\"#777777\" fill-opacity=\"0.266667\" stroke=\"#000000\" d=\"M2614,-44C2614,-44 2840,-44 2840,-44 2846,-44 2852,-50 2852,-56 2852,-56 2852,-107 2852,-107 2852,-113 2846,-119 2840,-119 2840,-119 2614,-119 2614,-119 2608,-119 2602,-113 2602,-107 2602,-107 2602,-56 2602,-56 2602,-50 2608,-44 2614,-44\"/>\n<text text-anchor=\"middle\" x=\"2727\" y=\"-103.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">res2</text>\n</g>\n<g id=\"clust11\" class=\"cluster\">\n<title>cluster_classifier</title>\n<path fill=\"#777777\" fill-opacity=\"0.266667\" stroke=\"#000000\" d=\"M3154,-74C3154,-74 3380,-74 3380,-74 3386,-74 3392,-80 3392,-86 3392,-86 3392,-137 3392,-137 3392,-143 3386,-149 3380,-149 3380,-149 3154,-149 3154,-149 3148,-149 3142,-143 3142,-137 3142,-137 3142,-86 3142,-86 3142,-80 3148,-74 3154,-74\"/>\n<text text-anchor=\"middle\" x=\"3267\" y=\"-133.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">classifier</text>\n</g>\n<!-- prep_conv -->\n<g id=\"node1\" class=\"node\">\n<title>prep_conv</title>\n<g id=\"a_node1\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.conv.Conv2d&#39;&gt; {&#39;in_channels&#39;: 3, &#39;out_channels&#39;: 64, &#39;kernel_size&#39;: (3, 3), &#39;stride&#39;: (1, 1), &#39;padding&#39;: (1, 1), &#39;bias&#39;: False}\">\n<path fill=\"#bebada\" stroke=\"#000000\" d=\"M132,-88C132,-88 102,-88 102,-88 96,-88 90,-82 90,-76 90,-76 90,-64 90,-64 90,-58 96,-52 102,-52 102,-52 132,-52 132,-52 138,-52 144,-58 144,-64 144,-64 144,-76 144,-76 144,-82 138,-88 132,-88\"/>\n<text text-anchor=\"middle\" x=\"117\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">conv</text>\n</a>\n</g>\n</g>\n<!-- prep_norm -->\n<g id=\"node2\" class=\"node\">\n<title>prep_norm</title>\n<g id=\"a_node2\"><a xlink:title=\"functools.partial(&lt;class &#39;__main__.GhostBatchNorm&#39;&gt;, num_splits=16, weight=False) {&#39;num_features&#39;: 64}\">\n<path fill=\"#b07b87\" stroke=\"#000000\" d=\"M222,-88C222,-88 192,-88 192,-88 186,-88 180,-82 180,-76 180,-76 180,-64 180,-64 180,-58 186,-52 192,-52 192,-52 222,-52 222,-52 228,-52 234,-58 234,-64 234,-64 234,-76 234,-76 234,-82 228,-88 222,-88\"/>\n<text text-anchor=\"middle\" x=\"207\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">norm</text>\n</a>\n</g>\n</g>\n<!-- prep_conv&#45;&gt;prep_norm -->\n<g id=\"edge2\" class=\"edge\">\n<title>prep_conv&#45;&gt;prep_norm</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M144.003,-70C152.0277,-70 160.9665,-70 169.5309,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"169.7051,-73.5001 179.705,-70 169.705,-66.5001 169.7051,-73.5001\"/>\n</g>\n<!-- prep_act -->\n<g id=\"node3\" class=\"node\">\n<title>prep_act</title>\n<g id=\"a_node3\"><a xlink:title=\"functools.partial(&lt;class &#39;torch.nn.modules.activation.CELU&#39;&gt;, 0.3) {}\">\n<path fill=\"#4e90e3\" stroke=\"#000000\" d=\"M312,-88C312,-88 282,-88 282,-88 276,-88 270,-82 270,-76 270,-76 270,-64 270,-64 270,-58 276,-52 282,-52 282,-52 312,-52 312,-52 318,-52 324,-58 324,-64 324,-64 324,-76 324,-76 324,-82 318,-88 312,-88\"/>\n<text text-anchor=\"middle\" x=\"297\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">act</text>\n</a>\n</g>\n</g>\n<!-- prep_norm&#45;&gt;prep_act -->\n<g id=\"edge3\" class=\"edge\">\n<title>prep_norm&#45;&gt;prep_act</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M234.003,-70C242.0277,-70 250.9665,-70 259.5309,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"259.7051,-73.5001 269.705,-70 259.705,-66.5001 259.7051,-73.5001\"/>\n</g>\n<!-- layer1_conv -->\n<g id=\"node4\" class=\"node\">\n<title>layer1_conv</title>\n<g id=\"a_node4\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.conv.Conv2d&#39;&gt; {&#39;in_channels&#39;: 64, &#39;out_channels&#39;: 128, &#39;kernel_size&#39;: (3, 3), &#39;stride&#39;: (1, 1), &#39;padding&#39;: (1, 1), &#39;bias&#39;: False}\">\n<path fill=\"#bebada\" stroke=\"#000000\" d=\"M402,-88C402,-88 372,-88 372,-88 366,-88 360,-82 360,-76 360,-76 360,-64 360,-64 360,-58 366,-52 372,-52 372,-52 402,-52 402,-52 408,-52 414,-58 414,-64 414,-64 414,-76 414,-76 414,-82 408,-88 402,-88\"/>\n<text text-anchor=\"middle\" x=\"387\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">conv</text>\n</a>\n</g>\n</g>\n<!-- prep_act&#45;&gt;layer1_conv -->\n<g id=\"edge4\" class=\"edge\">\n<title>prep_act&#45;&gt;layer1_conv</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M324.003,-70C332.0277,-70 340.9665,-70 349.5309,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"349.7051,-73.5001 359.705,-70 349.705,-66.5001 349.7051,-73.5001\"/>\n</g>\n<!-- layer1_pool -->\n<g id=\"node5\" class=\"node\">\n<title>layer1_pool</title>\n<g id=\"a_node5\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.pooling.MaxPool2d&#39;&gt; {&#39;kernel_size&#39;: 2}\">\n<path fill=\"#8dd3c7\" stroke=\"#000000\" d=\"M492,-88C492,-88 462,-88 462,-88 456,-88 450,-82 450,-76 450,-76 450,-64 450,-64 450,-58 456,-52 462,-52 462,-52 492,-52 492,-52 498,-52 504,-58 504,-64 504,-64 504,-76 504,-76 504,-82 498,-88 492,-88\"/>\n<text text-anchor=\"middle\" x=\"477\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">pool</text>\n</a>\n</g>\n</g>\n<!-- layer1_conv&#45;&gt;layer1_pool -->\n<g id=\"edge5\" class=\"edge\">\n<title>layer1_conv&#45;&gt;layer1_pool</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M414.003,-70C422.0277,-70 430.9665,-70 439.5309,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"439.7051,-73.5001 449.705,-70 439.705,-66.5001 439.7051,-73.5001\"/>\n</g>\n<!-- layer1_norm -->\n<g id=\"node6\" class=\"node\">\n<title>layer1_norm</title>\n<g id=\"a_node6\"><a xlink:title=\"functools.partial(&lt;class &#39;__main__.GhostBatchNorm&#39;&gt;, num_splits=16, weight=False) {&#39;num_features&#39;: 128}\">\n<path fill=\"#b07b87\" stroke=\"#000000\" d=\"M582,-88C582,-88 552,-88 552,-88 546,-88 540,-82 540,-76 540,-76 540,-64 540,-64 540,-58 546,-52 552,-52 552,-52 582,-52 582,-52 588,-52 594,-58 594,-64 594,-64 594,-76 594,-76 594,-82 588,-88 582,-88\"/>\n<text text-anchor=\"middle\" x=\"567\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">norm</text>\n</a>\n</g>\n</g>\n<!-- layer1_pool&#45;&gt;layer1_norm -->\n<g id=\"edge6\" class=\"edge\">\n<title>layer1_pool&#45;&gt;layer1_norm</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M504.003,-70C512.0277,-70 520.9665,-70 529.5309,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"529.7051,-73.5001 539.705,-70 529.705,-66.5001 529.7051,-73.5001\"/>\n</g>\n<!-- layer1_act -->\n<g id=\"node7\" class=\"node\">\n<title>layer1_act</title>\n<g id=\"a_node7\"><a xlink:title=\"functools.partial(&lt;class &#39;torch.nn.modules.activation.CELU&#39;&gt;, 0.3) {}\">\n<path fill=\"#4e90e3\" stroke=\"#000000\" d=\"M672,-88C672,-88 642,-88 642,-88 636,-88 630,-82 630,-76 630,-76 630,-64 630,-64 630,-58 636,-52 642,-52 642,-52 672,-52 672,-52 678,-52 684,-58 684,-64 684,-64 684,-76 684,-76 684,-82 678,-88 672,-88\"/>\n<text text-anchor=\"middle\" x=\"657\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">act</text>\n</a>\n</g>\n</g>\n<!-- layer1_norm&#45;&gt;layer1_act -->\n<g id=\"edge7\" class=\"edge\">\n<title>layer1_norm&#45;&gt;layer1_act</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M594.003,-70C602.0277,-70 610.9665,-70 619.5309,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"619.7051,-73.5001 629.705,-70 619.705,-66.5001 619.7051,-73.5001\"/>\n</g>\n<!-- layer1_residual_in -->\n<g id=\"node8\" class=\"node\">\n<title>layer1_residual_in</title>\n<g id=\"a_node8\"><a xlink:title=\"&lt;class &#39;__main__.Identity&#39;&gt; {}\">\n<path fill=\"#80b1d3\" stroke=\"#000000\" d=\"M762,-88C762,-88 732,-88 732,-88 726,-88 720,-82 720,-76 720,-76 720,-64 720,-64 720,-58 726,-52 732,-52 732,-52 762,-52 762,-52 768,-52 774,-58 774,-64 774,-64 774,-76 774,-76 774,-82 768,-88 762,-88\"/>\n<text text-anchor=\"middle\" x=\"747\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">in</text>\n</a>\n</g>\n</g>\n<!-- layer1_act&#45;&gt;layer1_residual_in -->\n<g id=\"edge8\" class=\"edge\">\n<title>layer1_act&#45;&gt;layer1_residual_in</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M684.003,-70C692.0277,-70 700.9665,-70 709.5309,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"709.7051,-73.5001 719.705,-70 709.705,-66.5001 709.7051,-73.5001\"/>\n</g>\n<!-- layer1_residual_res1_conv -->\n<g id=\"node9\" class=\"node\">\n<title>layer1_residual_res1_conv</title>\n<g id=\"a_node9\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.conv.Conv2d&#39;&gt; {&#39;in_channels&#39;: 128, &#39;out_channels&#39;: 128, &#39;kernel_size&#39;: (3, 3), &#39;stride&#39;: (1, 1), &#39;padding&#39;: (1, 1), &#39;bias&#39;: False}\">\n<path fill=\"#bebada\" stroke=\"#000000\" d=\"M852,-68C852,-68 822,-68 822,-68 816,-68 810,-62 810,-56 810,-56 810,-44 810,-44 810,-38 816,-32 822,-32 822,-32 852,-32 852,-32 858,-32 864,-38 864,-44 864,-44 864,-56 864,-56 864,-62 858,-68 852,-68\"/>\n<text text-anchor=\"middle\" x=\"837\" y=\"-46.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">conv</text>\n</a>\n</g>\n</g>\n<!-- layer1_residual_in&#45;&gt;layer1_residual_res1_conv -->\n<g id=\"edge9\" class=\"edge\">\n<title>layer1_residual_in&#45;&gt;layer1_residual_res1_conv</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M774.003,-63.9993C782.1158,-62.1965 791.1631,-60.186 799.8131,-58.2638\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"800.7024,-61.6516 809.705,-56.0655 799.1839,-54.8183 800.7024,-61.6516\"/>\n</g>\n<!-- layer1_residual_add -->\n<g id=\"node16\" class=\"node\">\n<title>layer1_residual_add</title>\n<g id=\"a_node16\"><a xlink:title=\"&lt;class &#39;__main__.Add&#39;&gt; {}\">\n<path fill=\"#fdb462\" stroke=\"#000000\" d=\"M1482,-98C1482,-98 1452,-98 1452,-98 1446,-98 1440,-92 1440,-86 1440,-86 1440,-74 1440,-74 1440,-68 1446,-62 1452,-62 1452,-62 1482,-62 1482,-62 1488,-62 1494,-68 1494,-74 1494,-74 1494,-86 1494,-86 1494,-92 1488,-98 1482,-98\"/>\n<text text-anchor=\"middle\" x=\"1467\" y=\"-76.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">add</text>\n</a>\n</g>\n</g>\n<!-- layer1_residual_in&#45;&gt;layer1_residual_add -->\n<g id=\"edge16\" class=\"edge\">\n<title>layer1_residual_in&#45;&gt;layer1_residual_add</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M771.2203,-88.104C780.3892,-93.9663 791.2234,-99.7818 802,-103 855.2752,-118.9095 871.4,-108 927,-108 927,-108 927,-108 1287,-108 1336.7971,-108 1393.4324,-97.4074 1429.6554,-89.2525\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1430.8023,-92.5799 1439.7594,-86.9214 1429.2285,-85.7591 1430.8023,-92.5799\"/>\n</g>\n<!-- layer1_residual_res1_norm -->\n<g id=\"node10\" class=\"node\">\n<title>layer1_residual_res1_norm</title>\n<g id=\"a_node10\"><a xlink:title=\"functools.partial(&lt;class &#39;__main__.GhostBatchNorm&#39;&gt;, num_splits=16, weight=False) {&#39;num_features&#39;: 128}\">\n<path fill=\"#b07b87\" stroke=\"#000000\" d=\"M942,-68C942,-68 912,-68 912,-68 906,-68 900,-62 900,-56 900,-56 900,-44 900,-44 900,-38 906,-32 912,-32 912,-32 942,-32 942,-32 948,-32 954,-38 954,-44 954,-44 954,-56 954,-56 954,-62 948,-68 942,-68\"/>\n<text text-anchor=\"middle\" x=\"927\" y=\"-46.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">norm</text>\n</a>\n</g>\n</g>\n<!-- layer1_residual_res1_conv&#45;&gt;layer1_residual_res1_norm -->\n<g id=\"edge10\" class=\"edge\">\n<title>layer1_residual_res1_conv&#45;&gt;layer1_residual_res1_norm</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M864.003,-50C872.0277,-50 880.9665,-50 889.5309,-50\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"889.7051,-53.5001 899.705,-50 889.705,-46.5001 889.7051,-53.5001\"/>\n</g>\n<!-- layer1_residual_res1_act -->\n<g id=\"node11\" class=\"node\">\n<title>layer1_residual_res1_act</title>\n<g id=\"a_node11\"><a xlink:title=\"functools.partial(&lt;class &#39;torch.nn.modules.activation.CELU&#39;&gt;, 0.3) {}\">\n<path fill=\"#4e90e3\" stroke=\"#000000\" d=\"M1032,-68C1032,-68 1002,-68 1002,-68 996,-68 990,-62 990,-56 990,-56 990,-44 990,-44 990,-38 996,-32 1002,-32 1002,-32 1032,-32 1032,-32 1038,-32 1044,-38 1044,-44 1044,-44 1044,-56 1044,-56 1044,-62 1038,-68 1032,-68\"/>\n<text text-anchor=\"middle\" x=\"1017\" y=\"-46.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">act</text>\n</a>\n</g>\n</g>\n<!-- layer1_residual_res1_norm&#45;&gt;layer1_residual_res1_act -->\n<g id=\"edge11\" class=\"edge\">\n<title>layer1_residual_res1_norm&#45;&gt;layer1_residual_res1_act</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M954.003,-50C962.0277,-50 970.9665,-50 979.5309,-50\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"979.7051,-53.5001 989.705,-50 979.705,-46.5001 979.7051,-53.5001\"/>\n</g>\n<!-- layer1_residual_res2_conv -->\n<g id=\"node12\" class=\"node\">\n<title>layer1_residual_res2_conv</title>\n<g id=\"a_node12\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.conv.Conv2d&#39;&gt; {&#39;in_channels&#39;: 128, &#39;out_channels&#39;: 128, &#39;kernel_size&#39;: (3, 3), &#39;stride&#39;: (1, 1), &#39;padding&#39;: (1, 1), &#39;bias&#39;: False}\">\n<path fill=\"#bebada\" stroke=\"#000000\" d=\"M1122,-68C1122,-68 1092,-68 1092,-68 1086,-68 1080,-62 1080,-56 1080,-56 1080,-44 1080,-44 1080,-38 1086,-32 1092,-32 1092,-32 1122,-32 1122,-32 1128,-32 1134,-38 1134,-44 1134,-44 1134,-56 1134,-56 1134,-62 1128,-68 1122,-68\"/>\n<text text-anchor=\"middle\" x=\"1107\" y=\"-46.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">conv</text>\n</a>\n</g>\n</g>\n<!-- layer1_residual_res1_act&#45;&gt;layer1_residual_res2_conv -->\n<g id=\"edge12\" class=\"edge\">\n<title>layer1_residual_res1_act&#45;&gt;layer1_residual_res2_conv</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1044.003,-50C1052.0277,-50 1060.9665,-50 1069.5309,-50\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1069.7051,-53.5001 1079.705,-50 1069.705,-46.5001 1069.7051,-53.5001\"/>\n</g>\n<!-- layer1_residual_res2_norm -->\n<g id=\"node13\" class=\"node\">\n<title>layer1_residual_res2_norm</title>\n<g id=\"a_node13\"><a xlink:title=\"functools.partial(&lt;class &#39;__main__.GhostBatchNorm&#39;&gt;, num_splits=16, weight=False) {&#39;num_features&#39;: 128}\">\n<path fill=\"#b07b87\" stroke=\"#000000\" d=\"M1212,-68C1212,-68 1182,-68 1182,-68 1176,-68 1170,-62 1170,-56 1170,-56 1170,-44 1170,-44 1170,-38 1176,-32 1182,-32 1182,-32 1212,-32 1212,-32 1218,-32 1224,-38 1224,-44 1224,-44 1224,-56 1224,-56 1224,-62 1218,-68 1212,-68\"/>\n<text text-anchor=\"middle\" x=\"1197\" y=\"-46.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">norm</text>\n</a>\n</g>\n</g>\n<!-- layer1_residual_res2_conv&#45;&gt;layer1_residual_res2_norm -->\n<g id=\"edge13\" class=\"edge\">\n<title>layer1_residual_res2_conv&#45;&gt;layer1_residual_res2_norm</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1134.003,-50C1142.0277,-50 1150.9665,-50 1159.5309,-50\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1159.7051,-53.5001 1169.705,-50 1159.705,-46.5001 1159.7051,-53.5001\"/>\n</g>\n<!-- layer1_residual_res2_act -->\n<g id=\"node14\" class=\"node\">\n<title>layer1_residual_res2_act</title>\n<g id=\"a_node14\"><a xlink:title=\"functools.partial(&lt;class &#39;torch.nn.modules.activation.CELU&#39;&gt;, 0.3) {}\">\n<path fill=\"#4e90e3\" stroke=\"#000000\" d=\"M1302,-68C1302,-68 1272,-68 1272,-68 1266,-68 1260,-62 1260,-56 1260,-56 1260,-44 1260,-44 1260,-38 1266,-32 1272,-32 1272,-32 1302,-32 1302,-32 1308,-32 1314,-38 1314,-44 1314,-44 1314,-56 1314,-56 1314,-62 1308,-68 1302,-68\"/>\n<text text-anchor=\"middle\" x=\"1287\" y=\"-46.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">act</text>\n</a>\n</g>\n</g>\n<!-- layer1_residual_res2_norm&#45;&gt;layer1_residual_res2_act -->\n<g id=\"edge14\" class=\"edge\">\n<title>layer1_residual_res2_norm&#45;&gt;layer1_residual_res2_act</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1224.003,-50C1232.0277,-50 1240.9665,-50 1249.5309,-50\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1249.7051,-53.5001 1259.705,-50 1249.705,-46.5001 1249.7051,-53.5001\"/>\n</g>\n<!-- layer1_residual_out -->\n<g id=\"node15\" class=\"node\">\n<title>layer1_residual_out</title>\n<g id=\"a_node15\"><a xlink:title=\"&lt;class &#39;__main__.Identity&#39;&gt; {}\">\n<path fill=\"#80b1d3\" stroke=\"#000000\" d=\"M1392,-78C1392,-78 1362,-78 1362,-78 1356,-78 1350,-72 1350,-66 1350,-66 1350,-54 1350,-54 1350,-48 1356,-42 1362,-42 1362,-42 1392,-42 1392,-42 1398,-42 1404,-48 1404,-54 1404,-54 1404,-66 1404,-66 1404,-72 1398,-78 1392,-78\"/>\n<text text-anchor=\"middle\" x=\"1377\" y=\"-56.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">out</text>\n</a>\n</g>\n</g>\n<!-- layer1_residual_res2_act&#45;&gt;layer1_residual_out -->\n<g id=\"edge15\" class=\"edge\">\n<title>layer1_residual_res2_act&#45;&gt;layer1_residual_out</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1314.003,-53.0003C1322.0277,-53.892 1330.9665,-54.8852 1339.5309,-55.8368\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1339.3796,-59.3414 1349.705,-56.9672 1340.1527,-52.3842 1339.3796,-59.3414\"/>\n</g>\n<!-- layer1_residual_out&#45;&gt;layer1_residual_add -->\n<g id=\"edge17\" class=\"edge\">\n<title>layer1_residual_out&#45;&gt;layer1_residual_add</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1404.003,-66.0007C1412.1158,-67.8035 1421.1631,-69.814 1429.8131,-71.7362\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1429.1839,-75.1817 1439.705,-73.9345 1430.7024,-68.3484 1429.1839,-75.1817\"/>\n</g>\n<!-- layer2_conv -->\n<g id=\"node17\" class=\"node\">\n<title>layer2_conv</title>\n<g id=\"a_node17\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.conv.Conv2d&#39;&gt; {&#39;in_channels&#39;: 128, &#39;out_channels&#39;: 256, &#39;kernel_size&#39;: (3, 3), &#39;stride&#39;: (1, 1), &#39;padding&#39;: (1, 1), &#39;bias&#39;: False}\">\n<path fill=\"#bebada\" stroke=\"#000000\" d=\"M1572,-98C1572,-98 1542,-98 1542,-98 1536,-98 1530,-92 1530,-86 1530,-86 1530,-74 1530,-74 1530,-68 1536,-62 1542,-62 1542,-62 1572,-62 1572,-62 1578,-62 1584,-68 1584,-74 1584,-74 1584,-86 1584,-86 1584,-92 1578,-98 1572,-98\"/>\n<text text-anchor=\"middle\" x=\"1557\" y=\"-76.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">conv</text>\n</a>\n</g>\n</g>\n<!-- layer1_residual_add&#45;&gt;layer2_conv -->\n<g id=\"edge18\" class=\"edge\">\n<title>layer1_residual_add&#45;&gt;layer2_conv</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1494.003,-80C1502.0277,-80 1510.9665,-80 1519.5309,-80\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1519.7051,-83.5001 1529.705,-80 1519.705,-76.5001 1519.7051,-83.5001\"/>\n</g>\n<!-- layer2_pool -->\n<g id=\"node18\" class=\"node\">\n<title>layer2_pool</title>\n<g id=\"a_node18\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.pooling.MaxPool2d&#39;&gt; {&#39;kernel_size&#39;: 2}\">\n<path fill=\"#8dd3c7\" stroke=\"#000000\" d=\"M1662,-98C1662,-98 1632,-98 1632,-98 1626,-98 1620,-92 1620,-86 1620,-86 1620,-74 1620,-74 1620,-68 1626,-62 1632,-62 1632,-62 1662,-62 1662,-62 1668,-62 1674,-68 1674,-74 1674,-74 1674,-86 1674,-86 1674,-92 1668,-98 1662,-98\"/>\n<text text-anchor=\"middle\" x=\"1647\" y=\"-76.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">pool</text>\n</a>\n</g>\n</g>\n<!-- layer2_conv&#45;&gt;layer2_pool -->\n<g id=\"edge19\" class=\"edge\">\n<title>layer2_conv&#45;&gt;layer2_pool</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1584.003,-80C1592.0277,-80 1600.9665,-80 1609.5309,-80\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1609.7051,-83.5001 1619.705,-80 1609.705,-76.5001 1609.7051,-83.5001\"/>\n</g>\n<!-- layer2_norm -->\n<g id=\"node19\" class=\"node\">\n<title>layer2_norm</title>\n<g id=\"a_node19\"><a xlink:title=\"functools.partial(&lt;class &#39;__main__.GhostBatchNorm&#39;&gt;, num_splits=16, weight=False) {&#39;num_features&#39;: 256}\">\n<path fill=\"#b07b87\" stroke=\"#000000\" d=\"M1752,-98C1752,-98 1722,-98 1722,-98 1716,-98 1710,-92 1710,-86 1710,-86 1710,-74 1710,-74 1710,-68 1716,-62 1722,-62 1722,-62 1752,-62 1752,-62 1758,-62 1764,-68 1764,-74 1764,-74 1764,-86 1764,-86 1764,-92 1758,-98 1752,-98\"/>\n<text text-anchor=\"middle\" x=\"1737\" y=\"-76.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">norm</text>\n</a>\n</g>\n</g>\n<!-- layer2_pool&#45;&gt;layer2_norm -->\n<g id=\"edge20\" class=\"edge\">\n<title>layer2_pool&#45;&gt;layer2_norm</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1674.003,-80C1682.0277,-80 1690.9665,-80 1699.5309,-80\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1699.7051,-83.5001 1709.705,-80 1699.705,-76.5001 1699.7051,-83.5001\"/>\n</g>\n<!-- layer2_act -->\n<g id=\"node20\" class=\"node\">\n<title>layer2_act</title>\n<g id=\"a_node20\"><a xlink:title=\"functools.partial(&lt;class &#39;torch.nn.modules.activation.CELU&#39;&gt;, 0.3) {}\">\n<path fill=\"#4e90e3\" stroke=\"#000000\" d=\"M1842,-98C1842,-98 1812,-98 1812,-98 1806,-98 1800,-92 1800,-86 1800,-86 1800,-74 1800,-74 1800,-68 1806,-62 1812,-62 1812,-62 1842,-62 1842,-62 1848,-62 1854,-68 1854,-74 1854,-74 1854,-86 1854,-86 1854,-92 1848,-98 1842,-98\"/>\n<text text-anchor=\"middle\" x=\"1827\" y=\"-76.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">act</text>\n</a>\n</g>\n</g>\n<!-- layer2_norm&#45;&gt;layer2_act -->\n<g id=\"edge21\" class=\"edge\">\n<title>layer2_norm&#45;&gt;layer2_act</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1764.003,-80C1772.0277,-80 1780.9665,-80 1789.5309,-80\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1789.7051,-83.5001 1799.705,-80 1789.705,-76.5001 1789.7051,-83.5001\"/>\n</g>\n<!-- layer3_conv -->\n<g id=\"node21\" class=\"node\">\n<title>layer3_conv</title>\n<g id=\"a_node21\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.conv.Conv2d&#39;&gt; {&#39;in_channels&#39;: 256, &#39;out_channels&#39;: 512, &#39;kernel_size&#39;: (3, 3), &#39;stride&#39;: (1, 1), &#39;padding&#39;: (1, 1), &#39;bias&#39;: False}\">\n<path fill=\"#bebada\" stroke=\"#000000\" d=\"M1932,-98C1932,-98 1902,-98 1902,-98 1896,-98 1890,-92 1890,-86 1890,-86 1890,-74 1890,-74 1890,-68 1896,-62 1902,-62 1902,-62 1932,-62 1932,-62 1938,-62 1944,-68 1944,-74 1944,-74 1944,-86 1944,-86 1944,-92 1938,-98 1932,-98\"/>\n<text text-anchor=\"middle\" x=\"1917\" y=\"-76.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">conv</text>\n</a>\n</g>\n</g>\n<!-- layer2_act&#45;&gt;layer3_conv -->\n<g id=\"edge22\" class=\"edge\">\n<title>layer2_act&#45;&gt;layer3_conv</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1854.003,-80C1862.0277,-80 1870.9665,-80 1879.5309,-80\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1879.7051,-83.5001 1889.705,-80 1879.705,-76.5001 1879.7051,-83.5001\"/>\n</g>\n<!-- layer3_pool -->\n<g id=\"node22\" class=\"node\">\n<title>layer3_pool</title>\n<g id=\"a_node22\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.pooling.MaxPool2d&#39;&gt; {&#39;kernel_size&#39;: 2}\">\n<path fill=\"#8dd3c7\" stroke=\"#000000\" d=\"M2022,-98C2022,-98 1992,-98 1992,-98 1986,-98 1980,-92 1980,-86 1980,-86 1980,-74 1980,-74 1980,-68 1986,-62 1992,-62 1992,-62 2022,-62 2022,-62 2028,-62 2034,-68 2034,-74 2034,-74 2034,-86 2034,-86 2034,-92 2028,-98 2022,-98\"/>\n<text text-anchor=\"middle\" x=\"2007\" y=\"-76.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">pool</text>\n</a>\n</g>\n</g>\n<!-- layer3_conv&#45;&gt;layer3_pool -->\n<g id=\"edge23\" class=\"edge\">\n<title>layer3_conv&#45;&gt;layer3_pool</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1944.003,-80C1952.0277,-80 1960.9665,-80 1969.5309,-80\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1969.7051,-83.5001 1979.705,-80 1969.705,-76.5001 1969.7051,-83.5001\"/>\n</g>\n<!-- layer3_norm -->\n<g id=\"node23\" class=\"node\">\n<title>layer3_norm</title>\n<g id=\"a_node23\"><a xlink:title=\"functools.partial(&lt;class &#39;__main__.GhostBatchNorm&#39;&gt;, num_splits=16, weight=False) {&#39;num_features&#39;: 512}\">\n<path fill=\"#b07b87\" stroke=\"#000000\" d=\"M2112,-98C2112,-98 2082,-98 2082,-98 2076,-98 2070,-92 2070,-86 2070,-86 2070,-74 2070,-74 2070,-68 2076,-62 2082,-62 2082,-62 2112,-62 2112,-62 2118,-62 2124,-68 2124,-74 2124,-74 2124,-86 2124,-86 2124,-92 2118,-98 2112,-98\"/>\n<text text-anchor=\"middle\" x=\"2097\" y=\"-76.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">norm</text>\n</a>\n</g>\n</g>\n<!-- layer3_pool&#45;&gt;layer3_norm -->\n<g id=\"edge24\" class=\"edge\">\n<title>layer3_pool&#45;&gt;layer3_norm</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2034.003,-80C2042.0277,-80 2050.9665,-80 2059.5309,-80\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2059.7051,-83.5001 2069.705,-80 2059.705,-76.5001 2059.7051,-83.5001\"/>\n</g>\n<!-- layer3_act -->\n<g id=\"node24\" class=\"node\">\n<title>layer3_act</title>\n<g id=\"a_node24\"><a xlink:title=\"functools.partial(&lt;class &#39;torch.nn.modules.activation.CELU&#39;&gt;, 0.3) {}\">\n<path fill=\"#4e90e3\" stroke=\"#000000\" d=\"M2202,-98C2202,-98 2172,-98 2172,-98 2166,-98 2160,-92 2160,-86 2160,-86 2160,-74 2160,-74 2160,-68 2166,-62 2172,-62 2172,-62 2202,-62 2202,-62 2208,-62 2214,-68 2214,-74 2214,-74 2214,-86 2214,-86 2214,-92 2208,-98 2202,-98\"/>\n<text text-anchor=\"middle\" x=\"2187\" y=\"-76.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">act</text>\n</a>\n</g>\n</g>\n<!-- layer3_norm&#45;&gt;layer3_act -->\n<g id=\"edge25\" class=\"edge\">\n<title>layer3_norm&#45;&gt;layer3_act</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2124.003,-80C2132.0277,-80 2140.9665,-80 2149.5309,-80\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2149.7051,-83.5001 2159.705,-80 2149.705,-76.5001 2149.7051,-83.5001\"/>\n</g>\n<!-- layer3_residual_in -->\n<g id=\"node25\" class=\"node\">\n<title>layer3_residual_in</title>\n<g id=\"a_node25\"><a xlink:title=\"&lt;class &#39;__main__.Identity&#39;&gt; {}\">\n<path fill=\"#80b1d3\" stroke=\"#000000\" d=\"M2292,-98C2292,-98 2262,-98 2262,-98 2256,-98 2250,-92 2250,-86 2250,-86 2250,-74 2250,-74 2250,-68 2256,-62 2262,-62 2262,-62 2292,-62 2292,-62 2298,-62 2304,-68 2304,-74 2304,-74 2304,-86 2304,-86 2304,-92 2298,-98 2292,-98\"/>\n<text text-anchor=\"middle\" x=\"2277\" y=\"-76.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">in</text>\n</a>\n</g>\n</g>\n<!-- layer3_act&#45;&gt;layer3_residual_in -->\n<g id=\"edge26\" class=\"edge\">\n<title>layer3_act&#45;&gt;layer3_residual_in</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2214.003,-80C2222.0277,-80 2230.9665,-80 2239.5309,-80\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2239.7051,-83.5001 2249.705,-80 2239.705,-76.5001 2239.7051,-83.5001\"/>\n</g>\n<!-- layer3_residual_res1_conv -->\n<g id=\"node26\" class=\"node\">\n<title>layer3_residual_res1_conv</title>\n<g id=\"a_node26\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.conv.Conv2d&#39;&gt; {&#39;in_channels&#39;: 512, &#39;out_channels&#39;: 512, &#39;kernel_size&#39;: (3, 3), &#39;stride&#39;: (1, 1), &#39;padding&#39;: (1, 1), &#39;bias&#39;: False}\">\n<path fill=\"#bebada\" stroke=\"#000000\" d=\"M2382,-88C2382,-88 2352,-88 2352,-88 2346,-88 2340,-82 2340,-76 2340,-76 2340,-64 2340,-64 2340,-58 2346,-52 2352,-52 2352,-52 2382,-52 2382,-52 2388,-52 2394,-58 2394,-64 2394,-64 2394,-76 2394,-76 2394,-82 2388,-88 2382,-88\"/>\n<text text-anchor=\"middle\" x=\"2367\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">conv</text>\n</a>\n</g>\n</g>\n<!-- layer3_residual_in&#45;&gt;layer3_residual_res1_conv -->\n<g id=\"edge27\" class=\"edge\">\n<title>layer3_residual_in&#45;&gt;layer3_residual_res1_conv</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2304.003,-76.9997C2312.0277,-76.108 2320.9665,-75.1148 2329.5309,-74.1632\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2330.1527,-77.6158 2339.705,-73.0328 2329.3796,-70.6586 2330.1527,-77.6158\"/>\n</g>\n<!-- layer3_residual_add -->\n<g id=\"node33\" class=\"node\">\n<title>layer3_residual_add</title>\n<g id=\"a_node33\"><a xlink:title=\"&lt;class &#39;__main__.Add&#39;&gt; {}\">\n<path fill=\"#fdb462\" stroke=\"#000000\" d=\"M3012,-118C3012,-118 2982,-118 2982,-118 2976,-118 2970,-112 2970,-106 2970,-106 2970,-94 2970,-94 2970,-88 2976,-82 2982,-82 2982,-82 3012,-82 3012,-82 3018,-82 3024,-88 3024,-94 3024,-94 3024,-106 3024,-106 3024,-112 3018,-118 3012,-118\"/>\n<text text-anchor=\"middle\" x=\"2997\" y=\"-96.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">add</text>\n</a>\n</g>\n</g>\n<!-- layer3_residual_in&#45;&gt;layer3_residual_add -->\n<g id=\"edge34\" class=\"edge\">\n<title>layer3_residual_in&#45;&gt;layer3_residual_add</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2294.5351,-98.3771C2304.5459,-107.5711 2317.8909,-117.8215 2332,-123 2384.1953,-142.1574 2401.4,-128 2457,-128 2457,-128 2457,-128 2817,-128 2866.7971,-128 2923.4324,-117.4074 2959.6554,-109.2525\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2960.8023,-112.5799 2969.7594,-106.9214 2959.2285,-105.7591 2960.8023,-112.5799\"/>\n</g>\n<!-- layer3_residual_res1_norm -->\n<g id=\"node27\" class=\"node\">\n<title>layer3_residual_res1_norm</title>\n<g id=\"a_node27\"><a xlink:title=\"functools.partial(&lt;class &#39;__main__.GhostBatchNorm&#39;&gt;, num_splits=16, weight=False) {&#39;num_features&#39;: 512}\">\n<path fill=\"#b07b87\" stroke=\"#000000\" d=\"M2472,-88C2472,-88 2442,-88 2442,-88 2436,-88 2430,-82 2430,-76 2430,-76 2430,-64 2430,-64 2430,-58 2436,-52 2442,-52 2442,-52 2472,-52 2472,-52 2478,-52 2484,-58 2484,-64 2484,-64 2484,-76 2484,-76 2484,-82 2478,-88 2472,-88\"/>\n<text text-anchor=\"middle\" x=\"2457\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">norm</text>\n</a>\n</g>\n</g>\n<!-- layer3_residual_res1_conv&#45;&gt;layer3_residual_res1_norm -->\n<g id=\"edge28\" class=\"edge\">\n<title>layer3_residual_res1_conv&#45;&gt;layer3_residual_res1_norm</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2394.003,-70C2402.0277,-70 2410.9665,-70 2419.5309,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2419.7051,-73.5001 2429.705,-70 2419.705,-66.5001 2419.7051,-73.5001\"/>\n</g>\n<!-- layer3_residual_res1_act -->\n<g id=\"node28\" class=\"node\">\n<title>layer3_residual_res1_act</title>\n<g id=\"a_node28\"><a xlink:title=\"functools.partial(&lt;class &#39;torch.nn.modules.activation.CELU&#39;&gt;, 0.3) {}\">\n<path fill=\"#4e90e3\" stroke=\"#000000\" d=\"M2562,-88C2562,-88 2532,-88 2532,-88 2526,-88 2520,-82 2520,-76 2520,-76 2520,-64 2520,-64 2520,-58 2526,-52 2532,-52 2532,-52 2562,-52 2562,-52 2568,-52 2574,-58 2574,-64 2574,-64 2574,-76 2574,-76 2574,-82 2568,-88 2562,-88\"/>\n<text text-anchor=\"middle\" x=\"2547\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">act</text>\n</a>\n</g>\n</g>\n<!-- layer3_residual_res1_norm&#45;&gt;layer3_residual_res1_act -->\n<g id=\"edge29\" class=\"edge\">\n<title>layer3_residual_res1_norm&#45;&gt;layer3_residual_res1_act</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2484.003,-70C2492.0277,-70 2500.9665,-70 2509.5309,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2509.7051,-73.5001 2519.705,-70 2509.705,-66.5001 2509.7051,-73.5001\"/>\n</g>\n<!-- layer3_residual_res2_conv -->\n<g id=\"node29\" class=\"node\">\n<title>layer3_residual_res2_conv</title>\n<g id=\"a_node29\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.conv.Conv2d&#39;&gt; {&#39;in_channels&#39;: 512, &#39;out_channels&#39;: 512, &#39;kernel_size&#39;: (3, 3), &#39;stride&#39;: (1, 1), &#39;padding&#39;: (1, 1), &#39;bias&#39;: False}\">\n<path fill=\"#bebada\" stroke=\"#000000\" d=\"M2652,-88C2652,-88 2622,-88 2622,-88 2616,-88 2610,-82 2610,-76 2610,-76 2610,-64 2610,-64 2610,-58 2616,-52 2622,-52 2622,-52 2652,-52 2652,-52 2658,-52 2664,-58 2664,-64 2664,-64 2664,-76 2664,-76 2664,-82 2658,-88 2652,-88\"/>\n<text text-anchor=\"middle\" x=\"2637\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">conv</text>\n</a>\n</g>\n</g>\n<!-- layer3_residual_res1_act&#45;&gt;layer3_residual_res2_conv -->\n<g id=\"edge30\" class=\"edge\">\n<title>layer3_residual_res1_act&#45;&gt;layer3_residual_res2_conv</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2574.003,-70C2582.0277,-70 2590.9665,-70 2599.5309,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2599.7051,-73.5001 2609.705,-70 2599.705,-66.5001 2599.7051,-73.5001\"/>\n</g>\n<!-- layer3_residual_res2_norm -->\n<g id=\"node30\" class=\"node\">\n<title>layer3_residual_res2_norm</title>\n<g id=\"a_node30\"><a xlink:title=\"functools.partial(&lt;class &#39;__main__.GhostBatchNorm&#39;&gt;, num_splits=16, weight=False) {&#39;num_features&#39;: 512}\">\n<path fill=\"#b07b87\" stroke=\"#000000\" d=\"M2742,-88C2742,-88 2712,-88 2712,-88 2706,-88 2700,-82 2700,-76 2700,-76 2700,-64 2700,-64 2700,-58 2706,-52 2712,-52 2712,-52 2742,-52 2742,-52 2748,-52 2754,-58 2754,-64 2754,-64 2754,-76 2754,-76 2754,-82 2748,-88 2742,-88\"/>\n<text text-anchor=\"middle\" x=\"2727\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">norm</text>\n</a>\n</g>\n</g>\n<!-- layer3_residual_res2_conv&#45;&gt;layer3_residual_res2_norm -->\n<g id=\"edge31\" class=\"edge\">\n<title>layer3_residual_res2_conv&#45;&gt;layer3_residual_res2_norm</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2664.003,-70C2672.0277,-70 2680.9665,-70 2689.5309,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2689.7051,-73.5001 2699.705,-70 2689.705,-66.5001 2689.7051,-73.5001\"/>\n</g>\n<!-- layer3_residual_res2_act -->\n<g id=\"node31\" class=\"node\">\n<title>layer3_residual_res2_act</title>\n<g id=\"a_node31\"><a xlink:title=\"functools.partial(&lt;class &#39;torch.nn.modules.activation.CELU&#39;&gt;, 0.3) {}\">\n<path fill=\"#4e90e3\" stroke=\"#000000\" d=\"M2832,-88C2832,-88 2802,-88 2802,-88 2796,-88 2790,-82 2790,-76 2790,-76 2790,-64 2790,-64 2790,-58 2796,-52 2802,-52 2802,-52 2832,-52 2832,-52 2838,-52 2844,-58 2844,-64 2844,-64 2844,-76 2844,-76 2844,-82 2838,-88 2832,-88\"/>\n<text text-anchor=\"middle\" x=\"2817\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">act</text>\n</a>\n</g>\n</g>\n<!-- layer3_residual_res2_norm&#45;&gt;layer3_residual_res2_act -->\n<g id=\"edge32\" class=\"edge\">\n<title>layer3_residual_res2_norm&#45;&gt;layer3_residual_res2_act</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2754.003,-70C2762.0277,-70 2770.9665,-70 2779.5309,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2779.7051,-73.5001 2789.705,-70 2779.705,-66.5001 2779.7051,-73.5001\"/>\n</g>\n<!-- layer3_residual_out -->\n<g id=\"node32\" class=\"node\">\n<title>layer3_residual_out</title>\n<g id=\"a_node32\"><a xlink:title=\"&lt;class &#39;__main__.Identity&#39;&gt; {}\">\n<path fill=\"#80b1d3\" stroke=\"#000000\" d=\"M2922,-98C2922,-98 2892,-98 2892,-98 2886,-98 2880,-92 2880,-86 2880,-86 2880,-74 2880,-74 2880,-68 2886,-62 2892,-62 2892,-62 2922,-62 2922,-62 2928,-62 2934,-68 2934,-74 2934,-74 2934,-86 2934,-86 2934,-92 2928,-98 2922,-98\"/>\n<text text-anchor=\"middle\" x=\"2907\" y=\"-76.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">out</text>\n</a>\n</g>\n</g>\n<!-- layer3_residual_res2_act&#45;&gt;layer3_residual_out -->\n<g id=\"edge33\" class=\"edge\">\n<title>layer3_residual_res2_act&#45;&gt;layer3_residual_out</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2844.003,-73.0003C2852.0277,-73.892 2860.9665,-74.8852 2869.5309,-75.8368\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2869.3796,-79.3414 2879.705,-76.9672 2870.1527,-72.3842 2869.3796,-79.3414\"/>\n</g>\n<!-- layer3_residual_out&#45;&gt;layer3_residual_add -->\n<g id=\"edge35\" class=\"edge\">\n<title>layer3_residual_out&#45;&gt;layer3_residual_add</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2934.003,-86.0007C2942.1158,-87.8035 2951.1631,-89.814 2959.8131,-91.7362\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2959.1839,-95.1817 2969.705,-93.9345 2960.7024,-88.3484 2959.1839,-95.1817\"/>\n</g>\n<!-- pool -->\n<g id=\"node34\" class=\"node\">\n<title>pool</title>\n<g id=\"a_node34\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.pooling.MaxPool2d&#39;&gt; {&#39;kernel_size&#39;: 4}\">\n<path fill=\"#8dd3c7\" stroke=\"#000000\" d=\"M3102,-118C3102,-118 3072,-118 3072,-118 3066,-118 3060,-112 3060,-106 3060,-106 3060,-94 3060,-94 3060,-88 3066,-82 3072,-82 3072,-82 3102,-82 3102,-82 3108,-82 3114,-88 3114,-94 3114,-94 3114,-106 3114,-106 3114,-112 3108,-118 3102,-118\"/>\n<text text-anchor=\"middle\" x=\"3087\" y=\"-96.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">pool</text>\n</a>\n</g>\n</g>\n<!-- layer3_residual_add&#45;&gt;pool -->\n<g id=\"edge36\" class=\"edge\">\n<title>layer3_residual_add&#45;&gt;pool</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M3024.003,-100C3032.0277,-100 3040.9665,-100 3049.5309,-100\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"3049.7051,-103.5001 3059.705,-100 3049.705,-96.5001 3049.7051,-103.5001\"/>\n</g>\n<!-- classifier_flatten -->\n<g id=\"node35\" class=\"node\">\n<title>classifier_flatten</title>\n<g id=\"a_node35\"><a xlink:title=\"&lt;class &#39;__main__.Flatten&#39;&gt; {}\">\n<path fill=\"#b3de69\" stroke=\"#000000\" d=\"M3192,-118C3192,-118 3162,-118 3162,-118 3156,-118 3150,-112 3150,-106 3150,-106 3150,-94 3150,-94 3150,-88 3156,-82 3162,-82 3162,-82 3192,-82 3192,-82 3198,-82 3204,-88 3204,-94 3204,-94 3204,-106 3204,-106 3204,-112 3198,-118 3192,-118\"/>\n<text text-anchor=\"middle\" x=\"3177\" y=\"-96.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">flatten</text>\n</a>\n</g>\n</g>\n<!-- pool&#45;&gt;classifier_flatten -->\n<g id=\"edge37\" class=\"edge\">\n<title>pool&#45;&gt;classifier_flatten</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M3114.003,-100C3122.0277,-100 3130.9665,-100 3139.5309,-100\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"3139.7051,-103.5001 3149.705,-100 3139.705,-96.5001 3139.7051,-103.5001\"/>\n</g>\n<!-- classifier_conv -->\n<g id=\"node36\" class=\"node\">\n<title>classifier_conv</title>\n<g id=\"a_node36\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.linear.Linear&#39;&gt; {&#39;in_features&#39;: 512, &#39;out_features&#39;: 10, &#39;bias&#39;: False}\">\n<path fill=\"#fccde5\" stroke=\"#000000\" d=\"M3282,-118C3282,-118 3252,-118 3252,-118 3246,-118 3240,-112 3240,-106 3240,-106 3240,-94 3240,-94 3240,-88 3246,-82 3252,-82 3252,-82 3282,-82 3282,-82 3288,-82 3294,-88 3294,-94 3294,-94 3294,-106 3294,-106 3294,-112 3288,-118 3282,-118\"/>\n<text text-anchor=\"middle\" x=\"3267\" y=\"-96.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">conv</text>\n</a>\n</g>\n</g>\n<!-- classifier_flatten&#45;&gt;classifier_conv -->\n<g id=\"edge38\" class=\"edge\">\n<title>classifier_flatten&#45;&gt;classifier_conv</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M3204.003,-100C3212.0277,-100 3220.9665,-100 3229.5309,-100\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"3229.7051,-103.5001 3239.705,-100 3229.705,-96.5001 3229.7051,-103.5001\"/>\n</g>\n<!-- classifier_scale -->\n<g id=\"node37\" class=\"node\">\n<title>classifier_scale</title>\n<g id=\"a_node37\"><a xlink:title=\"&lt;class &#39;__main__.Mul&#39;&gt; {&#39;weight&#39;: 0.0625}\">\n<path fill=\"#bc80bd\" stroke=\"#000000\" d=\"M3372,-118C3372,-118 3342,-118 3342,-118 3336,-118 3330,-112 3330,-106 3330,-106 3330,-94 3330,-94 3330,-88 3336,-82 3342,-82 3342,-82 3372,-82 3372,-82 3378,-82 3384,-88 3384,-94 3384,-94 3384,-106 3384,-106 3384,-112 3378,-118 3372,-118\"/>\n<text text-anchor=\"middle\" x=\"3357\" y=\"-96.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">scale</text>\n</a>\n</g>\n</g>\n<!-- classifier_conv&#45;&gt;classifier_scale -->\n<g id=\"edge39\" class=\"edge\">\n<title>classifier_conv&#45;&gt;classifier_scale</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M3294.003,-100C3302.0277,-100 3310.9665,-100 3319.5309,-100\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"3319.7051,-103.5001 3329.705,-100 3319.705,-96.5001 3319.7051,-103.5001\"/>\n</g>\n<!-- logits -->\n<g id=\"node38\" class=\"node\">\n<title>logits</title>\n<g id=\"a_node38\"><a xlink:title=\"&lt;class &#39;__main__.Identity&#39;&gt; {}\">\n<path fill=\"#80b1d3\" stroke=\"#000000\" d=\"M3462,-118C3462,-118 3432,-118 3432,-118 3426,-118 3420,-112 3420,-106 3420,-106 3420,-94 3420,-94 3420,-88 3426,-82 3432,-82 3432,-82 3462,-82 3462,-82 3468,-82 3474,-88 3474,-94 3474,-94 3474,-106 3474,-106 3474,-112 3468,-118 3462,-118\"/>\n<text text-anchor=\"middle\" x=\"3447\" y=\"-96.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">logits</text>\n</a>\n</g>\n</g>\n<!-- classifier_scale&#45;&gt;logits -->\n<g id=\"edge40\" class=\"edge\">\n<title>classifier_scale&#45;&gt;logits</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M3384.003,-100C3392.0277,-100 3400.9665,-100 3409.5309,-100\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"3409.7051,-103.5001 3419.705,-100 3409.705,-96.5001 3409.7051,-103.5001\"/>\n</g>\n<!-- input -->\n<g id=\"node39\" class=\"node\">\n<title>input</title>\n<path fill=\"#ffffff\" stroke=\"#000000\" d=\"M42,-88C42,-88 12,-88 12,-88 6,-88 0,-82 0,-76 0,-76 0,-64 0,-64 0,-58 6,-52 12,-52 12,-52 42,-52 42,-52 48,-52 54,-58 54,-64 54,-64 54,-76 54,-76 54,-82 48,-88 42,-88\"/>\n<text text-anchor=\"middle\" x=\"27\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">input</text>\n</g>\n<!-- input&#45;&gt;prep_conv -->\n<g id=\"edge1\" class=\"edge\">\n<title>input&#45;&gt;prep_conv</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M54.003,-70C62.0277,-70 70.9665,-70 79.5309,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"79.7051,-73.5001 89.705,-70 79.705,-66.5001 79.7051,-73.5001\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oe5ByKdin8ZX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "outputId": "bb30c0f4-bab0-47ca-e94e-cfd6608ad9db"
      },
      "source": [
        "epochs, batch_size = 18, 512\n",
        "transforms = (Crop(32, 32), FlipLR(), Cutout(8, 8))\n",
        "opt_params = {'lr': lr_schedule([0, epochs/5, epochs], [0.0, 0.6, 0.0], batch_size), 'weight_decay': Const(5e-4*batch_size), 'momentum': Const(0.9)}\n",
        "opt_params_bias = {'lr': lr_schedule([0, epochs/5, epochs], [0.0, 0.6*16, 0.0], batch_size), 'weight_decay': Const(5e-4*batch_size/16), 'momentum': Const(0.9)}\n",
        "\n",
        "logs = Table(report=every(epochs,'epoch'))\n",
        "for run in range(N_RUNS):\n",
        "    model = build_model(frozen_bn_scale_net, label_smoothing_loss(0.2))\n",
        "    is_bias = group_by_key(('bias' in k, v) for k, v in trainable_params(model).items())\n",
        "    state, timer = {MODEL: model, OPTS: [SGD(is_bias[False], opt_params), SGD(is_bias[True], opt_params_bias)]}, Timer(torch.cuda.synchronize)\n",
        "    for epoch in range(epochs):\n",
        "        logs.append(union({'run': run+1, 'epoch': epoch+1}, train_epoch(state, timer, train_batches(batch_size, transforms), valid_batches(batch_size))))\n",
        "summary(logs)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         run        epoch   train time   train loss    train acc   valid time   valid loss    valid acc   total time\n",
            "           1           18      10.5161       0.9598       0.9667       0.6356       0.9921       0.9442     189.3020\n",
            "           2           18      10.5418       0.9618       0.9653       0.6404       0.9944       0.9404     189.5064\n",
            "           3           18      10.5422       0.9599       0.9671       0.6394       0.9945       0.9411     189.7707\n",
            "           4           18      10.5382       0.9612       0.9663       0.6397       0.9950       0.9414     189.9616\n",
            "           5           18      10.5371       0.9608       0.9668       0.6366       0.9942       0.9404     189.8423\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>min</th>\n",
              "      <th>max</th>\n",
              "      <th>std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>valid_acc</th>\n",
              "      <td>5</td>\n",
              "      <td>0.9415</td>\n",
              "      <td>0.9404</td>\n",
              "      <td>0.9442</td>\n",
              "      <td>0.001572</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           count    mean     min     max       std\n",
              "valid_acc      5  0.9415  0.9404  0.9442  0.001572"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F29j8KyvenL_",
        "colab_type": "text"
      },
      "source": [
        "Test accuracy improves to 94.2%. Interestingly, had we not increased the learning rate of the batch norm biases, we would have achieved a substantially lower accuracy as the reader can verify. This suggests that the learnable biases are indeed doing something useful - either learning appropriate levels of sparsity or perhaps just adding regularisation noise. Indeed we can improve things slightly by increasing the learning rate of the biases even further:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USqjaYDnpogJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "outputId": "a4532fa8-551c-4fa3-f733-b6c2c1ba7825"
      },
      "source": [
        "epochs, batch_size = 17, 512\n",
        "transforms = (Crop(32, 32), FlipLR(), Cutout(8, 8))\n",
        "opt_params = {'lr': lr_schedule([0, epochs/5, epochs], [0.0, 0.6, 0.0], batch_size), 'weight_decay': Const(5e-4*batch_size), 'momentum': Const(0.9)}\n",
        "opt_params_bias = {'lr': lr_schedule([0, epochs/5, epochs], [0.0, 0.6*64, 0.0], batch_size), 'weight_decay': Const(5e-4*batch_size/64), 'momentum': Const(0.9)}\n",
        "\n",
        "logs = Table(report=every(epochs,'epoch'))\n",
        "for run in range(N_RUNS):\n",
        "    model = build_model(frozen_bn_scale_net, label_smoothing_loss(0.2))\n",
        "    is_bias = group_by_key(('bias' in k, v) for k, v in trainable_params(model).items())\n",
        "    state, timer = {MODEL: model, OPTS: [SGD(is_bias[False], opt_params), SGD(is_bias[True], opt_params_bias)]}, Timer(torch.cuda.synchronize)\n",
        "    for epoch in range(epochs):\n",
        "        logs.append(union({'run': run+1, 'epoch': epoch+1}, train_epoch(state, timer, train_batches(batch_size, transforms), valid_batches(batch_size))))\n",
        "summary(logs)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         run        epoch   train time   train loss    train acc   valid time   valid loss    valid acc   total time\n",
            "           1           18      10.5400       0.9539       0.9690       0.6366       0.9915       0.9414     189.6841\n",
            "           2           18      10.5205       0.9551       0.9677       0.6379       0.9924       0.9423     189.4809\n",
            "           3           18      10.5101       0.9546       0.9675       0.6333       0.9899       0.9437     189.3872\n",
            "           4           18      10.5179       0.9546       0.9678       0.6352       0.9906       0.9427     189.2879\n",
            "           5           18      10.5150       0.9546       0.9681       0.6345       0.9889       0.9443     189.3644\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>min</th>\n",
              "      <th>max</th>\n",
              "      <th>std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>valid_acc</th>\n",
              "      <td>5</td>\n",
              "      <td>0.94288</td>\n",
              "      <td>0.9414</td>\n",
              "      <td>0.9443</td>\n",
              "      <td>0.001145</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           count     mean     min     max       std\n",
              "valid_acc      5  0.94288  0.9414  0.9443  0.001145"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WpwXfP3sRIgU",
        "colab_type": "text"
      },
      "source": [
        "Finally we can use the increased accuracy to reduce training to 17 epochs. The new test accuracy is 94.1% and most importantly we've overtaken the 8 GPUs of BaiduNet9P with a time of 43s, placing us second on the leaderboard!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDGYbRmvQVts",
        "colab_type": "text"
      },
      "source": [
        "### Input patch whitening (36s)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmfdPrAIVhUE",
        "colab_type": "text"
      },
      "source": [
        "Batch norm does a good job at controlling distributions of individual channels but doesn't tackle covariance between channels and pixels. Controlling the covariance at internal layers, using a 'whitening' version of batch norm, might be helpful but would entail extra computation as well as non-trivial implementation effort. We are going to focus on the easier problem at the input layer.\n",
        "\n",
        "The classic way to remove input correlations is to perform global PCA (or ZCA) whitening. We propose a patch-based approach which is agnostic to the total image size and more in keeping with the structure of a conv net. We are going to apply PCA whitening to 3Ã—3 patches of inputs as an initial 3Ã—3 convolution with fixed (non-learnable) weights. We will follow this with a learnable 1Ã—1 convolution. The 27 input channels to this layer are a transformed version of the original 3Ã—3Ã—3 input patches whose covariance matrix is approximately the identity, which should make optimisation easier.\n",
        "\n",
        "First let's plot the leading eigenvectors of the covariance matrix of 3Ã—3 patches of the input data. The numbers in brackets are the square root of the corresponding eigenvalues to show the relative scales of variation along these directions and we plot the eigenvector with both signs to illustrate the direction of variation. As we might expect, variations in local brightness dominate.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zY1hEAoONY0P",
        "colab_type": "code",
        "outputId": "0b9e9ecb-9a8d-4b06-d05c-829dd4fac320",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "def cov(X):\n",
        "    X = X/np.sqrt(X.size(0) - 1)\n",
        "    return X.t() @ X\n",
        "\n",
        "def patches(data, patch_size=(3, 3), dtype=torch.float32):\n",
        "    h, w = patch_size\n",
        "    c = data.size(1)\n",
        "    return data.unfold(2,h,1).unfold(3,w,1).transpose(1,3).reshape(-1, c, h, w).to(dtype)\n",
        "\n",
        "def eigens(patches):\n",
        "    n,c,h,w = patches.shape\n",
        "    Î£ = cov(patches.reshape(n, c*h*w))\n",
        "    Î›, V = torch.symeig(Î£, eigenvectors=True)\n",
        "    return Î›.flip(0), V.t().reshape(c*h*w, c, h, w).flip(0)\n",
        "\n",
        "Î›, V = eigens(patches(train_set['data'][:10000,:,4:-4,4:-4])) #center crop to remove padding\n",
        "\n",
        "layout([\n",
        "    [partial(image_plot, img=V[i].to(torch.float16)*3, title=f'{i+1} ({torch.sqrt(Î›[i]):.2f})') for i in range(len(V))],\n",
        "    [partial(image_plot, img=-V[i].to(torch.float16)*3, title='') for i in range(len(V))],\n",
        "], col_width=1.0, row_height=1.0\n",
        ");"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABgYAAACZCAYAAADkSYGdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1944x144 with 54 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6qlex4zYaGm",
        "colab_type": "text"
      },
      "source": [
        "Now let's replace the first 3Ã—3 convolution of the network with a fixed 3Ã—3 whitening convolution to equalise the scales of the eigenpatches above, followed by a learnable 1Ã—1 convolution. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckzKy37AY1gq",
        "colab_type": "code",
        "outputId": "9cdbcae6-a5aa-4bea-dece-2c5bdd983f63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "def whitening_block(c_in, c_out, Î›=None, V=None, eps=1e-2):\n",
        "    filt = nn.Conv2d(3, 27, kernel_size=(3,3), padding=(1,1), bias=False)\n",
        "    filt.weight.data = (V/torch.sqrt(Î›+eps)[:,None,None,None])\n",
        "    filt.weight.requires_grad = False \n",
        "                                   \n",
        "    return {\n",
        "        'whiten': (identity, {'value': filt}),\n",
        "        'conv': conv(27, c_out, kernel_size=(1, 1), bias=False),\n",
        "        'norm': batch_norm(c_out), \n",
        "        'act':  relu(),\n",
        "    }\n",
        "\n",
        "input_whitening_net = network(conv_pool_block=conv_pool_block_pre, prep_block=partial(whitening_block, Î›=Î›, V=V), scale=1/16, types={\n",
        "    nn.ReLU: partial(nn.CELU, 0.3),\n",
        "    BatchNorm: partial(GhostBatchNorm, num_splits=16, weight=False)\n",
        "})\n",
        "show(input_whitening_net)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<__main__.DotGraph at 0x7f7eb26eaba8>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: G Pages: 1 -->\n<svg width=\"1080pt\" height=\"63pt\"\n viewBox=\"0.00 0.00 1080.00 62.55\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(.3022 .3022) rotate(0) translate(4 203)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-203 3570,-203 3570,4 -4,4\"/>\n<g id=\"clust1\" class=\"cluster\">\n<title>cluster_prep</title>\n<path fill=\"#777777\" fill-opacity=\"0.266667\" stroke=\"#000000\" d=\"M94,-44C94,-44 412,-44 412,-44 418,-44 424,-50 424,-56 424,-56 424,-107 424,-107 424,-113 418,-119 412,-119 412,-119 94,-119 94,-119 88,-119 82,-113 82,-107 82,-107 82,-56 82,-56 82,-50 88,-44 94,-44\"/>\n<text text-anchor=\"middle\" x=\"253\" y=\"-103.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">prep</text>\n</g>\n<g id=\"clust2\" class=\"cluster\">\n<title>cluster_layer1</title>\n<path fill=\"#777777\" fill-opacity=\"0.266667\" stroke=\"#000000\" d=\"M456,-8C456,-8 1590,-8 1590,-8 1596,-8 1602,-14 1602,-20 1602,-20 1602,-159 1602,-159 1602,-165 1596,-171 1590,-171 1590,-171 456,-171 456,-171 450,-171 444,-165 444,-159 444,-159 444,-20 444,-20 444,-14 450,-8 456,-8\"/>\n<text text-anchor=\"middle\" x=\"1023\" y=\"-155.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">layer1</text>\n</g>\n<g id=\"clust3\" class=\"cluster\">\n<title>cluster_layer1_residual</title>\n<path fill=\"#777777\" fill-opacity=\"0.266667\" stroke=\"#000000\" d=\"M816,-16C816,-16 1582,-16 1582,-16 1588,-16 1594,-22 1594,-28 1594,-28 1594,-128 1594,-128 1594,-134 1588,-140 1582,-140 1582,-140 816,-140 816,-140 810,-140 804,-134 804,-128 804,-128 804,-28 804,-28 804,-22 810,-16 816,-16\"/>\n<text text-anchor=\"middle\" x=\"1199\" y=\"-124.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">residual</text>\n</g>\n<g id=\"clust4\" class=\"cluster\">\n<title>cluster_layer1_residual_res1</title>\n<path fill=\"#777777\" fill-opacity=\"0.266667\" stroke=\"#000000\" d=\"M906,-24C906,-24 1132,-24 1132,-24 1138,-24 1144,-30 1144,-36 1144,-36 1144,-87 1144,-87 1144,-93 1138,-99 1132,-99 1132,-99 906,-99 906,-99 900,-99 894,-93 894,-87 894,-87 894,-36 894,-36 894,-30 900,-24 906,-24\"/>\n<text text-anchor=\"middle\" x=\"1019\" y=\"-83.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">res1</text>\n</g>\n<g id=\"clust5\" class=\"cluster\">\n<title>cluster_layer1_residual_res2</title>\n<path fill=\"#777777\" fill-opacity=\"0.266667\" stroke=\"#000000\" d=\"M1176,-24C1176,-24 1402,-24 1402,-24 1408,-24 1414,-30 1414,-36 1414,-36 1414,-87 1414,-87 1414,-93 1408,-99 1402,-99 1402,-99 1176,-99 1176,-99 1170,-99 1164,-93 1164,-87 1164,-87 1164,-36 1164,-36 1164,-30 1170,-24 1176,-24\"/>\n<text text-anchor=\"middle\" x=\"1289\" y=\"-83.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">res2</text>\n</g>\n<g id=\"clust6\" class=\"cluster\">\n<title>cluster_layer2</title>\n<path fill=\"#777777\" fill-opacity=\"0.266667\" stroke=\"#000000\" d=\"M1626,-54C1626,-54 1942,-54 1942,-54 1948,-54 1954,-60 1954,-66 1954,-66 1954,-117 1954,-117 1954,-123 1948,-129 1942,-129 1942,-129 1626,-129 1626,-129 1620,-129 1614,-123 1614,-117 1614,-117 1614,-66 1614,-66 1614,-60 1620,-54 1626,-54\"/>\n<text text-anchor=\"middle\" x=\"1784\" y=\"-113.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">layer2</text>\n</g>\n<g id=\"clust7\" class=\"cluster\">\n<title>cluster_layer3</title>\n<path fill=\"#777777\" fill-opacity=\"0.266667\" stroke=\"#000000\" d=\"M1986,-28C1986,-28 3120,-28 3120,-28 3126,-28 3132,-34 3132,-40 3132,-40 3132,-179 3132,-179 3132,-185 3126,-191 3120,-191 3120,-191 1986,-191 1986,-191 1980,-191 1974,-185 1974,-179 1974,-179 1974,-40 1974,-40 1974,-34 1980,-28 1986,-28\"/>\n<text text-anchor=\"middle\" x=\"2553\" y=\"-175.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">layer3</text>\n</g>\n<g id=\"clust8\" class=\"cluster\">\n<title>cluster_layer3_residual</title>\n<path fill=\"#777777\" fill-opacity=\"0.266667\" stroke=\"#000000\" d=\"M2346,-36C2346,-36 3112,-36 3112,-36 3118,-36 3124,-42 3124,-48 3124,-48 3124,-148 3124,-148 3124,-154 3118,-160 3112,-160 3112,-160 2346,-160 2346,-160 2340,-160 2334,-154 2334,-148 2334,-148 2334,-48 2334,-48 2334,-42 2340,-36 2346,-36\"/>\n<text text-anchor=\"middle\" x=\"2729\" y=\"-144.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">residual</text>\n</g>\n<g id=\"clust9\" class=\"cluster\">\n<title>cluster_layer3_residual_res1</title>\n<path fill=\"#777777\" fill-opacity=\"0.266667\" stroke=\"#000000\" d=\"M2436,-44C2436,-44 2662,-44 2662,-44 2668,-44 2674,-50 2674,-56 2674,-56 2674,-107 2674,-107 2674,-113 2668,-119 2662,-119 2662,-119 2436,-119 2436,-119 2430,-119 2424,-113 2424,-107 2424,-107 2424,-56 2424,-56 2424,-50 2430,-44 2436,-44\"/>\n<text text-anchor=\"middle\" x=\"2549\" y=\"-103.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">res1</text>\n</g>\n<g id=\"clust10\" class=\"cluster\">\n<title>cluster_layer3_residual_res2</title>\n<path fill=\"#777777\" fill-opacity=\"0.266667\" stroke=\"#000000\" d=\"M2706,-44C2706,-44 2932,-44 2932,-44 2938,-44 2944,-50 2944,-56 2944,-56 2944,-107 2944,-107 2944,-113 2938,-119 2932,-119 2932,-119 2706,-119 2706,-119 2700,-119 2694,-113 2694,-107 2694,-107 2694,-56 2694,-56 2694,-50 2700,-44 2706,-44\"/>\n<text text-anchor=\"middle\" x=\"2819\" y=\"-103.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">res2</text>\n</g>\n<g id=\"clust11\" class=\"cluster\">\n<title>cluster_classifier</title>\n<path fill=\"#777777\" fill-opacity=\"0.266667\" stroke=\"#000000\" d=\"M3246,-74C3246,-74 3472,-74 3472,-74 3478,-74 3484,-80 3484,-86 3484,-86 3484,-137 3484,-137 3484,-143 3478,-149 3472,-149 3472,-149 3246,-149 3246,-149 3240,-149 3234,-143 3234,-137 3234,-137 3234,-86 3234,-86 3234,-80 3240,-74 3246,-74\"/>\n<text text-anchor=\"middle\" x=\"3359\" y=\"-133.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">classifier</text>\n</g>\n<!-- prep_whiten -->\n<g id=\"node1\" class=\"node\">\n<title>prep_whiten</title>\n<g id=\"a_node1\"><a xlink:title=\"&lt;function identity at 0x7f7f2fdb0400&gt; {&#39;value&#39;: Conv2d(3, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)}\">\n<path fill=\"#dea05e\" stroke=\"#000000\" d=\"M134,-88C134,-88 102,-88 102,-88 96,-88 90,-82 90,-76 90,-76 90,-64 90,-64 90,-58 96,-52 102,-52 102,-52 134,-52 134,-52 140,-52 146,-58 146,-64 146,-64 146,-76 146,-76 146,-82 140,-88 134,-88\"/>\n<text text-anchor=\"middle\" x=\"118\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">whiten</text>\n</a>\n</g>\n</g>\n<!-- prep_conv -->\n<g id=\"node2\" class=\"node\">\n<title>prep_conv</title>\n<g id=\"a_node2\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.conv.Conv2d&#39;&gt; {&#39;in_channels&#39;: 27, &#39;out_channels&#39;: 64, &#39;kernel_size&#39;: (1, 1), &#39;bias&#39;: False}\">\n<path fill=\"#bebada\" stroke=\"#000000\" d=\"M224,-88C224,-88 194,-88 194,-88 188,-88 182,-82 182,-76 182,-76 182,-64 182,-64 182,-58 188,-52 194,-52 194,-52 224,-52 224,-52 230,-52 236,-58 236,-64 236,-64 236,-76 236,-76 236,-82 230,-88 224,-88\"/>\n<text text-anchor=\"middle\" x=\"209\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">conv</text>\n</a>\n</g>\n</g>\n<!-- prep_whiten&#45;&gt;prep_conv -->\n<g id=\"edge2\" class=\"edge\">\n<title>prep_whiten&#45;&gt;prep_conv</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M146.2941,-70C154.3803,-70 163.3168,-70 171.8479,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"171.9684,-73.5001 181.9684,-70 171.9683,-66.5001 171.9684,-73.5001\"/>\n</g>\n<!-- prep_norm -->\n<g id=\"node3\" class=\"node\">\n<title>prep_norm</title>\n<g id=\"a_node3\"><a xlink:title=\"functools.partial(&lt;class &#39;__main__.GhostBatchNorm&#39;&gt;, num_splits=16, weight=False) {&#39;num_features&#39;: 64}\">\n<path fill=\"#d0c281\" stroke=\"#000000\" d=\"M314,-88C314,-88 284,-88 284,-88 278,-88 272,-82 272,-76 272,-76 272,-64 272,-64 272,-58 278,-52 284,-52 284,-52 314,-52 314,-52 320,-52 326,-58 326,-64 326,-64 326,-76 326,-76 326,-82 320,-88 314,-88\"/>\n<text text-anchor=\"middle\" x=\"299\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">norm</text>\n</a>\n</g>\n</g>\n<!-- prep_conv&#45;&gt;prep_norm -->\n<g id=\"edge3\" class=\"edge\">\n<title>prep_conv&#45;&gt;prep_norm</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M236.003,-70C244.0277,-70 252.9665,-70 261.5309,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"261.7051,-73.5001 271.705,-70 261.705,-66.5001 261.7051,-73.5001\"/>\n</g>\n<!-- prep_act -->\n<g id=\"node4\" class=\"node\">\n<title>prep_act</title>\n<g id=\"a_node4\"><a xlink:title=\"functools.partial(&lt;class &#39;torch.nn.modules.activation.CELU&#39;&gt;, 0.3) {}\">\n<path fill=\"#f0e189\" stroke=\"#000000\" d=\"M404,-88C404,-88 374,-88 374,-88 368,-88 362,-82 362,-76 362,-76 362,-64 362,-64 362,-58 368,-52 374,-52 374,-52 404,-52 404,-52 410,-52 416,-58 416,-64 416,-64 416,-76 416,-76 416,-82 410,-88 404,-88\"/>\n<text text-anchor=\"middle\" x=\"389\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">act</text>\n</a>\n</g>\n</g>\n<!-- prep_norm&#45;&gt;prep_act -->\n<g id=\"edge4\" class=\"edge\">\n<title>prep_norm&#45;&gt;prep_act</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M326.003,-70C334.0277,-70 342.9665,-70 351.5309,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"351.7051,-73.5001 361.705,-70 351.705,-66.5001 351.7051,-73.5001\"/>\n</g>\n<!-- layer1_conv -->\n<g id=\"node5\" class=\"node\">\n<title>layer1_conv</title>\n<g id=\"a_node5\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.conv.Conv2d&#39;&gt; {&#39;in_channels&#39;: 64, &#39;out_channels&#39;: 128, &#39;kernel_size&#39;: (3, 3), &#39;stride&#39;: (1, 1), &#39;padding&#39;: (1, 1), &#39;bias&#39;: False}\">\n<path fill=\"#bebada\" stroke=\"#000000\" d=\"M494,-88C494,-88 464,-88 464,-88 458,-88 452,-82 452,-76 452,-76 452,-64 452,-64 452,-58 458,-52 464,-52 464,-52 494,-52 494,-52 500,-52 506,-58 506,-64 506,-64 506,-76 506,-76 506,-82 500,-88 494,-88\"/>\n<text text-anchor=\"middle\" x=\"479\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">conv</text>\n</a>\n</g>\n</g>\n<!-- prep_act&#45;&gt;layer1_conv -->\n<g id=\"edge5\" class=\"edge\">\n<title>prep_act&#45;&gt;layer1_conv</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M416.003,-70C424.0277,-70 432.9665,-70 441.5309,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"441.7051,-73.5001 451.705,-70 441.705,-66.5001 441.7051,-73.5001\"/>\n</g>\n<!-- layer1_pool -->\n<g id=\"node6\" class=\"node\">\n<title>layer1_pool</title>\n<g id=\"a_node6\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.pooling.MaxPool2d&#39;&gt; {&#39;kernel_size&#39;: 2}\">\n<path fill=\"#8dd3c7\" stroke=\"#000000\" d=\"M584,-88C584,-88 554,-88 554,-88 548,-88 542,-82 542,-76 542,-76 542,-64 542,-64 542,-58 548,-52 554,-52 554,-52 584,-52 584,-52 590,-52 596,-58 596,-64 596,-64 596,-76 596,-76 596,-82 590,-88 584,-88\"/>\n<text text-anchor=\"middle\" x=\"569\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">pool</text>\n</a>\n</g>\n</g>\n<!-- layer1_conv&#45;&gt;layer1_pool -->\n<g id=\"edge6\" class=\"edge\">\n<title>layer1_conv&#45;&gt;layer1_pool</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M506.003,-70C514.0277,-70 522.9665,-70 531.5309,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"531.7051,-73.5001 541.705,-70 531.705,-66.5001 531.7051,-73.5001\"/>\n</g>\n<!-- layer1_norm -->\n<g id=\"node7\" class=\"node\">\n<title>layer1_norm</title>\n<g id=\"a_node7\"><a xlink:title=\"functools.partial(&lt;class &#39;__main__.GhostBatchNorm&#39;&gt;, num_splits=16, weight=False) {&#39;num_features&#39;: 128}\">\n<path fill=\"#d0c281\" stroke=\"#000000\" d=\"M674,-88C674,-88 644,-88 644,-88 638,-88 632,-82 632,-76 632,-76 632,-64 632,-64 632,-58 638,-52 644,-52 644,-52 674,-52 674,-52 680,-52 686,-58 686,-64 686,-64 686,-76 686,-76 686,-82 680,-88 674,-88\"/>\n<text text-anchor=\"middle\" x=\"659\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">norm</text>\n</a>\n</g>\n</g>\n<!-- layer1_pool&#45;&gt;layer1_norm -->\n<g id=\"edge7\" class=\"edge\">\n<title>layer1_pool&#45;&gt;layer1_norm</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M596.003,-70C604.0277,-70 612.9665,-70 621.5309,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"621.7051,-73.5001 631.705,-70 621.705,-66.5001 621.7051,-73.5001\"/>\n</g>\n<!-- layer1_act -->\n<g id=\"node8\" class=\"node\">\n<title>layer1_act</title>\n<g id=\"a_node8\"><a xlink:title=\"functools.partial(&lt;class &#39;torch.nn.modules.activation.CELU&#39;&gt;, 0.3) {}\">\n<path fill=\"#f0e189\" stroke=\"#000000\" d=\"M764,-88C764,-88 734,-88 734,-88 728,-88 722,-82 722,-76 722,-76 722,-64 722,-64 722,-58 728,-52 734,-52 734,-52 764,-52 764,-52 770,-52 776,-58 776,-64 776,-64 776,-76 776,-76 776,-82 770,-88 764,-88\"/>\n<text text-anchor=\"middle\" x=\"749\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">act</text>\n</a>\n</g>\n</g>\n<!-- layer1_norm&#45;&gt;layer1_act -->\n<g id=\"edge8\" class=\"edge\">\n<title>layer1_norm&#45;&gt;layer1_act</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M686.003,-70C694.0277,-70 702.9665,-70 711.5309,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"711.7051,-73.5001 721.705,-70 711.705,-66.5001 711.7051,-73.5001\"/>\n</g>\n<!-- layer1_residual_in -->\n<g id=\"node9\" class=\"node\">\n<title>layer1_residual_in</title>\n<g id=\"a_node9\"><a xlink:title=\"&lt;class &#39;__main__.Identity&#39;&gt; {}\">\n<path fill=\"#80b1d3\" stroke=\"#000000\" d=\"M854,-88C854,-88 824,-88 824,-88 818,-88 812,-82 812,-76 812,-76 812,-64 812,-64 812,-58 818,-52 824,-52 824,-52 854,-52 854,-52 860,-52 866,-58 866,-64 866,-64 866,-76 866,-76 866,-82 860,-88 854,-88\"/>\n<text text-anchor=\"middle\" x=\"839\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">in</text>\n</a>\n</g>\n</g>\n<!-- layer1_act&#45;&gt;layer1_residual_in -->\n<g id=\"edge9\" class=\"edge\">\n<title>layer1_act&#45;&gt;layer1_residual_in</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M776.003,-70C784.0277,-70 792.9665,-70 801.5309,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"801.7051,-73.5001 811.705,-70 801.705,-66.5001 801.7051,-73.5001\"/>\n</g>\n<!-- layer1_residual_res1_conv -->\n<g id=\"node10\" class=\"node\">\n<title>layer1_residual_res1_conv</title>\n<g id=\"a_node10\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.conv.Conv2d&#39;&gt; {&#39;in_channels&#39;: 128, &#39;out_channels&#39;: 128, &#39;kernel_size&#39;: (3, 3), &#39;stride&#39;: (1, 1), &#39;padding&#39;: (1, 1), &#39;bias&#39;: False}\">\n<path fill=\"#bebada\" stroke=\"#000000\" d=\"M944,-68C944,-68 914,-68 914,-68 908,-68 902,-62 902,-56 902,-56 902,-44 902,-44 902,-38 908,-32 914,-32 914,-32 944,-32 944,-32 950,-32 956,-38 956,-44 956,-44 956,-56 956,-56 956,-62 950,-68 944,-68\"/>\n<text text-anchor=\"middle\" x=\"929\" y=\"-46.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">conv</text>\n</a>\n</g>\n</g>\n<!-- layer1_residual_in&#45;&gt;layer1_residual_res1_conv -->\n<g id=\"edge10\" class=\"edge\">\n<title>layer1_residual_in&#45;&gt;layer1_residual_res1_conv</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M866.003,-63.9993C874.1158,-62.1965 883.1631,-60.186 891.8131,-58.2638\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"892.7024,-61.6516 901.705,-56.0655 891.1839,-54.8183 892.7024,-61.6516\"/>\n</g>\n<!-- layer1_residual_add -->\n<g id=\"node17\" class=\"node\">\n<title>layer1_residual_add</title>\n<g id=\"a_node17\"><a xlink:title=\"&lt;class &#39;__main__.Add&#39;&gt; {}\">\n<path fill=\"#fdb462\" stroke=\"#000000\" d=\"M1574,-98C1574,-98 1544,-98 1544,-98 1538,-98 1532,-92 1532,-86 1532,-86 1532,-74 1532,-74 1532,-68 1538,-62 1544,-62 1544,-62 1574,-62 1574,-62 1580,-62 1586,-68 1586,-74 1586,-74 1586,-86 1586,-86 1586,-92 1580,-98 1574,-98\"/>\n<text text-anchor=\"middle\" x=\"1559\" y=\"-76.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">add</text>\n</a>\n</g>\n</g>\n<!-- layer1_residual_in&#45;&gt;layer1_residual_add -->\n<g id=\"edge17\" class=\"edge\">\n<title>layer1_residual_in&#45;&gt;layer1_residual_add</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M863.2203,-88.104C872.3892,-93.9663 883.2234,-99.7818 894,-103 947.2752,-118.9095 963.4,-108 1019,-108 1019,-108 1019,-108 1379,-108 1428.7971,-108 1485.4324,-97.4074 1521.6554,-89.2525\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1522.8023,-92.5799 1531.7594,-86.9214 1521.2285,-85.7591 1522.8023,-92.5799\"/>\n</g>\n<!-- layer1_residual_res1_norm -->\n<g id=\"node11\" class=\"node\">\n<title>layer1_residual_res1_norm</title>\n<g id=\"a_node11\"><a xlink:title=\"functools.partial(&lt;class &#39;__main__.GhostBatchNorm&#39;&gt;, num_splits=16, weight=False) {&#39;num_features&#39;: 128}\">\n<path fill=\"#d0c281\" stroke=\"#000000\" d=\"M1034,-68C1034,-68 1004,-68 1004,-68 998,-68 992,-62 992,-56 992,-56 992,-44 992,-44 992,-38 998,-32 1004,-32 1004,-32 1034,-32 1034,-32 1040,-32 1046,-38 1046,-44 1046,-44 1046,-56 1046,-56 1046,-62 1040,-68 1034,-68\"/>\n<text text-anchor=\"middle\" x=\"1019\" y=\"-46.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">norm</text>\n</a>\n</g>\n</g>\n<!-- layer1_residual_res1_conv&#45;&gt;layer1_residual_res1_norm -->\n<g id=\"edge11\" class=\"edge\">\n<title>layer1_residual_res1_conv&#45;&gt;layer1_residual_res1_norm</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M956.003,-50C964.0277,-50 972.9665,-50 981.5309,-50\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"981.7051,-53.5001 991.705,-50 981.705,-46.5001 981.7051,-53.5001\"/>\n</g>\n<!-- layer1_residual_res1_act -->\n<g id=\"node12\" class=\"node\">\n<title>layer1_residual_res1_act</title>\n<g id=\"a_node12\"><a xlink:title=\"functools.partial(&lt;class &#39;torch.nn.modules.activation.CELU&#39;&gt;, 0.3) {}\">\n<path fill=\"#f0e189\" stroke=\"#000000\" d=\"M1124,-68C1124,-68 1094,-68 1094,-68 1088,-68 1082,-62 1082,-56 1082,-56 1082,-44 1082,-44 1082,-38 1088,-32 1094,-32 1094,-32 1124,-32 1124,-32 1130,-32 1136,-38 1136,-44 1136,-44 1136,-56 1136,-56 1136,-62 1130,-68 1124,-68\"/>\n<text text-anchor=\"middle\" x=\"1109\" y=\"-46.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">act</text>\n</a>\n</g>\n</g>\n<!-- layer1_residual_res1_norm&#45;&gt;layer1_residual_res1_act -->\n<g id=\"edge12\" class=\"edge\">\n<title>layer1_residual_res1_norm&#45;&gt;layer1_residual_res1_act</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1046.003,-50C1054.0277,-50 1062.9665,-50 1071.5309,-50\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1071.7051,-53.5001 1081.705,-50 1071.705,-46.5001 1071.7051,-53.5001\"/>\n</g>\n<!-- layer1_residual_res2_conv -->\n<g id=\"node13\" class=\"node\">\n<title>layer1_residual_res2_conv</title>\n<g id=\"a_node13\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.conv.Conv2d&#39;&gt; {&#39;in_channels&#39;: 128, &#39;out_channels&#39;: 128, &#39;kernel_size&#39;: (3, 3), &#39;stride&#39;: (1, 1), &#39;padding&#39;: (1, 1), &#39;bias&#39;: False}\">\n<path fill=\"#bebada\" stroke=\"#000000\" d=\"M1214,-68C1214,-68 1184,-68 1184,-68 1178,-68 1172,-62 1172,-56 1172,-56 1172,-44 1172,-44 1172,-38 1178,-32 1184,-32 1184,-32 1214,-32 1214,-32 1220,-32 1226,-38 1226,-44 1226,-44 1226,-56 1226,-56 1226,-62 1220,-68 1214,-68\"/>\n<text text-anchor=\"middle\" x=\"1199\" y=\"-46.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">conv</text>\n</a>\n</g>\n</g>\n<!-- layer1_residual_res1_act&#45;&gt;layer1_residual_res2_conv -->\n<g id=\"edge13\" class=\"edge\">\n<title>layer1_residual_res1_act&#45;&gt;layer1_residual_res2_conv</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1136.003,-50C1144.0277,-50 1152.9665,-50 1161.5309,-50\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1161.7051,-53.5001 1171.705,-50 1161.705,-46.5001 1161.7051,-53.5001\"/>\n</g>\n<!-- layer1_residual_res2_norm -->\n<g id=\"node14\" class=\"node\">\n<title>layer1_residual_res2_norm</title>\n<g id=\"a_node14\"><a xlink:title=\"functools.partial(&lt;class &#39;__main__.GhostBatchNorm&#39;&gt;, num_splits=16, weight=False) {&#39;num_features&#39;: 128}\">\n<path fill=\"#d0c281\" stroke=\"#000000\" d=\"M1304,-68C1304,-68 1274,-68 1274,-68 1268,-68 1262,-62 1262,-56 1262,-56 1262,-44 1262,-44 1262,-38 1268,-32 1274,-32 1274,-32 1304,-32 1304,-32 1310,-32 1316,-38 1316,-44 1316,-44 1316,-56 1316,-56 1316,-62 1310,-68 1304,-68\"/>\n<text text-anchor=\"middle\" x=\"1289\" y=\"-46.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">norm</text>\n</a>\n</g>\n</g>\n<!-- layer1_residual_res2_conv&#45;&gt;layer1_residual_res2_norm -->\n<g id=\"edge14\" class=\"edge\">\n<title>layer1_residual_res2_conv&#45;&gt;layer1_residual_res2_norm</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1226.003,-50C1234.0277,-50 1242.9665,-50 1251.5309,-50\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1251.7051,-53.5001 1261.705,-50 1251.705,-46.5001 1251.7051,-53.5001\"/>\n</g>\n<!-- layer1_residual_res2_act -->\n<g id=\"node15\" class=\"node\">\n<title>layer1_residual_res2_act</title>\n<g id=\"a_node15\"><a xlink:title=\"functools.partial(&lt;class &#39;torch.nn.modules.activation.CELU&#39;&gt;, 0.3) {}\">\n<path fill=\"#f0e189\" stroke=\"#000000\" d=\"M1394,-68C1394,-68 1364,-68 1364,-68 1358,-68 1352,-62 1352,-56 1352,-56 1352,-44 1352,-44 1352,-38 1358,-32 1364,-32 1364,-32 1394,-32 1394,-32 1400,-32 1406,-38 1406,-44 1406,-44 1406,-56 1406,-56 1406,-62 1400,-68 1394,-68\"/>\n<text text-anchor=\"middle\" x=\"1379\" y=\"-46.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">act</text>\n</a>\n</g>\n</g>\n<!-- layer1_residual_res2_norm&#45;&gt;layer1_residual_res2_act -->\n<g id=\"edge15\" class=\"edge\">\n<title>layer1_residual_res2_norm&#45;&gt;layer1_residual_res2_act</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1316.003,-50C1324.0277,-50 1332.9665,-50 1341.5309,-50\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1341.7051,-53.5001 1351.705,-50 1341.705,-46.5001 1341.7051,-53.5001\"/>\n</g>\n<!-- layer1_residual_out -->\n<g id=\"node16\" class=\"node\">\n<title>layer1_residual_out</title>\n<g id=\"a_node16\"><a xlink:title=\"&lt;class &#39;__main__.Identity&#39;&gt; {}\">\n<path fill=\"#80b1d3\" stroke=\"#000000\" d=\"M1484,-78C1484,-78 1454,-78 1454,-78 1448,-78 1442,-72 1442,-66 1442,-66 1442,-54 1442,-54 1442,-48 1448,-42 1454,-42 1454,-42 1484,-42 1484,-42 1490,-42 1496,-48 1496,-54 1496,-54 1496,-66 1496,-66 1496,-72 1490,-78 1484,-78\"/>\n<text text-anchor=\"middle\" x=\"1469\" y=\"-56.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">out</text>\n</a>\n</g>\n</g>\n<!-- layer1_residual_res2_act&#45;&gt;layer1_residual_out -->\n<g id=\"edge16\" class=\"edge\">\n<title>layer1_residual_res2_act&#45;&gt;layer1_residual_out</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1406.003,-53.0003C1414.0277,-53.892 1422.9665,-54.8852 1431.5309,-55.8368\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1431.3796,-59.3414 1441.705,-56.9672 1432.1527,-52.3842 1431.3796,-59.3414\"/>\n</g>\n<!-- layer1_residual_out&#45;&gt;layer1_residual_add -->\n<g id=\"edge18\" class=\"edge\">\n<title>layer1_residual_out&#45;&gt;layer1_residual_add</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1496.003,-66.0007C1504.1158,-67.8035 1513.1631,-69.814 1521.8131,-71.7362\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1521.1839,-75.1817 1531.705,-73.9345 1522.7024,-68.3484 1521.1839,-75.1817\"/>\n</g>\n<!-- layer2_conv -->\n<g id=\"node18\" class=\"node\">\n<title>layer2_conv</title>\n<g id=\"a_node18\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.conv.Conv2d&#39;&gt; {&#39;in_channels&#39;: 128, &#39;out_channels&#39;: 256, &#39;kernel_size&#39;: (3, 3), &#39;stride&#39;: (1, 1), &#39;padding&#39;: (1, 1), &#39;bias&#39;: False}\">\n<path fill=\"#bebada\" stroke=\"#000000\" d=\"M1664,-98C1664,-98 1634,-98 1634,-98 1628,-98 1622,-92 1622,-86 1622,-86 1622,-74 1622,-74 1622,-68 1628,-62 1634,-62 1634,-62 1664,-62 1664,-62 1670,-62 1676,-68 1676,-74 1676,-74 1676,-86 1676,-86 1676,-92 1670,-98 1664,-98\"/>\n<text text-anchor=\"middle\" x=\"1649\" y=\"-76.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">conv</text>\n</a>\n</g>\n</g>\n<!-- layer1_residual_add&#45;&gt;layer2_conv -->\n<g id=\"edge19\" class=\"edge\">\n<title>layer1_residual_add&#45;&gt;layer2_conv</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1586.003,-80C1594.0277,-80 1602.9665,-80 1611.5309,-80\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1611.7051,-83.5001 1621.705,-80 1611.705,-76.5001 1611.7051,-83.5001\"/>\n</g>\n<!-- layer2_pool -->\n<g id=\"node19\" class=\"node\">\n<title>layer2_pool</title>\n<g id=\"a_node19\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.pooling.MaxPool2d&#39;&gt; {&#39;kernel_size&#39;: 2}\">\n<path fill=\"#8dd3c7\" stroke=\"#000000\" d=\"M1754,-98C1754,-98 1724,-98 1724,-98 1718,-98 1712,-92 1712,-86 1712,-86 1712,-74 1712,-74 1712,-68 1718,-62 1724,-62 1724,-62 1754,-62 1754,-62 1760,-62 1766,-68 1766,-74 1766,-74 1766,-86 1766,-86 1766,-92 1760,-98 1754,-98\"/>\n<text text-anchor=\"middle\" x=\"1739\" y=\"-76.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">pool</text>\n</a>\n</g>\n</g>\n<!-- layer2_conv&#45;&gt;layer2_pool -->\n<g id=\"edge20\" class=\"edge\">\n<title>layer2_conv&#45;&gt;layer2_pool</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1676.003,-80C1684.0277,-80 1692.9665,-80 1701.5309,-80\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1701.7051,-83.5001 1711.705,-80 1701.705,-76.5001 1701.7051,-83.5001\"/>\n</g>\n<!-- layer2_norm -->\n<g id=\"node20\" class=\"node\">\n<title>layer2_norm</title>\n<g id=\"a_node20\"><a xlink:title=\"functools.partial(&lt;class &#39;__main__.GhostBatchNorm&#39;&gt;, num_splits=16, weight=False) {&#39;num_features&#39;: 256}\">\n<path fill=\"#d0c281\" stroke=\"#000000\" d=\"M1844,-98C1844,-98 1814,-98 1814,-98 1808,-98 1802,-92 1802,-86 1802,-86 1802,-74 1802,-74 1802,-68 1808,-62 1814,-62 1814,-62 1844,-62 1844,-62 1850,-62 1856,-68 1856,-74 1856,-74 1856,-86 1856,-86 1856,-92 1850,-98 1844,-98\"/>\n<text text-anchor=\"middle\" x=\"1829\" y=\"-76.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">norm</text>\n</a>\n</g>\n</g>\n<!-- layer2_pool&#45;&gt;layer2_norm -->\n<g id=\"edge21\" class=\"edge\">\n<title>layer2_pool&#45;&gt;layer2_norm</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1766.003,-80C1774.0277,-80 1782.9665,-80 1791.5309,-80\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1791.7051,-83.5001 1801.705,-80 1791.705,-76.5001 1791.7051,-83.5001\"/>\n</g>\n<!-- layer2_act -->\n<g id=\"node21\" class=\"node\">\n<title>layer2_act</title>\n<g id=\"a_node21\"><a xlink:title=\"functools.partial(&lt;class &#39;torch.nn.modules.activation.CELU&#39;&gt;, 0.3) {}\">\n<path fill=\"#f0e189\" stroke=\"#000000\" d=\"M1934,-98C1934,-98 1904,-98 1904,-98 1898,-98 1892,-92 1892,-86 1892,-86 1892,-74 1892,-74 1892,-68 1898,-62 1904,-62 1904,-62 1934,-62 1934,-62 1940,-62 1946,-68 1946,-74 1946,-74 1946,-86 1946,-86 1946,-92 1940,-98 1934,-98\"/>\n<text text-anchor=\"middle\" x=\"1919\" y=\"-76.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">act</text>\n</a>\n</g>\n</g>\n<!-- layer2_norm&#45;&gt;layer2_act -->\n<g id=\"edge22\" class=\"edge\">\n<title>layer2_norm&#45;&gt;layer2_act</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1856.003,-80C1864.0277,-80 1872.9665,-80 1881.5309,-80\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1881.7051,-83.5001 1891.705,-80 1881.705,-76.5001 1881.7051,-83.5001\"/>\n</g>\n<!-- layer3_conv -->\n<g id=\"node22\" class=\"node\">\n<title>layer3_conv</title>\n<g id=\"a_node22\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.conv.Conv2d&#39;&gt; {&#39;in_channels&#39;: 256, &#39;out_channels&#39;: 512, &#39;kernel_size&#39;: (3, 3), &#39;stride&#39;: (1, 1), &#39;padding&#39;: (1, 1), &#39;bias&#39;: False}\">\n<path fill=\"#bebada\" stroke=\"#000000\" d=\"M2024,-98C2024,-98 1994,-98 1994,-98 1988,-98 1982,-92 1982,-86 1982,-86 1982,-74 1982,-74 1982,-68 1988,-62 1994,-62 1994,-62 2024,-62 2024,-62 2030,-62 2036,-68 2036,-74 2036,-74 2036,-86 2036,-86 2036,-92 2030,-98 2024,-98\"/>\n<text text-anchor=\"middle\" x=\"2009\" y=\"-76.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">conv</text>\n</a>\n</g>\n</g>\n<!-- layer2_act&#45;&gt;layer3_conv -->\n<g id=\"edge23\" class=\"edge\">\n<title>layer2_act&#45;&gt;layer3_conv</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1946.003,-80C1954.0277,-80 1962.9665,-80 1971.5309,-80\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1971.7051,-83.5001 1981.705,-80 1971.705,-76.5001 1971.7051,-83.5001\"/>\n</g>\n<!-- layer3_pool -->\n<g id=\"node23\" class=\"node\">\n<title>layer3_pool</title>\n<g id=\"a_node23\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.pooling.MaxPool2d&#39;&gt; {&#39;kernel_size&#39;: 2}\">\n<path fill=\"#8dd3c7\" stroke=\"#000000\" d=\"M2114,-98C2114,-98 2084,-98 2084,-98 2078,-98 2072,-92 2072,-86 2072,-86 2072,-74 2072,-74 2072,-68 2078,-62 2084,-62 2084,-62 2114,-62 2114,-62 2120,-62 2126,-68 2126,-74 2126,-74 2126,-86 2126,-86 2126,-92 2120,-98 2114,-98\"/>\n<text text-anchor=\"middle\" x=\"2099\" y=\"-76.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">pool</text>\n</a>\n</g>\n</g>\n<!-- layer3_conv&#45;&gt;layer3_pool -->\n<g id=\"edge24\" class=\"edge\">\n<title>layer3_conv&#45;&gt;layer3_pool</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2036.003,-80C2044.0277,-80 2052.9665,-80 2061.5309,-80\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2061.7051,-83.5001 2071.705,-80 2061.705,-76.5001 2061.7051,-83.5001\"/>\n</g>\n<!-- layer3_norm -->\n<g id=\"node24\" class=\"node\">\n<title>layer3_norm</title>\n<g id=\"a_node24\"><a xlink:title=\"functools.partial(&lt;class &#39;__main__.GhostBatchNorm&#39;&gt;, num_splits=16, weight=False) {&#39;num_features&#39;: 512}\">\n<path fill=\"#d0c281\" stroke=\"#000000\" d=\"M2204,-98C2204,-98 2174,-98 2174,-98 2168,-98 2162,-92 2162,-86 2162,-86 2162,-74 2162,-74 2162,-68 2168,-62 2174,-62 2174,-62 2204,-62 2204,-62 2210,-62 2216,-68 2216,-74 2216,-74 2216,-86 2216,-86 2216,-92 2210,-98 2204,-98\"/>\n<text text-anchor=\"middle\" x=\"2189\" y=\"-76.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">norm</text>\n</a>\n</g>\n</g>\n<!-- layer3_pool&#45;&gt;layer3_norm -->\n<g id=\"edge25\" class=\"edge\">\n<title>layer3_pool&#45;&gt;layer3_norm</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2126.003,-80C2134.0277,-80 2142.9665,-80 2151.5309,-80\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2151.7051,-83.5001 2161.705,-80 2151.705,-76.5001 2151.7051,-83.5001\"/>\n</g>\n<!-- layer3_act -->\n<g id=\"node25\" class=\"node\">\n<title>layer3_act</title>\n<g id=\"a_node25\"><a xlink:title=\"functools.partial(&lt;class &#39;torch.nn.modules.activation.CELU&#39;&gt;, 0.3) {}\">\n<path fill=\"#f0e189\" stroke=\"#000000\" d=\"M2294,-98C2294,-98 2264,-98 2264,-98 2258,-98 2252,-92 2252,-86 2252,-86 2252,-74 2252,-74 2252,-68 2258,-62 2264,-62 2264,-62 2294,-62 2294,-62 2300,-62 2306,-68 2306,-74 2306,-74 2306,-86 2306,-86 2306,-92 2300,-98 2294,-98\"/>\n<text text-anchor=\"middle\" x=\"2279\" y=\"-76.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">act</text>\n</a>\n</g>\n</g>\n<!-- layer3_norm&#45;&gt;layer3_act -->\n<g id=\"edge26\" class=\"edge\">\n<title>layer3_norm&#45;&gt;layer3_act</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2216.003,-80C2224.0277,-80 2232.9665,-80 2241.5309,-80\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2241.7051,-83.5001 2251.705,-80 2241.705,-76.5001 2241.7051,-83.5001\"/>\n</g>\n<!-- layer3_residual_in -->\n<g id=\"node26\" class=\"node\">\n<title>layer3_residual_in</title>\n<g id=\"a_node26\"><a xlink:title=\"&lt;class &#39;__main__.Identity&#39;&gt; {}\">\n<path fill=\"#80b1d3\" stroke=\"#000000\" d=\"M2384,-98C2384,-98 2354,-98 2354,-98 2348,-98 2342,-92 2342,-86 2342,-86 2342,-74 2342,-74 2342,-68 2348,-62 2354,-62 2354,-62 2384,-62 2384,-62 2390,-62 2396,-68 2396,-74 2396,-74 2396,-86 2396,-86 2396,-92 2390,-98 2384,-98\"/>\n<text text-anchor=\"middle\" x=\"2369\" y=\"-76.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">in</text>\n</a>\n</g>\n</g>\n<!-- layer3_act&#45;&gt;layer3_residual_in -->\n<g id=\"edge27\" class=\"edge\">\n<title>layer3_act&#45;&gt;layer3_residual_in</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2306.003,-80C2314.0277,-80 2322.9665,-80 2331.5309,-80\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2331.7051,-83.5001 2341.705,-80 2331.705,-76.5001 2331.7051,-83.5001\"/>\n</g>\n<!-- layer3_residual_res1_conv -->\n<g id=\"node27\" class=\"node\">\n<title>layer3_residual_res1_conv</title>\n<g id=\"a_node27\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.conv.Conv2d&#39;&gt; {&#39;in_channels&#39;: 512, &#39;out_channels&#39;: 512, &#39;kernel_size&#39;: (3, 3), &#39;stride&#39;: (1, 1), &#39;padding&#39;: (1, 1), &#39;bias&#39;: False}\">\n<path fill=\"#bebada\" stroke=\"#000000\" d=\"M2474,-88C2474,-88 2444,-88 2444,-88 2438,-88 2432,-82 2432,-76 2432,-76 2432,-64 2432,-64 2432,-58 2438,-52 2444,-52 2444,-52 2474,-52 2474,-52 2480,-52 2486,-58 2486,-64 2486,-64 2486,-76 2486,-76 2486,-82 2480,-88 2474,-88\"/>\n<text text-anchor=\"middle\" x=\"2459\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">conv</text>\n</a>\n</g>\n</g>\n<!-- layer3_residual_in&#45;&gt;layer3_residual_res1_conv -->\n<g id=\"edge28\" class=\"edge\">\n<title>layer3_residual_in&#45;&gt;layer3_residual_res1_conv</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2396.003,-76.9997C2404.0277,-76.108 2412.9665,-75.1148 2421.5309,-74.1632\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2422.1527,-77.6158 2431.705,-73.0328 2421.3796,-70.6586 2422.1527,-77.6158\"/>\n</g>\n<!-- layer3_residual_add -->\n<g id=\"node34\" class=\"node\">\n<title>layer3_residual_add</title>\n<g id=\"a_node34\"><a xlink:title=\"&lt;class &#39;__main__.Add&#39;&gt; {}\">\n<path fill=\"#fdb462\" stroke=\"#000000\" d=\"M3104,-118C3104,-118 3074,-118 3074,-118 3068,-118 3062,-112 3062,-106 3062,-106 3062,-94 3062,-94 3062,-88 3068,-82 3074,-82 3074,-82 3104,-82 3104,-82 3110,-82 3116,-88 3116,-94 3116,-94 3116,-106 3116,-106 3116,-112 3110,-118 3104,-118\"/>\n<text text-anchor=\"middle\" x=\"3089\" y=\"-96.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">add</text>\n</a>\n</g>\n</g>\n<!-- layer3_residual_in&#45;&gt;layer3_residual_add -->\n<g id=\"edge35\" class=\"edge\">\n<title>layer3_residual_in&#45;&gt;layer3_residual_add</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2386.5351,-98.3771C2396.5459,-107.5711 2409.8909,-117.8215 2424,-123 2476.1953,-142.1574 2493.4,-128 2549,-128 2549,-128 2549,-128 2909,-128 2958.7971,-128 3015.4324,-117.4074 3051.6554,-109.2525\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"3052.8023,-112.5799 3061.7594,-106.9214 3051.2285,-105.7591 3052.8023,-112.5799\"/>\n</g>\n<!-- layer3_residual_res1_norm -->\n<g id=\"node28\" class=\"node\">\n<title>layer3_residual_res1_norm</title>\n<g id=\"a_node28\"><a xlink:title=\"functools.partial(&lt;class &#39;__main__.GhostBatchNorm&#39;&gt;, num_splits=16, weight=False) {&#39;num_features&#39;: 512}\">\n<path fill=\"#d0c281\" stroke=\"#000000\" d=\"M2564,-88C2564,-88 2534,-88 2534,-88 2528,-88 2522,-82 2522,-76 2522,-76 2522,-64 2522,-64 2522,-58 2528,-52 2534,-52 2534,-52 2564,-52 2564,-52 2570,-52 2576,-58 2576,-64 2576,-64 2576,-76 2576,-76 2576,-82 2570,-88 2564,-88\"/>\n<text text-anchor=\"middle\" x=\"2549\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">norm</text>\n</a>\n</g>\n</g>\n<!-- layer3_residual_res1_conv&#45;&gt;layer3_residual_res1_norm -->\n<g id=\"edge29\" class=\"edge\">\n<title>layer3_residual_res1_conv&#45;&gt;layer3_residual_res1_norm</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2486.003,-70C2494.0277,-70 2502.9665,-70 2511.5309,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2511.7051,-73.5001 2521.705,-70 2511.705,-66.5001 2511.7051,-73.5001\"/>\n</g>\n<!-- layer3_residual_res1_act -->\n<g id=\"node29\" class=\"node\">\n<title>layer3_residual_res1_act</title>\n<g id=\"a_node29\"><a xlink:title=\"functools.partial(&lt;class &#39;torch.nn.modules.activation.CELU&#39;&gt;, 0.3) {}\">\n<path fill=\"#f0e189\" stroke=\"#000000\" d=\"M2654,-88C2654,-88 2624,-88 2624,-88 2618,-88 2612,-82 2612,-76 2612,-76 2612,-64 2612,-64 2612,-58 2618,-52 2624,-52 2624,-52 2654,-52 2654,-52 2660,-52 2666,-58 2666,-64 2666,-64 2666,-76 2666,-76 2666,-82 2660,-88 2654,-88\"/>\n<text text-anchor=\"middle\" x=\"2639\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">act</text>\n</a>\n</g>\n</g>\n<!-- layer3_residual_res1_norm&#45;&gt;layer3_residual_res1_act -->\n<g id=\"edge30\" class=\"edge\">\n<title>layer3_residual_res1_norm&#45;&gt;layer3_residual_res1_act</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2576.003,-70C2584.0277,-70 2592.9665,-70 2601.5309,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2601.7051,-73.5001 2611.705,-70 2601.705,-66.5001 2601.7051,-73.5001\"/>\n</g>\n<!-- layer3_residual_res2_conv -->\n<g id=\"node30\" class=\"node\">\n<title>layer3_residual_res2_conv</title>\n<g id=\"a_node30\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.conv.Conv2d&#39;&gt; {&#39;in_channels&#39;: 512, &#39;out_channels&#39;: 512, &#39;kernel_size&#39;: (3, 3), &#39;stride&#39;: (1, 1), &#39;padding&#39;: (1, 1), &#39;bias&#39;: False}\">\n<path fill=\"#bebada\" stroke=\"#000000\" d=\"M2744,-88C2744,-88 2714,-88 2714,-88 2708,-88 2702,-82 2702,-76 2702,-76 2702,-64 2702,-64 2702,-58 2708,-52 2714,-52 2714,-52 2744,-52 2744,-52 2750,-52 2756,-58 2756,-64 2756,-64 2756,-76 2756,-76 2756,-82 2750,-88 2744,-88\"/>\n<text text-anchor=\"middle\" x=\"2729\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">conv</text>\n</a>\n</g>\n</g>\n<!-- layer3_residual_res1_act&#45;&gt;layer3_residual_res2_conv -->\n<g id=\"edge31\" class=\"edge\">\n<title>layer3_residual_res1_act&#45;&gt;layer3_residual_res2_conv</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2666.003,-70C2674.0277,-70 2682.9665,-70 2691.5309,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2691.7051,-73.5001 2701.705,-70 2691.705,-66.5001 2691.7051,-73.5001\"/>\n</g>\n<!-- layer3_residual_res2_norm -->\n<g id=\"node31\" class=\"node\">\n<title>layer3_residual_res2_norm</title>\n<g id=\"a_node31\"><a xlink:title=\"functools.partial(&lt;class &#39;__main__.GhostBatchNorm&#39;&gt;, num_splits=16, weight=False) {&#39;num_features&#39;: 512}\">\n<path fill=\"#d0c281\" stroke=\"#000000\" d=\"M2834,-88C2834,-88 2804,-88 2804,-88 2798,-88 2792,-82 2792,-76 2792,-76 2792,-64 2792,-64 2792,-58 2798,-52 2804,-52 2804,-52 2834,-52 2834,-52 2840,-52 2846,-58 2846,-64 2846,-64 2846,-76 2846,-76 2846,-82 2840,-88 2834,-88\"/>\n<text text-anchor=\"middle\" x=\"2819\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">norm</text>\n</a>\n</g>\n</g>\n<!-- layer3_residual_res2_conv&#45;&gt;layer3_residual_res2_norm -->\n<g id=\"edge32\" class=\"edge\">\n<title>layer3_residual_res2_conv&#45;&gt;layer3_residual_res2_norm</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2756.003,-70C2764.0277,-70 2772.9665,-70 2781.5309,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2781.7051,-73.5001 2791.705,-70 2781.705,-66.5001 2781.7051,-73.5001\"/>\n</g>\n<!-- layer3_residual_res2_act -->\n<g id=\"node32\" class=\"node\">\n<title>layer3_residual_res2_act</title>\n<g id=\"a_node32\"><a xlink:title=\"functools.partial(&lt;class &#39;torch.nn.modules.activation.CELU&#39;&gt;, 0.3) {}\">\n<path fill=\"#f0e189\" stroke=\"#000000\" d=\"M2924,-88C2924,-88 2894,-88 2894,-88 2888,-88 2882,-82 2882,-76 2882,-76 2882,-64 2882,-64 2882,-58 2888,-52 2894,-52 2894,-52 2924,-52 2924,-52 2930,-52 2936,-58 2936,-64 2936,-64 2936,-76 2936,-76 2936,-82 2930,-88 2924,-88\"/>\n<text text-anchor=\"middle\" x=\"2909\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">act</text>\n</a>\n</g>\n</g>\n<!-- layer3_residual_res2_norm&#45;&gt;layer3_residual_res2_act -->\n<g id=\"edge33\" class=\"edge\">\n<title>layer3_residual_res2_norm&#45;&gt;layer3_residual_res2_act</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2846.003,-70C2854.0277,-70 2862.9665,-70 2871.5309,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2871.7051,-73.5001 2881.705,-70 2871.705,-66.5001 2871.7051,-73.5001\"/>\n</g>\n<!-- layer3_residual_out -->\n<g id=\"node33\" class=\"node\">\n<title>layer3_residual_out</title>\n<g id=\"a_node33\"><a xlink:title=\"&lt;class &#39;__main__.Identity&#39;&gt; {}\">\n<path fill=\"#80b1d3\" stroke=\"#000000\" d=\"M3014,-98C3014,-98 2984,-98 2984,-98 2978,-98 2972,-92 2972,-86 2972,-86 2972,-74 2972,-74 2972,-68 2978,-62 2984,-62 2984,-62 3014,-62 3014,-62 3020,-62 3026,-68 3026,-74 3026,-74 3026,-86 3026,-86 3026,-92 3020,-98 3014,-98\"/>\n<text text-anchor=\"middle\" x=\"2999\" y=\"-76.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">out</text>\n</a>\n</g>\n</g>\n<!-- layer3_residual_res2_act&#45;&gt;layer3_residual_out -->\n<g id=\"edge34\" class=\"edge\">\n<title>layer3_residual_res2_act&#45;&gt;layer3_residual_out</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2936.003,-73.0003C2944.0277,-73.892 2952.9665,-74.8852 2961.5309,-75.8368\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2961.3796,-79.3414 2971.705,-76.9672 2962.1527,-72.3842 2961.3796,-79.3414\"/>\n</g>\n<!-- layer3_residual_out&#45;&gt;layer3_residual_add -->\n<g id=\"edge36\" class=\"edge\">\n<title>layer3_residual_out&#45;&gt;layer3_residual_add</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M3026.003,-86.0007C3034.1158,-87.8035 3043.1631,-89.814 3051.8131,-91.7362\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"3051.1839,-95.1817 3061.705,-93.9345 3052.7024,-88.3484 3051.1839,-95.1817\"/>\n</g>\n<!-- pool -->\n<g id=\"node35\" class=\"node\">\n<title>pool</title>\n<g id=\"a_node35\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.pooling.MaxPool2d&#39;&gt; {&#39;kernel_size&#39;: 4}\">\n<path fill=\"#8dd3c7\" stroke=\"#000000\" d=\"M3194,-118C3194,-118 3164,-118 3164,-118 3158,-118 3152,-112 3152,-106 3152,-106 3152,-94 3152,-94 3152,-88 3158,-82 3164,-82 3164,-82 3194,-82 3194,-82 3200,-82 3206,-88 3206,-94 3206,-94 3206,-106 3206,-106 3206,-112 3200,-118 3194,-118\"/>\n<text text-anchor=\"middle\" x=\"3179\" y=\"-96.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">pool</text>\n</a>\n</g>\n</g>\n<!-- layer3_residual_add&#45;&gt;pool -->\n<g id=\"edge37\" class=\"edge\">\n<title>layer3_residual_add&#45;&gt;pool</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M3116.003,-100C3124.0277,-100 3132.9665,-100 3141.5309,-100\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"3141.7051,-103.5001 3151.705,-100 3141.705,-96.5001 3141.7051,-103.5001\"/>\n</g>\n<!-- classifier_flatten -->\n<g id=\"node36\" class=\"node\">\n<title>classifier_flatten</title>\n<g id=\"a_node36\"><a xlink:title=\"&lt;class &#39;__main__.Flatten&#39;&gt; {}\">\n<path fill=\"#b3de69\" stroke=\"#000000\" d=\"M3284,-118C3284,-118 3254,-118 3254,-118 3248,-118 3242,-112 3242,-106 3242,-106 3242,-94 3242,-94 3242,-88 3248,-82 3254,-82 3254,-82 3284,-82 3284,-82 3290,-82 3296,-88 3296,-94 3296,-94 3296,-106 3296,-106 3296,-112 3290,-118 3284,-118\"/>\n<text text-anchor=\"middle\" x=\"3269\" y=\"-96.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">flatten</text>\n</a>\n</g>\n</g>\n<!-- pool&#45;&gt;classifier_flatten -->\n<g id=\"edge38\" class=\"edge\">\n<title>pool&#45;&gt;classifier_flatten</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M3206.003,-100C3214.0277,-100 3222.9665,-100 3231.5309,-100\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"3231.7051,-103.5001 3241.705,-100 3231.705,-96.5001 3231.7051,-103.5001\"/>\n</g>\n<!-- classifier_conv -->\n<g id=\"node37\" class=\"node\">\n<title>classifier_conv</title>\n<g id=\"a_node37\"><a xlink:title=\"&lt;class &#39;torch.nn.modules.linear.Linear&#39;&gt; {&#39;in_features&#39;: 512, &#39;out_features&#39;: 10, &#39;bias&#39;: False}\">\n<path fill=\"#fccde5\" stroke=\"#000000\" d=\"M3374,-118C3374,-118 3344,-118 3344,-118 3338,-118 3332,-112 3332,-106 3332,-106 3332,-94 3332,-94 3332,-88 3338,-82 3344,-82 3344,-82 3374,-82 3374,-82 3380,-82 3386,-88 3386,-94 3386,-94 3386,-106 3386,-106 3386,-112 3380,-118 3374,-118\"/>\n<text text-anchor=\"middle\" x=\"3359\" y=\"-96.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">conv</text>\n</a>\n</g>\n</g>\n<!-- classifier_flatten&#45;&gt;classifier_conv -->\n<g id=\"edge39\" class=\"edge\">\n<title>classifier_flatten&#45;&gt;classifier_conv</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M3296.003,-100C3304.0277,-100 3312.9665,-100 3321.5309,-100\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"3321.7051,-103.5001 3331.705,-100 3321.705,-96.5001 3321.7051,-103.5001\"/>\n</g>\n<!-- classifier_scale -->\n<g id=\"node38\" class=\"node\">\n<title>classifier_scale</title>\n<g id=\"a_node38\"><a xlink:title=\"&lt;class &#39;__main__.Mul&#39;&gt; {&#39;weight&#39;: 0.0625}\">\n<path fill=\"#bc80bd\" stroke=\"#000000\" d=\"M3464,-118C3464,-118 3434,-118 3434,-118 3428,-118 3422,-112 3422,-106 3422,-106 3422,-94 3422,-94 3422,-88 3428,-82 3434,-82 3434,-82 3464,-82 3464,-82 3470,-82 3476,-88 3476,-94 3476,-94 3476,-106 3476,-106 3476,-112 3470,-118 3464,-118\"/>\n<text text-anchor=\"middle\" x=\"3449\" y=\"-96.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">scale</text>\n</a>\n</g>\n</g>\n<!-- classifier_conv&#45;&gt;classifier_scale -->\n<g id=\"edge40\" class=\"edge\">\n<title>classifier_conv&#45;&gt;classifier_scale</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M3386.003,-100C3394.0277,-100 3402.9665,-100 3411.5309,-100\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"3411.7051,-103.5001 3421.705,-100 3411.705,-96.5001 3411.7051,-103.5001\"/>\n</g>\n<!-- logits -->\n<g id=\"node39\" class=\"node\">\n<title>logits</title>\n<g id=\"a_node39\"><a xlink:title=\"&lt;class &#39;__main__.Identity&#39;&gt; {}\">\n<path fill=\"#80b1d3\" stroke=\"#000000\" d=\"M3554,-118C3554,-118 3524,-118 3524,-118 3518,-118 3512,-112 3512,-106 3512,-106 3512,-94 3512,-94 3512,-88 3518,-82 3524,-82 3524,-82 3554,-82 3554,-82 3560,-82 3566,-88 3566,-94 3566,-94 3566,-106 3566,-106 3566,-112 3560,-118 3554,-118\"/>\n<text text-anchor=\"middle\" x=\"3539\" y=\"-96.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">logits</text>\n</a>\n</g>\n</g>\n<!-- classifier_scale&#45;&gt;logits -->\n<g id=\"edge41\" class=\"edge\">\n<title>classifier_scale&#45;&gt;logits</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M3476.003,-100C3484.0277,-100 3492.9665,-100 3501.5309,-100\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"3501.7051,-103.5001 3511.705,-100 3501.705,-96.5001 3501.7051,-103.5001\"/>\n</g>\n<!-- input -->\n<g id=\"node40\" class=\"node\">\n<title>input</title>\n<path fill=\"#ffffff\" stroke=\"#000000\" d=\"M42,-88C42,-88 12,-88 12,-88 6,-88 0,-82 0,-76 0,-76 0,-64 0,-64 0,-58 6,-52 12,-52 12,-52 42,-52 42,-52 48,-52 54,-58 54,-64 54,-64 54,-76 54,-76 54,-82 48,-88 42,-88\"/>\n<text text-anchor=\"middle\" x=\"27\" y=\"-66.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">input</text>\n</g>\n<!-- input&#45;&gt;prep_whiten -->\n<g id=\"edge1\" class=\"edge\">\n<title>input&#45;&gt;prep_whiten</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M54.303,-70C62.268,-70 71.1237,-70 79.6375,-70\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"79.77,-73.5001 89.77,-70 79.77,-66.5001 79.77,-73.5001\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqAvZkzucX9W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "outputId": "c2b18482-4cb9-4631-ea90-c7083302af8c"
      },
      "source": [
        "N_RUNS = 2\n",
        "epochs, batch_size = 17, 512\n",
        "transforms = (Crop(32, 32), FlipLR(), Cutout(8, 8))\n",
        "opt_params = {'lr': lr_schedule([0, epochs/5, epochs], [0.0, 0.6, 0.0], batch_size), 'weight_decay': Const(5e-4*batch_size), 'momentum': Const(0.9)}\n",
        "opt_params_bias = {'lr': lr_schedule([0, epochs/5, epochs], [0.0, 0.6*64, 0.0], batch_size), 'weight_decay': Const(5e-4*batch_size/64), 'momentum': Const(0.9)}\n",
        "\n",
        "logs = Table(report=every(epochs,'epoch'))\n",
        "for run in range(N_RUNS):\n",
        "    model = build_model(input_whitening_net, label_smoothing_loss(0.2))\n",
        "    is_bias = group_by_key(('bias' in k, v) for k, v in trainable_params(model).items())\n",
        "    state, timer = {MODEL: model, OPTS: [SGD(is_bias[False], opt_params), SGD(is_bias[True], opt_params_bias)]}, Timer(torch.cuda.synchronize)\n",
        "    for epoch in range(epochs):\n",
        "        logs.append(union({'run': run+1, 'epoch': epoch+1}, train_epoch(state, timer, train_batches(batch_size, transforms), valid_batches(batch_size))))\n",
        "summary(logs)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         run        epoch   train time   train loss    train acc   valid time   valid loss    valid acc   total time\n",
            "           1           17      10.4784       0.9499       0.9694       0.6442       0.9845       0.9437     178.5611\n",
            "           2           17      10.4673       0.9498       0.9699       0.6474       0.9868       0.9446     178.1304\n",
            "           3           17      10.4927       0.9483       0.9702       0.6481       0.9880       0.9436     178.4495\n",
            "           4           17      10.4536       0.9509       0.9695       0.6452       0.9877       0.9423     177.7566\n",
            "           5           17      10.4852       0.9478       0.9705       0.6481       0.9860       0.9432     178.1645\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>min</th>\n",
              "      <th>max</th>\n",
              "      <th>std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>valid_acc</th>\n",
              "      <td>5</td>\n",
              "      <td>0.94348</td>\n",
              "      <td>0.9423</td>\n",
              "      <td>0.9446</td>\n",
              "      <td>0.000835</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           count     mean     min     max       std\n",
              "valid_acc      5  0.94348  0.9423  0.9446  0.000835"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfjLj-HORxWe",
        "colab_type": "text"
      },
      "source": [
        "17 epoch test accuracy jumps to 94.4% allowing a further 2 epoch reduction in training time. 15 epochs brings a test accuracy of 94.1% in 39s, closing in on the 4-GPU, test-time-augmentation assisted DAWNBench leader! If we increase the maximum learning rate by a further ~50% and reduce the amount of cutout augmentation, from 8Ã—8 to 5Ã—5 patches, to compensate for the extra regularisation that the higher learning rate brings, we can remove a further epoch and reach 94.1% test accuracy in 36s, moving us narrowly into top spot on the leaderboard!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TouhGnnKIBn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "outputId": "90a7c6f9-1c5b-4b78-e578-8a6c5a0e5e76"
      },
      "source": [
        "epochs, batch_size = 14, 512\n",
        "transforms = (Crop(32, 32), FlipLR(), Cutout(5, 5))\n",
        "opt_params = {'lr': lr_schedule([0, epochs/5, epochs], [0.0, 1.0, 0.0], batch_size), 'weight_decay': Const(5e-4*batch_size), 'momentum': Const(0.9)}\n",
        "opt_params_bias = {'lr': lr_schedule([0, epochs/5, epochs], [0.0, 1.0*64, 0.0], batch_size), 'weight_decay': Const(5e-4*batch_size/64), 'momentum': Const(0.9)}\n",
        "\n",
        "logs = Table(report=every(epochs,'epoch'))\n",
        "for run in range(N_RUNS):\n",
        "    model = build_model(input_whitening_net, label_smoothing_loss(0.2))\n",
        "    is_bias = group_by_key(('bias' in k, v) for k, v in trainable_params(model).items())\n",
        "    state, timer = {MODEL: model, OPTS: [SGD(is_bias[False], opt_params), SGD(is_bias[True], opt_params_bias)]}, Timer(torch.cuda.synchronize)\n",
        "    for epoch in range(epochs):\n",
        "        logs.append(union({'run': run+1, 'epoch': epoch+1}, train_epoch(state, timer, train_batches(batch_size, transforms), valid_batches(batch_size))))\n",
        "summary(logs)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         run        epoch   train time   train loss    train acc   valid time   valid loss    valid acc   total time\n",
            "           1           14      10.4800       0.9532       0.9675       0.6484       0.9916       0.9398     146.7802\n",
            "           2           14      10.4625       0.9508       0.9698       0.6467       0.9923       0.9402     146.6974\n",
            "           3           14      10.4693       0.9529       0.9686       0.6483       0.9898       0.9429     146.7279\n",
            "           4           14      10.4572       0.9520       0.9681       0.6472       0.9913       0.9406     146.6801\n",
            "           5           14      10.4706       0.9520       0.9698       0.6469       0.9929       0.9395     146.7542\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>min</th>\n",
              "      <th>max</th>\n",
              "      <th>std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>valid_acc</th>\n",
              "      <td>5</td>\n",
              "      <td>0.9406</td>\n",
              "      <td>0.9395</td>\n",
              "      <td>0.9429</td>\n",
              "      <td>0.001351</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           count    mean     min     max       std\n",
              "valid_acc      5  0.9406  0.9395  0.9429  0.001351"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bz_9Q9MapvH7",
        "colab_type": "text"
      },
      "source": [
        "### Exponential moving averages (33.5s)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DD_F0A7fpzBb",
        "colab_type": "text"
      },
      "source": [
        "High learning rates are necessary for rapid training since they allow stochastic gradient descent to traverse the necessary distances in parameter space in a limited amount of time. On the other hand, learning rates need to be annealed towards the end of training to enable optimisation along the steeper and noisier directions in parameter space. Parameter averaging methods allow training to continue at a higher rate whilst potentially approaching minima along noisy or oscillatory directions by averaging over multiple iterates. \n",
        "\n",
        "We shall investigate exponential moving averaging of parameters which is a standard approach. For efficiency reasons we update the moving average every 5 batches since we find that more frequent updates don't improve things. We need to choose a new learning rate schedule with higher learning rates towards the end of training, and a momentum for the moving average. For the learning rate, a simple choice is to stick with the piecewise linear schedule that we've been using throughout, floored at a low fixed value for the last 2 epochs and we choose a momentum of 0.99 so that averaging takes place over a timescale of roughly the last epoch.\n",
        "\n",
        "Test accuracy improves to 94.3% allowing us to trim a further epoch. 13 epoch training reaches a test accuracy of 94.1%, achieving a training time below 34s and a 10Ã— improvement over the single-GPU state-of-the-art at the outset of the series!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Jef-6wWUcpH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "outputId": "3234914a-f2a4-4072-dd29-c5ebe5715d0e"
      },
      "source": [
        "#Final training setup\n",
        "epochs, batch_size, ema_epochs=13, 512, 2\n",
        "transforms = (Crop(32, 32), FlipLR(), Cutout(5, 5))\n",
        "opt_params = {'lr': lr_schedule([0, epochs/5, epochs - ema_epochs], [0.0, 1.0, 0.1], batch_size), 'weight_decay': Const(5e-4*batch_size), 'momentum': Const(0.9)}\n",
        "opt_params_bias = {'lr': lr_schedule([0, epochs/5, epochs - ema_epochs], [0.0, 1.0*64, 0.1*64], batch_size), 'weight_decay': Const(5e-4*batch_size/64), 'momentum': Const(0.9)}\n",
        "\n",
        "logs = Table(report=every(epochs,'epoch'))\n",
        "for run in range(N_RUNS):\n",
        "    model = build_model(input_whitening_net, label_smoothing_loss(0.2))\n",
        "    is_bias = group_by_key(('bias' in k, v) for k, v in trainable_params(model).items())\n",
        "    state, timer = {MODEL: model, VALID_MODEL: copy.deepcopy(model), OPTS: [SGD(is_bias[False], opt_params), SGD(is_bias[True], opt_params_bias)]}, Timer(torch.cuda.synchronize)\n",
        "    for epoch in range(epochs):\n",
        "        logs.append(union({'run': run+1, 'epoch': epoch+1}, train_epoch(state, timer, train_batches(batch_size, transforms), valid_batches(batch_size), train_steps=(*train_steps, update_ema(momentum=0.99, update_freq=5)))))\n",
        "summary(logs)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         run        epoch   train time   train loss    train acc   valid time   valid loss    valid acc   total time\n",
            "           1           13      10.4816       0.9588       0.9651       0.6471       0.9903       0.9411     136.3729\n",
            "           2           13      10.4881       0.9569       0.9660       0.6440       0.9884       0.9400     136.4279\n",
            "           3           13      10.5064       0.9579       0.9656       0.6475       0.9897       0.9403     136.5292\n",
            "           4           13      10.4995       0.9597       0.9644       0.6495       0.9912       0.9401     136.5933\n",
            "           5           13      10.5175       0.9617       0.9636       0.6496       0.9880       0.9434     136.7407\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>min</th>\n",
              "      <th>max</th>\n",
              "      <th>std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>valid_acc</th>\n",
              "      <td>5</td>\n",
              "      <td>0.94098</td>\n",
              "      <td>0.94</td>\n",
              "      <td>0.9434</td>\n",
              "      <td>0.00142</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           count     mean   min     max      std\n",
              "valid_acc      5  0.94098  0.94  0.9434  0.00142"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dv-Q0jUA-oHi",
        "colab_type": "text"
      },
      "source": [
        "### Test-time augmentation (26s)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-2DG-xvVr2g",
        "colab_type": "text"
      },
      "source": [
        "Suppose that you'd like your network to classify images the same way under horizontal flips of the input. One possibility, that we've been using till now, is to present the network with a large amount of data, possibly augmented by label preserving left-right flips, and hope that the network will eventually learn the invariance through extensive training. \n",
        "\n",
        "A second approach, which doesn't leave things to chance, is to present both the input image and its horizontally flipped version and come to a consensus by averaging network outputs for the two versions, thus guaranteeing invariance. This eminently sensible approach goes by the name of test-time augmentation.\n",
        "\n",
        "At training time, we still present the network with a single version of each image - potentially subject to random flipping as a data augmentation so that different versions are presented on different training epochs. An alternative, would be to use the same procedure at training time as at test time and present each image along with its mirror. In this case, we could claim to have changed the network by splitting into two identical branches, one of which sees the flipped image, and then merging at the end. Through this lens, the original training can be viewed as a stochastic training procedure for a weight-tied, two branch network in which a single branch is 'dropped-out' for each training example.\n",
        "\n",
        "This dropout-training viewpoint makes it clear that any attempt to introduce a rule disallowing TTA from a benchmark is going to be fraught with difficulties. From this point of view, we have just introduced a larger network for which we have an efficient stochastic training methodology. On the other hand, if we don't limit the amount of work that we are prepared to do at test time then there are some obvious degenerate solutions in which training takes as little time as is required to store the dataset!\n",
        "\n",
        "These arguments are not only relevant to artificial benchmarks but also to end use-cases. In some applications, classification accuracy is all that is desired and in that case TTA should most definitely be used. In other cases, inference time is also a constraint and a sensible approach is to maximise accuracy subject to such constraints. This is probably a good approach for training benchmarks too. \n",
        "\n",
        "In the case at hand, the Kakao Brain team has applied the simple form of TTA described here - presenting an image and its left-right mirror at inference time, thus doubling the computational load. More extensive forms of TTA are of course possible for other symmetries (such as translational symmetry, variations in brightness/colour etc.) but these would come at a higher computational cost. \n",
        "\n",
        "Now because these entries are based of a computationally light 9-layer ResNet _total inference time including TTA_ is likely to be much lower for these entries than for some of the 100+ layer networks that have been entered at earlier stages of the competition! According to our discussion above, any reasonable rule to limit this kind of approach should be based on inference time constraints and not an arbitrary feature of the implementation and so from this point-of-view, we should accept the approach.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GcFJZJeg__W",
        "colab_type": "text"
      },
      "source": [
        "Let's see what improvement TTA brings. We shall restrict ourselves to horizontal flip TTA for consistency with the current DAWNBench submissions and because this seems a sweet spot between accuracy and inference cost. With our current network and 13 epoch training setup, the test accuracy with TTA rises to 94.6%, making this the largest individual effect we've studied today. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjS1RJ11oLef",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "valid_steps_tta = (forward_tta([identity, flip_lr]), log_activations(('loss', 'acc')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3r9fcUEnlk_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "outputId": "e0630d90-2bc8-4a19-d4cb-dca88731502d"
      },
      "source": [
        "epochs, batch_size, ema_epochs=13, 512, 2\n",
        "transforms = (Crop(32, 32), FlipLR(), Cutout(5, 5))\n",
        "opt_params = {'lr': lr_schedule([0, epochs/5, epochs - ema_epochs], [0.0, 1.0, 0.1], batch_size), 'weight_decay': Const(5e-4*batch_size), 'momentum': Const(0.9)}\n",
        "opt_params_bias = {'lr': lr_schedule([0, epochs/5, epochs - ema_epochs], [0.0, 1.0*64, 0.1*64], batch_size), 'weight_decay': Const(5e-4*batch_size/64), 'momentum': Const(0.9)}\n",
        "\n",
        "logs = Table(report=every(epochs,'epoch'))\n",
        "for run in range(N_RUNS):\n",
        "    model = build_model(input_whitening_net, label_smoothing_loss(0.2))\n",
        "    is_bias = group_by_key(('bias' in k, v) for k, v in trainable_params(model).items())\n",
        "    state, timer = {MODEL: model, VALID_MODEL: copy.deepcopy(model), OPTS: [SGD(is_bias[False], opt_params), SGD(is_bias[True], opt_params_bias)]}, Timer(torch.cuda.synchronize)\n",
        "    for epoch in range(epochs):\n",
        "        logs.append(union({'run': run+1, 'epoch': epoch+1}, train_epoch(state, timer, train_batches(batch_size, transforms), valid_batches(batch_size), \n",
        "                                                                        train_steps=(*train_steps, update_ema(momentum=0.99, update_freq=5)),\n",
        "                                                                        valid_steps=valid_steps_tta)))\n",
        "summary(logs)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         run        epoch   train time   train loss    train acc   valid time   valid loss    valid acc   total time\n",
            "           1           13      10.5189       0.9588       0.9649       1.2983       0.9788       0.9469     136.7839\n",
            "           2           13      10.5146       0.9575       0.9670       1.2944       0.9803       0.9450     136.7803\n",
            "           3           13      10.4378       0.9592       0.9657       1.2879       0.9797       0.9474     136.2066\n",
            "           4           13      10.4694       0.9612       0.9640       1.2982       0.9836       0.9440     136.1764\n",
            "           5           13      10.5149       0.9595       0.9648       1.2975       0.9827       0.9456     136.5321\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>min</th>\n",
              "      <th>max</th>\n",
              "      <th>std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>valid_acc</th>\n",
              "      <td>5</td>\n",
              "      <td>0.94578</td>\n",
              "      <td>0.944</td>\n",
              "      <td>0.9474</td>\n",
              "      <td>0.001386</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           count     mean    min     max       std\n",
              "valid_acc      5  0.94578  0.944  0.9474  0.001386"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vH4hq224nqQh",
        "colab_type": "text"
      },
      "source": [
        "If we remove the remaining cutout data augmentation - which is getting in the way on such a short training schedule - we can reduce training to 10 epochs (!) and achieve a TTA test accuracy of 94.1% in 26s!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oewy20lcoBVK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "outputId": "7f8e71ff-9adf-4892-a7e3-7510dce5f537"
      },
      "source": [
        "epochs, batch_size, ema_epochs=10, 512, 2\n",
        "transforms = (Crop(32, 32), FlipLR())\n",
        "opt_params = {'lr': lr_schedule([0, epochs/5, epochs - ema_epochs], [0.0, 1.0, 0.1], batch_size), 'weight_decay': Const(5e-4*batch_size), 'momentum': Const(0.9)}\n",
        "opt_params_bias = {'lr': lr_schedule([0, epochs/5, epochs - ema_epochs], [0.0, 1.0*64, 0.1*64], batch_size), 'weight_decay': Const(5e-4*batch_size/64), 'momentum': Const(0.9)}\n",
        "\n",
        "logs = Table(report=every(epochs,'epoch'))\n",
        "for run in range(N_RUNS):\n",
        "    model = build_model(input_whitening_net, label_smoothing_loss(0.2))\n",
        "    is_bias = group_by_key(('bias' in k, v) for k, v in trainable_params(model).items())\n",
        "    state, timer = {MODEL: model, VALID_MODEL: copy.deepcopy(model), OPTS: [SGD(is_bias[False], opt_params), SGD(is_bias[True], opt_params_bias)]}, Timer(torch.cuda.synchronize)\n",
        "    for epoch in range(epochs):\n",
        "        logs.append(union({'run': run+1, 'epoch': epoch+1}, train_epoch(state, timer, train_batches(batch_size, transforms), valid_batches(batch_size), \n",
        "                                                                        train_steps=(*train_steps, update_ema(momentum=0.99, update_freq=5)),\n",
        "                                                                        valid_steps=valid_steps_tta)))\n",
        "summary(logs)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         run        epoch   train time   train loss    train acc   valid time   valid loss    valid acc   total time\n",
            "           1           10      10.5066       0.9556       0.9678       1.3029       0.9902       0.9416     105.0825\n",
            "           2           10      10.5133       0.9565       0.9668       1.2995       0.9892       0.9417     105.0900\n",
            "           3           10      10.4834       0.9554       0.9690       1.2944       0.9917       0.9393     105.0147\n",
            "           4           10      10.4755       0.9561       0.9678       1.2961       0.9890       0.9412     104.7340\n",
            "           5           10      10.5007       0.9553       0.9660       1.2981       0.9888       0.9437     104.9814\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>min</th>\n",
              "      <th>max</th>\n",
              "      <th>std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>valid_acc</th>\n",
              "      <td>5</td>\n",
              "      <td>0.9415</td>\n",
              "      <td>0.9393</td>\n",
              "      <td>0.9437</td>\n",
              "      <td>0.001567</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           count    mean     min     max       std\n",
              "valid_acc      5  0.9415  0.9393  0.9437  0.001567"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dD7-fE8Xoq_r",
        "colab_type": "text"
      },
      "source": [
        "### Training to convergence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yO8eWpWOdFS-",
        "colab_type": "text"
      },
      "source": [
        "Here is a simple experiment to investigate whether the gains in training speed that we have collected also translate into gains in final accuracy for the model if it is trained to convergence. We have every reason to believe that this should be the case, if only because many of the techniques that we have been using today were originally proposed as techniques to improve converged accuracy on ImageNet! If it is the case that the same techniques which speed up training time to 94% accuracy on CIFAR10 also improve converged accuracy on ImageNet, then this suggests a rather effective way to accelerate research on the latter problem!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9G4gjGueEAZ",
        "colab_type": "text"
      },
      "source": [
        "Unlike the previous experiments, this is going to be very rough and ready and we leave it to future work to do this experiment more carefully. We are going to pick a fixed learning rate schedule with lower learning rates appropriate for longer training and increase the amount of cutout augmentation to 12Ã—12 patches to allow training for longer without overfitting. We will fix the other hyperparameters as they were above and train both the baseline network and the final network for a range of different times from 24 to 100 epochs. Finally we're going to break all the rules and only run each experiment 5 times! Here are the results: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HShJN2xh22e",
        "colab_type": "text"
      },
      "source": [
        "#### Convergence experiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2LQrVTMgTSq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "valid_steps_tta = (forward_tta([identity, flip_lr]), log_activations(('loss', 'acc')))\n",
        "\n",
        "def train_epoch_tta(state, timer, train_batches, valid_batches, train_steps=train_steps, \n",
        "                    valid_steps=valid_steps, valid_steps_tta=valid_steps_tta, on_epoch_end=identity):\n",
        "    train_summary, train_time = epoch_stats(on_epoch_end(reduce(train_batches, state, train_steps))), timer()\n",
        "    valid_summary, valid_time = epoch_stats(reduce(valid_batches, state, valid_steps)), timer(update_total=False) #DAWNBench rules\n",
        "    valid_summary_tta, valid_time_tta = epoch_stats(reduce(valid_batches, state, valid_steps_tta)), timer(update_total=False) #DAWNBench rules\n",
        "    return {\n",
        "        'train': union({'time': train_time}, train_summary), \n",
        "        'valid': union({'time': valid_time}, valid_summary), \n",
        "        'tta': union({'time': valid_time}, valid_summary_tta), \n",
        "        'total time': timer.total_time\n",
        "    }\n",
        "\n",
        "#baseline model\n",
        "transforms = (Crop(32, 32), FlipLR(), Cutout(12, 12))\n",
        "logs = Table()\n",
        "for run in range(5):\n",
        "    for epochs in [24, 40, 60, 80, 100]:\n",
        "        opt_params = {'lr': lr_schedule([0, 5, epochs], [0.0, 0.4, 0.0], batch_size), 'weight_decay': Const(5e-4*batch_size), 'momentum': Const(0.9)}\n",
        "\n",
        "        model = build_model(network(), x_ent_loss)\n",
        "        state, timer = {MODEL: model, OPTS: [SGD(trainable_params(model).values(), opt_params)]}, Timer(torch.cuda.synchronize)\n",
        "        for epoch in range(epochs-1):\n",
        "            train_epoch(state, timer, train_batches(batch_size, transforms),  valid_batches(batch_size)) \n",
        "        logs.append(union({'run': run+1, 'epoch': epochs, 'experiment': baseline}, \n",
        "                          train_epoch_tta(state, timer, train_batches(batch_size, transforms),  valid_batches(batch_size), \n",
        "                                          valid_steps_tta=valid_steps_tta)))   \n",
        "#final model\n",
        "ema_epochs=2\n",
        "for run in range(5):\n",
        "    for epochs in [24, 40, 60, 80, 100]:\n",
        "        opt_params = {'lr': lr_schedule([0, epochs/5, epochs - ema_epochs], [0.0, 0.4, 0.04], batch_size), 'weight_decay': Const(5e-4*batch_size), 'momentum': Const(0.9)}\n",
        "        opt_params_bias = {'lr': lr_schedule([0, epochs/5, epochs - ema_epochs], [0.0, 0.4*64, 0.04\n",
        "                                                                          *64], batch_size), 'weight_decay': Const(5e-4*batch_size/64), 'momentum': Const(0.9)}\n",
        "\n",
        "        model = build_model(input_whitening_net, label_smoothing_loss(0.2))\n",
        "        is_bias = group_by_key(('bias' in k, v) for k, v in trainable_params(model).items())\n",
        "        state, timer = {MODEL: model, VALID_MODEL: copy.deepcopy(model), OPTS: [SGD(is_bias[False], opt_params), SGD(is_bias[True], opt_params_bias)]}, Timer(torch.cuda.synchronize)\n",
        "        for epoch in range(epochs-1):\n",
        "            train_epoch(state, timer, train_batches(batch_size, transforms), valid_batches(batch_size), \n",
        "                                                                            train_steps=(*train_steps, update_ema(momentum=0.99, update_freq=5)))\n",
        "        logs.append(union({'run': run+1, 'epoch': epochs, 'experiment': final}, \n",
        "                          train_epoch_tta(state, timer, train_batches(batch_size, transforms), valid_batches(batch_size), \n",
        "                                          train_steps=(*train_steps, update_ema(momentum=0.99, update_freq=5)))))  \n",
        "        \n",
        "data = logs.df()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GI_eqtvSh6Ng",
        "colab_type": "text"
      },
      "source": [
        "#### Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-5yQ-E3g-xt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scale = alt.Scale(zero=False)\n",
        "c = alt.Chart(data).encode(x=alt.X('epoch', scale=scale), color='experiment')\n",
        "\n",
        "c1=(c.mark_point().encode(y=alt.Y('valid_acc',scale=scale, axis=alt.Axis(title='valid acc'))) + \n",
        "c.mark_line().encode(y=alt.Y('mean(valid_acc)',scale=scale)))\n",
        "\n",
        "c2=(c.mark_point().encode(y=alt.Y('tta_acc',scale=scale, axis=alt.Axis(title='valid acc (tta)'))) + \n",
        "c.mark_line().encode(y=alt.Y('mean(tta_acc)',scale=scale)))\n",
        "\n",
        "c1 | c2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tExlB_cQiADd",
        "colab_type": "text"
      },
      "source": [
        "Despite the lack of tuning of the various extra hyperparameters of the final training setup for longer runs, it appears to maintain a healthy lead over the baseline even out to 100 epochs of training and approximate convergence. The final TTA accuracy of our little 9-layer ResNet at 80 epochs is 96.1% even though we never optimised anything for training above 94% accuracy! We could presumably go quite a bit higher with proper hyperparameter optimisation. \n",
        "\n",
        "It appears that 96% accuracy is reached in about 70 epochs and 3 minutes of total training time, answering a question that I've been asked several times by people who (perhaps rightly) believe that the 94% threshold of DAWNBench is too low. Note that we have made almost no attempt to optimise the 96% time and we would expect it to come down considerably from here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXPU8vZJlgpC",
        "colab_type": "text"
      },
      "source": [
        "### Final thoughts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9qabx_UlkoN",
        "colab_type": "text"
      },
      "source": [
        "Thanks to everyone who contributed to, supported or provided feedback on the project. Special thanks to Sam Davis, to Thomas Read for his work last summer on what became the post on weight decay and to everyone at Myrtle.\n",
        "\n",
        "It has been tremendous fun working on this project, exploring dynamics of neural network training and extending the work of others to bring training times to a level where rapid experimentation becomes possible. I hope that the reader will find this useful in their work and believe that training times have a long way to fall yet (or accuracies improve if that's your thing!) through further algorithmic developments.\n",
        "\n",
        "At the outset of the series I half joked that if we could achieve 100% compute efficiency, training should take 40s. I would have been surprised to find that target surpassed by the end of the series with compute efficiency little better than it ever was! There is much scope for improvement on that front as well."
      ]
    }
  ]
}