{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CVPR2021_paper_statistics_using_chrome.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyO4xAAsQ2LmbmAKdnjHhQMm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Simon-Pu/Temp/blob/master/CVPR2021_paper_statistics_using_chrome.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hE57bWUGM-ZO"
      },
      "source": [
        "!apt-get update\n",
        "!pip install selenium\n",
        "!apt install chromium-chromedriver\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin\n",
        "import sys\n",
        "sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYSTSeHINZvz"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt \n",
        "import time\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsiW5E5FNghi"
      },
      "source": [
        "# Crawl the meta data from NeurIPS official homepage\n",
        "# Set up a browser to crawl from dynamic web pages \n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium.webdriver.common.by import By\n",
        "\n",
        "chrome_options = webdriver.ChromeOptions()\n",
        "chrome_options.add_argument('--headless')\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "wd = webdriver.Chrome('chromedriver',chrome_options=chrome_options)\n",
        "\n",
        "\n",
        "\n",
        "meta_list = [] \n",
        "wait_time = 0.5\n",
        "max_try = 1000\n",
        "\n",
        "title_list = []\n",
        "\n",
        "\n",
        "for page_name in range(168, 180):\n",
        "  # Load URL for all CVPR 2021 accepted papers.\n",
        "  wd.get(\"http://cvpr2021.thecvf.com/node/{}\".format(page_name)) #FIXME\n",
        "\n",
        "  table =  wd.find_elements_by_tag_name(\"table\") \n",
        "  print(\"length of table : \", len(table))\n",
        "\n",
        "  for i in range(len(table)):\n",
        "      tbody = table[i].find_elements_by_tag_name(\"tbody\")\n",
        "      trs = tbody[0].find_elements_by_tag_name(\"tr\")\n",
        "      \n",
        "      for j in range(1, len(trs)):\n",
        "          tds = trs[j].find_elements_by_tag_name('td')\n",
        "          print(tds[1].text)\n",
        "          title_list.append(tds[1].text)\n",
        "          #print(i+1, \"th table, \", j-1, \"th paper : \", tds[3].text)\n",
        "          #title_list.append(tds[3].text)\n",
        "\n",
        "print(\"The number of total accepted paper titles : \", len(title_list))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gG5J710qN4Et"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from collections import Counter\n",
        "\n",
        "print(stopwords.words('english'))\n",
        "\n",
        "stopwords_deep_learning = ['learning', 'network', 'neural', 'networks', 'deep', 'via', 'using', 'convolutional', 'single']\n",
        "\n",
        "keyword_list = []\n",
        "\n",
        "for i, title in enumerate(title_list):\n",
        "  \n",
        "  print(i, \"th paper's title : \", title)\n",
        "    \n",
        "  word_list = title.split(\" \")\n",
        "  word_list = list(set(word_list))\n",
        "    \n",
        "  word_list_cleaned = [] \n",
        "  for word in word_list: \n",
        "    word = word.lower()\n",
        "    if word not in stopwords.words('english') and word not in stopwords_deep_learning: #remove stopwords\n",
        "          word_list_cleaned.append(word)  \n",
        "    \n",
        "  for k in range(len(word_list_cleaned)):\n",
        "    keyword_list.append(word_list_cleaned[k])\n",
        "  \n",
        "keyword_counter = Counter(keyword_list)\n",
        "print(keyword_counter)  \n",
        "\n",
        "print('{} different keywords before merging'.format(len(keyword_counter)))\n",
        "\n",
        "# Merge duplicates: CNNs and CNN\n",
        "duplicates = []\n",
        "for k in keyword_counter:\n",
        "    if k+'s' in keyword_counter:\n",
        "        duplicates.append(k)\n",
        "for k in duplicates:\n",
        "    keyword_counter[k] += keyword_counter[k+'s']\n",
        "    del keyword_counter[k+'s']\n",
        "print('{} different keywords after merging'.format(len(keyword_counter)))\n",
        "print(keyword_counter)  \n",
        "\n",
        "print(\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31cymVvwOCw9"
      },
      "source": [
        "# Show N most common keywords and their frequencies\n",
        "num_keyowrd = 75 #FIXME\n",
        "keywords_counter_vis = keyword_counter.most_common(num_keyowrd)\n",
        "\n",
        "plt.rcdefaults()\n",
        "fig, ax = plt.subplots(figsize=(8, 18))\n",
        "\n",
        "key = [k[0] for k in keywords_counter_vis] \n",
        "value = [k[1] for k in keywords_counter_vis] \n",
        "y_pos = np.arange(len(key))\n",
        "ax.barh(y_pos, value, align='center', color='green', ecolor='black', log=True)\n",
        "ax.set_yticks(y_pos)\n",
        "ax.set_yticklabels(key, rotation=0, fontsize=10)\n",
        "ax.invert_yaxis() \n",
        "for i, v in enumerate(value):\n",
        "    ax.text(v + 3, i + .25, str(v), color='black', fontsize=10)\n",
        "ax.set_xlabel('Frequency')\n",
        "ax.set_title('CVPR 2021 Submission Top {} Keywords'.format(num_keyowrd))\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MJ5oRR_OMQz"
      },
      "source": [
        "# Show the word cloud forming by keywords\n",
        "from wordcloud import WordCloud\n",
        "wordcloud = WordCloud(max_font_size=128, max_words=160, \n",
        "                      width=1920, height=1080,\n",
        "                      background_color=\"black\").generate(' '.join(keyword_list))\n",
        "plt.figure(figsize=(32, 16))\n",
        "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
        "plt.title('CVPR 2021 Paper Keyword Statistics')\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}